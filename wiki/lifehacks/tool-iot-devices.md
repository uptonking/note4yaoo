---
title: tool-iot-devices
tags: [iot, tool]
created: 2019-08-11T07:36:17.519Z
modified: 2022-01-16T15:52:31.293Z
---

# tool-iot-devices

# watch

- ä¸ä½¿ç”¨å½•éŸ³ç¬”ï¼Œè€Œä½¿ç”¨å½•éŸ³æ‰‹è¡¨

- [æ™ºèƒ½æ‰‹è¡¨å½•éŸ³åŠŸèƒ½æ€»ç»“ - çŸ¥ä¹Ž _202212](https://zhuanlan.zhihu.com/p/592180358)
  - åŽå°
  - ç¤¾ç•œä»¬éœ€æ±‚å¾ˆç®€å• èƒ½æ¯å±ä¸€é”®å½•éŸ³ å½•åˆ°æ²¡ç”µ èƒ½åŒæ­¥åˆ°æ‰‹æœº ä¸”å¯ä»¥å¯¼å‡ºæ–‡ä»¶ æœ‰è¡€æ°§ å¿ƒçŽ‡ç›‘æŽ§ç­‰å¥åº·åŠŸèƒ½ æ‰‹è¡¨åˆ†è¿åŠ¨äº§å“çº¿å’Œå•†åŠ¡äº§å“çº¿ è´¨æ„Ÿåšåˆ°æœ€å¥½ è¿™è¡¨æˆ‘å‡º3000
  - åŽç±³gtr4 å¯å½•éŸ³ä¸”æ— æ³•é€€å‡ºå½•éŸ³ç•Œé¢ è´¨æ„Ÿå¥½
  - å°ç±³watch s1 pro åŒåŽç±³gtr4
  - ticwatch pro3å¼€å§‹å½•éŸ³åŽå¯ä»¥é€€å‡ºå½•éŸ³ç•Œé¢ æŒç»­å½•éŸ³30åˆ†é’Ÿ, é€€å‡ºåŽå±å¹•æœ‰çº¢è‰²å½•éŸ³æç¤º ä½†ä¸æ˜“è§‚å¯Ÿ åˆ‡æ¢çœç”µå±å¹•åŽçœ‹ä¸å‡ºæ¥, æ•ˆæžœè¿˜å¯ä»¥ å½•éŸ³æ–‡ä»¶å¯é€šè¿‡appåŒæ­¥åˆ°æ‰‹æœº, ä½†æ‰‹è¡¨è´¨æ„Ÿä¸€èˆ¬ è½»é£˜é£˜
  - oppo watch3å’Œ3proåŒticwatch åŒºåˆ«æ˜¯æ— æ³•å¯¼å‡ºå½•éŸ³ è´¨æ„Ÿå¥½
  - åŽä¸ºæ‰‹è¡¨å…¨ç³»æ²¡æœ‰å½•éŸ³åŠŸèƒ½, åŽä¸ºwatch5ä¸‹è½¯ä»¶å¯ä»¥å®žçŽ°å½•éŸ³äº†â€¦â€¦ä½†æ˜¯ç»­èˆªä¹Ÿå¤ªçŸ­äº†â€¦â€¦ä¸¤å¤©ä¸€å……ä¸èƒ½æŽ¥å—

- [èƒ–è¡¨å“¥å°è¯¾å ‚ï¼šAmazfit GTS4>R4æ‰‹è¡¨å½•éŸ³åŠŸèƒ½æµ‹è¯„ï¼Œèƒ½å¦æ¯å±å½•éŸ³ï¼ŸéŸ³è´¨å¦‚ä½•ï¼Ÿ_å“”å“©å“”å“©](https://www.bilibili.com/video/BV1vm4y1v7yY/)

- [åˆ†æžåŽç±³Amazfit T-Rexå’ŒGTRå¯¹æ¯”åŒºåˆ«ï¼Ÿ](http://bbs.mydigit.cn/read.php?tid=2831142)
  - GTRæ”¯æŒå½•éŸ³
  - åŠŸèƒ½æ˜¯ä¸€æ ·çš„ï¼Œå°±æ˜¯å¤–è§‚ä¸åŒçš„ï¼Œæˆ‘è‡ªå·±ä¹Ÿæ˜¯æ‰è´­çš„ï¼Œæ–°å“trexçš„ï¼Œæ ·å¼å¾ˆä¸é”™ï¼Œå¾ˆè¿åŠ¨çš„æ„Ÿè§‰

- [æ•™ä½ å°†OPPO Watch X/X2 å˜ä¸ºéšæ—¶ä¸€é”®å½•éŸ³ç¬” æ— éœ€è§¦æŽ§å¯åŠ¨ è¶…éšè”½_å“”å“©å“”å“© ](https://www.bilibili.com/video/BV1eE421M7gJ/)
  - å·²æŽ¨å‡ºå¯åŠ¨å½•éŸ³è‡ªåŠ¨æ¯å±ç‰ˆæœ¬ï¼Œå¯åŠ¨å½•éŸ³è‡ªåŠ¨æ¯å±ï¼Œéšè”½æ€§æ›´é«˜
  - éœ€è¦ä½¿ç”¨adbç­‰æ–¹å¼æŠŠè¿™ä¸ªappè£…åˆ°æ‰‹è¡¨ä¸Šï¼Œç„¶åŽç»‘å®šæŒ‰é”®å¯åŠ¨è¿™ä¸ªappï¼Œå°±ä¼šç«‹åˆ»å¯åŠ¨æ‰‹è¡¨è‡ªå¸¦çš„å½•éŸ³appå¹¶å¼€å§‹å½•éŸ³ï¼Œå…¨ç¨‹æ— éœ€ç‚¹å‡»æ‰‹è¡¨ï¼Œæ¯å±ä¹Ÿå¯ç”¨
  - åŽä¸ºæ‰‹è¡¨å•†åŸŽçŽ°æœ‰çš„ä¸€ä¸ªç¬¬ä¸‰æ–¹å½•éŸ³è½¯ä»¶ï¼Œå½•éŸ³æ–‡ä»¶éƒ½ä¸èƒ½ä¸Šä¼ åˆ°æ‰‹æœºï¼Œè€Œä¸”åšä¸åˆ°ç†„å±å½•éŸ³
  - OPPO watch 3pro å¯ä»¥ç”¨
  - åº—å‘˜è¯´è¿™ä¸ªå½•éŸ³32Gçš„åªèƒ½å½•2ä¸ªå°æ—¶å°±æ»¡äº†ã€‚è¿˜æ˜¯ä¸å¤ªå®žç”¨
  - ä¸å¯èƒ½ï¼Œæˆ‘æ‰‹æœºå½•ä¸¤ä¸ªå°æ—¶ä¹Ÿæ‰å‡ ä¸ªgè€Œå·²
  - äº²æµ‹ï¼Œ2å°æ—¶ä¼šè‡ªåŠ¨æ–­ã€‚åŽé¢çš„éƒ½æ²¡å½•ä¸Šã€‚ä¸è¿‡è¯è¯´å›žæ¥ï¼Œå½•çš„æ•ˆæžœä¹Ÿå¤ªå·®äº†ï¼ŒèŠèƒœäºŽæ— ï¼Œè¿œä¸ä¸ä¸ŠApplewatch.
  - æŽ¨èæ‰‹æœºä½¿ç”¨Hi-Q MP3 Recorderï¼Œæ”¯æŒæ‰“å¼€å³å½•éŸ³ï¼Œæ”¯æŒå¤šç§å½•éŸ³æ ¼å¼ï¼Œå¯ä»¥è®¾å®šå‰©ä½™å¤šå¤§å†…å­˜è‡ªåŠ¨å…³åœ
# Uç›˜
- Uç›˜çš„ä¼˜ç‚¹ä¸»è¦åœ¨äºŽï¼Œ
  - Uç›˜çš„ä½¿ç”¨ä¸éœ€è¦ä¾èµ–ç½‘ç»œï¼Œ
  - å¹¶ä¸”Uç›˜èƒ½å¤Ÿä¿æŠ¤ç”¨æˆ·çš„éšç§å’Œæ•°æ®å®‰å…¨ã€‚
  - å¦å¤–ï¼Œå°†ç”µè„‘æ–‡ä»¶ä»Žæœ¬åœ°ä¸Šä¼ è‡³Uç›˜çš„ä¼ è¾“é€Ÿåº¦å¾ˆå¿«ã€‚
- Uç›˜çš„ä¸»è¦ç¼ºç‚¹åœ¨äºŽï¼Œ
  - ä»·æ ¼å¯èƒ½ç›¸å¯¹æ˜‚è´µï¼Œèƒ½å¤Ÿå‚¨å­˜çš„æ•°æ®å®¹é‡æœ‰é™ï¼Œé€šå¸¸ä»¥GBä¸ºå•ä½ã€‚
  - æ­¤å¤–ï¼ŒUç›˜ä½œä¸ºä¸€ä¸ªç‰©ç†ç¡¬ä»¶å®¹æ˜“è¢«ä¸¢å¤±ï¼ŒUç›˜ä¸­çš„æ–‡ä»¶ä¹Ÿæ²¡åŠžæ³•éšç€æœ¬åœ°æ–‡ä»¶ä¿®æ”¹è¿›åº¦è€Œè¿›è¡Œå®žæ—¶æ›´æ–°ã€‚
  - Uç›˜é—´è¿›è¡Œæ•°æ®ä¼ è¾“ä¹Ÿæ¯”è¾ƒéº»çƒ¦ã€‚
- äº‘ç›˜çš„ä¼˜ç‚¹åœ¨äºŽï¼Œ
  - ç”¨æˆ·é€šå¸¸å¯ä»¥å…è´¹ä½“éªŒäº‘ç›˜æ‰€å¸¦æ¥çš„æœåŠ¡ã€‚
  - äº‘ç›˜èƒ½å¤Ÿæä¾›è¾ƒå¤§çš„æ•°æ®å®¹é‡ï¼Œé€šå¸¸ä»¥Tä¸ºå•ä½ã€‚
  - äº‘ç›˜ä¸­çš„æ–‡ä»¶å¯ä»¥ä¸Žç”µè„‘ä¸­ä¿å­˜çš„æœ¬åœ°æ–‡ä»¶è¿›è¡Œå®žæ—¶åŒæ­¥ã€‚ï¼ˆå¾®è½¯çš„OneDriveå’Œç™¾åº¦äº‘éƒ½æ˜¯å¾ˆå¥½çš„ä¾‹å­ï¼‰
  - äº‘ç›˜ä¹‹é—´æƒ³è¦ä¼ è¾“æ–‡ä»¶ä¹Ÿä¼šç›¸å¯¹ä¾¿æ·ã€‚äº‘ç›˜ä¹Ÿä¼šå¸¦æœ‰ä¸€å®šçš„ç½‘ç»œç¤¾äº¤å±žæ€§ã€‚
- äº‘ç›˜çš„ç¼ºç‚¹åœ¨äºŽï¼Œ
  - äº‘ç›˜çš„ä½¿ç”¨éœ€è¦ä¾èµ–äºŽç½‘ç»œï¼Œå¹¶ä¸”å¤„äºŽæŸäº›åŽŸå› å‚¨å­˜åœ¨äº‘ç›˜ä¸­çš„æ–‡ä»¶ä¼šè¢«ç¬¬ä¸‰æ–¹æŸ¥é˜…ã€ä¿®æ”¹æˆ–è€…åˆ é™¤ã€‚
  - è¿™æ ·å°±ä¼šå¯¼è‡´äº‘ç›˜ç”¨æˆ·çš„ä¸ªäººéšç§å’Œæ•°æ®å®‰å…¨å¾—ä¸åˆ°ä¿éšœã€‚
  - æ–‡ä»¶ä¸Šä¼ è‡³äº‘ç›˜çš„é€Ÿåº¦è¿˜ä¼šå—åˆ°ç½‘é€Ÿçš„é™åˆ¶ã€‚
# screen resolution
- guide
  - é™¤äº†åˆ†è¾¨çŽ‡ï¼Œè¿˜è¦è€ƒè™‘ä½¿ç”¨åœºæ™¯ï¼Œå¦‚ç³»ç»Ÿåˆ†å±ã€å¤šçª—å£æŽ’åˆ—
  - è¿˜è¦è€ƒè™‘æŒç»­æ›´æ–°ã€æ¶ˆè´¹çš„èƒ½åŠ›
  - [Screen Resolution Stats Worldwide](https://gs.statcounter.com/screen-resolution-stats)

- android
  - ldpi: 240x320, 240x432
  - mdpi: 320x480, 480x800, 480x854, 1024x600, 1280x800
  - hdpi: 480x800
  - xhdpi: 720x1280, 1200x1290, 2560x1600
  - xxhdpi: 1080x1920
  - tvdpi: 1280x800
- [Screen sizes and densities](https://developer.android.com/about/dashboards/index.html)
  - ldpi/0.001, mdpi/0.062, tvdpi/0.027, hdpi/0.179, xhdpi/0.45, xxhdpi/0.281

- desktop
  - **1920x1080**/0.215, 1366x768/0.201, 1536x864/0.096, 1440x900/0.064, 1280x720/0.054, 1600x900/0.036

- mobile
  - 360x640/0.106, 414x896/0.072, 360x780/0.057
# android
- vulkan version
  - none: 0.42
  - v1.03: 0.22
  - v1.1: 0.36

- opengel es version
  - v2.0: 0.105
  - v3.0: 0.141
  - v3.1: 0.079
  - v3.2: 0.675
# è®¾å¤‡ä½¿ç”¨é—®é¢˜
- å¼ºåˆ¶å…¨å®¶æ¡¶
- æ‰‹æœºç®¡å®¶/å®‰å…¨ç®¡å®¶
- æŽ¨é€æ¶ˆæ¯å¤ªå¤š
- éšç§æ•°æ®
# laptop-ç¬”è®°æœ¬
- è¦ç‚¹
  - é”®ç›˜çš„ä¸Šä¸‹å·¦å³4ä¸ªæ–¹å‘é”®è¦å¤§å°ç›¸åŒ
# Fuchsia OS

# é˜¿é‡ŒYunOS/AliOS

- 2011å¹´7æœˆ28æ—¥ï¼Œé˜¿é‡Œå·´å·´æ­£å¼æŽ¨å‡ºYunOSï¼ŒåŸºäºŽlinux kernelï¼Œè®¾è®¡å€Ÿé‰´äº†Android
- YunOSå…¼å®¹Androidåº”ç”¨ï¼ŒYunOSçš„è™šæ‹Ÿæœºè¿˜æ˜¯Dalvikè™šæ‹Ÿæœºä¿®æ”¹ç‰ˆ
- é­…æ—æ”¯æŒè¿‡YunOSï¼Œä½†åšæŒä½¿ç”¨é­…æ—UIï¼Œåœ¨ä¸€ä¸ªå•†ä¸šåŒ–çš„æ“ä½œç³»ç»Ÿä¸­ï¼Œæ ¸å¿ƒå±‚å¹¶ä¸æ ¸å¿ƒ
- YunOSåº”ç”¨åœ¨ç”µè§†ç›’å­ä¸ŠåŽç§è‡ªåˆ é™¤ç”¨æˆ·è½¯ä»¶ï¼Œå¼ºè¿«ä½¿ç”¨YunOSè‡ªå¸¦è½¯ä»¶
- æ”¹åä¸ºAliOSåŽä¸“æ³¨äºŽæ±½è½¦ï¼Œä¸ŽandroidåŒºåˆ«è¶Šæ¥è¶Šå¤§ï¼Œlinuxå†…æ ¸+è¿è¡Œåº“
# åŽä¸ºHarmonyOSé¸¿è’™ç³»ç»Ÿ
- ç‰¹ç‚¹ï¼šåˆ†å¸ƒæž¶æž„ã€é«˜æ€§èƒ½ã€å†…æ ¸å®‰å…¨ã€ç”Ÿæ€å…±äº«ã€å¼€æº
# discuss-tv
- å‚æ•°é…ç½®
  - å°ºå¯¸
  - å±å¹•æŠ€æœ¯
  - åˆ†è¾¨çŽ‡
  - åˆ·æ–°çŽ‡
  - äº®åº¦
  - è‰²åŸŸ
  - CPU
  - RAM
  - è¾¹æ¡†

- ## 

- ## [äº’è”ç½‘ç”µè§†ä¸èƒ½è£…ç½‘ç»œæµè§ˆå™¨â€¦ä¹Ÿæ˜¯é†‰äº† - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/6700c411000000001a0223db?xsec_token=ABoe1ug9YJJDbnOMEN4Q6C0fZ0dK1qg9_RVKDLAdWF5b8=&xsec_source=pc_search&source=web_explore_feed)
- æ³•è§„è¦æ±‚ï¼Œç”µè§†ä¸Šçš„å†…å®¹å¿…é¡»ç®¡èµ·æ¥ï¼Œæµè§ˆå™¨ä¸Šçš„å†…å®¹ç®¡ä¸äº†ï¼Œä¸è®©è£…ã€‚

- ## [Why Chrome browser is not available on Android TV (Google TV)? : r/AndroidTV _202304](https://www.reddit.com/r/AndroidTV/comments/12yc3mi/why_chrome_browser_is_not_available_on_android_tv/)
- I don't know the reason but TV Bro does a great job instead.

- Google doesn't think you need to browse the web in your TV. That's just for consuming media.

- Mozilla used to have a Firefox for Fire TV (and then generic ATV) but they killed that years ago as well.
  - firefox continues to work on ATV but it requires a mouse to operate correctly.

- ## [å°ç±³ç”µè§†ä¸ç”¨æŒ‚å¢™ï¼Œå°±è£…ä¸ªåº•åº§ä¸ºå•¥è¿˜è¦å®‰è£…è´¹ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/686c7ba7000000000b02db9e?xsec_token=ABL7n_fleKY2d2yJ0Kl5bHj7o_Vw4sUjrEkqzyYIDNIto=&xsec_source=pc_search&source=web_explore_feed)
- å°±æ‹§å››é¢—èžºä¸è¿™ä¹ˆç®€å•ï¼Œä½•é¡»èŠ±50å—ï¼Œè‡ªå·±è£…ä¸å°±è¡Œäº†å—ï¼Ÿ

- å…¶å®žå®‰è£…å¾ˆç®€å•ï¼Œå°±æ˜¯ç”µè§†å¤ªå¤§äº†è¦ä¸¤ä¸ªäººè£…

- é¦–å…ˆå†ç®€å•ä¹Ÿè¦æ—¶é—´æˆæœ¬ã€‚å…¶æ¬¡åªè¦è¿‡æ‰‹äº†å°±ä¼šæœ‰é£Žé™©ã€‚

- ## [å°ç±³ç”µè§†æ²¡æ³•è£…ç¬¬ä¸‰æ–¹è½¯ä»¶ï¼Ÿçœ‹è¿™é‡Œï¼ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/6885f1cc000000001c037e3d?xsec_token=ABFqR2NYsx0tMZ2_1jW9XRC31wt0kSyS-GYe02iCV-ca8=&xsec_source=pc_search&source=web_explore_feed)
- å°ç±³ç”µè§†å®‰è£…ç¬¬ä¸‰æ–¹è½¯ä»¶ç¬¬ä¸€æ­¥ï¼Œç”µè§†æ¢å¤å‡ºåŽ‚è®¾ç½®ã€‚è¿™ä¸€æ­¥æ˜¯ä¸ºäº†æ¸…é™¤ç”µè§†å†…çš„appé»‘åå•ã€‚
  - æ¢å¤å‡ºåŽ‚è®¾ç½®åŽç”µè§†é‡å¯ï¼Œè¿›å…¥æ–°ç”µè§†è®¾ç½®é˜¶æ®µï¼Œä¸€å®šä¸è¦è”ç½‘ï¼Œè·³è¿‡WiFiæ— çº¿ç½‘ç»œé€‰æ‹©ã€‚ä¿æŒæ–­ç½‘çš„çŠ¶æ€å°±ä¸ä¼šæ›´æ–°é»‘åå•ã€‚
  - æ‰“å¼€ç”µè§†çš„è®¾ç½®-è´¦å·ä¸Žå®‰å…¨-é€‰æ‹©å…è®¸å®‰è£…æœªçŸ¥æ¥æºçš„åº”ç”¨ã€‚
  - å®‰è£…éœ€è¦çš„APPï¼šå°†ä¸‹è½½å¥½çš„appçš„apkæ–‡ä»¶æ‹·è´åˆ°Uç›˜ï¼ŒæŠŠUç›˜æ’å…¥ç”µè§†çš„USBæŽ¥å£ï¼Œæ‰“å¼€Uç›˜ã€‚æ‰¾åˆ°APKæ–‡ä»¶ï¼Œç‚¹å‡»ç¡®å®šè¿›è¡Œå®‰è£…å³å¯ã€‚å¼¹çª—æç¤ºå¯èƒ½å­˜åœ¨æœªçŸ¥é£Žé™©ï¼Œé€‰æ‹©ç»§ç»­å®‰è£…ã€‚è½¯ä»¶å®‰è£…æˆåŠŸã€‚

- ## [çº¢ç±³ç”µè§†è§£å†³åº•åº§èžºä¸éš¾æ‹§çš„å°æŠ€å·§ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/6794beb00000000029032fe0?xsec_token=ABvhnSCS5ukgPATsbc3yLg8-KBvtXyfeWGHlUGivnnbQQ=&xsec_source=pc_search&source=web_explore_feed)
  - åˆšä¹°äº†ä¸ªçº¢ç±³ç”µè§†, å®¶é‡Œäººè¯´åº•åº§è£…ä¸ä¸Š, æŸ¥äº†ç½‘ä¸Šå¾ˆå¤šäººè¯´èžºä¸éš¾æ‹§
  - å…¶å®žåªè¦è£…æ”¯æž¶å‰èžºä¸å…ˆæ‹§è¿›å­”é‡Œå†æ‹§å‡ºæ¥ï¼Œä¹‹åŽå®‰è£…å°±å¾ˆç®€å•äº†
- å°±æ˜¯å…ˆä¸å¸¦æž¶å­å•ç‹¬æ‹§ä¸€éèžºä¸ï¼Œç„¶åŽèžºä¸æ‹¿å‡ºæ¥ä¹‹åŽå†é‡æ–°å®‰æž¶å­ä¸ï¼Ÿ
  - å¯¹ï¼Œæ‹§çš„æ—¶å€™å°å¿ƒç‚¹ï¼Œç”¨å·§åŠ²åˆ«æ­»æ‘
- å…ˆåˆ«è£…æ”¯æž¶ï¼ŒæŠŠå­”æ‹§æ¾

- ## [çº¢ç±³ç”µè§†aproç³»åˆ—å’Œaç³»åˆ—æœ‰ä»€ä¹ˆåŒºåˆ«ï¼ŸRedmi A55 Proå’Œa55 2025æ¬¾æ€Žä¹ˆé€‰ï¼Ÿ - çŸ¥ä¹Ž](https://zhuanlan.zhihu.com/p/721352900)
- å¤„ç†å™¨
  - çº¢ç±³a55proï¼šå››æ ¸A55ã€3GB+64GB
  - çº¢ç±³a55 2025æ¬¾ï¼šå››æ ¸A35ã€2GB+32GB

- çº¢ç±³a55proé‡‡ç”¨NFCé¥æŽ§å™¨ï¼Œæ”¯æŒä¸€è§¦æŠ•å±ï¼›çº¢ç±³a55 2025æ¬¾é‡‡ç”¨çš„æ˜¯çº¢å¤–é¥æŽ§å™¨ã€‚

- çº¢ç±³a55proæ”¯æŒ2.4G&5GåŒé¢‘wifiï¼Œçº¢ç±³a55 2025æ¬¾æ”¯æŒ2.4Gï¼Œçº¢ç±³a55proç½‘é€Ÿæ›´ç¨³å®šã€‚

- [å°ç±³ç”µè§†redmi A55å’Œå°ç±³ç”µè§†redmi X50å“ªä¸ªå¥½ä¸€ç‚¹ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/466093554)
  - å‚æ•°å¯¹æ¯”å›¾

- ## [ä¸ºä»€ä¹ˆå°ç±³ç”µè§†çªç„¶å°±æ²¡äººå…³æ³¨äº†ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/662395651)
- ç”µè§†æœºä¸‹ä¸€ä»£æ‰“æ³•åº”è¯¥æ˜¯å–65 75å¯¸çš„æ˜¾ç¤ºå™¨ï¼Œä¸å¸¦ä»»ä½•å†…å®¹åŠŸèƒ½ï¼Œä»…æä¾›å¤–æŽ¥æŽ¥å£ï¼Œæ­¤æ—¶åˆè§„å®¡æŸ¥çš„ä»»åŠ¡å°±ä¼šè½åˆ°ç”µè§†ç›’å­è¿™ä¸ªä¸œè¥¿ä¸Šé¢ã€‚

- ä¸æ˜¯å°ç±³ç”µè§†æ²¡äººå…³æ³¨äº†ï¼Œæ˜¯æ•´ä¸ªç”µè§†è¡Œä¸šéƒ½é»„äº†è€Œå·²ï¼Œå„ç§ä¼šå‘˜æ”¶è´¹åŸºæœ¬æŠŠç”µè§†è¿™ä¸ªè¡Œä¸šæžæ®‹åºŸäº†ã€‚
- å®¢åŽ…çš„ç”µè§†ï¼Œä¿©æœˆæ²¡æ‰“å¼€äº†ï¼Œæµªè´¹ç©ºé—´

- å°ç±³ç”µè§†èˆ†è®ºæœ€ç«çš„æ—¶å€™, æ˜¯åŽä¸ºå’Œè£è€€è¦è¿›å†›â€œæ™ºæ…§å±â€å‰åŽ, çŽ°åœ¨è¿™æ‘Šä¸šåŠ¡æ²¡ä¸‹æ–‡äº†ï¼Œå°ç±³ç”µè§†ä¹Ÿå°±æ²¡å•¥å£°é‡äº†ã€‚
- å› ä¸ºæ™ºæ…§å±é”€é‡åªæœ‰å°ç±³ç”µè§†é”€é‡çš„é›¶å¤´ï¼ŒèŠ±ç²‰å’Œæ°´å†›ä»¬æ”¾å¼ƒè¿™ä¸ªé˜µåœ°äº†ï¼Œç›®å‰é›†ç«çš„æ˜¯å°ç±³æ±½è½¦

- åˆ«å®¶ä»Šå¹´çš„é«˜ç«¯ï¼š4000nitäº®åº¦ï¼Œ4000åˆ†åŒºèƒŒå…‰ï¼Œé‡å­ç‚¹å¹¿è‰²åŸŸï¼Œé»‘è€€å±ã€‚ 
  - å°ç±³ä»Šå¹´çš„é«˜ç«¯ï¼šçœ‹ä»€ä¹ˆçœ‹ï¼Œè¿˜æ²¡å‡ºå‘¢ã€‚
- åœ¨ç­‰ä¾›åº”é“¾æˆç†Ÿè´´ç‰Œå‘¢

- å°ç±³ä»Šå¹´æœ‰äº›æ‘†çƒ‚ï¼ŒåŠå¹´è¿‡åŽ»äº†æ‰å‡ºäº†ä¸€ä¸ªS Mini LEDç³»åˆ—ã€‚åˆ«å®¶éƒ½åœ¨æžæœºæµ·äº†

- æ›¾ç»ä»»èŒäºŽå€’é—­äº’è”ç½‘ç”µè§†æœºå“ç‰Œå¾®é²¸ã€‚æ‹†è¿‡å„ä¸ªç«žå“äº’è”ç½‘å“ç‰Œï¼Œå°ç±³æ€Žä¹ˆè¯´å‘¢ã€‚ç”¨æ–™å±žäºŽè¿˜è¡Œï¼Œä½†æ˜¯å¹¶éžæœ€å¥½ã€‚
  - ä»¥16å¹´çš„äº§å“ç”¨æ–™æ¥çœ‹ã€‚å½“å¹´æœ€å¥½çš„å…¶å®žæ˜¯ä¹è§†å’Œå¾®é²¸ï¼Œå°ç±³Aç³»åˆ—å°±å·®äº†ä¸å°‘ï¼Œè¿žå¤–æ¡†åŽç›–éƒ½ä¸èˆå¾—é…äº†ï¼Œç›´æŽ¥è£¸å¥”ä¸Šå¸‚pptv, æš´é£Žï¼Œé£Žè¡Œå°±æ›´ç³Ÿç³•äº†ã€‚
  - 17å¹´ï¼Œäº’è”ç½‘ç”µè§†å“ç‰Œå‡ºçŽ°äº†é—®é¢˜ï¼Œé’±çƒ§å…‰ï¼Œä¼ ç»Ÿå“ç‰Œç­‰ç€è¿™ç¬”çƒ­é’±çƒ§å®Œï¼Œå¼€å§‹å›žæ¥æ”¶å‰²å¸‚åœºäº†ã€‚è¿™é‡Œé¢é›·é¸Ÿä¾é è‡ªå·±åŽæ˜Ÿå…‰çš„é¢æ¿èµ„æºå’ŒTCLçš„è§„æ¨¡ä¼˜åŠ¿ï¼Œä»¥åŠè½¯ä»¶è¿è¥æ–¹é¢ç›´æŽ¥ç”¨TCLç³»ç»ŸæŠŠç ”å‘æˆæœ¬æ‘Šå¹³ï¼Œç‰©æµå”®åŽæ–¹é¢å®Œå…¨å¯ä»¥å…±ç”¨TCLæ¯å“ç‰Œçš„èµ„æºã€‚è¿œæ¯”å°ç±³çš„æˆæœ¬ä¼˜åŠ¿æ˜Žæ˜¾ã€‚å¯¹å°ç±³æ¥è¯´ï¼Œç”µè§†ä¸šåŠ¡æ˜¯è¡¥è¶³è‡ªå·±å…¨å±‹æ™ºèƒ½çš„æ‹¼æ¿ï¼Œå¯ä»¥ä¸èµšé’±ï¼Œä½†ç»å¯¹ä¸ä¼šä¸ºäº†è¿™ä¸ªä¸šåŠ¡æŠ•é’±ã€‚å› æ­¤æ€§ä»·æ¯”ä¼˜åŠ¿ä¹Ÿå°±æ²¡æœ‰äº†

- å°ç±³ç”µè§†ä¸»æ‰“çš„è¿˜æ˜¯ä½Žä»·å’Œç±³å®¶ç”Ÿæ€ï¼Œ2021å¹´ä¸‹åŠå¹´å¼€å§‹ï¼Œå°ç±³ç”µè§†è¢«é›·é¸Ÿç”µè§†é’ˆå¯¹ï¼Œç«žäº‰æ¯”è¾ƒæ¿€çƒˆ
# discuss-screen
- ## 

- ## 

- ## [ä¸ºä»€ä¹ˆçŽ°åœ¨çš„æ™ºèƒ½æ‰‹æœºä¸ä½¿ç”¨åŠååŠé€æŠ€æœ¯çš„æ˜¾ç¤ºå±ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/264049308)
- åŠååŠé€çš„å¥½å¤„å°±æ˜¯ä¿æŒå½©è‰²å±å¹•å’Œé˜³å…‰ä¸‹å¯è¯»æ€§çš„åŒæ—¶è¿˜èƒ½åšåˆ°çœç”µã€‚ä¸è¿‡è¿™ç§å±å¹•è‰²å½©è¿˜åŽŸæ€§ä¸æ˜¯å¾ˆå¥½ï¼Œè¿™ç§å±å¹•çœ‹ä¸ªç®€å•çš„å›¾å½¢æˆ–è€…æ•°å­—æ–‡å­—è¿˜è¡Œï¼Œè¦æ˜¯çœ‹å›¾ç‰‡è§†é¢‘äº†å°±ä¸èˆ’æœäº†ï¼Œè‰²å½©è¿˜åŽŸä¸å¥½ã€‚

- æˆ‘æƒ³æ˜¯å¤§é‡ç”Ÿäº§é—®é¢˜ï¼Œå§‹ç»ˆæ˜¯å°‘ä¼—ï¼Œäººä»¬éƒ½ä¹ æƒ¯äº†èƒŒå…‰ï¼ŒèƒŒé€åœ¨å½©è‰²æ˜¾ç¤ºä¸Šå·®å¼ºäººæ„ï¼Œæ‰€ä»¥æœ‰äº›æ™‚åœ¨æ²’èƒŒå…‰ä¸‹æœƒä½¿ç”¨AMBRITEï¼ˆè™Žç€ï¼‰/é»‘ç™½æ¨¡å¼ï¼Œåœ¨æ™šé—´æˆ–ç¨æš—æ—¶æ˜¯ä¸æ–¹ä¾¿å’Œå°´å°¬çš„ï¼Œçœäº†ç‚¹ç”µä½†æ¢æ¥ä¸ä¾¿ï¼ŒçŽ°åœ¨å¤šä½¿ç”¨åœ¨å°‘ç”µçš„ç©¿æˆ´äº§å“ã€‚

- [åŠé€åå°„å¼TFTæ¶²æ™¶å±ä¸ºä½•æ²¡æœ‰æµè¡Œï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/20807503/answers/updated)
  - è¿™ç§å±å¹•çŽ°åœ¨é™¤äº†ä¸€äº›ä¸“ä¸šçš„æˆ·å¤–å™¨æï¼ˆä¾‹å¦‚è¿åŠ¨æ‰‹è¡¨å•¥çš„ï¼‰ä¸Šæœ‰ç”¨ï¼Œå·²ç»ç¦»å¤§ä¼—è¶Šæ¥è¶Šè¿œäº†ï¼Œä¹Ÿç®—æ˜¯æ—¶ä»£çš„çœ¼æ³ªäº†ã€‚
# discuss-ai/ml-hardware
- ## 

- ## 

- ## ç­‰è¿™æ³¢AIæ³¡æ²«ç ´è£‚ï¼Œæˆ‘éƒ½ä¸æ•¢æƒ³ä¼šæœ‰å¤šå°‘ä¸‹æž¶çš„æœåŠ¡å™¨ç¡¬ä»¶ä¼šå†²å‡»åžƒåœ¾ä½¬å¸‚åœºã€‚æ“æ‰‹ç­‰å¾…
- https://x.com/riaqn_zh/status/2004907309336875298
- â€œæˆ‘å…„å¼Ÿåœ¨ç­‰æˆ¿ä»·å´©ç›˜â€
  - æ²¡é‚£ä¹ˆå¿«ï¼Œä½ çœ‹22å¹´è¿˜æœ‰ä¸€æ³¢æš´æ¶¨å‘¢ã€‚

- ä¸ç”¨å¤ªä¹…ï¼ŒæœåŠ¡å™¨ä¼šæŠŠæ—§ç¡¬ä»¶æ·˜æ±°çš„ï¼Œå¤§åŽ‚ä¸å·®é’±ï¼Œè€Œä¸”ä¼šä¸»åŠ¨è¿½æ±‚æœ€æ–°æ˜¾å¡ï¼Œå³ä½¿ä¸ç ´è£‚ä¹Ÿèƒ½æ¡åˆ°ç¡¬ä»¶
- ä¸ç”¨ç ´è£‚ï¼Œå¾ˆå¤šæ•°æ®ä¸­å¿ƒçš„æœåŠ¡å™¨2-3å¹´å°±æ·˜æ±°äº†

- è¿™æ¬¡çš„æ³¡æ²«å¯ä¸åƒæˆ¿åœ°äº§å’Œå…ƒå®‡å®™å‘€ã€‚å¦‚æžœçœŸçš„ç®—åŠ›è¶³å¤Ÿï¼Œæ˜¯å¯ä»¥ä»Žåº•å±‚æ•™è‚²åˆ°ç”Ÿæ´»çš„å„ç§æ–¹é¢éƒ½å¯ä»¥æ”¹é©ã€‚å°±è¦çœ‹è°æŠŠè›‹ç³•ç”»å¤§è¿˜å®žçŽ°å®ƒã€‚

- ## [Would a Ryzen AI Max+ 395 benefit from dedicated GPU? : r/LocalLLaMA _202512](https://www.reddit.com/r/LocalLLaMA/comments/1ps2cjk/would_a_ryzen_ai_max_395_benefit_from_dedicated/)
  - I just ordered a Framework desktop motherboard, first time I will have some hardware that let me play with some local AI.
  - The motherboard has a 4x pci express port, so with an adapter I could put a gpu on it.
  - I was wondering if it would benefit from a dedicated GPU like a 5060 or 5070 ti (or should it be an AMD GPU?)?

- The 395 combined with the 128 GB of memory is a somewhat affortable System for use of "large" LLMs. It isn't the fasted, but it is a compromise and gets more t/s than LLMs larger than the VRAM of a regular GPU.
  - A GPU combined with a 395 makes no real sense to me, except if you have a mix of models were some fit into the GPU VRAM. A real upgrade would be a GPU with similar sized VRAM than the 395 like a RTX 6000.

- I guess an 395 together with an 5090 could be currently the best AI machine when it comes to cost and power consumption. It should do well with LLM (395 brings the RAM and the 5090 is a very capable extension) as well as with image generation tasks (5090 in lead, 395 is just the host). But at least the Framework case doesn't support it.
  - The 5090 is limited to the 32 GB VRAM onboard. The performance advantage of the 5090 is lost by communication overhead.
- Only when you have something communication heavy. When it's fitting in the 32 GB, like most text2image models, it'll work very well.

- ## ðŸ†š [Studio + Air combo vs MacBook Pro : r/MacStudio _202512](https://www.reddit.com/r/MacStudio/comments/1pfl6hk/studio_air_combo_vs_macbook_pro/)
- I used to have a MBP for my work and travel machine. After three years I realized I had it docked 90% of the time as I didnâ€™t like taking it when I traveled so I got a cheap M2 Air for travel. 
  - In August of this year I moved to an M4 Max Studio plus M4 Air (24/512 version) combo. I donâ€™t need heavy lifting when I travel so the Air meets all my needs. Most of my computing is done on my Studio. 
  - For me, itâ€™s worked out great. The Studio is awesome and I have everything synced to my Air with my NAS and iCloud. I have a nice and small Crucial 4TB external SSD hooked up to my Studio for large files and projects, and when I travel I just take it with me. 

- Im going back and forth with the same question for years now and after quite a few MacBooks running as a main machine, Iâ€™d gladly stay with faster desktop and laptop you donâ€™t need to care about.
  - Price to performance with desktop
  - Better cooling
  - Better longevity
  - and better workflow for your mind - now you have one work machine and other one for private use (and sometimes work related). Less time spend in front of main, work computer means less distractions when doing work. If you work and have fun with the same machine itâ€™s pretty hard to differentiate work from having fun, which leads to burnout and other issues.

- Iâ€™ve used Mac laptops exclusively since 1993, and MacBook Pros exclusively since 2012. I bought a Mac Studio M3 Ultra base model this summer and, when my MacBook Pro died, I replaced it with the base model M4 MacBook Air.
  - One thing I havenâ€™t really worked out yet is syncing the two machines. Iâ€™ve been meaning to try ChronoSync and its Agent application and have the trials downloaded. For now I just make sure I have the files I need on the Air. I think itâ€™s a great combination.

- Performance wise, the M4 Max Mac Studio and MacBook Pros can both be configured identically, though the M4 Max in the MacBook (especially the 14â€) can thermal throttle, whereas the Studio has more robust cooling. Ultimately the right choice for you will depend on how you prefer to work.

- I have this exact setup. 16GB M1 Air and a 64GB M4 Max. But the air is more of personal computer, I don't try to sync them. I use Rust Desk to phone into the studio with varying degrees of success.

- ## [AMD 395+ and NVIDIA GPU : r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/comments/1p9dier/amd_395_and_nvidia_gpu/)
  - Is there any reason I canâ€™t put an NVIDIA GPU in an AMD 395+ machine?
- It works fine simultaneously, several of us have done it
- Nvidia dGPUs work better in the Strix Halo than do either Intel or AMD, apparently.

- Is there a 395+ machine that you can fit an Nvidia GPU in?
  - I'm looking into doing it with a Framework Desktop motherboard, which is mITX sized.

- Physical space, cooling, power would be the first 3 problems...
  - External GPU docks exist

- NVIDIA GPUs work fine on 395 platform as long as you can put them together physically (with M.2 to PCIe adapters or 395 boards with standard PCIe slots). AMD dGPUs may be more problematic due to VBIOS compatibility issues.

- ## [Need some honest opinions on GPU Ai in a box : r/ollama](https://www.reddit.com/r/ollama/comments/1p4z140/need_some_honest_opinions_on_gpu_ai_in_a_box/)
  - For my use case my models and software burn about $2000 per month if I rent a pod using runpod and I have to be extra careful due to rate limits. I want to consider running my models using llamacpp or ollama or offering direct inference for customer using their own on prem machine shipped by me.

- The DGX Spark and similar are not meant to be servers. Could you use them? I guess. But for 8b models you donâ€™t need $3000 of anything. At full 16bit youâ€™d need 16GB of memory plus some context. 24GB tops. Less with quants.
  - And donâ€™t deploy with llama.cpp based anything. Those are personal use tools. Use vLLM, SGLang or TensorRT.
- Why canâ€™t you use it as a server? Is it only for inference via vLLM?
  - tldr the ones I mentioned are built for production and high parallel work loads.

- Have you tried your models on various Mac minis or studios? Very stable and speedy enough.
  - Yes i run my models on Mac mini m4 but running multiple models at the same time is a pain

- ## ðŸ  [Most Economical Way to Run GPT-OSS-120B for ~10 Users : r/LocalLLaMA _202511](https://www.reddit.com/r/LocalLLaMA/comments/1p4evyr/most_economical_way_to_run_gptoss120b_for_10_users/)
- A quad of 3090s will get you there cheapest, assuming you have a way of mounting four 3-slot GPUs in a reasonably secure manner! Itâ€™s probably going to need a bunch of PCIe riser cables and a mining frame to accommodate the space, noise and cooling requirementsâ€¦ youâ€™d have 1500W of GPU alone!

- 4x 3090 with vLLM

- What's your use case? Are you running documents through it (RAG)? or just Q&A to the base model?
  - If its the latter, you mainly need something with sufficient VARM. As once the model its loaded in VRAM it can server multiple users. I'm running 20B on RTX 4090. For 120B you can do it on 4x 3090

- 3 x Radeon R 9700 AI PRO 32 GB = 96 GB total mit Vulkan. Cards will be around 4K USD. Then u need some reasonble CPU and some 128 GB RAM.

- ## [Macbook pro 128gb RAM owners, whats the best AI you're running for reasoning & knowledge? : r/LocalLLaMA _202511](https://www.reddit.com/r/LocalLLaMA/comments/1p0yu23/macbook_pro_128gb_ram_owners_whats_the_best_ai/)
- GLM-4.5-Air
  - minimax is next to it but itâ€™s hard to fit in the good quant. 
- Agree! I use MiniMax-M2 @ Q3 and it works mostly great, with a relatively long context. But I am not sure itâ€™s better than GLM-4.5-Air @Q6. Both on par for my coding and agentic tasks. MMM2 is faster though.
- what do you serve GLM with? I really like using LM Studio for tools parsing on MLX quants, but LM Studio doesnâ€™t offer native tools parsing for GLM which causes issues for opencode and zed.
  - I serve GLM-4.5-Air with LM Studio. Use this fixed Jinja template to replace the original one in LM Studio for GLM
  - I really don't get why they never fixed it officially for such popular and useful local model. Maybe with the GLM-4.6-Air release

- I actually use GPT-OSS 120b and GLM 4.5 Air a lot. Qwen Next is pretty good too. Was running an unsloth IQ2 of Minimax M2 today- fun model to chat with but makes a lot of small mistakes at that quantization. Can do similar with Qwen3 235b a22b. Those are cool big models, and nice for low stakes, lower context stuff, but that may not be right for your uses.

- ## ðŸ§© [Apple is considering putting miniHBM on iPhones in 2027 : r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/comments/1oz9vs3/apple_is_considering_putting_minihbm_on_iphones/)
- Mobile HBM will be very expensive though, i think it is possible they will do a hybrid for macs
  - At 20 watts tdp don't expect gpu type performance, probably like nvidia orin order of magnitude
- It will probably be slower due to the battery constraints but they will improve the battery too. However when hbm reaches the mac studio, there will be way less power constraints , it will run real fast like 2.8-8TB/s.. even on the m7 or m8 max macnooks, it will be fast

- What's mini-HBM?
  - Mini-HBM isnâ€™t â€œVRAM stacked on a waferâ€ and it isnâ€™t literally on top of the GPU. Itâ€™s a small HBM-style DRAM stack placed next to the SoC on a silicon interposer.

- Looking at mobile devices, the memory bandwidth for the most part is less than 100GB/s so they really need to up those. And companies are too focused on getting their proprietary models to run well rather than let people just run the open weights models.
  - I do agree, but there is a world that models are introduced in the background before users are able to directly chat with them. Small models can unlock categorization and data collection workflows that are not time sensitive, and will give users improved recommendations and insights without sending data off site. Realistically they could even have a nightly processing step that runs through data over night so it doesn't affect UX.

- I fear on-device inference will greatly reduce battery life which is quite important on a mobile device.

- HBM for bandwidth, Neural block in each GPU core for prefill, 3nm and arm64 for energy efficiency. Apple is shaping up to be a good consumer AI company.
  - Yeah, it is gonna be good, the 2nm process ( 20 nm metal pitch) will come in 2026 and fp 8 native compute will likely come too.. they make good hardware but real expensive on the ram and ssd configs But still so much cheaper than nvidia.

- Ironically Huawei uses LPDDR phone RAM on GPU.

- I donâ€™t understand why itâ€™s Iphone first and then Mac not the other way around.
  - Apple is a mobile first company, they usually test on iphones first then implement it for ipads and macs â€¦ if it works on iphones, it will be easier and better on macs. M series chips are essentially scaled up iphone chipa

- ## [AMD Ryzen AI Max 395+ 256/512 GB Ram? : r/LocalLLaMA _202511](https://www.reddit.com/r/LocalLLaMA/comments/1oyy0fy/amd_ryzen_ai_max_395_256512_gb_ram/)
  - Iâ€™m looking at the new AI boxes using the Ryzen AI Max+ 395 (GMKtec EVO-X2, Minisforumâ€™s upcoming units, etc.) and Iâ€™m wondering if weâ€™ll actually see higher-end RAM configs â€” specifically 256GB or even 512GB LPDDR5X.

- Thereâ€™s little point in producing a box with more RAM if the bandwidth isnâ€™t sufficient. 
- Will not see higher RAM configs for Strix Halo. The 256 bit bus width and available LPDDR5X density prohibit this. Even if somehow someone would make a more dense module, the limited bandwidth would not make it useful for LLMs.

- AMD to my knowledge has no interest in supporting this SoC with a 128GB+ config, and the more likely result is a more bespoke SoC in a successor that goes up to 256GB/512GB, possibly with higher bandwidth or a better programming model.
- AMD will never do any powerful AI consumer products, that they wont eat their workststion/server shit

- AMD's next iteration of this chip, Medusa Halo, and that is expected to use either 384-bit LPDDR6 or 256-bit LPDDR5X meaning possible configurations of: 273, 342, and all the way up to 691GB/s in the extreme case.

- Samsung is releasing lpddr6x modules with more 10k mhz modules, which if utilized would increase the memory bandwidth for more than 330 Gb/s. Another way is if AMD uses octa channel method as used in threadripper pro, it can be a game changer. It can increase the memory bandwidth to more than 650 gb/s. With octa channel they can easily go upto 256gb using 32gb modules or 192gb with 24gb modules. It would increase cost, but AMD can capture numerous clients from mac lineup.

- ## [Is it possible we ever get CPU native LLMs? : r/LocalLLaMA _202511](https://www.reddit.com/r/LocalLLaMA/comments/1oyj16n/is_it_possible_we_ever_get_cpu_native_llms/)
- CPUs aren't really suitable for the type of calculations AI uses. "CPU native LLMs" will be just regular LLMs that are running in NPU unit inside of a regular cpu. One day, when NPUs will get decent, it'll be normal.

- MoE models run pretty well on CPU, I have a 21B running on an SBC at 15 tps.

- it's common knowledge on machine learning 101 . Machine learning /AI is mostly about matrix calculations , and which can be done by CPUâ€™s as well however it depends on your CPU core size. Meanwhile GPU is meant todo this operation for each pixel 100times per second. CPU is costly consumes a lot more power per core and its core isnâ€™t scalable . You canâ€™t have cpu with 1million core. If you do it will be size of a watermelon and cost you 10million dolar to buy and 10K electric bill.

- ## [Mac studio ultra M3 512GB : r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/comments/1oy9kkv/mac_studio_ultra_m3_512gb/)
  - Is there anyone use it in production environment? I didn't find serious benchmark data about it, is it possible to run such as kimi-k2 thinking with two Mac studio 512GB ? 
- Yes, you can run a quantized version of Kimi K2 on two clustered Mac Studio M3 Ultras, but it's not ideal for a production environment. 
  - The main issue is that processing a large 256k context window will be extremely slow, as the M3 Ultra's GPU performance creates a bottleneck despite the large amount of unified memory. 
  - While tools like MLX or Exo can link the machines, this setup is better suited for a single developer's workstation than for serving multiple requests with low latency.

- I recently saw a post showing someone getting 15 tps on Kimi-K2 on two linked M3 Ultra Mac Studios. So it can be done, and 15 tps is certainly usable.
  - I just finished building a server using an EPYC 9455P and RTX Pro 6000 (just one) which can hit the same 15 tps on Kimi-K2 for about the same price and without any of the other drawbacks of the Mac (like trying to link two machines, being stuck on a Mac, etc.).
  - The EPYC 9005 series has 12 independent DDR5 channels at 6400 MT/s, giving it 614 GB/s of memory bandwidth. Not quite as high as the M3 Ultra's 800 GB, but not far off, especially considering you aren't limited to 512 GB and you have 96 lanes of PCIe 5.0 to use for whatever you feel like.

- Problems is with lack of continuous batching. you have to queue incoming requests, vLLM does them in async way but do it support Apple GPU. I do a lot of tests with aider and prefill was never a problem.. but I test only small models

- ## [Model recommendations for 128GB Strix Halo and other big unified RAM machines? : r/LocalLLaMA _202511](https://www.reddit.com/r/LocalLLaMA/comments/1oy1v7q/model_recommendations_for_128gb_strix_halo_and/)

- GPT-OSS-120B is the best model you can run on the Strix Halo. 
  - GLM Air fits, but it runs less than half the speed, and GPT-OSS-120B is already super slow in practice. 
  - You can get 50 tokens/sec, but in real use the prompt processing is so slow it feels like 1 token/second for anything but light chatting.

- ## [Ryzen AI MAX+ 395 - LLM metrics : r/ollama _202511](https://www.reddit.com/r/ollama/comments/1oxw4ir/ryzen_ai_max_395_llm_metrics/)
  - MACHINE: AMD Ryzen AI MAX+ 395 "Strix Halo" (Radeon 8060s) 128GB Ram
  - OS: Windows 11 pro 25H2 build 26200.7171 (15/11/25)
  - INFERENCE ENGINES: Lemonade V9.0.2, LMstudio 0.3.31 (build7)
  - I would reccomend Lemonade (supported by AMD) but the python API is the generic OpenAI style while LMstudio Python API is more friendly. Up to you.
  - LMstudio (No NPU) is faster with Vulkan llama.cpp engine rather than Rocm llama.cpp engine (bad bad AMD).
  - Lemonade offers also NPU only mode (very power efficient but at 20% of GPU speed) perfect for overnight activities, and Hybrid mode (NPU+GPU) useful for large context/complex prompts.

- Framework has an ITX sized board which you can put in a server or desktop case. It even has 1 PCIE4x4 slot. The CPU doesn't have enough PCIe lanes for more slots
  - Easy, buy a Xeon or a threadripper server. Dual CPU with lots of lanes.

- ## [Why aren't there cheap NVLink adapters for RTX 3090s? : r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/comments/1owxob9/why_arent_there_cheap_nvlink_adapters_for_rtx/)
  - Is the NVLink only a wire jumper linking both cards together? Can I make my own homemade connections?
- 4 slot bridges go for $600-700 on eBay

- I believe they are passive but contain 128x high speed lanes with two 90 degree connectors, that's a signal integrity nightmare all those traces need to be matched in length. Does this justify them being $600 tho? Not at all
  - This is the correct answer. You can't just jumper a high-speed interconnect. They went from flexible ribbon to PCB for a reason.
  - That being said, it IS 100% supply and demand (similar to current DDR4/DDR5 prices). The 4-slot adapters were $59-$79 when I got mine a few years back. The 3-slot were like $120-150. BECAUSE gamers didn't care about them. The current demand is from people re-using 3090's for compute work.

- ## [Nvidia Tesla H100 80GB PCIe vs mac Studio 512GB unified memory : r/LocalLLM _202511](https://www.reddit.com/r/LocalLLM/comments/1owy5sm/nvidia_tesla_h100_80gb_pcie_vs_mac_studio_512gb/)
  - A Nvidia Tesla H100 80GB PCIe costs about ~30, 000
  - A max out mac studio with M4 ultra with 512 gb unified memory costs $13, 749.00 CAD

- H100 is not 10, 000 times faster, more like 10X for training and 20X for inference, so one order of magnitude.

- H100 costs $30, 000 because they allow clustering with HBM 3tb/s allowing you to combine multiple H100s into a single giant GPU super computer. Cant do that with the Mac. Can't do that with the Pro 6000.
  - These LLMs are trained with clusters as large at 500 - 15, 000 H100s...

- ## [Kimi K2 Thinking Q4_K_XL Running on Strix Halo : r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/comments/1ouuko3/kimi_k2_thinking_q4_k_xl_running_on_strix_halo/)
- When file size is larger than your mem+vram, there's little you can do since bottleneck is the disk read speed(besides bad system managed caching). You can buy 3 more machine and use RPC to speed up

- ## [Half-trillion parameter model on a machine with 128 GB RAM + 24 GB VRAM : r/LocalLLaMA _202511](https://www.reddit.com/r/LocalLLaMA/comments/1oueiuj/halftrillion_parameter_model_on_a_machine_with/)
  - CPU: Intel i9-13900KS
  - RAM: 128 GB (DDR5 4800 MT/s)
  - GPU: RTX 4090 (24 GB VRAM)
  - Iâ€™ve successfully run Qwen3-Coder-480B on llama.cpp
  - UD-Q3_K_XL: ~2.0 tokens/sec (generation)
  - UD-Q4_K_XL: ~1.0 token/sec (generation)

- Be careful with any method of running a model that heavily leverages swapping in and out of your SSD, it can kill it prematurely. Enterprise grade SSD can take more of a beating but even then it's not a great practice.
  - This is only half correct. Repeatedly writing to an ssd shortens its lifespan. But repeatedly reading from an ssd is not harmful.
  - When you use mmap() for models exceeding RAM capacity, 100% of the activity on the ssd will be read activity. No writing is involved other than initially storing the model on the ssd.
- writing and erasing data on ssdâ€™s are intensive, and ssdâ€™s generally have a limit on how many times you can do that before they become read only or inoperable.
- Memory mapping is reading to memory and discarded as needed. It isn't writing to disk so no concern on excessive writing like swap space / Windows virtual memory.
- It is not swapping! It is using mmap (memory-map model). So it is only reading from SSD (there are no writes, context is kept in RAM).

- ## [What is the best hardware under 10k to run local big models with over 200b parameters? : r/LocalLLaMA _202511](https://www.reddit.com/r/LocalLLaMA/comments/1otdr19/what_is_the_best_hardware_under_10k_to_run_local/)
  - Short term I will use this to refactor codebases, coding features, etc. I don't mind if it runs slow, but I need to be able to run thinking/high quality models that can follow long processes (like splitting big tasks into smaller ones, and following procedures). 
  - But long term I just want to learn and experiment, so anything that can actually run big models would be good enough, even if slow.

- Caution: buying hardware to run specific models is not sustainable unless you are 110% satisfied with the model at hand and will not find the urge to upgrade to something even better. Its a race against big datacenters and you might as well just rent the hardware.
  - Actual answer: Stack 3090s, 4090s, however cheap you can get them. thats how you run big models fast and "cheap" (relatively speaking). RAM Prices are skyrocketing and it is entirely unfeasable imo to buy (64gb 6000mhz is $360+++). 3090s for 700-800 are way higher performance. 
  - Rule of thumb i use: DDR5 6000Mhz is 10x slower than a 4070's VRAM. If u can get 10x more RAM than VRAM for the same price, speeds *can* be compared, but then u start looking at 6-channel motherboards etc.
  - tl; dr: due to ram situation, just stack 3090s while you can. nothing else beats its price/performance. good luck

- A good alternative to the 3090 for running large MoE models is the AMD Mi50 32gb, much cheaper and has 1tb memory bandwidth due to the HBM2 memory
- 8xMI50: qwen3 235B Q4_1 runs at ~21t/s with 350t/s prompt processing (llama.cpp)

- an M3 ultra will have very bad prompt processing, so if you use any prompts longer than 8k or so, get ready for a world of pain. MoE only helps so much too.
  - Partial offloading, especially with MoE, is still mainly RAM Bandwidth bound, im not 100% sure what 4 or 6 channel motherboards are available, and if you can get enough high speed RAM at any price below 10k to make that worthwhile.
  - If you want an out of the box option that isnt speed optimized, m3 ultra works. If you at all have speed requirements (and by that i mean, not waiting half an hour for a big response), i dont think 10k will cut it without some heavy DIY (e.g. crazy motherboard with tons of PCIe, think older threadrippers, to use all those gpus)
- Remember there are models such as Qwen 3 Next with closer to linear prompt processing time, and more such models will continue to appear over the coming years :) also even with large system prompts (ie for agentic uses), you can cache those and get decent performance. At the moment we're just throwing compute at everything, but the algorithms and implementations will become more efficient over time.

- ## ðŸ†š [Benchmark Results: GLM-4.5-Air (Q4) at Full Context on Strix Halo vs. Dual RTX 3090 : r/LocalLLaMA _202511](https://www.reddit.com/r/LocalLLaMA/comments/1osuat7/benchmark_results_glm45air_q4_at_full_context_on/)
  - I benchmarked the GLM-4.5-Air (Q4) model running at a near-maximum context on two very different systems: a Strix Halo APU and a dual RTX 3090 server. Both tests were conducted under Debian GNU/Linux with the latest llama.cpp 
- Why is the prompt processing for RTX is so low? It should be hundreds if not thousands. The model is too big and you have to spill some part to regular system RAM? These prompt processing figures make it unusable in such setup then
  - This is essentially a pp119702 test. I'm sure their numbers are MUCH higher at 0 context.

- Numbers from my system: RTX 5090 + pcie5 x16 + DDR5-6000 and 46 MoE layers offloaded to the CPU:
  - PP 31.2x faster than your Strix Halo machine
  - PP 10.7x faster than your Dual 3090 machine (you are prob limited by slow pcie)
  - TG 2.1x faster than your Strix Halo machine
  - TG 1.7x faster than your Dual 3090 machine

- vllm will be much faster for dual GPUs.

- ## [I tested Strix Halo clustering w/ ~50Gig IB to see if networking is really the bottleneck : r/LocalLLaMA _202511](https://www.reddit.com/r/LocalLLaMA/comments/1ot3lxv/i_tested_strix_halo_clustering_w_50gig_ib_to_see/)
  - TLDR: While InfiniBand is cool, 10 Gbps Thunderbolt is sufficient for llama.cpp.
  - During inference, I observed that the network was never used at more than maybe ~100 Mbps or 10 MB/s most of the time, suggesting the gain might not come from bandwidthâ€”maybe latency? But I don't have a way to prove what exactly is affecting the performance gain from 2.5 Gbps to 10 Gbps IP over Thunderbolt.

- Llama cpp doesnâ€™t use tensor parallel so everything is done sequentially. This test was meaningless. You need to test it with TP on VLLM or Sglang
  - As I state in the post, there is no RCCL support. Without RCCL support, frameworks like vLLM and PyTorch can't perform collective operations (all-reduce, all-gather, etc.) across multiple nodes. This is the fundamental blocker for tensor-parallel inference on Strix Haloâ€”you literally can't split a model across nodes without these primitives. It's always the software support that's lacking on the AMD side
- It's meaningless because:
  - Pipeline parallelism only help you run models that you can't fit in a single node. It can't be faster than the single slowest node. So there is no sense testing it for performance, unless you want to test for performance bugs in implementation.
  - Using pipeline parallelism, the network transfer between nodes are minimal. Each token only has 2880 elements of embedding. Even you use 100Mbps network it's only like 1ms time for a token. So what are you trying to test?

- I believe you can use GLOO instead if NCCL is not available (I assume RCCL is the rocm version).

- It is not meaningless at all. It's quite meaningful since network speed is a topic that often comes up. You don't have just be doing TP for it to be of interest.

- As expected. I don't find the difference to be substantial between 2.5 to 10 to 50. Sure, it gets a little faster but not nearly as much as the increase in network speed would suggest. Not enough for me to pay several times more for a 10GBE network versus 2.5GBE.

- ## [Mac vs. Nvidia Part 2 : r/LocalLLM _202511](https://www.reddit.com/r/LocalLLM/comments/1opo89e/mac_vs_nvidia_part_2/)
  - I recently purchased a Mac Studio M4 Max w/ 64GB (128 was out of my budget). I also was able to get my hands on a laptop at work with a 24GB Nvidia GPU (I think itâ€™s a 5090?).
  - I was shocked how less capable the Nvidia GPU is! I loaded gpt-oss-20B with 4096 token context window and was only getting 13tok/sec max. Loaded the same model on my Mac and itâ€™s 110tok/sec. Iâ€™m running LM Studio on both machines with the same model parameters. 
- The laptop 5090 has 24gb
  - Yep and it is essentially a 5080 desktop crammed into a laptop (Nvidia always does this).

- 13 tokens/second sounds right if you load gpt-oss-20b into some dual channel DDR5 system memory. I don't use LM Studio personally but by any chance did you not tell the 5090 rig to load any layers into the GPU?
  - So I had that problem at first where LM studio was not loading all the layers into the GPU and the utilization stayed low. But I changed a setting that forces the model to be loaded exclusively to the GPU and utilization when up, but the gain was only like 3-4tok/sec speed up
- You must be running that model with layers on the CPU or you're mistaken about which GPU your laptop has

- Remember the 5090 mobile is the 5080 desktop chip (GB203) but upgraded to use 3GB memory modukes instead of 2GB like the 5080. Like most laptop gpus it is comparably power and heat limited compared to the desktop equivalent (5080).

- Make sure you have all the layers of the model loaded onto the GPU. 

- ## [If I want to train, fine tune, and do image gen then... DGX Spark? : r/LocalLLaMA _202511](https://www.reddit.com/r/LocalLLaMA/comments/1om7ccz/if_i_want_to_train_fine_tune_and_do_image_gen/)
- Apple is no good for finetuning/training, only for inference afaik.
  - AMD works, I guess. Story of their hardware in AI.
  - Both Apple and AMD probably don't work for image stuff (especially for anything niche, less supported). It's usually based on CUDA.
  - If you just want to "do everything AI", DGX will work and it will be slow-ish and if you can live with that (or optimize using MXFP4 etc.), it's perfect for you. If you got dem cash of course.

- ## ðŸ¤” [Best setup for running local LLMs? Budget up to $4, 000 : r/LocalLLaMA _202511](https://www.reddit.com/r/LocalLLaMA/comments/1olsh0j/best_setup_for_running_local_llms_budget_up_to/)
- Depends on what kind of route you want to go. Do you want an open mining rack style build with the potential to have 8 GPUs? Do you want a system that fits into a standard ATX case? What size models do you want to run? Do you want to do image or video generation?
- I've done a few builds recently and the two best value routes I found are for a DDR4 based system:
  - Huananzhi H12D-8D  åŽå—é‡‘ç‰Œ
  - AMD EPYC 7532 (The cheapest EPYC Rome that gives you full memory bandwidth.)
  - AMD EPYC 7D12 (Best value EPYC, downside is missing half of the memory bandwidth.)
  - DDR4 2133 to 3200 RDIMM 8x16GB (128GB) or 8x32GB (256GB).
- For a DDR5 system:
  - GIGABYTE MS03-CE0
  - Intel 8480+ QYFS 
  - DDR5 4800 RDIMM 8x16GB (128GB) or 8x32GB (256GB)
  - I built/purchased the above parts with 256GB of memory for around $2, 000, the price of the memory was half of the build. Currently the memory price has risen by +50% and 256GB of memory is around $1, 500.
- For the GPUs the best value for text only inference is still the MI50 16GB (~$150) and the MI50 32GB (~$250-300, price has risen could have been had for around ~$150 1-2 months ago). 
  - If you want a more plug and play experience or want to do image/video generation, then you're probably still looking at getting 3090s (~$700). 
  - There are other GPUs to look for, but I'm sure they'll be recommended by others in this thread.
- With the above parts you have two routes. 
  - You can either go for GPUs and run smaller models fast, or you can go for a hybrid approach with a single 3090 for prompt processing and put the rest of the money into memory to run a larger model at a slower speed (Deepseek at home). 
  - If you want an example build of the top end you can have with CPU+GPU hybrid, then this video is a good comparison point. The video showcases 12-channels of DDR5 5600 with a 3090 getting 15t/s with DeepSeek_V3_0324 Q4_K_M. Using that as a comparison point, you'd expect the DDR5 4800 system above to be around ~7-9t/s and the DDR4 3200 system to get ~4-6t/s.

- 4x 3090s and whatever else supports this
- My 4x3090 rig is loud, uses a lot of power, puts off a lot of heat, and seems to require constant care and feeding. The DGX Spark sits on my desk, is quiet, and "just works". Unless you need to eek out the absolute most inference performance per $ spent, I would go with the turn-key solution and call it a day.

- If you go with multiple GPUs, you need a server mobo in order to get a server CPU that has enough pci-e lanes. GPUs want 16x each even though you can get by on less
  - Server motherboards are meant to run in very loud 2U chasis' with high airflow. I stuffed mine into a large PC case but have extra fans and an AIO CPU cooler for SP5.
  - Also, server CPUs a generally woser at gaming and single threaded performance than consumer CPUs.
  - If money is no object a ThreadRipper is the way to go.

- ## [Building PC in 2026 for local LLMs. : r/LocalLLM _202511](https://www.reddit.com/r/LocalLLM/comments/1ol3lcy/building_pc_in_2026_for_local_llms/)
- you can run a quantized deepseek-v3.1-terminus with 671b params at roughly 20 t/s, with full 128k context, using a single 5090 if your CPU + RAM is beefy enough, and if you're using `ik_llama.cpp` .
  - 2x AMD Epyc 9355 and a shit ton of RAM ought do it. My server build has 768 gb RAM and I use it to power Roo Code and SillyTavern

- You will get much closer to your goal with an nVidia RTX pro 5000 blackwell, with 72 gb of vram, >$6K. Another option is something like strix halo computers, ~$2k. Will be slow around 10 tps, but is faster than most can read.
  - Rumor has it that in more than a year, AMD will release medusa halo, that has twice the memory and twice the speed of strix halo

- No. No local model running on a single GPU (or even several) can match the huge professional cloud models in quality. We do local models for privacy and for the fun of hobbying.
  - local models can be fine tuned locally into very specialized models that can do specific things much better than the SoTA cloud models. This gets pretty niche

- ## [DGX Spark Benchmarks (Stable Diffusion edition) : r/StableDiffusion _202510](https://www.reddit.com/r/StableDiffusion/comments/1ogjjlj/dgx_spark_benchmarks_stable_diffusion_edition/)
  - tl; dr: DGX Spark is slower than a RTX5090 by around 3.1 times for diffusion tasks.
  - I happened to procure a DGX Spark (Asus Ascent GX10 variant). This is a cheaper variant of the DGX Spark costing ~US$3k, and this price reduction was achieved by switching out the PCIe 5.0 4TB NVMe disk for a PCIe 4.0 1TB one.
  - Based on profiling this variant using llama.cpp, it can be determined that in spite of the cost reduction the GPU and memory bandwidth performance appears to be comparable to the regular DGX Spark baseline.
  - Now on to the benchmarks focusing on diffusion models. Because the DGX Spark is more compute oriented, this is one of the few cases where the DGX Spark can have an advantage compared to its other competitors such as the AMD's Strix Halo and Apple Sillicon.
  - While the DGX Spark is not as fast as the Blackwell desktop GPU, its performance puts it close in performance to a RTX3090 for diffusion tasks, but having access to a much larger amount of memory.

- 3 times slower than a 5090 soâ€¦. Roughly the equivalent of a 5060ti?
  - Their benchmark for SDXL 3.13it/s makes it roughly equal to 3090, that also has about 3it/s.
- If we did the math purely based on TFLOPs/ in FP16/BF16, it would indicate closer to 5070-like performance.

- You can find many benchmarks for AMD AI MAX and compare. Nothing spectacular here, because inference performance limited by memory bandwidth, and DGX has 270Gb/s while AMD thingy has 250Gb/s.

- ## [Running DeepSeek-R1 671B (Q4) Locally on a MINISFORUM MS-S1 MAX 4-Node AI Cluster : r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/comments/1oevvyu/running_deepseekr1_671b_q4_locally_on_a/)

- So you spend $20, 000 to get 5 TPS. You could have spent $1000 and run it on ram/cpu and got the same speed.

- ## ðŸ†š [DGX Spark vs AI Max 395+ : r/LocalLLaMA _202510](https://www.reddit.com/r/LocalLLaMA/comments/1o6izz2/dgx_spark_vs_ai_max_395/)
- I just ran some benchmarks to compare the M2 ultra.
- OSS-120B
  - DGX PP=817, TG=41
  - 395 PP512=350, TG=34 (Vulkan)
  - 395 PP512=645, TG=46 (Rocm) *per Sillylilbearâ€™s tests
  - M2U PP=590, TG=70
- OSS-20B
  - DGX PP512=2053, TG=48
  - 395 PP512=1000, TG=47
  - M2U PP512=1000, TG=80
- Llama 3
  - DGX PP512=7991, TG=21
  - 395 PP512=1000, TG=47
  - M2U PP512=2500, TG=70

- NVIDIA didn't build this for our community. It's a dev platform for GB200 clusters, meant to be purchased by institutions. For an MLE prototyping a training loop, it's much more important that they can complete 1 training step to prove that it's working than that they can run inference on it or even train at a different pace. 
  - If you want to replicate GB200 environment as closely as possible, you need three things: NVIDIA Grace ARM CPU, Infiniband, and CUDA support. RTX 6000 Pro Blackwell only provides one of those three. Buy two DGX Sparks and you've nailed all three requirements for under $10k.

- If you want LLMs with working speeds and diffusion models with slow speeds, both devices are fine. Vulkan support for AI Max 395+ is really good, so you can get better performance with most llms than DGX Sparks (or at least the same) for LLM uses.
  - However, the main problem arrives when you try to use the latest non-LLM models such as TTS, openmcp, and omni models with video support, where you are dependent on ROCm for HIP. Most of these latest models are optimized and tested for CUDA, and they usually fail on Halo (even with ROCm 7.0).
  - I own a 395+, and since I am a developer, I am really happy with my purchase. I can keep multiple 30B MOE models in memory and can get a very fast response. Every day, I try to run new AI models on my system, but the success rate for non-LLMs is 40% compared to my 4090, where it is 90%.

- ## [Fast loading and initialization of LLMs : r/LocalLLaMA _202407](https://www.reddit.com/r/LocalLLaMA/comments/1e3hknt/fast_loading_and_initialization_of_llms/)
  - Now normally I use vLLM to serve LLMs, but it seems to be very slow at loading up models. For Llama 8 FP16 it takes 8s to be ready from a warm cache. Qwen 14 takes 11s with a warm cache. Way too slow.
  - The above is for a single 3090 on PCIe 4.0 x16, 4 sticks of DDR4 RAM rated at 3200 on a X570s motherboard with a Ryzen 5600X CPU.

- A co-worker and I are building a local LLM server for testing (see my profile) and we have looked at various ways to maximize loading of LLM files across different CPU brands/architecture for a customer.
  - We did consult with one of our biggest customers who has a few dozen local LLM workstations and they all have AMD Threadripper 7980X boxes, 192GB of RAM (4x48GB) with a pair of RTX A6000 48GB cards w/ NVLink bridge and dual 15TB U.2 NVMe drives. They have moved to ZFS w/o L2ARC and storing all their LLM files on 30TB worth of U.2 NVMe drives and a 168GB ARC.
  - We are building a Splunk app for them to monitor their usage of LLM apps and models.
  - TL; DR: Use ZFS and set ARC to cache as many LLMs as you can for faster transfer to VRAM. Or if you only need to test a coupe of LLM constantly, then create a RAM disk and copy your LLM files there.

- ## [Orange Pi AI Studio Pro mini PC with 408GB/s bandwidth : r/LocalLLaMA _202502](https://www.reddit.com/r/LocalLLaMA/comments/1im141p/orange_pi_ai_studio_pro_mini_pc_with_408gbs/)
- As always, hardware is only one part. Where's the software support? Is there a Linux kernel driver? Is it supported in any good inference engine? Will it keep working 6 months after launch? Orange Pi are traditionally really really bad at the software side of their devices.
  - For all their fruit clone boards they release one distro once and never update it ever again. The device tree or GPU drivers were proprietary so you can't just compile your own either.

- Rumored to have an Atlas 300I Duo inference card inside, but with double memory and a better price. Now the 192GB version is pre-ordering at Â¥15, 698 (~USD $2150).
  - 12-channel 64-bit 4266 MHz LPDDR4X = 409.5 GB/s
  - Atlas 300I Duo specs: 408 GB/s
- So itâ€™ll be about 10-15% slower than M4 Max and about 80-90% faster than M4 Pro. If thatâ€™s really true than 2100$ is an amazing price point provided we also get the needed software support.

- ## ðŸ†š [What laptop would you choose? Ryzen AI MAX+ 395 with 128GB of unified RAM or Intel 275HX + Nvidia RTX 5090 (128GB of RAM + 24GB of VRAM)? : r/LocalLLaMA _202510](https://www.reddit.com/r/LocalLLaMA/comments/1o3evon/what_laptop_would_you_choose_ryzen_ai_max_395/)
- more net RAM = more net model + context size, at whatever speed.

- The Ryzen and run the larger models like gpt oss 120b or glm 4.5 air. The 5090 will run models that fit much faster like Qwen3 30b variants.
  - The Ryzen may be very slow on promo processing. A big deal if you are dropping 50k or more tokens. You may be waiting a few minutes before the output starts.

- Depends, do you want to run larger models somewhat slowly - 395 Or do you want to run smaller models and larger MoE models very quickly - 5090

- depends what you want to do, if you are gaming then the 5090 makes more sense, for ai the 395 makes more sense since you will be able to run better stuff.

- For LLMs the Ryzen can run large MOE models much faster, but the one with the 5090 can run smaller models that fit into the 24 GB vram really really fast. For image or video generation, Nvidia unfortunately is still the top choice, it usually takes some time until new models are supported on Amd 

- I have GMK x2 and I'm killing this machine with everything you can think about, run everything even Q2 GLM4.6 with 10 tokens (not bad for 115G) model all in ram.

- 
- 
- 
- 
- 
- 
- 

- ## [4x64 DDR5 - 256GB consumer grade build for LLMs? : r/LocalLLaMA _202504](https://www.reddit.com/r/LocalLLaMA/comments/1k6p20z/4x64_ddr5_256gb_consumer_grade_build_for_llms/)
  - I have recently discovered that there are 64GB single sticks of DDR5 available - unregistered, unbuffered, no ECC, so the should in theory be compatible with our consumer grade gaming PCs.
  - Both AMD 7950x specs and most motherboards (with 4 DDR slots) only list 128GB as their max supported memory - I know for a fact that its possible to go above this, as there are some Ryzen 7950X dedicated servers with 192GB (4x48GB) available.

- I have 64GB of DDR5-6000 and it is great at inference - of models that don't take more than around 16GB (preferably 10GB) - anything bigger becomes too slow to use.

- If you're going for a CPU based build, you want to go for epyc, not a consumer CPU.
  - It won't be super fast; expect memory speed of around 200GB/s, so about 1/5th the performance of a 3090 or 4090 in token generation, and maybe 1/10th in processing speed.

- Yeah, I've got 128Gb of DDR4 3200, now I am running 110Gb models with 0.3t/s

- On desktop Zen 4/Zen 5, I wouldn't recommend doing that.
  - You're quite limited by the Infinity fabric bandwidth, limiting you to a max of 62-68GB/s on DDR5-6000 to 6400, while theoritical DDR5 6000 128-bit is 100GB/s.

- I'm running a Ryzen 9 7900X on MSI PRO B650M-A WIFI AM5 Micro-ATX with 256GB using 4 of those 64GB DDR5 sticks. So it is possible. Your memory bandwidth drops, as you need to slow the memory down to stay stable. If you are building from scratch you may want to use a CPU with more memory channels.

- ## [Did someone ever benchmark how cpu inference performs with quad and eight channel memory ? : r/LocalLLaMA _202401](https://www.reddit.com/r/LocalLLaMA/comments/1920l93/did_someone_ever_benchmark_how_cpu_inference/)
  - Since people always say that bandwidth is the problem. And a full 8 channel memory board with ddr4 3200 would be about 200gb/s per second i was wondering if anyone ever benchmarks that stuff and how it scales with cores ?

- I have a 8ch epyc build, after some experiments i have found that the effective bandwidth is about 135 gb/s, so a 40gb model is ~ 3, 3 t/s, a 20gb is twice the speed.

- Intel Xeon E5-2680 v4, 128GB DDR4 2400 RAM 4 chanels. llama.cpp, model: mixtral8x7b Q5_K_M 6 tokens/sec

- R720 2x xeon 2670, 192gb ddr3-1333 dram, llama.cpp running mixtral q3_k_m quant w/ 10k context, pure cpu inference: 3.6 t/s. If use installed P40: 9.1 t/s

- ## [AI setup for cheap? : r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/comments/1ovbzi3/ai_setup_for_cheap/)
  - My current setup is: i7-9700f, RTX 4080, 128GB RAM, 3745MHz. In GPT, I get ~10.5 tokens per second with 120b OSS, and only 3.0-3.5 tokens per second with QWEN3 VL 235b A22b Thinking. 
- If you're only getting 10 tok/s, you're probably not using GPU at all. I have i7 13700k with a 4090. I get 38 tok/s with GPU, and 11 tok/s with only CPU.
  - If you're running llama.cpp, did you compile with CUDA support. Did you remember to set your -ngl 99 flag? using --n-cpu-moe instead of -ot exps=CPU?
  - Try llama-server -ngl 99 --n-cpu-moe 32 -ngl 99 -c 50000 -fa on -m file/to/model.gguf --no-mmap -t 8 -ub 2048 -b 2048 --jinja

- The CPU doesn't matter, the CPU's memory speed (i.e. your ram) determines TPS

- ## [AI LLM Workstation setup - Run up to 100B models : r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/comments/1ov7idh/ai_llm_workstation_setup_run_up_to_100b_models/)
  - Planning to buy 320GB DDR5 RAM (5 * 64GB) first. Also with high MT/s(6000-6800 minimum) as much as possible to get better CPU-only performance. In future, I'll buy some more DDR5 RAM to make that 320GB to 512GB or 1TB.

- 50+t/s with 30-50B Dense models is not possible for CPUs. As you need 20GB(32B Q4)x 50 ~= 1000GB/s of bandwidth, which is impossible before Epyc Venice or Diamond Rapids Xeon.

- Planning to buy 320GB DDR5 RAM (5 * 64GB) first
  - Don't do 5. In order to get maximum bandwidth you need to have an even number of DIMMs all the same size (and there might be some restrictions beyond that depending on CPU). If you have 5 you'll have 4*64GB of 'fast' memory and 64GB of slow memory. Keep in mind also that if you only have 5 out of 8 DIMMs installed you only get 5/8 the maximum memory bandwidth for the platform which directly impact your performance.

- "50+t/s with 30-50B Dense models"? A 6000 Blackwell can barely do that: I get 58t/s with Qwen3-32B-Q4. My 400W Epyc with 12x 5200MHz RAM only gets 14-18t/s.
  - The only reason CPU is usable with MoE is because the amount of RAM needed and the fact that bandwidth is often the bottleneck before compute and even then it's medeocre unless you offload the attention calculations which are more compute than memory bound.

- Optimized Power saving Setup
  - You seem to be confusing power draw with efficiency. Running a 200W CPU for 5min is not better than a 600W GPU for 1min. Get a RTX 6000 Max-Q, which runs the models you want and is one of the most efficient inference engines that are available. My Epyc system idles at ~90W while a Max-Q idles at ~15W and can be put in some <40W desktop.

- ## ðŸ¤” [Budget LLM pc builds, new CPU only approaches : r/LocalLLaMA _202410](https://www.reddit.com/r/LocalLLaMA/comments/1fycnc1/budget_llm_pc_builds_new_cpu_only_approaches/)
  - iGPU and lot's of memory: Like using 192gb of DDR5 RAM on the AMD Ryzen 9 7950x iGPU, or the budget Ryzen 5 8500G?
  - AVX-512: Llamafile now has AVX-512 Support, meaning 10x Faster Prompt Eval Times For AMD Zen 4, like AMD Ryzen 9 5900X?

- Unfortunately the answer is no. Even if you can build a consumer PC with a lot of DDR5 Ram, they cannot take advantage of it for LLMs, for the following reasons:
  - they have limited memory bandwidth for large models.
  - they have limited compute throughput for long context.
- Only 64-96 core Genoa EPYCs with 12-channel DDR5 RAM (and the new Intel Granite Rapids) can approach practical levels of performance, and this is only for models up to 70GB . But these are certainly not budget options.

- 2 channels of ddr5 9000/10000 should be something like 150 GB/s. Thats more than enough to have a real time conversation with the current gen 10B class models. Even the 30B+.

- Faster RAM, more channels (e.g. Strix Halo and HEDT with 4, EPYC with 8-12), and faster/more cores+AVX512 can enable the practical use of slightly bigger models but still far smaller than the 96-192GB people are discussing about.

- let's define model performance first. There are 2 stages: Prompt Processing (the model reading your input) which is compute bound, and Token Generation (the model writing its response) which is memory bound.
- The rule of thumb for token generation is:
  - `tokens/sec = memory_bandwidth_in_gb_per_sec / model_size_in_gb`
- The actual bandwidth which can be achieved is ~70-75% of the theoretical.
  - A dual-channel 3600MT/s DDR4 system has 51.2 GB/s theoretical memory bandwidth. Therefore, the actual achievable bandwidth is between 35.8 - 38.4 GB/sec.
  - An example model: Qwen2.5 7b when quantized to 8 bits is 8.1GB (by default models are shipped to FP16 which is double that).
  - So, you may expect a token generation speed between 4.4 and 4.7 tokens/sec (38.4 / 8.1) for this model. Half of that for the FP16 version of the model, and double of that for the Q4 version of the model.
- That's why large (dense) models don't make sense in CPUs. A 70GB model (e.g. Llama-3.1 70b q8_0) would be slower than 1 t/s. You need 8+ channel memory to reach practical speeds.
- ðŸ¤” But if you need to process long context (summarize documents, explain/debug/enhance code, continue a story, have long chat sessions) then the Prompt processing is compute bound, therefore compute throughput is very important and this is where modern GPUs seriously outperform CPUs by 25-100x due to their tensor cores.
  - For the above model, you may achieve 60 tokens/sec for prompt processing with a CPU and about 2500 tokens/sec with a RTX 3090. Therefore, if you want to summarize a 1500 words document, it will take 1 second in the GPU and 40 seconds in the CPU (just for the model to ingest your input).
- P. S. CPUs become practical with Mixture of Experts (MOE) models because the active parameters are usually 15-25% of the total, therefore the speed is 4-6x of that of a dense model.

- My understanding is that due to the memory bandwidth being a bottleneck, using a NPU or iGPU isn't any faster than simply using the normal CPU cores themselves when you're limited to two channel memory. CPU only can certainly be useful, and I think people are too quick to discount it as an option for small context sizes and smaller models 

- ## ðŸ†š [Thread for CPU-only LLM performance comparison : r/LocalLLaMA _202509](https://www.reddit.com/r/LocalLLaMA/comments/1nj4axf/thread_for_cpuonly_llm_performance_comparison/)
  - I could not find any recent posts about CPU only performance comparison of different CPUs. 
  - With recent advancements in CPUs, we are seeing incredible memory bandwidth speeds with DDR5 6400 12 channel EPYC 9005 (614.4 GB/s theoretical bw). 
  - AMD also announced that Zen 6 CPUs will have 1.6TB/s memory bw. The future of CPUs looks exciting. 
  - For this CPU only comparison, I want to use ik_llama 
  - use CPU only inference (No APUs, NPUs, or build-in GPUs allowed)
- llama-bench benchmark (make sure GPUs are disabled with CUDA_VISIBLE_DEVICES="" just in case if you compiled for GPUs):
  - qwen3moe 30B Q4_1: 38.9
  - GPT-OSS 120B Q8_0: 24.7

- those dusty EPYCs/Xeons with fat memory channels you see on eBay suddenly look like budget LLM toys..it; s crazy that decommissioned gear can outpace shiny new desktop CPUs for this niche.

- That's my server, I think there are some config issue here as using thread 64 would be much slower, maybe I should enable HT.
  - CPU: 1S Epyc 7B13(64c, HT disabled manually)
  - RAM: 8 x 64GB DDR4 2666
  - Motherboard: Tyan S8030GM2NE
  -  qwen3moe 30B Q4_K: 31.0 
  -  gpt-oss 120B F16: 14.9
-  Yes, there is definitely something wrong with the server in your case. You should get better results than my server.

- [CPU Only OSS 120 : r/LocalLLaMA _202510](https://www.reddit.com/r/LocalLLaMA/comments/1o6d4a6/cpu_only_oss_120/)
  - just try it on CPU only (gulp) on my home lab server and actually it's more than usable at a fraction of the power cost too. This is also running in a VM with only half cores given.
  - prompt eval time = 260.39 ms / 13 tokens ( 20.03 ms per token, 49.92 tokens per second)
  - eval time = 51470.09 ms / 911 tokens ( 56.50 ms per token, 17.70 tokens per second)total time = 51730.48 ms / 924 tokens

- ## [Looks like Intel Arrow Lake can support 4 DIMMs @ up to 6400 speeds : r/LocalLLaMA _202411](https://www.reddit.com/r/LocalLLaMA/comments/1gindy1/looks_like_intel_arrow_lake_can_support_4_dimms/)
  - After searching through a few boards, it looks like Arrow Lake can do 4 Dimms @ 6400. For an ASrock example, see below - select vendor "Corsair", and there is a 24GB per DIMM options @ 6400. Crucial and ADATA have 48GB "4 channel" options @ 5600.
  - Anyway just wanted to pass along that we may see "certified" 6400+ speed 4 DIMM setups become common with Arrow Lake (Core Ultra 200 series). An x86 way to have 192GB-256GB (when DIMMs are available) on a standard desktop at reasonable speed.

- But they are only dual channel, so you can expect at most around 100 GB/s of memory bandwidth.
  - Missed opportunity...

- Iâ€™m running 6200 stable on 128gb 4 dimms with Ryzen 7950x3D since 1+ year lol

- 4 dimms does not mean 4 channels. MBs have had 4 slots forever. Arrow Lake is dual channel.
- Arrow lake is dual channel. 4 dimms does not mean 4 channels. MBs have had 4 slots forever.

- it actually has 4 channels. It has the ability to address each half of the ram seperately. And it's a 4 channel controller, for 4x 32Bit. It's just that that's the same bandwidth as 2x 64 bit.

- [Is 96GB of DDR5 6800Hz RAM enough for training? : r/LocalLLaMA _202402](https://www.reddit.com/r/LocalLLaMA/comments/1b1e4z8/is_96gb_of_ddr5_6800hz_ram_enough_for_training/)
  - I went with 96GB of fast RAM thinking that it would be more than enough, but I've been seeing that people recommend at least 128GB for training and interfacing.
- What is your ram capacity and ram speed, I'm running 4x32gb at 6200mhz which speeds up inference. You can run AIDA to benchmark your ddr memory speed bandwidth
  - I want to get 128 gb of ram 6000MT/s. Cl30. But most people say that there is no way the ryzen 9 7950x3d could reach that at all without it melting or being unstable. Even 5200 would be a miracle. Apparently for am5, 4 DIMMS should not be used. You shouldnâ€™t quadrank. The most you can go for is 96 gb ram 6400MT/s (2x48). So how did you do it? Please teach me

- ## [CPU RAM only speeds on 65B? : r/LocalLLaMA _202307](https://www.reddit.com/r/LocalLLaMA/comments/14q4d0a/cpu_ram_only_speeds_on_65b/)
- I have both Dual RTX 3090s+NVLink and 128GB RAM (@3200) and for 65B models, using the CPU (i have a 3rd gen 8 core Ryzen) is just too slow. It's around 1 token per second, far from 7/s. From what i've seen getting a better CPU (16 cores) doesn't help much.

- The 7950x with DDR5 6000 on a 65b_4_ks model is 1.75t/s.
  - When it comes to token generation speed, the core count doesn't really matter. What does matter is the RAM bandwidth.
  - However, if you don't have a GPU, then the core count becomes important for prompt evaluation speed. But it's not worth buying a high-end CPU just for this.
  - In my opinion, if you can tolerate a speed of 2t/s on 65b models, the most cost-effective option would be to go for the 13400f($170)processor (disable the E-cores), paired with 64GB of high-frequency DDR5 RAM, and a second hand RTX 2060 for just $100. This GPU can be used for prompt processing and offloading as many layers as possible.

- I have CPU Ryzen 9 3950X and 64Gb RAM at 3600MHZ. The airoboros-65b-gpt4-1.4.ggmlv3.q5_K_M.bin generates at the average of 1077ms per token, with very small variance actually.

- ## [Is RAM latency very relevant for LLMs (Ollama)? : r/LocalLLaMA _202411](https://www.reddit.com/r/LocalLLaMA/comments/1gws9yp/is_ram_latency_very_relevant_for_llms_ollama/)
- No overclocking will not produce notable gains. When you offload to CPU your major bottleneck is the processing not memory bandwidth. You'll do a lot of work and adding potential instability for something that you won't really notice, maybe an extra token per hundred generated.
  - You are confidently wrong. I went from 3.45 tokens/s to 5.29 tokens/s just by enabling XMP profile (2666 MHz to 3600 MHz).

- ## [Will DDR6 be the answer to LLM? : r/LocalLLaMA _202510](https://www.reddit.com/r/LocalLLaMA/comments/1o0i4fz/will_ddr6_be_the_answer_to_llm/)
  - Bandwidth doubles every generation of system memory. And we need that for LLMs.

- I think the combination of smart quantization, smarter small models and rapidly improving RAM will make local LLM's inevitable in 5 years.

- Prompt processing will be even more critical with faster RAM - you need lots of compute for larger models, DDR6 will be used for, and CPUs do not have enough compute. You still absolutely would need GPU.

- Isn't Apple unified memory just multi channel RAM? It does deepseek fairly well.
  - Unified memory without upgradable ram is such a double-edge sword. I want it but I don't want it to be "The future"

- ## [How fast big LLMs can work on consumer CPU and RAM instead of GPU? : r/LocalLLaMA _202407](https://www.reddit.com/r/LocalLLaMA/comments/1edryd2/how_fast_big_llms_can_work_on_consumer_cpu_and/)
  - Would not it be cheaper to build a PC with 256-512 GB of RAM and run very big models on it than buying two Rtx 3090 and having only 48gb of VRAM?

- I'll get some example numbers with Llama 3.1 8B Instruct Q6_K with a context size of 8192 tokens.
  - Running on my RTX 4060 Ti: 25.46 tokens/s
  - Running on my Ryzen 5 7600: 6.66 tokens/s
  - As you can see, CPUs are the devil.
  - The RTX 4060 Ti's memory bandwidth is 288 GB/s, and my RAM is 81.25 GB/s (dual-channel DDR5 5200), and dividing those numbers comes out to close to the same ratio--while the GPU memory is 3.54x as fast, using the GPU for inference is 3.82x as fast.
  - Using shared memory with the GPU is far worse because PCI-e 4.0 x8 is only about 16 GB/s one way (PCI-e 5.0 is only twice that fast).

- I built a pc with 128G RAM , I9 14900K and one 4090 GPU. I have loaded Llama3.1 70B Q2 with Ollama, and test it, the token per second is about 9. Then I loaded Mistral Large 2 123B Q2, the token per second is about 2

- 14900K has only two memory channels which gets bandwidth bottleneck at 6 threads alone! So you get almost same CPU performance as me with 12700H in a laptop. I wish you researched more before building such a system there was no point of buying 14900K at all neither for LLMs or gaming expect you use it for something else ofc..

- For running LLMs on CPU you must buy something with at least 8 memory channels. Dual channel CPUs get bandwidth bottleneck at 6 threads alone and begin loosing performance severely as you increase thread count. Not cores rather only threads! So with 8 memory channels you can use 24 threads and gain around 4 times more performance. (Exact performance depends on clock, memory speed etc ofc but it is roughly like this.)

- ## [Running LLMs partially on cpu. DDR5 R1(single rank) vs R2(dual rank) : r/LocalLLaMA _202403](https://www.reddit.com/r/LocalLLaMA/comments/1b3vhc7/running_llms_partially_on_cpu_ddr5_r1single_rank/)
  - 2x32gb, dual rank(8x32bit/256bit), 6800mhz, 13600 MT/s, total bandwidth 217.6 GBps
  - 2x24gb, single rank(4x32bit/128bit), 7800mhz, 15600 MT/s , total bandwidth 124.8 GBps

- I would go for the first one with much more bandwith. As far as I know this usually is the bottleneck. But I haven't benchmarked anything like it myself.
  - 217 GBps sounds almost too good to be true. Only 3.5x slower than 4080's bandwidth.

- ## [Anyone actully try to run gpt-oss-120b (or 20b) on a Ryzen AI Max+ 395? : r/LocalLLaMA _202509](https://www.reddit.com/r/LocalLLaMA/comments/1nabcek/anyone_actully_try_to_run_gptoss120b_or_20b_on_a/)
- people post actual good benchmarks, 49T/s on TG and 700T/s on PP. 
  - Better than my 14900k (96GB 6800) + RTX3090: (32T/s on TG and 220-280T/s on PP).

- Ryzen 7950X + 3080 + 96GB DDR5-6000 gets me around 330T/s on PP and 15 on TG for the 120b

- ## [Most economical way to run GPT-OSS-120B? : r/LocalLLaMA _202508](https://www.reddit.com/r/LocalLLaMA/comments/1n13rsq/most_economical_way_to_run_gptoss120b/)
- I get 100t/s on short (2-3k) context and ~85t/s on longer context (12-14k) using three 3090s.
  - Two Mi50s and a Cascade Lake ES Xeon get me ~25t/s on the same 12-14k context. 

- Framework PC - 128GB LPDDR5x-8000 ! I have 5090 + DDR4-2933 = 18 t/s for GPT-OSS-120B

- Also 5090 + DDR5-6000 (offloading 22 layers) = ~35 t/s for GPT-OSS-120B (full precision â‰ˆ 60GB)

- Given that you already have a PC, I think, the most economical way to run gpt-oss 120b at good speeds is to buy 3 used rtx 3090. It will give you 72gb of vram and it will cost you around 1800 + PSU. It will be roughly the x4 speed of the Framework. 

- I have a Framework Desktop with 64GB. It almost explodes with GPT-OSS-120b loaded but I can actually run the 4bit version for a question or two until it fails and it runs at 50 tokens/s, even with the system having been exiled to SWAP. (openSUSE Tumbleweed, llama.cpp)

- ## [gpt-oss-120b on CPU and 5200Mt/s dual channel memory : r/LocalLLaMA _202508](https://www.reddit.com/r/LocalLLaMA/comments/1mj6xif/gptoss120b_on_cpu_and_5200mts_dual_channel_memory/)
  - I have run gpt-oss-120b on CPU, I am using 96GB dual channel DDR5 5200Mt/s memory, Ryzen 9 7945HX CPU. I am getting 8-11 tok/s. I am using CPU llama cpp Linux runtime.

- 5800x with 96gb of system ram DDR4 3200 in dual channel. Getting just over 5t/s with the 120, nothing offloaded to GPU

- ## [How to run gpt-oss-120b faster? 4090 and 64GB of RAM. : r/LocalLLaMA _202508](https://www.reddit.com/r/LocalLLaMA/comments/1mnsg6d/how_to_run_gptoss120b_faster_4090_and_64gb_of_ram/)
  - llama-server --hf-repo unsloth/gpt-oss-120b-GGUF --hf-file gpt-oss-120b-F16.gguf ^ -c 16384 -ngl 99 -ot ".ffn_.*_exps.=CPU" -fa ^
  - with 16k context here, I am getting around 14tps 

- I'm getting 35T/s and 120T/s prefill on a 3090 and 14900K but that is with 96GB of fast DDR5 (6800)

- ## [gpt-oss-120b performance with only 16 GB VRAM- surprisingly decent : r/LocalLLaMA _202508](https://www.reddit.com/r/LocalLLaMA/comments/1miprwe/gptoss120b_performance_with_only_16_gb_vram/)
  - GPU: RTX 4070 TI Super (16 GB VRAM)
  - CPU: i7 14700K
  - System RAM: 96 GB DDR5 @ 6200 MT/s (total usage, including all Windows processes, is 61 GB, so only having 64GB RAM is probably sufficient)
  - Model runner: LM Studio
  - 13 t/s is a speed that I'd consider "usable"

- Just posting my numbers too! 5090 + 60GB of DDR5, 22 cpu moe layers offloaded:
  - 36.61 tokens per second

- ## [10.48 tok/sec - GPT-OSS-120B on RTX 5090 32 VRAM + 96 RAM in LM Studio (default settings + FlashAttention + Guardrails: OFF) : r/LocalLLaMA _202508](https://www.reddit.com/r/LocalLLaMA/comments/1mk9c1u/1048_toksec_gptoss120b_on_rtx_5090_32_vram_96_ram/)
  - Just tested GPT-OSS-120B (MXFP4) locally using LM Studio v0.3.22 (Beta build 2) on my machine with an RTX 5090 (32â€¯GB VRAM) + Ryzen 9 9950X3D + 96â€¯GB RAM.
  - Everything is mostly default. I only enabled Flash Attention manually and adjusted GPU offload to 30/36 layers + Guardrails OFF + Limit Model Offload to dedicated GPU Memory OFF.

- Try llama.cpp with-ot ".ffn_(up|down)_exps.=CPU" This offloads up and down projection MoE layers instead of full MoE layers. You should get 30 t/s
  - I have a budget workstation that costs less than your GPU alone and I get 20 t/s with Unsloth their 120b. That is 20 t/s for the first 1K tokens, it slows down to 13 t/s at 30K context.
  - My specs: 16 GB RTX 5060 Ti + 16 GB P5000 + 64 GB DDR5 6000

- I can second that: With the same (short) prompt I get 17.9 t/s
  - Specs: 16 GB RTX 5060 Ti + 128 GB DDR5 5600 / Ryzen 9 9900X
  - .\llama-server.exe -c 60000 --chat-template-kwargs "{\"reasoning_effort\": \"low\"}" -fa -ctk f16 -ctv f16 -m "c:/....../gpt-oss-120b-GGUF/gpt-oss-120b-BF16.gguf" -ub 512 --temp 1.0 --top-p 1.0 --top-k 0 --min-p 0 --repeat-penalty 1.0 --no-mmap -sm none -ngl 99 --n-cpu-moe 44

- Thats really bad. I get 30T/s for 3090 + 14900K 96GB. 25T/s for the 14900K with just 8GB VRAM usage.
  - This is the trick: 
  - --n-cpu-moe 36 \    #this model has 36 MOE blocks. So cpu-moe 36 means all moe are running on the CPU. You can adjust this to move some MOE to the GPU, but it doesn't even make things that much faster.
  - --n-gpu-layers 999 \   #everything else on the GPU, about 8GB

- I get 9 t/s on integrated gpu in my thinkpad, you are doing something wrong

- I'll trade my 4070 Ti Super that gets 50 tokens/second for your ridiculously slow 5090.

- GPU: NVIDIA RTX 4000 SFF Ada Generation GPU: AMD ATI 04:00.0 Raphael Memory: 54.6GiB / 94.2GiB
  - eval rate: 8.03 tokens/s 

- ## [16â†’31 Tok/Sec on GPT OSS 120B : r/LocalLLaMA _202509](https://www.reddit.com/r/LocalLLaMA/comments/1ndit0a/1631_toksec_on_gpt_oss_120b/)
  - CPU: Intel 13600k
  - GPU: NVIDIA RTX 5090
  - Old RAM: DDR4-3600MHz - 64gb
  - New RAM: DDR5-6000MHz - 96gb
  - Model: unsloth gpt-oss-120b-F16.gguf
  - 16 tok/sec with LM Studio â†’ ~24 tok/sec by switching to llama.cpp â†’ ~31 tok/sec upgrading RAM to DDR5
  - `llama-server --n-gpu-layers 999 --n-cpu-moe 22 --flash-attn on --ctx-size 48768 --jinja --reasoning-format auto -m C:\Users\Path\To\models\unsloth\gpt-oss-120b-F16\gpt-oss-120b-F16.gguf  --host 0.0.0.0 --port 6969 --api-key "redacted" --temp 1.0 --top-p 1.0 --min-p 0.005 --top-k 100  --threads 8 -ub 2048 -b 2048`

- You can get more speed on computers with hybrid cores (a mix of p and e cores) by pinning llama.cpp to p-cores only. 

- Maybe even some more speed to win by offloading only up and down projection MoE layers: https://docs.unsloth.ai/basics/gpt-oss-how-to-run-and-fine-tune#improving-generation-speed
  - In my testing, the suggestion in that link is outdated.

- You should spend money on unified memory systems for models like this instead of on a strong GPU like 5090. For example, M4 Max has GPU equivalent to 4070 mobile, which is not super fast, but it can run this model at 75 t/s on llama.cpp and 95 t/s on mlx (though mlx implementation currently has slow PP speed).

- You want to only use 2 lanes if possible so 48x2. If you use all 4 ram slots your speed will be limited.

- For more "long running" sessions, servers, permanent agent running etc, llama.cpp, vLLM and especially ktransformers are FAAAAR better options.

- I am getting 10-11 tokens per second with GPT-OSS-120b on DDR5 4800, 7940HS CPU, 96GB RAM in LM Studio. Guessing I could get at least another 50% performance based on what you're saying
  - GLM 4.5 Air is running at 4-5 TPS with this setup. Qwen3 30b-A3B runs at about the same speed as GPT-OSS-120b.

- ## [gpt-oss-120b in 7840HS with 96GB DDR5 : r/LocalLLaMA _202509](https://www.reddit.com/r/LocalLLaMA/comments/1nf3fof/gptoss120b_in_7840hs_with_96gb_ddr5/)
  - With this setting in LM Studio Windows, I am able to get high context length and 7 t/s speed (noy good, but still acceptable for slow reading).
  - Is there a better configuration to make it run faster with iGPU (vulkan) & CPU only? I tried to decrease/increase GPU offload but got similar speed.
  - I read that using llama.cpp will guarantee a better result. Is it significantly faster?

- Don't force the experts onto CPU, just load them all in gpu, that's why you have the iGPU in the first place! You should be able to load ALL the layers on GPU as well.

- Loading all layer to iGPU will result unable to load vulkan0 buffer, I think because only 48GB can be allocated to my iGPU
  - No, . Put them all there, it will work. If dont, put 23 or so, do a tryout load. VRAM is also your shared ram, all equal. I got ryzen 7940hs, runing unsloth Q4-K-XL, with 20K context, its about 63Gb of space, i just put all on the GPU on LMstudio, ans just one processor on inference. I get 11 tokens per second, linux mint.

- Thoughts from someone who has the same iGPU and used to have 96GB memory:
  - Your offload config looks about right for your memory size (I wrote a comment about it on a lower message thread)

- ## [Managed to get GPT-OSS 120B running locally on my mini PC! : r/selfhosted _202508](https://www.reddit.com/r/selfhosted/comments/1mk6jlt/managed_to_get_gptoss_120b_running_locally_on_my/)
  - I was able to get the GPT-OSS 120B model running locally on my mini PC with an Intel U5 125H CPU and 96GB of RAM to run this massive model without a dedicated GPU, and it was a surprisingly straightforward process. The performance is really impressive for a CPU-only setup. 
  - MINIPC: Minisforum UH125 Pro
  - CPU: Intel u5 125H
  - RAM: 96GB
  - Model: GPT-OSS 120B (Ollama)
  - prompt eval rate: 31.83 tokens/s
  - eval rate: 2.77 tokens/s
  - This is running on a mini pc with a total cost of $460 ($300 uh125p + $160 96gb ddr5)

- ## [You can now run OpenAI's gpt-oss model on your local device! (14GB RAM) : r/selfhosted _202508](https://www.reddit.com/r/selfhosted/comments/1mjbwgn/you_can_now_run_openais_gptoss_model_on_your/)
  - The 20B model runs at >10 tokens/s in full precision, with 14GB RAM/unified memory. Smaller versions use 12GB RAM.
  - The 120B model runs in full precision at >40 token/s with ~64GB RAM/unified mem.
  - There is no minimum requirement to run the models as they run even if you only have a 6GB CPU, but it will be slower inference.
  - Thus, no is GPU required, especially for the 20B model, but having one significantly boosts inference speeds (~80 tokens/s). With something like an H100 you can get 140 tokens/s throughput which is way faster than the ChatGPT app

- ## [What hardware to run gpt-oss-120b? : r/LocalLLaMA _202508](https://www.reddit.com/r/LocalLLaMA/comments/1miggb2/what_hardware_to_run_gptoss120b/)
- 64GB RAM with ~16GB - 24GB VRAM offloading, or just 128GB RAM.

- Is it really possible to run it with just 128 GB RAM and no VRAM?
  - I'm running it with 96GB RAM and 12GB VRAM and it's usable
  - my setup: 2x RTX 4070, 96GB DDR5 6400MHz RAM, Ryzen 9 7900X
  - It's not a memory issue with WSL (I know that an I've allocated 80 GB of memory to WSL), it just doesn't run very fast. I hit around 10-15 tokens/sec with CPU on Windows using LM Studio, but running it in the same LM Studio (or Ollama) on Linux does not go well. I'm getting around 0.8 tokens/sec, not sure why.
  - I'm running the 20B version at around 200-250 tokens/sec though, which is great
  - I can run it straight from CPU on 96GB and it seems to run about the same. I'm not sure. to stop LM Studio from using my GPUs, I ran it on a WSL instance without GPU access, it got the same-issue Tok/s, maybe slightly lower by the token per second, but really not that big of a difference when it's already that slow

- I was able to run gpt-oss-120b in LM-studio on a 5060ti 16Gb video card + 64Gb DDR4 RAM. I placed 8 layers in video memory, the rest in RAM. The performance was 10 tokens per second, for comparison, the younger model worked at a speed of 85 tokens per second.

- ## ðŸ’¡ðŸš§ [gpt-oss 120B is running at 20t/s with $500 AMD M780 iGPU mini PC and 96GB DDR5 RAM : r/LocalLLaMA _202510](https://www.reddit.com/r/LocalLLaMA/comments/1nxztlx/gptoss_120b_is_running_at_20ts_with_500_amd_m780/)
  - Everyone here is talking about how great AMD Ryzen AI MAX+ 395 128GB is. But mini PCs with those specs cost almost $2k. 
  - I searched for mini PCs that supported removable DDR5 sticks and had PCIE4.0 slots for future external GPU upgrades. 
  - I focused on AMD CPU/iGPU based setups since Intel specs were not as performant as AMD ones. The iGPU that came before AI MAX 395 (8060S iGPU) was AMD Radeon 890M (still RDNA3.5). Mini PCs with 890M iGPU were still expensive.
  - The cheapest I could find was Minisforum EliteMini AI370 (32GB RAM with 1TB SSD) for $600. Otherwise, these AI 370 based mini PCs are still going for around $1000.
  - Next, I looked at previous generation of AMD iGPUs which are based on RDNA3. I found out AMD Radeon 780M iGPU based mini PC start from $300 for barebone setup (no RAM and no SSD). 780M iGPU based mini PCs are 2x times cheaper and is only 20% behind 890M performance metrics. 
  - I checked many online forums if there was ROCm support for 780M. Even though there is no official support for 780M, I found out there were multiple repositories that added ROCm support for 780M (gfx1103)
  - ðŸ–¥ï¸ I bought MINISFORUM UM870 Slim Mini PC barebone for $300 and 2x48GB Crucial DDR5 5600Mhz for $200. I already had 2TB SSD, so I paid $500 in total for this setup.
  - There was no guidelines on how to install ROCm or allocate most of the RAM for iGPU for 780M. So, I did the research and this is how I did it.
  - I know ROCm support is not great but vulkan is better at text generation for most models (even though it is 2x slower for prompt processing than ROCm).
  - Mini PCs with 780M are great value and enables us to run large MoE models at acceptable speeds. Overall, this mini PC is more than enough for my daily LLM usage (mostly asking math/CS related questions, coding and brainstorming).
  - I was getting great numbers that aligned with dual DDR5 5600Mhz speeds (~80GB/s).
  - I know ROCm support is not great but vulkan is better at text generation for most models (even though it is 2x slower for prompt processing than ROCm).

- ROCM with gpt-oss 120B mxfp4
  - tg128: 18.7 
- VULKAN (RADV only) all with Flash attention enabled
  - qwen3moe 30B. A3B Q4_1:  32.6, 22.3
  - gpt-oss 20B MXFP4 MoE: 28.1, 24.8
  - gpt-oss 120B MXFP4 MoE:  20.4, 18.1
  - qwen3moe 235B. A22B Q3_K:4.3
  - glm4moe 106B. A12B Q4_1:9.1

- just in case someone wants to compare with strix halo:
- STRIX-HALO @ Debian 13 6.16.3+deb13-amd64 (kernel >= 6.16.x for optimal memory sharing)
- ROCm
  - gpt-oss 120B MXFP4 MoE: 47.8
- Vulkan
  - gpt-oss 120B MXFP4 MoE: 51.5

- For me also same but the problem is when context become big speed decrease
  - I get 18t/s at 8k context 

- DDR5 is almost 2x faster than my DDR4 tower PC with AMD Ryzen 5950x CPU. DDR6 should come soon (2026 or 2027?). Also, It is high time that consumer PC industry embraced quad channel memory setup (e.g. DDR5 with 4 channels in mini PC would be amazing).

- Pretty incredible is 96gb the max or can it go 128?
  - it can potentially go up to 256GB but I could not find SO-DIMM DDR5 with that size. But yes, 2x64GB = 128GB is possible but those sticks are expensive! From $200 for 96GB to $400 for 128GB. So, 96GB is cost effective.

- with 90GB RAM allocated to iGPU, gpt-oss-120b-GGUF should comfortably fit 64k context. Also, running with that context will be slow for the initial cache loading (it may take hours).
  - Update: just laoded gpt-oss 120b with 130k context. With flash attention, that context took extra 5GB only. So, I would say it is possible to load the full context.

- 2x64GB dual channel near or above 6000 mt/s are not seen yet. 2x48GB dual channle can go up to 6800mst/s and some may overclock(è¶…é¢‘) it to even higher speed depending your luck, may not be stable.
  - The key is to use 2 slots only. 4 slots will drop the speed significantly even from the exact same brand model spec.

- Is this a one-off for only running gpt-oss 120B or is this platform expected to be somewhat future proof and newer models a likely to work on it?
  - Yes. This is future proof as long as llama.cpp and vulkan exist. Yes, this will run Qwen3 235B. Q3 should run at 6t/s.

- did you also compare the performance against running it on the CPU only, without iGPU? If I remember correctly, using the iGPU mostly improves pp performance while tg is still limited by the (shared) memory bandwidth speed? Is that (still) true?
  - Also, since you seem into getting the most out of (relatively) limited hardware, I think it could be an interesting experiment to run a bigger MoE using mmap and a PCIe Gen 4 NVMe SSD (max. ~8 GB/s). I think this might be surprisingly usable for use cases without limited context, etc.
- Yes, I tested with ik-llama for CPU. The best I got for gpt-oss 120b with CPU was 13t/s. So, iGPU improves TG by ~65-70%. I also tried glm 4.5 air in vulkan. I got 9t/s TG. I haven't tried SSD offloading. But yes, I could try qwen3 235B Q4 for that.

- Excellent results! My M4 Max 128GB was more like $6k and is only about 2.5X faster (55tok/s) with flash attention. Without flash attention, itâ€™s down around <10tok/sec.
  - What a cool budget option you found! gpt-oss-120b is a great tool-using, private, safe LLM.

- I squeeze 11 tokens/ s with mini pc ryzen 7940hs, 780M and 64 GB 5600 mhz ddr5. Vulkan cpp. I fit 21 Layers. The rest goes to cpu. Inference 6 cpu cores. Context 18000. Maybe 20000. Linux mint mate latest version. Do not use last vulcan cpp 1.51. Use 1.50.2
  - I get 13 t/s with CPU only in ik-llama cpp

- Can you give AMDVLK a try in addition to RADV for your Vulkan perf? On my (completely different but still AMD so it may transfer to yours) hardware AMDVLK basically matches ROCm in PP while still being slightly faster than ROCm at TG (not as fast as RADV though).
  - you're right, RADV starts off slower, but then doesn't slow down as much when context increases.

- Can someone do the same with a Ryzen AI HX 370? They are on Alibaba for around 400$ now (Mini PCs incl an Oculink port) and can be equipped with 128GB DDR5.

- Whats the max context it can run?
  - I have not tested it yet. But with 90GB RAM allocated to iGPU, gpt-oss-120b-GGUF should comfortably fit 64k context. Also, running with that context will be slow for the initial cache loading (it may take hours).
  - Update: just laoded gpt-oss 120b with 130k context. With flash attention, that context took extra 5GB only. So, I would say it is possible to load the full context.
- The problem with context is not at the ininitial run, it tends to deminish the infererence speed as the context filled up.

- I wonder what speedup you would get if you slapped a 3060 12gb EGPU onto it
  - much slower. I have a mini PC with an even older iGPU (680m), and I run almost all MoE models > 20B sometimes faster than folks with 12GB vRAM

- Would a similar approach work with say an Intel iGPU on a desktop motherboard using vulkan? I've got an older 12th Gen i7 but 4x64gb DDR4 (will be slow I know) and wondering how it would compare to just CPU-only.
  - It should be possible but ddr4 will be 2 times slower
- No, desktop iGPUs are very weak, usually. They just exist to provide video out. AMD has some large desktop iGPUs (the G series processors), but I don't think Intel does. Intel iGPUs are also generally not as good as AMD's, at least for llama.cpp.

- ## [More RAM or faster RAM? : r/LocalLLaMA _202510](https://www.reddit.com/r/LocalLLaMA/comments/1nzf0zf/more_ram_or_faster_ram/)
  - If I were to run LLMs off the CPU and had to choose between 48GB 7200MHz RAM (around S$250 to S$280) or 64GB 6400MHz (around S$380 to S$400), which one would give me the better bang for the buck? This will be with an Intel Core Ultra.
- Little to no difference in speed. You need to optimize for the number of memory channels you have to ensure the highest bandwidth possible.
  - This is why folks opt for older Xeon or Epyc machines, because even with slower ram, they have oodles(å¤§é‡æˆ–å¾ˆå¤š) more ram bandwidth.

- I bought 2x64 sticks at 6400 on paper but only 5600 stable for my system. I can run GLM 4.6 at 5 t/s and q2, but it beats anything else I could run easily. Cost me 380 euros, totally worth it.

- More Ram.. I use all 32 GB Vram from RTX5090 and 50+ GB Ram just to run Wan2.2.
  - I would say at the minimum you should get 128 GB ram if you want to run LLM (so you can offload and run 70B model). 
  - Personally my spec is 5090 + 256 GB ram so I can offloading most mid size LLM.

- VRAM is up to 20 times faster than 6000MHz RAM, there lies your answer
  - Those models are MoE models and will run at usable speed. Even a 355b GLM 4.6 runs at 4 to 5 tokens per second on 128gb ram on my system. 
  - With upcoming implementations of MTP this might get uplifted into the 10 tokens per second range. MoE models are also getting sparser and sparser. 128 GB ram even if it's just dual channel is absolutely worth it in my opinion.

- Neither of those rams will make a significant difference in inference speeds for llms, both are quite slow bandwidth wise. The useful bit of those ram kits is the capacity, could you get a cheaper 64gb kit instead?

- You even sure your CPU and mobo can utilize these speeds?

- 
- 
- 
- 
- 
- 
- 

- ## ðŸ–¥ï¸ æˆ‘æƒ³ä¹°ä¸ª å·²è£…å¥½ä½†å¯è‡ªå·±é…ç½®çš„å°å¼æœºå·¥ä½œç«™ æˆ– è‡ªå·±ä¹°æœºç®±/cpu/2å¼ 3090æ˜¾å¡è‡ªå·±è£…å°å¼æœº, è¦æ±‚å°å¼æœºçš„æœºç®±è¦å°½é‡å°ï¼ŒåŒæ—¶èƒ½å‘æŒ¥å¤šå¼ æ˜¾å¡çš„è®¡ç®—èƒ½åŠ›ï¼Œæ•£çƒ­è¦æ­£å¸¸
- é“­ç‘„ ARL-HX è¿·ä½ åŒå¡å·¥ä½œç«™
  - å†…éƒ¨æ­è½½äº†ä¸¤å¼ Intel Arc Pro B60æ˜¾å¡ï¼Œåˆè®¡æä¾›48GB GDDR6æ˜¾å­˜

- [æ±‚æŽ¨èä¸€æ¬¾å°åž‹æœºç®±ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/1945481402184364122)
  - åšå®šå°åž‹åŒ–ï¼Œå°±å¾—æŠŠé¢„ç®—æåˆ°600ä»¥ä¸Šã€‚ä¸ªäººæŽ¨èæ–¹ç³–æœºæ¢°å¤§å¸ˆc28è¿™ä¸ªåž‹å·ï¼Œå»ºè®®ç›´æŽ¥ä¸Šé—²é±¼æœäºŒæ‰‹çš„
  - åšæŒè¦å°æœºç®±ä¸ä»…æ˜¯æé«˜é¢„ç®—çš„é—®é¢˜ï¼ŒåŽé¢è£…æœºä¼šæœ‰ä¸€å †éº»çƒ¦

- ### [2025å¹´5æœˆæ›´æ–°ï¼Œç”µè„‘æœºç®±æŽ¨èã€‚æŽ¨èä¸€æ³¢é«˜é¢œå€¼çš„æœºç®±ã€‚åŒ…å«ITX, M-ATX, ATX, E-ATXæœºç®±](https://www.zhihu.com/tardis/zm/art/210537601?source_id=1003)
- ITXï¼šä¸“é—¨ä¸ºå°åž‹ç”µè„‘æœºç®±è®¾è®¡çš„ä¸»æ¿è§„æ ¼ï¼Œå°ºå¯¸ 170mmÃ—170mmã€‚
  - mini-itxæœºç®±çš„ç‰¹ç‚¹æ˜¯æ¯”è¾ƒå°å·§ï¼Œæºå¸¦ç›¸æ¯”å¤§æœºç®±è¦æ–¹ä¾¿äº›ï¼Œä½†æ˜¯æ•£çƒ­ç›¸å¯¹å¤§æœºç®±è¦å·®ä¸€ç‚¹ç‚¹ï¼Œä¹Ÿæœ‰æ•£çƒ­å¾ˆå¥½çš„ITXæœºç®±ã€‚ITXæœºç®±çš„å¦ä¸€ä¸ªç¼ºç‚¹å°±æ˜¯é…å¥—çš„ä¸»æ¿åŠç”µæºè¦è´µä¸å°‘ã€‚
- DTXï¼šå°ºå¯¸ä¸º170mmÃ—203mmã€‚è¿™ä¸ªå°ºå¯¸çš„ä¸»æ¿å¾ˆå°‘è§ï¼ŒROGçš„éƒ¨åˆ†é«˜ç«¯ä¸»æ¿æ˜¯è¿™ä¸ªè§„æ ¼ï¼ˆå¦‚ROG C8Iä¸»æ¿ï¼‰ï¼Œè¿™ä¸ªè§„æ ¼ä¹Ÿæ˜¯ä¸ºå°é’¢ç‚®è®¾è®¡çš„ï¼Œéƒ¨åˆ†ITXé’¢ç‚®æœºç®±æ”¯æŒè¿™ä¸ªå°ºå¯¸ï¼Œè´­ä¹°æœºç®±çš„æ—¶å€™éœ€è¦ä»”ç»†çœ‹çœ‹
- ATXï¼šATX å¯ä»¥ç†è§£ä¸ºå…¨å°ºå¯¸ä¸»æ¿ï¼Œå°ºå¯¸305mmÃ—244mmã€‚
  - ATXï¼ˆä¸­å¡”ï¼‰æœºç®±æ˜¯ç›®å‰å¤§éƒ¨åˆ†ç”¨æˆ·çš„é€‰æ‹©ï¼Œè¿™ç±»çš„æœºç®±å°ºå¯¸åå¤§ï¼ŒåŸºæœ¬éƒ½æ”¯æŒATXï¼ŒM-ATXï¼ŒITXç‰ˆåž‹ï¼Œéƒ¨åˆ†æ”¯æŒåŒ…æ‹¬E-ATXåœ¨å†…çš„æ‰€æœ‰ç‰ˆåž‹ã€‚
  - ä¼˜ç‚¹åœ¨äºŽæ•£çƒ­å¥½ï¼ŒATXæœºç®±åŸºæœ¬éƒ½æ”¯æŒ240åŠ360æ°´å†·ï¼Œå¯¹å¤§åž‹åŒå¡”é£Žå†·æ•£çƒ­çš„æ”¯æŒä¹Ÿæ›´å¥½ã€‚
  - æ‰©å±•ä½å¤šï¼Œæ–¹ä¾¿å®‰è£…æ›´å¤šçš„ç¡¬ç›˜ç­‰è®¾å¤‡ã€‚
- M-ATXï¼šå°±æ˜¯ç¼©å°ç‰ˆçš„ ATXã€‚é•¿244mmï¼Œå®½åº¦æœ‰å¤šç§è§„æ ¼ã€‚ä¸»æµä¸º244mmÃ—244mmã€‚
  - M-ATXæœºç®±çš„ä¼˜ç‚¹åœ¨äºŽå¤§å°é€‚ä¸­ï¼Œé…å¥—çš„M-ATXä¸»æ¿ä»·æ ¼åˆé€‚ï¼Œæ€§ä»·æ¯”é«˜ï¼Œæ‰©å±•æ€§ä¹Ÿå¤Ÿç”¨ï¼Œæ˜¯å¤§éƒ¨åˆ†ç”¨çš„é€‰æ‹©ã€‚
  - M-ATXæœºç®±çš„æ•£çƒ­ä¹Ÿä¸é”™ï¼Œå¾ˆå¤šéƒ½æ”¯æŒ240æ°´å†·åŠä¸­ç­‰å°ºå¯¸çš„é£Žå†·ã€‚
  - ä½†æ˜¯ç›®å‰ä¼˜ç§€çš„M-ATXæœºç®±æ¯”è¾ƒå°‘ï¼Œå°¤å…¶æ˜¯é«˜ç«¯çš„M-ATXæœºç®±å‡ ä¹Žæ˜¯ç©ºç™½ã€‚
- E-ATXï¼šåŠ å¤§åž‹ä¸»æ¿ï¼Œå°ºå¯¸305mm Ã— 330 mmã€‚ä¸»è¦ç”¨äºŽæœåŠ¡å™¨ä¸»æ¿ã€‚ä¾‹å¦‚æ­é…AMD 3990Xçš„ä¸»æ¿ã€‚
  - E-ATXï¼ˆä¸­å¡”ï¼Œå…¨å¡”ï¼‰æœºç®±æŽ¨è, è¿™ç±»åž‹çš„æœºç®±æ¯”è¾ƒå¤§ï¼Œé€šå¸¸éƒ½æ”¯æŒ360æ°´å†·ï¼Œå¤§åž‹é£Žå†·ï¼Œæ•£çƒ­åŸºæœ¬éƒ½éžå¸¸ä¼˜ç§€ã€‚ç¡¬ç›˜ä½ä¹Ÿå¾ˆå¤šã€‚
  - è¿™ç±»åž‹çš„æœºç®±æ¯”è¾ƒé€‚åˆæ¸¸æˆå‘çƒ§å‹ï¼Œæˆ–æœåŠ¡å™¨å·¥ä½œç«™ã€‚
  - åšæœåŠ¡å™¨æˆ–å·¥ä½œç«™ç”¨çš„æœ‹å‹å»ºè®®è€ƒè™‘ä½¿ç”¨åˆ†å½¢å·¥è‰ºçš„Meshify 2å’ŒD7ï¼Œä»¥åŠè¿™ä¸¤æ¬¾æœºç®±çš„XLåž‹å·ï¼ˆåŒæ˜¾å¡ç”¨ï¼‰ã€‚æˆ‘ä¸ªäººåœ¨ä½¿ç”¨è¿™ä¸¤æ¬¾æœºç®±ï¼Œæ•£çƒ­ä¼˜ç§€ï¼Œè®¾è®¡ï¼Œç”¨æ–™ï¼Œåšå·¥éƒ½éžå¸¸ä¸é”™ã€‚Meshify 2æ˜¯çªå‡ºæ•£çƒ­ï¼ŒD7æ˜¯çªå‡ºé™éŸ³ã€‚
  - åˆ†å½¢å·¥è‰º Torrent: ç®±ä½“é•¿å®½é«˜ï¼ˆmmï¼‰544ï¼ˆé•¿ï¼‰*242ï¼ˆå®½ï¼‰*530ï¼ˆé«˜ï¼‰mm

- ### [25L Portable NV-linked Dual 3090 LLM Rig : r/LocalLLaMA _202506](https://www.reddit.com/r/LocalLLaMA/comments/1l0zsv7/25l_portable_nvlinked_dual_3090_llm_rig/)
  - cpu: AMD Ryzen 7 5800X 3.8 GHz 8-Core Processor
  - Motherboard: Asus ROG Strix X570-E Gaming ATX AM4 Motherboard
  - NVlink SLI bridge
  - Mechanic Master C34Plus Portable Desktop ATX Case with Aluminum Handle: 5.2 Kilograms, 39.1 x 18.5 x 34.3 cm.
  - CORSAIR RMe Series Fully Modular Low-Noise Power Supplies: 1200 watts
  - âš ï¸ WARNING - these components don't fit if you try to copy this build. The bottom GPU is resting on the Arctic p12 slim fans at the bottom of the case and pushing up on the GPU. Also the top arctic p14 Max fans don't have mounting points for half of their screw holes
  - All that being said, with a 300w power limit applied to both gpus in a silent fan profile, this rig has surprisingly good temperatures and noise levels considering how compact it is.
  - During Cinebench 24 with both gpus being 100% utilized, the CPU runs at 63 C and both gpus at 67 Celsius somehow with almost zero gap between them and the glass closed. All the while running at about 37 to 40 decibels from 1 meter away.
- I did a bunch of testing back when I had a 4x 3090 rig. The sweet spot was always between 250-300W for inference. Above that I saw no improvement in inference speed (this was a DDR4 system, YMMV with DDR5). Below 250 speed would start dropping off quite quickly.
  - If memory serves me, I settled on 275W and enjoyed the power savings while not sweating the .05 tokens/sec it cost me for not running over 300W
- Neat build. Even power limiting to 200W doesn't have that big of a hit on inference. (Exl2)
  - I power limit all mine to 200w. It's perfectly fine.

- ### [Smallest case possible for dual gpu? : r/sffpc _202312](https://www.reddit.com/r/sffpc/comments/187og11/smallest_case_possible_for_dual_gpu/)
- Someone else just posted details of their NR200 build with dual 4090s, might be worth a look?
  - 18.49 x 37.49 x 29.18 cm
  - æ–°æ¬¾mini-itxæ˜¯ NR200P V2
- Didn't realise the NR200 had the possibility of going dual GPU. I'mm super new to SFF.
  - pretty sure you would have to do PCIe birfurcation for that
- Yeah, max mobo you're going to fit in there is an ITX, and building round it already a squeeze with one GPU to think about (with any kind of air CPU cooler)

- check out Cerberus (mATX) or Cerberus X (full ATX)

- Generally sff cases are designed around ITX motherboards with only one pcie slot, finding a sff case that will fit an m-ATX motherboard is going to be near I possible. I have a nr200p same as the guy with dual 4090s, it only officially supports ITX boards.. it's also not really small form anymore (I have a tophat with a radiator it)

- [Smallest case for mATX + air cooled cpu + 2 gpu : r/buildapc _202308](https://www.reddit.com/r/buildapc/comments/15x7h9h/smallest_case_for_matx_air_cooled_cpu_2_gpu/)
  - Asus Prime AP201 MicroATX Mini Tower Case: 20 x 35 x 46
  - Sliger Cerberus. mATX case much smaller than the Asus AP201 (huge at 33L, when the Sliger Cerberus is 19.6L).

- [Good pc case for dual gpu setup? : r/VFIO _202402](https://www.reddit.com/r/VFIO/comments/1ao7gsj/good_pc_case_for_dual_gpu_setup/)
  - Take a look at Fractal Design Meshify 2, or even the XL version. It should have plenty room for what you want.

- ### [Small-form-factor all-air-cooled dual RTX 3090 SLI 1000W build : r/sffpc _202107](https://www.reddit.com/r/sffpc/comments/orug4s/smallformfactor_allaircooled_dual_rtx_3090_sli/)
  - Case: Sliger Cerberus X
  - Motherboard: MSI MEG X570 Godlike
  - CPU: AMD Ryzen 5600X
  - RAM: HyperX Predator 32GB 3333Mhz
  - GPU: 2x RTX 3090 Founder's Edition SLI
  - PSU: Silverstone SX1000 Platinum SFX-L
  - CPU Cooler: Cryorig H7
  - Case fans: 2x Arctic P14 140mm, 3x BeQuiet Pure Wings 2 92mm
  - Temps under full load: GPU core 66/50, GPU memory junction 102/102, CPU 85
  - Using software to estimate power draw at full load I'm guessing around 800W. I am confident the PSU can handle a 5900X even without undervolting but temps would be an issue so I'm leaving it with the 5600X for now. The 5600X is slightly undervolted using PPT 70W, negligible performance hit compared to stock but a few degrees lower temps.

- ### [Looking for a 2 x 3090 case : r/LocalLLaMA _202503](https://www.reddit.com/r/LocalLLaMA/comments/1j3h23g/looking_for_a_2_x_3090_case/)
  - I am looking for either a case or an open air rig where I could fit two 3090 FE connected with nvlink.
  - I need to be able to use pcie extender otherwise there is not enough spacing on the Mobo for putting the nvlink because of the 3 slots GPUs.

- I feel like this shouldn't require too much special consideration. I have a standard mid-tower case and it fits 2 3090s in it just fine.

- If you can afford it, phanteks enthoo pro 2 server edition is amazing. Internal fan bracket lets you direct air onto the gpus. My 2x3090s stay below 30 C at idle, and never go above 70 on load.
  - 24 x 56 x 58, 77L

- I can just barely fit 3 MSI 3090s in my Corsair 7000D Airflow, 2 horizontal and one vertical with riser. Tons of fans.
  - 24 x 55 x 60

- Almost any full ATX case with 8 pcie slots would work fine. Antec P101 for example.

- [Smallest case for dual air-cooled 3090's? : r/sffpc _202104](https://www.reddit.com/r/sffpc/comments/mzfg3p/smallest_case_for_dual_aircooled_3090s/)
- Wondering if getting a smaller case with Quadro A6000 would be better option than bigger case with Dual 3090?
  - An A6000 would be amazing but itâ€™s just so damn expensive. It doesnâ€™t make sense to me from a value perspective.
  - And since the 3090 and A6000 have the same amount of cuda cores, having dual 3090â€™s would actually give me up to twice the performance as a single A6000, but with the same amount of total memory.
- Are you sure you can combine the VRAM in your workload? You'd most likely need an NVLink bridge aswell.
  - The 3090 has NVLink, although certain features are disabled in software. For ML training though Iâ€™m pretty sure I would be getting the full NVLink bandwidth.

- Fractal R6 has a lot of room. So does the 7

- If you need the NVLink, you'll need one with two 16x slots spaced 4 slots apart (NVidia only sells 4-slot spacing NVLink-bridges). 
  - Also: Do you need the PCIE bandwith for your workload? Most consumer CPUs don't have enough PCIE lanes, so the two GPUs will be running in only 8x each.
- Yeah, Cerberus X won't be an option if you wanna aircool the CPU. The O11D is a pretty giant case (57L).
  - If you want something smaller, I'd recommend the Meshify C. It's just under 40L, has a standard mid-tower layout, can fit big ATX PSUs, a big aircooler like the NH-D15 and has good ventilation (if you add 3x 120mm fans in the front) so your GPUs will get enough airflow.

- ## [ä¸€æ¬¡æ€§ä»·æ¯”çˆ†æ£šçš„æ˜¾å¡å‡çº§ä¹‹æ—…ï¼šæŠ˜è…¾ V100 æ˜¾å¡ç»­é›†ï¼ŒäºŒæ‰‹ç¥žå¡è·‘ComfyUIï¼ - çŸ¥ä¹Ž _202507](https://zhuanlan.zhihu.com/p/1929587520502498303)
- Tesla V100 SXM2	
- V100 æ˜¯ Volta æž¶æž„ï¼ˆsm_70ï¼‰ï¼Œè€ŒçŽ°åœ¨ä¸€å † AI æ¡†æž¶éƒ½è¦æ±‚ Ampere èµ·æ­¥ï¼ˆsm_75 ä»¥ä¸Šï¼‰ã€‚å¯¼è‡´è¿™äº›æ¨¡å—ç›´æŽ¥æŠ¥é”™
- LTX-Video-Q8-Kernels çš„ setup.py æœªé€‚é… Tesla V100 çš„ sm_70 æž¶æž„ï¼Œä»…æ”¯æŒ Ampereï¼ˆsm_80+ï¼‰ç­‰è¾ƒæ–°æž¶æž„ã€‚
- Triton 3.3.0 ä¸Ž sm_70 å…¼å®¹æ€§å·®ï¼Œsageattention çš„ INT8 ä¼˜åŒ–å¯èƒ½ä¸æ”¯æŒ V100ã€‚PyTorch 2.7.1+ è¦æ±‚ sm_75ï¼Œè€Œ PyTorch 2.4.1 æ˜¯æœ€åŽä¸€ä¸ªæ”¯æŒ sm_70 çš„ç‰ˆæœ¬ã€‚ è§£å†³ï¼š å›žé€€åˆ° PyTorch 2.4.1 å’Œ Triton 3.0.0
- is_flash_attention_available æ˜¯ PyTorch 2.5.0+ çš„ APIï¼ŒPyTorch 2.4.1 ä¸æ”¯æŒã€‚
- FlashAttention-2 çš„ flash_attn_func ä¸å­˜åœ¨äºŽ FlashAttention-1ï¼ˆ1.0.9ï¼‰ï¼Œè€Œ V100ï¼ˆsm_70ï¼‰ä¸æ”¯æŒ FlashAttention-2ã€‚ è§£å†³ï¼š å®‰è£… FlashAttention-1
- PyTorch çš„ æ³¨æ„åŠ›æœºåˆ¶ï¼ŒFlashAttention-1æˆ–è€…xformerså†…å­˜æ•ˆçŽ‡ä½Žï¼Œè§†é¢‘ç”Ÿæˆæ¨¡åž‹ï¼ˆå¦‚ Wan2.1ã€Hunyuanï¼‰éœ€ å¤§é‡æ˜¾å­˜ï¼ŒV100 çš„ 16GB ä¸è¶³ã€‚è€Œsageattentionåˆä¸æ”¯æŒV100ï¼Œæ‰€ä»¥æš‚æ—¶æ— è§£

- ## [Laptop with 32 GB VRAM for Stable Diffusion : r/StableDiffusion _202305](https://www.reddit.com/r/StableDiffusion/comments/1353g26/laptop_with_32_gb_vram_for_stable_diffusion/)
- I don't think so, unless you do an "egpu" with a card in a separate case connected via thunderbolt. My card has 16gb VRAM and I can run a 2048x2048 without tiling. Tiling lets that go much higher, so that's the way to go if you want to do large images. Generally speaking the vram stuff is mostly an issue if you want to train LoRAs/embeddings/hypernetworks/etc.

- Is 16 GB of VRAM on your machine enough to train LoRAs and checkpoints? I can do very limited training with my current 8 GB VRAM machine, and I'd be very interested in training LoRAs and checkpoints to personalize my work. 
  - Yes, 16gb is enough. Until recently I was able to do batch sizes of 8 for Dreambooth fine-tuning, generally in other AI training it's good to do that or accumulate gradients

- ## [AMD è®¡åˆ’äºŽ 2026 å¹´æŽ¨å‡º Zen 6 æž¶æž„ Ryzen å¤„ç†å™¨ï¼Œæœ‰ä½•äº®ç‚¹å€¼å¾—æœŸå¾…ï¼Ÿ - çŸ¥ä¹Ž _202506](https://www.zhihu.com/question/1944114025425269198)
- 2006å¹´ï¼ŒATiè¢«AMDä»¥54äº¿ç¾Žå…ƒæ”¶è´­ï¼Œâ€œFusionèžåˆâ€æˆä¸ºæ–°AMDæœ€é«˜æˆ˜ç•¥ã€‚CPUã€GPUã€ä¸»æ¿èŠ¯ç‰‡ç»„ä¸‰è€…åˆä¸€ï¼Œé›†æˆä¸ºå‰æ‰€æœªæœ‰çš„SOCå•èŠ¯ç‰‡ï¼Œå³â€œAPUâ€ï¼Œå¼‚æž„è¿ç®—ä»¥æå‡è¿ç®—æ•ˆèƒ½
- 2017å¹´ï¼Œâ€œZenç¦…â€æž¶æž„çš„é”é¾™å¤„ç†å™¨ä¸Šå¸‚ã€‚å•èŠ¯ç‰‡è®¾è®¡çš„APUåŠ›æŒ½ç‹‚æ¾œï¼Œæ¡Œé¢å¤„ç†å™¨è§¦åº•åå¼¹ã€ç§»åŠ¨å¤„ç†å™¨è¿…é€Ÿå´›èµ·ã€æ‹¿ä¸‹åŒæ¸¸æˆä¸»æœºå¤§å•ã€‚ä½†ç§°é›„æ¡Œé¢ã€åˆ¶éœ¸æœåŠ¡å™¨ç«¯ï¼ŒAMDä¾é çš„æ˜¯Zen2å¼€å§‹çš„Chipletå¤šæ™¶ç²’æ¨¡å—åŒ–è®¾è®¡ï¼Œå¤šæ ¸å †æ­»è€å¸ˆå‚…ã€‚
- æ‘©å°”å®šå¾‹å¤±æ•ˆï¼Œå•èŠ¯ç‰‡é¢ç§¯æœ‰é™ï¼Œå…ˆè¿›åˆ¶ç¨‹ä»£ä»·æ˜‚è´µï¼Œå‰¥ç¦»äº†GFæ ¼ç½—æ–¹å¾·å·¥åŽ‚ã€å‡ è¿‘ç ´äº§è¾¹ç¼˜æŠ¢æ•‘å›žæ¥çš„AMDï¼Œå¿…é¡»å¾—ç²¾æ‰“ç»†ç®—
- æ–°ä¸€ä»£Zen6æž¶æž„ï¼ŒCCDè®¡ç®—æ ¸é¦–å‘2çº³ç±³åˆ¶ç¨‹ï¼Œè¿žè´¢å¤§æ°”ç²—çš„è‹¹æžœã€é«˜é€šéƒ½æ²¡æ•¢ä¸‹è¿™ä¹ˆé‡çš„æœ¬ã€‚
- AMDé€‰æ‹©å°†Chipletè¿›è¡Œåˆ°åº•ï¼š 2nmçš„Zen6 CCDè®¡ç®—æ ¸ï¼Œ2-3ç§3nmçš„RDNA5GPUï¼Œç”¨4ç§ä»¥ä¸Š3nmçš„APUç»„åˆåœ¨ä¸€èµ·
  - Strix Haloæž¶æž„é‚£é¢—AI MAX+ 395ä¸Šå–å¾—çš„ç»éªŒï¼Œæˆä¸ºæ—¥åŽçš„å°è£…æ ‡å‡†

- Strix Haloæž¶æž„çš„AI MAX+ 395ï¼Œæ€§èƒ½è¶³ä»¥åª²ç¾ŽRTX4060ï¼›åªæ˜¯åŒCCDè®¡ç®—æ ¸æ‹‰é«˜äº†æˆæœ¬ï¼Œè¯•æ°´æ–°å°è£…è‰¯çŽ‡ä¸é«˜ï¼Œåˆé‡ä¸ŠAIæŽ¨ç†æœ¬åœ°åŒ–çƒ­æ½®ï¼Œé€ æˆå‡ºåŽ‚ä»·å¥‡é«˜ï¼Œå•Uä»·æ ¼è¶…è¿‡4060æ¸¸æˆæœ¬æ•´æœºï¼Œå«å¥½ä¸å«åº§ã€‚

- 2027å¹´æœ«ä¸Šå¸‚çš„AI MAX 500ç³»åˆ—æ–°å“ï¼Œæ˜¯APUï¼Œä¹Ÿæ˜¯ä¸€é¢—å¯ä»¥åšæˆç‹¬æ˜¾çš„GPUï¼š
  - ã€å°æ¯ã€‘Medusa Halo miniï¼Œä¹Ÿæ˜¯ AT4 GPUï¼Œ12å¤§å°æ ¸2LPï¼Œ24CU RDNA5ï¼ŒPTX 1050åŒèŠ¯ï¼Œå¯¹æ ‡4060
  - ã€å¤§æ¯ã€‘Medusa Haloï¼Œä¹Ÿæ˜¯ AT3 GPUï¼Œè‡³å°‘å…·å¤‡12æ ¸ï¼Œå¯é€‰CCDè®¡ç®—æ ¸æ¡¥æŽ¥è¡¥é½ï¼Œ48CU RDNA5ï¼ŒPTX 1060åŒèŠ¯ï¼Œå¯¹æ ‡4070
  - å°æ¯ä½¿ç”¨128bit LPDDR5Xå†…å­˜æŽ§åˆ¶å™¨ï¼Œæ˜¾å­˜å¯è¾¾128Gï¼Œæ›´é€‚åˆç»æµŽæ¸¸æˆæœ¬
  - å¤§æ¯é‡‡ç”¨384bit LPDDR6å†…å­˜æŽ§åˆ¶å™¨ï¼Œæ˜¾å­˜å¯è¾¾512Gï¼Œé’ˆå¯¹ä»·æ ¼ä¸æ•æ„Ÿçš„AIè¡Œä¸šç”¨æˆ·

- ## [How well does ComfyUI perform on macOS with the M4 Max and 64GB RAM? : r/comfyui _202503](https://www.reddit.com/r/comfyui/comments/1jhifyi/how_well_does_comfyui_perform_on_macos_with_the/)
- TLDR - if you want to work linear on one image, a Mac is a huge waste of time. Maybe 25% of the speed of a decent NVIDIA PC for AI generation. 
  - However, if you know how or want to multitask, itâ€™s easily the best system you can purchase.

- I don't know if you'll find this information but based on estimates comparing to the M4 Pro, it should reach close to half the performance of an $800 PC with an RTX 3060

- I have a Mac Mini M4 Pro with 48GB of unified RAM. As my daily driver for everyday things, it's great, even great at media encoding, but for generative AI stuff, compared with my Linux PC with a RTX 4090 - it pales in comparison. We are talking minutes vs seconds here for a 1024x1024 Flux generation. Most of it is tuned for Nivida CUDA and that is the key. Apple Silicon offers great performance for everyday computing, but its support for machine learning frameworks like PyTorch sucks butt compared to CUDA.

- I transitioned from dabbling with generative AI images on M1 Max Macbook to using a PC that I owned with Nvidia RTX 3060 graphics card. 
  - The PC with ComfyUI was 3 times faster than my Mac which was using DrawThings (I installed ComfyUI on Mac but abandoned it because DrawThings was more convenient and faster). 
  - After getting more involved I ended up buying a PC with Nvidia RTX 4090 graphics card. Very happy with that decision. I love the Mac for most things but most likely even the M4 Max might prove to be frustrating to use to keep up with the rapid advances in the ComfyUI - Stable Diffusion world.

- AI image and video generation require cuda cores to function properly so Apple or even AMD gpus are not recommended.

- I ran ComyUI Flux Schnell, Pro and several LORAs on Mac studio Max4 base model and most models will run fine. I only ran into memory issues with video generation therefore moved to M3 Ultra 96GB. I dont have a reference point with PC but i am getting 15-30sec for 1024x1024 img generation for most workflows.
  - That's pretty slow. A NVIDIA 3090ti 24gb PC can do that in under half that

- my Mac M4 16gb is much more slower than my old PC with the good old Geforce 3060. An Apple a day keeps the Comfyui away.

- ## [Setting up ComfyUI with AI MAX+ 395 in Bazzite : r/StableDiffusion _202510](https://www.reddit.com/r/StableDiffusion/comments/1nux1f0/setting_up_comfyui_with_ai_max_395_in_bazzite/)
  - Qwen took 3 min 20s with fp8 image and clip at 20 steps
  - 1 min 22s for Qwen 4-step lightning lora with 8 steps - 8-step lora doesn't work since it's bf16
  - Flux was super slow first time, running flux-dev at fp8, but after that it was about 1 min 51s
  - WAN 2.2 fp8 high-lo 20 steps took 4 min 14s for an image (no speed up lora)
  - WAN 2.2 fp8 with Lightx2v took 18 seconds for an image

- 3 times more expensive than 4070 but 3 times slower than 4070?
  - The purpose is the 128gb of unified ram, it's meant for LLM use, not image generation. 
  - Obviously if you only care about small models that fit in 16gb vram there are way cheaper and faster methods.

- [System Question: AMD Ryzen AI Max + 395 with 128GB LPDDR5x 8000mhz Memory -- Will this work to run ComfyUI? : r/comfyui](https://www.reddit.com/r/comfyui/comments/1nr9ttv/system_question_amd_ryzen_ai_max_395_with_128gb/)
  - It would be really sloooooow. Assuming youâ€™re talking about ai max. There is a YouTube video of a review in Chinese. He shows running some T2i and t2v using some Chinese software. Regardless it was super slow.
  - TLDR CUDA is still king.
- You can load large LLMs and run them decently on that machine but it is not meant for heavy image and video work. 
  - A dedicated GPU will run rings around that machine for rendering time. With a 5090 I can generate 8 seconds of 720p video with FP16 high and low noise models and Loras using sage attention 2 in about 3 to 5 minutes, you donâ€™t need to be running them as high as I am if you want good results with 16 a 24gb vram. 
  - The main difference is that VRAM is faster (much faster) than ram and the GPU chip turns out many more TFLOPS of 16 floating point precision than the tiny 8060S can, not to mention the LPPDR 8000 ddr ram is much slower than GDDR7. 
  - If you just want to run language models get that machine. Otherwise, youâ€™ll be badly equipped and your render times will be forever

- ## [DIY vs Nvidia dgx spark? : r/StableDiffusion _202509](https://www.reddit.com/r/StableDiffusion/comments/1nfoi9d/diy_vs_nvidia_dgx_spark/)
- As already suggested, go for 5090. Or if you need more VRAM and have the budget, go for RTX PRO 6000 (if you are planning some video work, that may be a better option).

- The spark can be a good option for LLMs but not for image generation. Here the currently best options that you can run in an office are the 5090 and the RTX Pro 6000.
  - When it's coming to training you could (should) even consider multiple 5090 like 2 or 4.

- just buy 5090, DGX spark is 40/5060 Ti ish performance

- Spark can do nvlink? did you mean network based NCCL?
  - You want to train Stable Diffusion, i assume UNET based model like XL and 1.5 variant. The less pain in the ass way to train in multi gpu setup is DDP. splitting unet is pain you need special libs like https://github.com/mit-han-lab/distrifuser
  - Incur communication cost, no free meal, DDP even though less demanding than FSDP in communication, it stilll need allreduce the gradient across rank.
  - Is 128G VRAM really important for your use case? DGX Spark is mainly for LLM workflow, large weight model but low active compute sequence (tokens), since LLM sequence isn't as crazy as diffusion models.
  - Engineering and salary cost. Your engineer need to learn to parallelizing gpu, manage networking, setting up torch distribution
  - Most SD trainer is mainly for single gpu
  - DGX Spark is not GDDR memory but LPDDR, and boy moving tensor from GDDR to share memory (gpu internal memory) is already slow, relative to SM speed, and now LPDDR is much slower

- ## [Will this thing work for Video Generation? NVIDIA DGX Spark with 128GB : r/StableDiffusion _202504](https://www.reddit.com/r/StableDiffusion/comments/1ju2mfk/will_this_thing_work_for_video_generation_nvidia/)
- For a machine with 128 GB of LPDDR5 with 273 GB/s memory bandwidth and a paltry 200 GbE ConnectX-7 I find $4k a bit much.

- 4090 still superior to this despite the 128GB of memory. That memory speed is much slower and the TOPS is lower. A 4090 is still best dollar value if your focus is SD and video.

- Check out the HP Z2 G1a that's dropping on Monday. Allocate up to 96GB of RAM to the GPU (I've heard that on Linux you can allocate even more) and the price has surprised me. I'll be getting one as soon as I know Ollama and SD support its APU.
  - Yes, it's 110GB on Linux. Are you surprised that the price is so high? Other Strix Halo machines also with the same APU and the same 128GB of RAM are much cheaper. The Framework Desktop starts at $2000 or just $1700 to buy the motherboard. The GTK is well spec'ed out for around $1800 ready to run. Those are like half the cost of the HP.

- ## [DGX Spark? : r/comfyui _202506](https://www.reddit.com/r/comfyui/comments/1ljbgxn/dgx_spark/)
- 4090 or 5090 for images. RTX 6000 Pro if you're doing video. DGX Spark is for running medium to large-ish LLMs slowly and does not have the right mix of performance for image/video work.
  - The 6000 is about 3x the price of a 5090 so I'll have to think about that one.
  - 96GB of RAM on one GPU. Video models were mostly engineered to run on 80GB H100s. You can run them on less VRAM but with hokey compromises and limitations. Not saying people donâ€™t do it but I donâ€™t have the appetite, would rather just use models as intended.
- Yes, any RTX *90 series card will be faster. DGX Spark is targeted at large text based models. I would not buy this if you plan on using it for image/video gen.

- Just get a nuc and a pro 6000 Blackwell and you'll be set for a long while.
  - Wow it's at least 10kâ‚¬ just for the gpu!

- [NVIDIA says DGX Spark releasing in July : r/comfyui](https://www.reddit.com/r/comfyui/comments/1labkat/nvidia_says_dgx_spark_releasing_in_july/)
  - Lmao. It has 1/5 the memory bandwidth and cuda cores of a rtx6000 pro. 
  - comfyUI would need to be able to run on arm CPU. All Mac users have ARM CPU 

- ## ðŸ§®ðŸ¤” [NVIDIA says DGX Spark releasing in July : r/LocalLLaMA _202505](https://www.reddit.com/r/LocalLLaMA/comments/1kq4ey4/nvidia_says_dgx_spark_releasing_in_july/)
- Let's do some quick napkin math on the expected tokens per second:
  - If you're lucky you might get 80% out of 273 GB/s in practice, so 218 GB/s.
  - Qwen 3 32B Q6_K is 27 GB.
  - A low-context "tell me a joke" will thus give you about 8 t/s.
  - When running with 32K context there's 8 GB KV cache + 4 GB compute buffer on top: 39 GB, so still 5.5 t/s. If you have a larger.
  - If you run a larger (72B) model with long context to fill all the RAM then it drops to 1.8 t/s.
- Yes, these architectures aren't the best for dense models, but they can be quite useful for MoE. Qwen 3 30B A3B should probably yield 40+ t/s. Now we just need a bit more RAM to fit DeepSeek R1.

- Is that how you can calculate the maximum speed? Just bandwidth / model size => tokens / second? I guess it makes sense, I've just never thought about it that way. I didn't realize you would need to transfer the entire model size constantly.
  - You don't transfer the model, but for every token generated it needs to go through the whole model, which is why it is bandwidth limited for single user local inference.
  - As for bandwidth, it's a MT/s multiplied by the bus width. Normally in desktop systems one channel = 64bit so dual channel is 128bit etc. Spark uses 8 of DDR5X chips of which each is connected with 32bits, so 256bit total. The speed is 8533MT/s and that give you the 273GB/s bandwidth. So (256/8)*8533=273056MB/s or 273GB/s.
- > "You don't transfer the model, but for every token generated it needs to go through the whole model"
  - Except when you use models with "sparse" support, apparently. Which is why its a big deal the things have hardware accel for sparse models.

- My MacBook Pro M1 Pro is close to 5yo and it runs qwen3 30B-a3B q4 at 45-47t/s on commands with context. It might drop to 37t/s with long context.
  - when you run a smaller quant like Q4 of the 30B A3B model you might get close to 60 t/s in your not-long-context case.

- Running the same Qwen model with a 32k context size, I can get 13+ tokens a second on my M4 Max.
  - With just 32k context size set, or also mostly filled with text? Anyway, 13 tps * 39 GB gives us about 500 GB/s. The M4 Max has 546GB/s memory bandwidth, so this sounds about right, even though it's a bit higher than expected.

- thank you. those numbers look terrible. I have a 3090, I can easily get 29 t/s for the models you mentioned.
  - I don't think you can fit a 27 GB model file fully into 24 GB VRAM. I think you could fit about Q4_K_M version of Qwen 3 32B (20 GB file) with maybe 8K context into 3090, but it would be really close. So comparison would be more like Q4 quant and 8K context at 30 t/s with risk of slowdown/out of memory vs. Q6 quant and 32K context at 5 t/s and not being near capacity.

- But 128GB of memory will be amazing for ComfyUI. Operating on 12GB is impossible, you can generate a random image, but you can't then take the character created and iterate on it in any way or use it again in another scene without getting an OOM error. At least not within the same workflow. For those of us who don't want an Apple for our desktops this is going to bring a whole new range of desktops we can use alternatively. They are starting at $3k from partnered manufactures and might down to the same price as a good desktop at $1-2k in just another year.
  - You're probably better off with an RTX 4090 (and a full desktop PC to support it, so it is going to be more expensive) for image generation, as the Spark is going to be slower than a gpu. It can run far bigger models, yes. But 128GB is too much for just image generation while the speed will suffer due the limited bandwith. A sweetspot would be half the memory at twice the speed, but that doesn't quite exist, at least in that price range. A modded RTX 4090 with 48GB of ram (and the accompanying desktop) is going to perform better - although the entire thing would probably cost more than twice as much. BUT, if you already have a desktop, upgrading your gpu will give you better bang per buck.
- It likely depends on how big your workflows are. Your right in that if I don't run out of memory on my gaming graphics card, image generation is super fast, but if I do run out of memory all the speed in the world is not going to help me finish my workflow. Also the speed is not as important for developing, since your the only user. I can let this little guy do the work while I game on my gaming card and the power draw is so low it can share the same circuit.
  - This is similar to my thoughts. You have CUDA-capable running in the background and reasonably low wattage. Just throw some stuff at it and come back later to see the results. It won't bog down your main system and hopefully it won't waste too much electricity (maxing at 170 watts? Each, since you could have multiple linked). Having an always available local LLM is also just nice. MSTY or similar can make it available to your whole home network rather easily.

- So, basically like a 128 GB strix halo but almost triple the price. Yawn.
  - But it has CUDA man. CUDA!!!!!

- Just a note that DGX Spark is listed as $3999 on their page currently. There are some licensed competitors that have cheaper machines available but they all sacrifice something to get there.

- You can get an Apple Studio M4 128 GB for a little less than DGX Spark. The Apple device will have slower prompt processing but more memory bandwidth and thus faster token generation. So there is a choice to make there.

- ## [Comparing AI Performance of DGX Spark to Jetson Thor - DGX Spark / GB10 User Forum / DGX Spark / GB10 - NVIDIA Developer Forums _202508](https://forums.developer.nvidia.com/t/comparing-ai-performance-of-dgx-spark-to-jetson-thor/343159)
  - Jetson Thor: â€œNVIDIAÂ® Jetson Thorâ„¢ series modules give you the ultimate platform for physical AI and robotics, delivering up to 2070 FP4 TFLOPS of AI compute and 128 GB of memory with power configurable between 40 W and 130 W.â€
  - DGX Spark: â€œPowered by the NVIDIA GB10 Grace Blackwell Superchip, NVIDIA DGXâ„¢Spark delivers 1 petaFLOP of AI performance in a power-efficient, compact form factor.â€
  - Is this a case of marketing terminology conflation, or might the Jetson AGX Thor provide better local inference performance compared to DGX Spark?

- The NVIDIA Jetson Thor Developer Kit is a purpose-built developer platform targeted at developers creating robotics and physical AI solutions that deploy with embedded Jetson modules. 
  - DGX Spark is a purpose-build compute to build and run AI, targeted at AI developers and data scientists who need to augment current laptop, desktop, cloud, or data center resources to provide large local memory and access to the NVIDIA AI software stack for their AI prototyping, fine-tuning, inference, data science, and general edge workloads.

- The RAM being similar but performance different could be down to scaling with power draw. The DGX Spark ships with a 240w USB-C brick, and I think itâ€™s specced to draw significantly higher than the Thor at 170W.

- The DGX Spark has 6144 CUDA cores, or just as many as RTX 5070. I believe I saw numbers claiming 1000 TOPS in FP4 sparse mode. Iâ€™m not sure how many tensor cores, or what type of tensor cores even, if any?
  - The AGX Thor has 2560 CUDA cores, with 96 fifth-generation Tensor cores; benchmarks Iâ€™ve seen so far indicate it performs on LLMs about as fast as an RTX 5070. Iâ€™m unsure if these were tests used in FP4 Sparse mode, as NVIDIA rates it for 2070 TOPS in FP4 sparse mode
  - I suppose I can see the Spark using more power due to using CUDA cores instead of Tensor Cores as the main source of processing, offering FP32 performance needed for precision during training and perhaps greatly versatility

- Some other differences that are noteworthy
  - DGX Spark has one NVENC/ NVDEC chip. Thor has Two.
  - DGX Spark has a connect-x nic. Thor is not connect-x but a 4x25g nic. It doesnâ€™t appear to support RDMA among other features you get with connect-x. which also means you probably canâ€™t combine the thor modules very easily.

- ## [AGX Thor LLM Inference Performance & Implications for DGX Spark? : r/LocalLLaMA _202508](https://www.reddit.com/r/LocalLLaMA/comments/1n0rheb/agx_thor_llm_inference_performance_implications/)
  - Excited to see the initial benchmarks rolling in for the AGX Thor following yesterday's release. A recent YouTube video showed around 30 tokens/sec generation speed with gpt-oss-120b using llama.cpp
  - This got me thinking about the DGX Spark. NVIDIA advertises the AGX Thor as having 2 PFLOPS of FP4 performance, while the DGX Spark is listed at 1 PFLOP

- Why would LLM inference scale with available FLOPs? 
  - Most of the operations used are dot produces (particularly matrix-matrix products) which are memory bound operations fundamentally; the number of FLOPs don't matter (within reason). Even a 4 core CPU with sufficient bandwidth can still run an LLM like GPT OSS
  - Where the FLOPs might matter is prefill (long context operation) or for concurrent inference serving, like maybe if you were doing async agents or something in parallel. These operations are compute bound, and FLOPs do matter (though in the case of prefill, with KV caching it doesn't matter for iterative workflows like chatting or iterative coding, and you're memory bandwidth bound again).

- I think one of the biggest drawbacks of the Spark (and something that is holding back many current offerings for AI and Handheld gaming) is the memory bandwidth
  - The one benefit that Spark might bring is NVIDIA MIG, which would allow us to partition GB10 into several instances and maybe run several models in parallel. Might be interesting for exploring LM Agents, especially if you got several of them working at the same time.

- I think there are two versions of the future: MXFP4 - will become the standard. MXFP4 - will not become the standard. 
  - In the first case, DGX Spark and Blackwell will make other solutions garbage. In the second case, DGX Spark will be garbage.

- ## [Nvidia DGX Spark | Hacker News _202508](https://news.ycombinator.com/item?id=45008434)

```markdown
<!-- FP4-sparse -->
| GPU Model | FP4-sparse (TFLOPS) | Price ($) | $/TF4s |
|-----------|---------------------|-----------|--------|
| 5090      | 3352                | 1999      | 0.60   |
| Thor      | 2070                | 3499      | 1.69   |
| Spark     | 1000                | 3999      | 4.00   |

<!-- FP8-dense -->
| Model        | FP8-dense (TFLOPS) | Price | $/TF8d (4090s have no FP4) |
|--------------|---------------------|-------|----------------------------|
| 4090         | 661                 | 1599  | 2.42                      |
| 4090 Laptop  | 343                 | vary  | -                         |

<!-- Geekbench -->
| Model      | Geekbench 6 (compute score) | Price | $/100k |
|------------|-----------------------------|-------|--------|
| 4090       | 317800                      | 1599  | 503    |
| 5090       | 387800                      | 1999  | 516    |
| M4 Max     | 180700                      | 1999  | 1106   |
| M3 Ultra   | 259700                      | 3999  | 1540   |

```

- Memory is the bottleneck. It limits the size of the models you can run and what you pay for.
  - Spark: 200B 
  - 5090 : 12B (raw)

- spark is $3, 999 and current M3 Max 28-Core CPU 60-Core GPU is the same price.

- I run 4 Mac Studio ultras at work (theyâ€™re pricy when maxed out), for local-first AI dev services. But thereâ€™s a few things that make me want to switch to the Spark. 
  - Networking is the biggest one, the Macs have Thunderbolt and Ethernet, but if I run distributed inference with EXO over Thunderbolt; the drop in tokens/second is massive. These Sparks get RDMA and can stack nicely. 
  - The other big one is access to CUDA, MLX has come a long way but being able to have CUDA and GPU access in containers would simplify the stack so nicely. 
  - If I had a USB-C/Thunderbolt backplane it might compare, but scaling with the Spark is likely a lot more straightforward.

- Biggest problem with Macs is that they don't have dedicated tensor cores in the GPU which makes prompt processing very slow compared to Nvidia and AMD.
  - there's been a little speculation that Apple adding TensorOps to Metal 4 suggests M5/M6 may get tensor cores.

- If that would be true why aren't Mac sales banned in China instead of Nvidia GPUs?
  - Because it's only a superior solution if you just want one box, and that mostly for inference. Once you start scaling to larger loads, it's much trickier to get a clusters of Macs to efficiently process them in parallel, whereas datacenter GPUs are designed for clusters.

- ## [What is the estimated token/sec for Nvidia DGX Spark : r/LocalLLaMA _202505](https://www.reddit.com/r/LocalLLaMA/comments/1krsast/what_is_the_estimated_tokensec_for_nvidia_dgx/)
- generation rate (tokens / s) are almost always bound by memory bandwidth not compute. 
  - It will be bound by the LPDDR5x memory to 273 GB/s.
  - Of course the compute will help with prompt processing and batching multiple queries, and the huge RAM will allow you to (slowly) run big models

- Slightly more than Strix Halo, due to better GPU/drivers, but nothing major.

- Ohhh.. now i see why they are willing to sell this high memory product to the general public. This is straight up trash tier performance. Fast enough that it will be bought and used by AI developers and enthusiasts... but slow enough as to not be hoarded and abused by cloud providers.

- Strix Halo devices are all at $2000 and are now widely shipping from many manufacturers. These are RDNA3.5 devices and while WIP, have full PyTorch support.

- ## [Nvidia digits specs released and renamed to DGX Spark : r/LocalLLaMA _202503](https://www.reddit.com/r/LocalLLaMA/comments/1jedy17/nvidia_digits_specs_released_and_renamed_to_dgx/)
- Framework Desktop is 256GB/s for $2000â€¦ much cheaper for running 70gb - 200 gb models than a Spark.
  - Yup, and being X86 is much more usable. These small AMD APUs are quite nice for a console/multi-media box purposes when not using LLMs. 
  - Nvidia offering is ARM so Linux only and not even X86 Linux so pretty much no gaming will be possible.

- ## [Local inference with Snapdragon X Elite : r/LocalLLaMA _202506](https://www.reddit.com/r/LocalLLaMA/comments/1l5k290/local_inference_with_snapdragon_x_elite/)
- I've been using mine (Surface Laptop 7) since it came out. It's good, but not in the exact way marketed.
  - I use it with LM Studio and AnythingLLM running models up to about 21B, the model size is limited by my 32GB integrated RAM. The token rate on an 8B is like 17-20 per second. 
  - But the NPU doesn't seem to have to do with anything. All the inference is on CPU, but not in that bad way people complain about if they have Intel products, more in the good way people talk about if they have Macs.

- I've been using local inference on multiple Snapdragon X Elite and X Plus laptops.
  - In a nutshell, llama.cpp or Ollama or LM Studio for general LLM inference, using ARM accelerated CPU instructions or OpenCL on the Adreno GPU. CPU is faster but uses a ton of power and puts out plenty of heat; the GPU is about 25% slower but uses less than half the power, so that's my usual choice.
  - I can run everything from small 4B and 8B Gemma and Qwen models to 49B Nemotron, as long as it fits completely into unified RAM. 64 GB RAM is the max for this platform.

- NPU support for LLMs is here, at least by Microsoft. 
  - You can download AI Toolkit under Visual Studio Code or Foundry Local. 
  - Both of them allow running of ONNX-format models on the NPU. 
  - Phi-4-mini-reasoning, deepseek-r1-distill-qwen-7b-qnn-npu and deepseek-r1-distill-qwen-14b-qnn-npu are available for now.
- Microsoft has AI Foundry which uses the Hexagon NPU. You're limited to Phi models and DeepSeek Distill Qwen models. Performance is fine but the models are old.
- Microsoft just added Qwen 7B and 14B DeepSeek Distill models that run on NPUs. I think for the moment, only the Snapdragon X Hexagon NPU is supported using the QNN framework. These are ONNX models that require Microsoft's AI Toolkit to run. 

- the X elite, would maybe use the gpu for the transformers i dont know if it would be possible for the llm since im using llama cpp
  - I don't think it's possible. A lot of Python ML-related frameworks don't have ARM64 Windows wheels or they can't be compiled without getting into a dependency nightmare. They won't work under WSL Linux because there's no Vulkan or OpenCL GPU passthrough.
  - If you want to use the Adreno GPU for inference, you're stuck with llama.cpp, LM Studio or Ollama, which all use the same ggml backend code.

- [Snapdragon X CPU inference is fast! (Q\_4\_0\_4\_8 quantization) : r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/comments/1emd3bg/snapdragon_x_cpu_inference_is_fast_q_4_0_4_8/)
  - On a Surface Pro 11 with a Snapdragon X Plus 10-core chip, running CPU inference for Llama 3.1 8B, I'm getting the following:
  - llama_print_timings: prompt eval time = 895.37 ms / 126 tokens ( 7.11 ms per token, 140.72 tokens per second)
  - llama_print_timings: eval time = 90360.33 ms / 1391 runs ( 64.96 ms per token, 15.39 tokens per second)
- I get ~5.5 tokens/s with Llama 3.1 8B Q8_0 and DDR4-3600 memory, so ~15.5 tokens/s for Q4 and dual-channel LPDDR5X-8400 memory doesn't seem that impressive.
- Well it's not close to m2 levels at all. M2 max gets 66 t/s and 671 pp/s at q4
- Wow, I have ~5.8 tokens/s on 8+gen1 in llama 3.1 8b

- ## [Snapdragon X Elite - local llm? : r/LocalLLaMA _202406](https://www.reddit.com/r/LocalLLaMA/comments/1ddyc51/snapdragon_x_elite_local_llm/)
- I have purchased the new Surface Pro CoPilot+PC and am struggling to get the LLMs to run using the embedded NPU. I guess I was spoiled by using Ollama and Llama.cpp, now I am having to learn the basics of quantizing a model and using HuggingFace APIs to host the models.

- Should be good for 13B. There is a video out there showing itâ€™s real world performance already on a model called â€œPhi Silicaâ€

- [Snapdragon X Elite llama.cpp ? : r/LocalLLaMA _202406](https://www.reddit.com/r/LocalLLaMA/comments/1dj6h6x/snapdragon_x_elite_llamacpp/)

- [$899 mini PC puts Snapdragon X Elite into a mini desktop for developers (with 32GB RAM) : r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/comments/1cxhh1q/899_mini_pc_puts_snapdragon_x_elite_into_a_mini/)
  - every modern CPU since AMD phenom is a SoC with unified memory architecture. The key thing is the memory controller and how many steps it needs. CPUs benefit from being able to quickly go back and forth between ram compared to GPUs, which is why RAM performance isnt a direct competitor to VRAM in GB/s because the MT/s is more important for RAM and how efficiently your data and instructions are packed into every transfer.
  - Thanks for correcting that AMD and other competitors have had UMA for years. My mistake. But still stands that apple has 800GB/s memory bandwidth vs things like Snapdragon X Eliteâ€™s 136GB/s

- ## [éªé¾™X Eliteå†é­ç—›æ®´, ç¬¬äºŒä»£é…·ç¿Ultra è‹±ç‰¹å°”Meteor Lakeæœ‰å¤šå¼ºï¼Ÿ - çŸ¥ä¹Ž _202406](https://zhuanlan.zhihu.com/p/701851374)
- ç¬¬ä¸€ä»£é…·ç¿Ultraå¹³å°ï¼ˆæµæ˜Ÿæ¹–ï¼ŒMeteor Lakeï¼‰çš„å››å¤§æ¨¡å—ä¸­ï¼Œé™¤äº†è®¡ç®—æ¨¡å—é‡‡ç”¨äº†è‡ªå®¶çš„Intel 4å·¥è‰ºï¼Œå…¶ä»–ä¸‰ä¸ªæ¨¡å—éƒ½æ˜¯å°ç§¯ç”µä»£å·¥ã€‚
  - åˆ°äº†ã€æœˆäº®æ¹–ã€‘ï¼Œå°±è¿žæœ€æ ¸å¿ƒçš„è®¡ç®—æ¨¡å—ä¹Ÿæ”¹ç”¨äº†å°ç§¯ç”µçš„N3Bå·¥è‰ºï¼Œè‹±ç‰¹å°”ä»…ä¿ç•™äº†è‡ªå·±çš„å…ˆè¿›å°è£…å·¥è‰ºï¼ˆFoverosï¼‰ã€‚
  - åœ¨ã€æœˆäº®æ¹–ã€‘ä¸Šï¼Œè‹±ç‰¹å°”è¿˜å¸¦æ¥äº†ç±»ä¼¼è‹¹æžœç»Ÿä¸€å†…å­˜æž¶æž„çš„è®¾è®¡ï¼Œç›´æŽ¥å°†LPDDR5X-8533å†…å­˜å°è£…åœ¨äº†èŠ¯ç‰‡ä¹‹ä¸Šï¼Œå¯é€‰16GBæˆ–32GBå®¹é‡ã€‚
  - è¿™ç§è®¾è®¡çš„å¥½å¤„æ˜¯ï¼Œèƒ½ä½¿æ•°æ®ä¼ è¾“è´Ÿè½½é™ä½Žå¤§çº¦40%ï¼Œå»¶è¿Ÿæ›´ä½Žï¼Œç›¸è¾ƒä¼ ç»Ÿçš„æ¿è½½å†…å­˜è¿˜èƒ½èŠ‚çœå¤§çº¦250å¹³æ–¹æ¯«ç±³çš„ä¸»æ¿ç©ºé—´
- ã€æœˆäº®æ¹–ã€‘çš„æ ¸å¿ƒç«žäº‰åŠ›ï¼Œå°±æ˜¯è®¡ç®—æ¨¡å—ä¸­çš„CPUã€GPUå’ŒNPUä¸‰å¤§å•å…ƒéƒ½è¿Žæ¥äº†å…¨é¢æå‡ã€‚
  - é¦–å…ˆå°±æ˜¯NPUï¼Œä»Žç¬¬ä¸€ä»£é…·ç¿Ultraçš„11TOPSï¼Œå¤§æ¶¨åˆ°48TOPS
  - ã€æœˆäº®æ¹–ã€‘CPUéƒ¨åˆ†çš„AIç®—åŠ›ä¸º5TOPSï¼ŒGPUä¸º67TOPSï¼Œåœ¨å¼‚æž„è®¡ç®—çš„åŠ æŒä¸‹ï¼Œæ•´ä½“AIç®—åŠ›é«˜è¾¾120TOPSï¼Œä¸€ä¸¾è¶…è¶Šäº†éªé¾™X Eliteçš„æ•´ä½“75TOPSï¼ˆNPUä¸º45TOPSï¼‰ï¼Œå’Œé”é¾™AI 300çš„æ•´ä½“80TOPSï¼ˆNPUä¸º50TOPSï¼‰ã€‚
  - AI PCæ—¶ä»£ä¹‹æ‰€ä»¥æ ¼å¤–å¼ºè°ƒAIç®—åŠ›ï¼Œå°±æ˜¯å› ä¸ºå¾®è½¯å³å°†åœ¨Windowsæ“ä½œç³»ç»Ÿå±‚é¢ï¼Œå°±æŠŠç”Ÿæˆå¼AIæŠ€æœ¯åº”ç”¨åˆ°åŸºç¡€ä½“éªŒä¹‹ä¸­ã€‚å¦‚æžœä½¿ç”¨CPUå’ŒGPUè¿›è¡Œå¤„ç†ï¼Œç¬”è®°æœ¬çš„ç»­èˆªä¼šå°¿å´©ã€‚æ­¤æ—¶ï¼Œå”¯æœ‰ä½ŽåŠŸè€—é«˜AIæ€§èƒ½çš„NPUï¼Œæ‰èƒ½åœ¨å…¼é¡¾ç»­èˆªçš„åŒæ—¶ï¼Œéšæ—¶éšåœ°äº«å—AIå¸¦æ¥çš„ä¾¿åˆ©
  - åœ¨GPUæ–¹é¢ï¼Œã€æœˆäº®æ¹–ã€‘å‡çº§åˆ°äº†æ–°ä¸€ä»£çš„Xe2æž¶æž„ï¼Œæ€§èƒ½æœ‰äº†å¹³å‡50%çš„æå‡ï¼Œæœ‰æœºä¼šä¸ŽAMDé”é¾™AI 9 HX 370é›†æˆçš„Radeon 890MæŽ°æŽ°æ‰‹è…•

- ## ðŸ†šðŸŒ° [AMD AI Max+ 395 CPU æœ¬åœ°å¤§æ¨¡åž‹æŽ¨ç†æ€§èƒ½è¯„æµ‹æŠ¥å‘Š - çŸ¥ä¹Ž _202509](https://zhuanlan.zhihu.com/p/1952045270763283746)
- é’ˆå¯¹æ­è½½AMD AI Max+ 395 CPUçš„é›¶åˆ»GTR9è¿·ä½ ä¸»æœºè¿›è¡Œäº†ä¸€ç³»åˆ—ä¸¥æ ¼çš„å¤§æ¨¡åž‹æŽ¨ç†é€Ÿåº¦æµ‹è¯•ã€‚
  - ç¡¬ä»¶å¹³å°: é›¶åˆ» (MINISFORUM) GTR9 è¿·ä½ ä¸»æœº
  - æ ¸å¿ƒç»„ä»¶: AMD AI Max+ 395 CPU
  - ä»»åŠ¡ç±»åž‹: æœ¬åœ°å¤§è¯­è¨€æ¨¡åž‹æŽ¨ç†
  - æ€§èƒ½æŒ‡æ ‡: Tokens/s (æ¯ç§’ç”ŸæˆTokenæ•°) â€” è¯¥æ•°å€¼è¶Šé«˜ï¼Œä»£è¡¨æŽ¨ç†é€Ÿåº¦è¶Šå¿«
- è®¾è®¡äº†æ¶µç›–å¤šç§ä»»åŠ¡ç±»åž‹çš„æ ‡å‡†åŒ–é—®é¢˜ï¼š
  - ç»¼åˆèƒ½åŠ›: "ä½ æ˜¯è°ï¼Ÿè¯·è¯¦ç»†ä»‹ç»ä¸€ä¸‹ä½ èƒ½å¹²ä»€ä¹ˆã€‚"
  - çŸ¥è¯†é—®ç­”: "ä½œä¸ºä¸“ä¸šäººå·¥æ™ºèƒ½ä¸“å®¶ï¼Œè¯·å‘Šè¯‰æˆ‘å¦‚ä½•å­¦ä¹ æ·±åº¦å­¦ä¹ ï¼Ÿ"
  - æ•°å­¦è®¡ç®—: "å¦‚æžœA+B=12, A-B=10ï¼Œåˆ™Açš„å€¼æ˜¯ï¼Ÿ"
  - è‡ªç„¶è¯­è¨€ç†è§£: "è¯†åˆ«å¥å­â€˜æˆ‘å°†ä¼šåœ¨æ˜Žå¤©æ—©ä¸Šçš„8ç‚¹åˆ°æ¹–åŒ—é»„é™‚çš„æ£®æž—å…¬å›­â€™ä¸­çš„æ‰€æœ‰åœ°åã€‚"
  - ä»£ç ç”Ÿæˆ: "è¯·ä½¿ç”¨Pythonç¼–å†™ä¸€ä¸ªè´ªåƒè›‡æ¸¸æˆã€‚"

- å‚è¯„å¤§æ¨¡åž‹:
  - deepseek-r1:70b, 30
  - qwen3 ç³»åˆ—ï¼ˆ32b / 30b / 14b / 8bï¼‰
  - gpt-ossï¼ˆ120b / 20bï¼‰

```markdown
| Model          | Ollama | LM Studio |
|----------------|--------|-----------|
| deepseek-r1:70b | 4.43  | 4.97      |
| qwen3:32b      | 8.97   | 10.12     |
| qwen3:14b      | 19.47  | 21.70     |
| qwen3:8b       | 29.93  | 35.96     |
| gpt-oss:120b   | 30.84  | 42.07     |
| gpt-oss:20b    | 42.57  | 60.54     |
| qwen3:30b      | 48.93  | 68.70     |
```

- å¯¹æ¯”ä¸¤ç»„æ•°æ®å¯è§ï¼ŒåŒä¸€æ¨¡åž‹åœ¨LM-Studioä¸­çš„æŽ¨ç†é€Ÿåº¦æ™®éä¼˜äºŽOllama
- AMD AI Max+ 395 CPUé‡‡ç”¨CPU/GPUå…±äº«å†…å­˜çš„ç»Ÿä¸€å†…å­˜æž¶æž„ï¼ˆUMAï¼‰ï¼Œè¿™ç§è®¾è®¡å¤©ç„¶é€‚åˆè¿è¡Œæ··åˆä¸“å®¶ï¼ˆMoEï¼‰æ¨¡åž‹ï¼ˆå¦‚gpt-ossç³»åˆ—ã€qwen3:30bï¼‰ã€‚
  - MoEæ¨¡åž‹è™½ç„¶æ€»å‚æ•°é‡åºžå¤§ï¼Œä½†æ¯æ¬¡æŽ¨ç†ä»…æ¿€æ´»éƒ¨åˆ†"ä¸“å®¶"å‚æ•°ï¼Œéžå¸¸å¥‘åˆè¿™ç§å¤§å®¹é‡å†…å­˜ä½†ç»å¯¹ç®—åŠ›ç›¸å¯¹æœ‰é™çš„ç¡¬ä»¶ã€‚
  - ç›¸æ¯”ä¹‹ä¸‹ï¼Œå¯¹äºŽå‚æ•°å¯†é›†çš„ä¼ ç»Ÿç¨ å¯†æ¨¡åž‹ï¼ˆå¦‚deepseek-r1:70bã€qwen3:32bï¼‰ï¼Œç”±äºŽéœ€è¦æ›´é«˜çš„ç»å¯¹ç®—åŠ›ï¼Œè¯¥å¤„ç†å™¨çš„é›†æˆæ˜¾å¡åˆ™ç¨æ˜¾åƒåŠ›ã€‚

- DFRobotä½œä¸ºåœ¨å•æ¿è®¡ç®—æœºï¼ˆSBCï¼‰ã€AIè¾¹ç¼˜è®¡ç®—å’Œå¼€æºç¡¬ä»¶é¢†åŸŸçš„åˆ›æ–°è€…ï¼Œæ­¤æ¬¡æµ‹è¯•ç»“æžœæ„ä¹‰éžå‡¡ã€‚è‹¥æœªæ¥DFRobotæŽ¨å‡ºåŸºäºŽAMD AI Max+ 395 CPUçš„å•æ¿è®¡ç®—æœºï¼Œå°†å…¶å¼ºå¤§çš„æœ¬åœ°AIæŽ¨ç†èƒ½åŠ›ä¸ŽDFRobotæˆç†Ÿçš„æ¨¡å—åŒ–ä¼ æ„Ÿå™¨ç”Ÿæ€ï¼ˆå¦‚Gravityç³»åˆ—ï¼‰ç›¸ç»“åˆï¼Œå°†å‚¬ç”Ÿå‡ºæ›´å¤šå®žæ—¶ã€æ™ºèƒ½çš„ç‰©è”ç½‘ä¸Žæœºå™¨äººåº”ç”¨

- ## ðŸ†š [AI max+ 395 128gb vs 5090 for beginner with ~$2k budget? : r/LocalLLaMA _202510](https://www.reddit.com/r/LocalLLaMA/comments/1nunlls/ai_max_395_128gb_vs_5090_for_beginner_with_2k/)
- ComfyUI? 5090.  LLMs? AI Max
  - FWIW, you can also use a thunderbolt eGPU with the AI Max.

- I've been able to run ComfyUI on max+ 395. It's a pain, but it's possible.

- As for ComfyUI, I run that just fine on my Max+ 395 as well. But saying ComfyUI doesn't mean much. It's just a framework to run things. What exactly do you want to do? If it's just image gen, then the Max+ is as good as anything else. If it's video gen, it does work but uses way more memory than Nvidia. If it's voice cloning, that just works too. So other than using way so much memory, which you have plenty of on a Max+ 128GB, what is this bugginess you are talking about?
  - Max+ 395 owner, and I agree, the level of experimenting i've reached has been great with the device.
- I love my 395+ 128 GB, and I've got LLM, image generation, voice, etc. working, but I cannot for the life of me get video working. Mainly trying to experiment with I2V with WAN 2.1 and 2.2, but have never got a successful run. Either get OOM or seemingly infinite time per iteration. Not sure if you can provide any tips. Using the pytorch 2.9.0+rocm7 RC since that was the most stable for everything else.

- Iâ€™d personally go 395, because almost all AI labs are going with MoE architecture at this point. So big RAM can accomplish a lot even if itâ€™s not the fastest.

- The AI Max+ 395 handles all my AI needs for now and itâ€™s pretty snappy once you get things working in Linux.
  - The downside is if you need/want to run anything super fast - you will need a different setup. Eventually I might get a setup like that, and use the Max+ 395 for my mobile AI needs.
  - Still, I can get 20+ TPS on GLM Air 4.5, and even faster with the GPT-OSS models.

- How much memory ddr5 with 5090? Just 32gb is limited 128gb can run huge Moe's.
  - If your running 30b models and under 5090 all day. 
  - If your running large 120b moe models or smaller dense models 395plus all day.

- if you want to do some training stuff, CUDA, and ... maybe gaming, go for the 5090
  - if you just want to run some local model to try them or serve them locally 24/7, strix halo is probably a better option, almost all the best latest open model are MoE and they need a lot of ram/vram (glm 4.5 air, gpt oss 120b, some qwant of qwen 235, qwen 3 next, ... will all run better on strix halo vs 5090+128gb ram). Also strix halo is usually a full machine, while the 5090 you still need the rest of the PC

- AMD AI 395 miniPC preferably with Oculink (there are couple) where you can hook later external dGPU like AMD AI PRO R9700.

- If you're interested in image/video gen, you need the 5090. That is going to be miserably slow on CPU.
  - If you just want to run MoE models interactively, the AI 395 will be enough.
  - Personally? I'd go with both. You can in fact attach a 5090 to an AI 395 system. Then you can run LLMs for your prompt generation/improvement workflows while generating video and imagery to your heart's content.
  - I don't think people who have not experienced a Blackwell GPU understand how much faster they are for image/video work. Even against a 4090 my workflow times cut in half.
- I agree, I think I start with 395 and add the 5090 if it becomes necessary.

- if it was only to play around and learn llm stuff i'd lean towards the framework 128.
  - but the moment you mention comfy, amd is off the table. get the 5090 instead.

- If you're looking mostly to be able to inference bigger MoE models with llama.cpp then I think the 395 can be a good choice.
  - However, if you have an interest in playing round w/ image/video generation, doing any further poking around (vLLM/SGLang, voice, PyTorch, model training/fine tuning, etc) then I think the 5090 is the clear way to go.
  - If you're working w/ smaller models btw it's not just about stability either, the 5090 is a whole different animal in performance - as long as you're OK w/ running ~30B/smaller models.

- ## [Advice: 2Ã— RTX 5090 vs RTX Pro 5000 (48GB) for RAG + local LLM + AI development : r/LocalLLM _202509](https://www.reddit.com/r/LocalLLM/comments/1nsyiag/advice_2_rtx_5090_vs_rtx_pro_5000_48gb_for_rag/)
- As someone with 2x 5090s, started from 1.. don't do it. Go straight to the pro 6000. Thank me later. It'll save you time, money, and effort. :) I now have a pro 6000. You can pick one up from Exxact for $7200.
  - Dual 5090s are greatâ€¦ you can run many models. 
  - However, even with quantized KV cache itâ€™ll crash often. You canâ€™t max out the 1million context Qwen coder. You canâ€™t really fine tune models that donâ€™t fit in a single GPU. Youâ€™ll have issues with accelerate. 
  - Heat is very hot. At least 10 degrees warmer in a whole room when fine tuning. Power usage is very high. Youâ€™ll need to run new electrical or have your machine shut off when someone plugs in a vacuum. Youâ€™ll need to run dual psus or buy a 2000w+ psu. 
  - Case options are very limited. The cards are massive in size. Youâ€™ll need 8 slot pc cases minimum for 2 cards. 
  - Youâ€™ll want to run 70b+ models guaranteed. Even Qwen next 80b. 2x 5090s isnâ€™t enough. 
  - This is all solved with a single pro 6000. So for an extra $1000 you can save yourself a lot of headaches and get access to nvidia enterprise

- Rent GPUs online unless you have a reason other than inference

- Remember the most important thing: whatever you choose initially, you will have to switch to RTX 6000 PRO 96Gb on Epic or Threadripper platrofm eventually if you want to continue running large local llms efficiently. The cost of those things will dwarf your current current setup. So, do not sweat much while deciding on the current config. Just make sure that your case and motherboard allow to connect at least 2 GPUs via riser cards with PCI 5.0 on each, even if at x8 speed. 

- Be sure you get a motherboard with dual x8 pcie slots if you go with two GPUs. Most AM5 boards donâ€™t support that but a handful do. Just wanted to give you a heads up
  - Yeps, Asus Pro Art 2x pice 5.0

- ## [The NVIDIA DGX Spark at $4, 299 can run 200B parameter models locally - This is our PC/Internet/Mobile moment all over again : r/LlamaFarm _202509](https://www.reddit.com/r/LlamaFarm/comments/1nee9fq/the_nvidia_dgx_spark_at_4299_can_run_200b/)
- DGX has 273gb/s versus 1.7Tb/s for a rtx 5090...
  - The bandwidth is terrible. You'll run your models at 5 tps
  - I literally don't see who's gonna buy this aside from people who just got blinded by the unified RAM...
- At 273 GB/s memory bandwidth this unified RAM there will make inference VERY SLOW... For comparison: RTX 4090 has 1008 GB/s and RTX 5090 has 1792 GB/s memory bandwidth

- u can easily get an m1 max with 128 gb of unified memory for 1k cheaper than that and double the memory bandwidth. Donâ€™t see how this is a good deal.
  - It's not a good deal. It is more of a sign. MLX is growing, but the ecosystem is still tiny compared to CUDA. With Blackwells coming to PCs and AMD shipping powerful GPUs, there will be real competition in this area for the first time.

- M3 Ultra with 256GB RAM does cost roughly $1000 more, but has 256GB unified memory
  - And 819 gb/s vs Spark's 273.

- Mac Studio, Ultra series, either M1 or M2 with 96GB or 128GB RAM. And more recently, the M4 Max. I bet by next year the Mini will likely have a 128GB configuration too.
  - What I am NOT saying is that Appleâ€™s offerings are the best local inference for 128GB workloads. I am saying they are relatively cheap and capable, and the inflection point for fairly large local models (>60GB) was two years ago.
  - I bought my M4 Max 128GB last year for local models. It does not disappoint.

- No thanks, I'm not taking my wallet out until I see the AMD Medusa Halo 128GB AI mini-PCs in two years. I CAN WAIT.

- Jetson AGX Thor claims 2000 TOPS of AI at FP4, but it is the same memory bandwidth as DGX spark so I have my doubts. Guess we have to wait for some benchmarks.

- [DGX spark vs MAC studio vs Server (Advice Needed: First Server for a 3D Vision AI Startup (\~$15k-$22k Budget) : r/deeplearning](https://www.reddit.com/r/deeplearning/comments/1lylfuw/dgx_spark_vs_mac_studio_vs_server_advice_needed/)
- Macs are decent for inference, but nobody "real" is training models on Mac. Even Apple was using TPUs earlier (when that team was still run by the ex-Google guy) and grapevine says they're on Nvidia now

- DGX Spark is like a RTX 5060(70?) class GPU with 128GB of slowish (for GPU) memory.
  - The only thing Spark really has going for it is it might be SM100 (real Blackwell with Tensor Memory) instead of SM120 (basically Ada++) which may be useful for developing SM100 CUDA kernels without needing a B200.
  - Much better off I think with a NVIDIA RTX PRO 6000 Blackwell Series (96GB) for most people, or 512GB Mac Studio if you need very large LLMs but less GPU perf.

- ## ðŸŽ [MacBook M4 Max isn't great for LLMs : r/LocalLLaMA _202503](https://www.reddit.com/r/LocalLLaMA/comments/1jn5uto/macbook_m4_max_isnt_great_for_llms/)
- M4 Max is about 50% faster than an Nvidia P40 (both in compute throughput and memory bandwidth). 
  - It is about 2.5x slower than a 3060 in computeÂ¹ throughput (FP16) and 50% faster in memory bandwidth. 
  - Compared to 3090, it is about 7x slower in computeÂ¹ throughput (FP16) and almost 2x slower in memory bandwidth.
- P40s (and generally Pascal) were the last ones without tensor cores (which increase FP16 throughout by 4x).
  - The lack of tensor cores is also the reason Apple M3 Ultra/M4 Max and AMD 395 Max, lag in Prompt Processing throughput compared to Nvidia, even if the M3 Ultra almost matches a 3080/4070 in raster throughput (FP32).
  - Compared to CPU-only inference, P40s are still great value, since they cost $150-300 and are only matched by dual 96-core Epycs with 8-12 channel DDR5 which start from $5000 used.
- Pascal doesn't even have FP16 support, all the operations are done through fp32 units afaik so throughput is effectively halved. It wasn't until Ampere that NVidia had FP16 support.

- Try swapping to serving with LMStudio - then use MLX, and speculative decoding with 0.5b as draft for 14b! Tripled my speed on my M1 Max
  - Speculative decoding really is great. It at least doubled my speeds. In token generation. Prompt processing didn't get and bump though. I'd love to have a 128gb+ RAM machine to also activate KV Cache

- ## [æœ¬åœ°éƒ¨ç½²å¤§æ¨¡åž‹æ€§ä»·æ¯”ä¹‹çŽ‹çœŸçš„æ˜¯Apple Mac Studio M3 Ultra 192æˆ–512å—ï¼Ÿ - çŸ¥ä¹Ž _202503](https://www.zhihu.com/question/14548406514)
- deepseek r1 ç”¨mac studioæµ‹è¯•
  - ollama: 16 tops
  - lmstudio: 18 tops
  - 512Gbå†…å­˜è¿˜æ˜¯åªèƒ½éƒ¨ç½²4bité‡åŒ–ç‰ˆæœ¬ï¼Œ8bitä¸è¡Œ
- å¦‚æžœæŒ‰ç…§18.11token/sçš„è¾“å‡ºé€Ÿåº¦ï¼Œä¸è€ƒè™‘å…¶ä»–ï¼Œå…¨å¤©24å°æ—¶è¿è¡Œï¼ˆä¸è€ƒè™‘prefillç­‰æ—¶é—´ï¼‰18.11Ã—86400s=156.5ä¸‡tokensï¼Œè€Œå®˜ç½‘ç™¾ä¸‡tokenså”®ä»·æ‰16å—ï¼Œ156.5ä¸‡å”®ä»·25å—é’±
  - è€ŒMac studio 512Gå†…å­˜ï¼Œ1tç¡¬ç›˜ç‰ˆæœ¬å”®ä»·7.3wæ•™è‚²ä¼˜æƒ ä¹Ÿè¦6.7wï¼Œéœ€è¦365Ã—24hä¸åœè¿è¡Œ8å¹´/7.3å¹´æ‰èƒ½å›žæœ¬

- é‚£è¦çœ‹ä½ æ€Žä¹ˆå®šä¹‰æ€§ä»·æ¯”äº†ï¼Œ[ktransformers] + [epyc] çŽ°åœ¨ä¹Ÿå·²ç»çŽ©å¾—å¾ˆå¼ºäº†ï¼Œè‹¹æžœèƒœåœ¨ä¸Šæ‰‹å°±èƒ½ç”¨ä¸ç”¨æŠ˜è…¾è£…ï¼Œåœ¨é‚£ä¸ªä»·ä½ç®—ä¸€ä¸ªå¯è¡Œæ–¹æ¡ˆï¼Œä½†å¹¶éžç®—å”¯ä¸€æ€§ä»·æ¯”æ–¹æ¡ˆ

- ## [MAC mini M4èŠ¯ç‰‡32G+256èƒ½è·‘å¤§æ¨¡åž‹å—ï¼Ÿ - çŸ¥ä¹Ž _202503](https://www.zhihu.com/question/14795834393)
- çœŸè·‘aiåªæŽ¨èProä»¥ä¸Šçš„èŠ¯ç‰‡ã€‚
  - m4çš„å†…å­˜å¸¦å®½å…¶å®žå’Œæ™®é€šæ ¸æ˜¾winæœºå­å·®ä¸å¤šã€‚è€Œåˆ°äº†Proï¼Œå†…å­˜å¸¦å®½å°±è¾¾åˆ°256äº†ï¼Œè¾¾åˆ°4060çš„æ°´å‡†ã€‚
  - maxå’Œultraå¸¦å®½åˆ†åˆ«æ˜¯400ï¼‹å’Œ800ï¼‹ï¼ŒåŸºæœ¬æ˜¯æ˜¾å¡çº§åˆ«çš„å¸¦å®½ï¼Œç”¨æ¥è·‘aiæŽ¨ç†å¾ˆåˆé€‚ã€‚

- ä¸»è¦æ˜¯å†…å­˜å¤§å•Šï¼Œæˆ‘ç”¨ä¸€ä¸‡å‡ºå¤´çš„macèƒ½è·‘27Bçš„gemma3 8bité‡åŒ–ï¼Œå¦‚æžœç”¨æ˜¾å¡çš„è¯è‡³å°‘å¾—æ˜¯ä¸ª3090çº§åˆ«çš„

- Mac Mini å½“å‰¯æœºå¯ä»¥ï¼Œç»Ÿä¸€å†…å­˜çœ‹ç€é¦™ï¼Œä½†å¾ˆå¤šæ¨¡åž‹ä¸æ”¯æŒ MPSï¼Œæˆ–è€…ç”¨ MPS è·‘å¾—æ¯” CPU è¿˜æ…¢ã€‚

- ## [Apple M5 could ditch unified memory architecture for split CPU and GPU designs | Hacker News _202412](https://news.ycombinator.com/item?id=42552494)
- UMA hurts the GPU too much. Widely parallel processing wants to access memory in bigger chunks than a CPU. If you try to mix access and modification, you lose the benefit of widely parallel processing. 
  - Other GPU designers have considered and eschewed unified memory models, to the tune of hundreds of millions in research dollars.
- I agree that single cache-line fetches are pretty poor for parallel vector units, but supporting the former in an environment designed for the latter doesn't seem to off-putting (the CM-5 did this).

- You can split the CPU and GPU and still have UMA. Splitting CPU/GPU is a packaging and interconnect concern and is not mutually exclusive with UMA.

- ## [æ±‚æŽ¨èï¼æƒ³ç»„ä¸€å°256Gâž•ç¬”è®°æœ¬è·‘å¤§æ¨¡åž‹ðŸ¥¹ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/6892017700000000030274de?xsec_token=ABHUpmj6nmLewRxGBOYsEYt2FVRxDHjqOHSnhQfgUJJnc=&xsec_source=pc_search&source=web_explore_feed)
- æ™®é€šç¬”è®°æœ¬ä¸æ”¯æŒ256ï¼Œåˆ«å¼‚æƒ³å¤©å¼€
  - ç¬”è®°æœ¬å†…å­˜æœ‰æ˜¯æœ‰ï¼Œä½†æ˜¯ç¬”è®°æœ¬ä¸æ”¯æŒï¼Œä¹°äº†ä¹Ÿæ²¡ç”¨ï¼Œåˆ°æ—¶å€™æ’ä¸ŠåŽ»ä¸è¯†åˆ«å°±è€å®žäº†
- åˆ«æƒ³äº†ï¼Œç¬”è®°æœ¬ä¸æ”¯æŒeccå†…å­˜ï¼Œè·‘æ—¶é—´é•¿å®¹æ˜“å‡ºé”™
- å“ªä¸ªè‹¹æžœç¬”è®°æœ¬æœ‰512å†…å­˜ ä½ æ‰¾å‡ºæ¥æˆ‘çœ‹çœ‹ï¼Œæˆ‘å°±çŸ¥é“æŽ¨å‡ºè¿‡2tå†…å­˜çš„mac proè¿˜æœ‰512å†…å­˜çš„mac studioï¼Œmbpæœ€å¤§çš„å°±128gå†…å­˜å§ m4max

- æ•£çƒ­åŽ‹ä¸ä½çš„

- ç¬”è®°æœ¬ç›®å‰èƒ½æœ¬åœ°éƒ¨ç½²å¤§æ¨¡åž‹çš„åªæœ‰mç³»èŠ¯ç‰‡çš„mbpå†…å­˜æ‹‰æ»¡ï¼ˆä»ç„¶æ˜¯å‹‰å¼ºå¤Ÿç”¨æ°´å¹³ï¼‰å’Œryzen ai max+395æ¿è½½å†…å­˜æ‹‰æ»¡128ï¼ˆè¿™ä¸ªçš„å†…å­˜å’Œæ•ˆçŽ‡ä¼°è®¡ä¸å¤ªå¤Ÿï¼Œå”¯ä¸€ä¼˜åŠ¿x86æ—¥å¸¸æ–¹ä¾¿ï¼‰ï¼Œå› æ­¤ä¸»è¦å¾€itxä¸Šé¢åŽ»å‡‘ï¼ŒçŽ°æœ‰äº§å“ä¹Ÿå°±æ˜¯æˆ‘è¯´çš„è¿™ä¸¤å¥—å³è‹¹æžœmç³»å’Œamd aiï¼Œå› ä¸ºæœ‰ç»Ÿä¸€å†…å­˜å¯ä»¥ç”¨æ ¸æ˜¾æ¥è·‘aiå…åŽ»å¤šè·¯gpuçš„éº»çƒ¦ã€‚

- å¦‚æžœä½ éœ€è¦cpué«˜æ€§èƒ½ï¼Œé‚£ä¹ˆå¯ä»¥è€ƒè™‘ç”¨æ¯”è¾ƒæ–°çš„æœåŠ¡å™¨å¹³å°ï¼ˆå› ä¸ºæˆ‘ä¼°è®¡è¿žhedtéƒ½æ— æ³•æ»¡è¶³ä½ çš„å†…å­˜éœ€æ±‚ï¼‰å’Œitxä¸»æ¿ï¼ˆå½“ç„¶ï¼ŒåŽæ“Žä¸ä¸€å®šè¿˜åœ¨åšè¿™ç±»å¥‡ç‰¹çš„äº§å“ï¼‰ã€‚ä½ åªéœ€æ±‚å•å¡çš„è¯å¯ä»¥å‹‰å¼ºå¡žä¸€å¥—itxï¼Œä½†æ˜¯å„æ–¹é¢éƒ½å¾ˆæžé™äº†ï¼ŒåŒ…æ‹¬ä¾›ç”µå’Œæ•£çƒ­ï¼Œå¤§æ¦‚æ˜¯è·‘ä¸æ»¡çš„ã€‚å¦‚æžœä½ éœ€æ±‚å¤šå¡çš„è¯ï¼Œå¯èƒ½å¾—å‡ å¼ å¡ç”¨æ‰©å±•å¡è¿žæŽ¥ä»¥åˆ†ç€ç”¨itxä¸»æ¿ä»…æœ‰çš„é‚£ä¸€ä¸¤ä¸ªpcie x16æŽ¥å£ï¼Œè¿™æ ·åšæ€§èƒ½è‚¯å®šä¼šæœ‰æŠ˜æŸï¼Œå¹¶ä¸”100%éœ€è¦åšåˆ†ä½“çš„ä¸¤ä¸ªitxæœºç®±ï¼Œè¿™ç§æƒ…å†µä½ éœ€è¦è‡ªå·±ç”»è®¾è®¡å›¾åŽ»tbä¹‹ç±»çš„å¹³å°æ‰¾å·¥åŽ‚å®šåšæ¿æï¼Œå¥½å¤„æ˜¯ä¾›ç”µå’Œæ•£çƒ­æ²¡ä¹‹å‰é‚£ä¹ˆæžé™ï¼Œåå¤„æ˜¯è¿™ä¸€å¥—ä¸‹æ¥ä¼°è®¡ä¸æ¯”eatxæœºç®±è½»ä¾¿å¤šå°‘ã€‚

- ## [é€‰ä¸ªèƒ½æœ¬åœ°è·‘70Bå¤§æ¨¡åž‹çš„ç¬”è®°æœ¬å½“ä¸»åŠ›æœºè¯• - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/6811b115000000002301de1a?xsec_token=ABZEBEajWMF79jFUPp-RsmTEccFriosXMc79IFdgiGHWo=&xsec_source=pc_search&source=web_explore_feed)
  - ä¹‹å‰ä¸€ç›´ç”¨çµåˆƒ16 2024ç‰ˆçš„å½“ä¸»åŠ›æœºï¼Œè·‘èµ·æ¥é£Žæ‰‡å®žåœ¨æ˜¯å“ï¼Œå¼€ä¸ªçº¿ä¸Šä¼šåˆ«äººéƒ½å¬ä¸æ¸…ï¼Œè€Œä¸”é‡é‡å®žåœ¨æ— æ³•ç§»åŠ¨ã€‚
  - æœ€è¿‘çœ‹åˆ°HP æˆ˜99 Ultraåˆ°è´§å°±ç›´æŽ¥æ‹¿ä¸‹äº† 128Gã€‚ç”¨äº†ä¸€å¤©ï¼Œæ„Ÿè§‰AMD AI395+è·Ÿä¹‹å‰i9-14900hxæ€§èƒ½å·®åˆ«ä¸å¤§ ä¸è¿‡å™ªéŸ³å¥½äº†å¾ˆå¤šï¼Œé›†æ˜¾8060sçš„æ€§èƒ½è™½ç„¶ä¸å¦‚ä¹‹å‰4070ï¼Œä½†æ˜¯è·‘ä¸ªæœ¬åœ°å°æ¨¡åž‹ä¹Ÿæ²¡ä»€ä¹ˆåŽ‹åŠ›ã€‚
  - é‡é‡ä¸Š1.6KGç¨å¾®é‡äº†ä¸€ç‚¹ç‚¹ï¼Œè·ŸX1Cæ²¡æ³•æ¯”ï¼Œè·Ÿmacbook pro 14å·®ä¸å¤šï¼Œæ¯”çµåˆƒå¼ºå¤ªå¤šäº†ã€‚
  - è§¦å±çš„

- pdå……ç”µèƒ½æœ‰åŽŸåŽ‚å……ç”µå™¨å‡ æˆçš„æ€§èƒ½ï¼Ÿ
  - åŽŸåŽ‚130wçš„ï¼Œ65wçš„PDä¼šæç¤ºæ…¢é€Ÿå……ç”µå™¨ï¼Œåªæœ‰ä¸€åŠä¸åˆ°çš„é€Ÿåº¦

- æœ¬åœ°70Bé€Ÿåº¦æ€Žä¹ˆæ ·ï¼Ÿ
  - æœ‰ä¸ª20-30 token/s å‡‘åˆç”¨
- æˆ‘qwrn32é‡åŒ–8ä¹Ÿæ‰5ä¸ªtokenï¼Œä½ è¿™ä¸ª70b 20-30tokenæ˜¯æ€Žä¹ˆæ¥çš„
  - 70é‡åŒ–4å¯ä»¥çš„ï¼Œé‡åŒ–8è‚¯å®šä¸è¡Œ

- ## ðŸ†š [å…³äºŽå‡ ä¸ªæ¡Œé¢çº§çš„AIç»Ÿä¸€å†…å­˜é›†æˆæ–¹æ¡ˆçš„å¯¹æ¯” - çŸ¥ä¹Ž _202503](https://zhuanlan.zhihu.com/p/31599083340)
- ç›®å‰æ¡Œé¢çº§åˆ«çš„AIæ–¹æ¡ˆï¼Œé™¤äº†nvçš„ç‹¬æ˜¾å¤–ï¼Œè¿˜æœ‰å‡ ä¸ªç»Ÿä¸€å†…å­˜çš„é›†æˆæ–¹æ¡ˆ
  - è‹¹æžœMac miniå’ŒMac studio
  - AMD AI 395 MAX
  - è‹±ä¼Ÿè¾¾ DGX Spark

- å¸¦å®½ ï¼š(â“æŽ¨ç†/éƒ¨ç½²æ—¶é‡è¦)
  - m4pro 64G å’Œnv dgx spark 128Géƒ½æ˜¯ 273 GB/s
  - amd AI 395 max+128G æ˜¯            256 GB/s
  - m3ultra 96Gæ˜¯                     400 GB/s (m3uæ— 128Gï¼Œ256Gä»¥ä¸Šæ‰æœ‰800GB/s)
  - m4max 128G æ˜¯                     546 GB/s

- AIç®—åŠ›ï¼š(â“è®­ç»ƒæ—¶é‡è¦)
  - nv dgx sparkæ˜¯  1000 TOPS (FP4)
  - amd AI395maxæ˜¯  126 TOPSï¼ˆint4ï¼‰
  - m3ultraæ˜¯       72 TOPS(int4)
  - m4maxå’Œm4proéƒ½æ˜¯ 38 TOPS(int4)

- ä»·æ ¼ï¼š
  - nv dgx spark  3000 ç¾Žå…ƒï¼ˆä¼°è®¡23000äººæ°‘å¸ï¼Ÿï¼‰
  - amd ai395max  25999 äººæ°‘å¸
  - m3ultra 96G   32999 äººæ°‘å¸
  - m4max 128G    29249 äººæ°‘å¸
  - m4pro 64G+1T  16999 äººæ°‘å¸

- ç»¼åˆçœ‹æ¥å¦‚æžœæ€§ä»·æ¯”å’Œé€šç”¨æ€§æ¯”è¾ƒå¥½çš„é€‰æ‹©åº”è¯¥æ˜¯nv DGX Sparkï¼ˆç”Ÿå›¾ï¼Œç”Ÿè§†é¢‘ä¹‹ç±»çš„ç®—åŠ›æ¯”å¸¦å®½æ›´é‡è¦ï¼‰ï¼Œ
  - å¦‚æžœå•çº¯ä¸ºäº†LLMæ€§èƒ½ï¼ˆç»Ÿä¸€å†…å­˜å¸¦å®½æ¯”ç®—åŠ›æ›´é‡è¦ï¼‰m3ultra 96G å¯èƒ½æ˜¯æ¯”è¾ƒå¥½çš„é€‰æ‹©ã€‚
- è‡³äºŽä¹‹å‰æœ‰çœ‹åˆ°çš„ä¸€äº›ç”¨mac minié€šè¿‡é›·ç”µå£å †å çš„è™½ç„¶å¯ä»¥ä½Žæˆæœ¬åšåˆ°å¤§æ˜¾å­˜ï¼Œä½†æ˜¯å‡ ä¹Žæ²¡å•¥å®žç”¨ä»·å€¼ï¼Œå› ä¸ºé›·ç”µå£å¸¦å®½åªæœ‰15GB/sã€‚ã€‚ã€‚
  - é›·ç”µå †å æ˜¯ä¸ºäº†ä½Žå»¶è¿Ÿè·‘tensor parallelismå§ï¼Œåˆä¸æ˜¯remoteè®¿é—®å†…å­˜ã€‚PCIEå¸¦å®½ä¹Ÿä¸å¦‚å†…å­˜ï¼Œä½†å¤šå¡å¹¶è¡Œè¿˜æ˜¯æœ‰æ•ˆçš„

- çŽ°åœ¨ç½‘ä¸Šai max 395çš„å°ä¸»æœºå·²ç»å–åˆ°14000å·¦å³äº†ï¼Œè¿™æ ·æ¯”ä¸‹æ¥ï¼Œæ„Ÿè§‰ai max 395æ€§ä»·æ¯”è¿˜ä¸é”™ã€‚

- ## [å¦‚ä½•è¯„ä»·å”®ä»· 18999 å…ƒçš„æƒ æ™®æš—å½±ç²¾çµ MAX æ¸¸æˆæœ¬? å“ªäº›äº®ç‚¹å€¼å¾—å…³æ³¨? - çŸ¥ä¹Ž _202503](https://www.zhihu.com/question/15023061538/answers/updated)
- æš—å½±ç²¾çµMAXè¿™ä¸ªæ–°æ¨¡å…·å°±ç”¨æ¥å–ä»£æš—å½±ç²¾çµPlusçš„ï¼Œä¾ç„¶æ˜¯ä¸»æ‰“ä¸€ä¸ªâ€œä¸€çº¿å“ç‰Œä¸­çš„æ€§ä»·æ¯”â€å®šä½ã€‚
- ä¸€çº¿å“ç‰Œé«˜ç«¯æ¸¸æˆæœ¬çš„å®ˆé—¨å‘˜ï¼ŒåŽŸæ¥æš—å½±ç²¾çµPLUSçš„æ›¿ä»£è€…ã€‚

- è¿™ä»£Maxæ•´ä½“çš„å‡çº§ç‚¹ï¼š
  - æ•£çƒ­è§„æ ¼å‡çº§ï¼šé‡‡ç”¨äº†VCå‡çƒ­æ¿è®¾è®¡ï¼ŒåŠ ä¸Šæ¶²é‡‘æ•£çƒ­ä¸Ž4å‡ºé£Žå£è®¾è®¡ï¼Œæ•´ä½“å¯ä»¥åšåˆ°250W+çš„æ€§èƒ½é‡Šæ”¾ï¼ŒåŒçƒ¤75+175Wï¼›
  - å±å¹•æ”¹ä¸ºæ›´ä¸»æµçš„16å¯¸ï¼š2.5Kåˆ†è¾¨çŽ‡16:10æ¯”ä¾‹é«˜åˆ†å±ï¼Œ500nitäº®åº¦240Hzåˆ·æ–°çŽ‡ï¼›
  - æ–°å¢žå¤§å¸ˆæ¨¡å¼ï¼Œå…è®¸ç”¨æˆ·æ‰‹åŠ¨è¶…é¢‘ã€‚

- å…¶ä»–é…ç½®åªèƒ½è¯´ä¸­è§„ä¸­çŸ©äº†ï¼š
  - 32GB DDR5-5600å†…å­˜+1TBç¡¬ç›˜ï¼ŒåŒç¡¬ç›˜ä½åŒå†…å­˜æ’æ§½ï¼›
  - åªç»™äº†2A2Cï¼ˆ2ä¸ªé›·ç”µ4ï¼‰+HDMI+RJ45çš„æŽ¥å£ï¼Œåœ¨æ¸¸æˆæœ¬é‡Œé¢ç®—æ¯”è¾ƒå°‘çš„äº†ï¼›
  - ç»™äº†RGBèƒŒå…‰é”®ç›˜ï¼Œä½†ç›®å‰æ¥çœ‹è¿˜æ˜¯å››åŒºRGBè€Œéžå•é”®RGBï¼Œå¹¶ä¸”æ–¹å‘é”®ä¾æ—§ä¸ºåŠé«˜ï¼›
  - ç”µæ± å®¹é‡83Whï¼Œä¸»æµæ——èˆ°å®šä½çš„æ¸¸æˆæœ¬éƒ½90Wh+äº†ï¼Œæœ‰çš„ç”šè‡³99Wh

- ç›®å‰æƒ æ™®ç²¾çµé‡åˆ°ä¸€ä¸ªæ¯”è¾ƒå°´å°¬çš„é—®é¢˜ï¼Œæ¯”ä¸Šæ²¡æœ‰å“ç‰ŒåŠ›ï¼Œæ¯”ä¸‹æ²¡æœ‰æ€§ä»·æ¯”ï¼š
  - åŠ 3000å¯ä»¥ä¸Šé€¼æ ¼æ›´é«˜ã€æ›´æœ‰æ°›å›´æ„Ÿã€å¯çŽ©æ€§æ›´é«˜çš„ä¸”å“ç‰Œæ›´å¼ºçš„ROGæžªç¥ž9ç³»åˆ—ï¼›
  - é¢„ç®—æ›´ä½Žï¼Œç­‰äºŒçº¿å“ç‰Œä¸Šäº†ä¹‹åŽï¼Œå¤§æ¦‚çŽ‡1W4ä¸åˆ°å°±å¯ä»¥æ‹¿ä¸‹ä½ŽUé«˜æ˜¾çš„RTX5080æ¸¸æˆæœ¬äº†ï¼Œæ€§ä»·æ¯”æ›´é«˜ã€‚
- å›½å†…æ¸¸æˆæœ¬å¸‚åœºç›®å‰è¿˜æ˜¯ä»¥æ€§ä»·æ¯”ä¸ºä¸»å¯¼ï¼Œå°±è¿žROGè¿™ä¸¤å¹´éƒ½å˜å¾—æœ‰æ€§ä»·æ¯”èµ·æ¥ï¼Œæ‰€ä»¥å¯¹äºŽæš—å½±ç²¾çµMAXè¿™ç±»çš„ä¸ä¸Šä¸ä¸‹çš„ä¸»æµç³»åˆ—æ——èˆ°æœ¬ï¼Œæˆ‘æ˜¯è°¨æ…Žçœ‹å¥½çš„ï¼Œæ¯”ä¸Šæ— å“ç‰ŒåŠ›ï¼Œæ¯”ä¸‹æ— æ€§ä»·æ¯”ã€‚

- å°ç±³Gçš„ç›®æ ‡å®¢æˆ·æ˜¯è¿½æ±‚æ€§ä»·æ¯”çš„ç”¨æˆ·ï¼Œä½†è¿™å¸®ç”¨æˆ·ä¼šå› ä¸ºå°ç±³Gæ²¡æœ‰æ€§ä»·æ¯”ä¸é€‰æ‹©å°ç±³Gâ€¦â€¦

- ## ðŸ†šðŸ“ˆ [2025ä¹°ä¸ªRTX 5090ç¬”è®°æœ¬ï¼Œæœ‰ä»€ä¹ˆæŽ¨èå—ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/1890528801219405195)

> ä¸å¤ªåœ¨æ„ä¾¿æºï¼Œä¸»è¦æ˜¯çœ‹æ€§èƒ½+æ€§ä»·æ¯”ã€‚ç¥žèˆŸæ€§ä»·æ¯”å¤ªé«˜äº†ï¼Œä½†æ˜¯åˆæœ‰ç‚¹å®³æ€•ç¿»èˆ¹ã€‚

- åœ¨åœˆå®šè¦RTX5090æ¸¸æˆæœ¬çš„å‰æä¸‹ï¼Œé¢˜ä¸»çš„æœ€ä½³é€‰æ‹©è‚¯å®šæ˜¯ä¸€çº¿å“ç‰Œé«˜ç«¯æ¸¸æˆæœ¬ä¸€ç›´ä»¥æ¥çš„æ€§ä»·æ¯”æ‰›æŠŠå­ï¼Œæš—å½±ç²¾çµMAXå•Š
  - U9-275HX+RTX5090+2.5k 240hz 500nit IPS+32/1T PCIe 5.0çš„æ ¸å¿ƒé…ç½®ï¼Œ250w+çš„æ•´æœºæ€§èƒ½é‡Šæ”¾è¡¨çŽ°ä¸­ç­‰åä¸Šï¼Œæ‹“å±•æ€§ä¸€ä¸ª5.0 M.2ä¸€ä¸ª4.0 M.2ï¼Œé‡é‡2.75kgï¼ŒæŽ¥å£æ˜¯ä¿©é›·ç”µ4ï¼Œä¿©USB-Aï¼ŒHDMIå’Œrj45ã€‚
  - ä¸Šé¢è¿™ä¸ªé…ç½®ä¹Ÿå°±22999ï¼Œå›½è¡¥åŽæ‰20000å‡ºå¤´
  - ROGä¹Ÿå®Œå…¨æ²¡å¿…è¦çœ‹æžªç¥ž9 Plusè¶…ç«žç‰ˆå§ï¼Œæ†ç»‘äº†64Gå†…å­˜åŽä»·æ ¼ç›´æŽ¥33999äº†ï¼Œå®žåœ¨æ˜¯å¤ªå¤¸å¼ ã€‚æžªç¥ž9 è¶…ç«žç‰ˆé™¤äº†å†…å­˜ç¡¬ç›˜éƒ½ç¼©å°ä¸€åŠä»¥åŠå°ºå¯¸ä¸º16å‹ä¹‹å¤–ï¼Œå‡ ä¹Žæ²¡å•¥åŒºåˆ«ï¼Œä»·æ ¼åˆ™ç›´æŽ¥ä¸‹é™åˆ°äº†29999ï¼Œç«‹çœ4000.

- ## [æœ‰æ²¡æœ‰24gæ˜¾å­˜çš„ç¬”è®°æœ¬ç”µè„‘æŽ¨èï¼Ÿ - çŸ¥ä¹Ž _202409](https://www.zhihu.com/question/666131987)

> æƒ³è¦ä¹°ä¸ªæ–°ç”µè„‘æ¥çŽ©AIã€‚ä¸»è¦è¿˜æ˜¯æƒ³è€ƒè™‘ç¬”è®°æœ¬ï¼Œä½†æ˜¯çœ‹äº†ä¸€åœˆï¼Œå¥½åƒéƒ½æ˜¯8gæ˜¾å­˜ã€‚æœ€å¤§çš„ä¹Ÿå°±16gæ˜¾å­˜ã€‚æ²¡æœ‰æ‰¾åˆ°æœ‰24gæ˜¾å­˜ã€‚

- ç›®å‰åšAIæŽ¨èNå¡ï¼ŒNå¡24Gæ˜¾å­˜åªæœ‰4090ï¼Œ4090åšæˆä¾¿æºå¼åªæœ‰è¿™ä¸€ä¸ªæ–¹æ³•

- æœ‰ä¸‰ä¸ªæ–¹æ¡ˆï¼š
- ç¬¬ä¸€ä¸ªæ–¹æ¡ˆæ˜¯å†…ç½®æ˜¾å¡çš„ç¬”è®°æœ¬ç”µè„‘ï¼Œä¼˜ç‚¹æ˜¯ä¾¿æºæ€§å¥½ï¼Œç¼ºç‚¹æ˜¯æ€§èƒ½å·®ç‚¹ï¼Œä¹Ÿå¾—åšå¥½æ•£çƒ­ã€‚
  - æƒ³è¦16Gæ˜¾å­˜åªèƒ½RTX4090çš„åž‹å·ï¼Œç»å¤§éƒ¨åˆ†RTX4080ç§»åŠ¨ç«¯æ˜¯12Gæ˜¾å­˜ï¼Œç›®å‰ä½¿ç”¨RTX4090çš„ç¬”è®°æœ¬ç”µè„‘ä¸ç®—å¤šï¼Œæƒ³è¦æ€§ä»·æ¯”å°±æœºæ¢°é©å‘½è€€ä¸–16Superï¼Œæƒ³è¦æ›´å¼ºçš„æ•´æœºæ€§èƒ½é‡Šæ”¾å¯ä»¥è€ƒè™‘ROGæžªç¥žã€‚
- ç¬¬äºŒä¸ªæ–¹æ¡ˆæ˜¯æ‹“å±•åžå¤–æŽ¥æ¡Œé¢æ˜¾å¡ï¼Œä¼˜ç‚¹æ˜¯æ€§èƒ½å¼ºä¸ç”¨è€ƒè™‘æ•£çƒ­ï¼Œå¹¶ä¸”åŽæœŸè¿˜èƒ½éšæ—¶æ— ç—›å‡çº§æ˜¾å¡ï¼Œç¼ºç‚¹æ˜¯ä¸§å¤±äº†ä¾¿æºæ€§ï¼Œå¹¶ä¸”è¦æ³¨æ„åˆ«æ²¡æ–­ç”µå°±æ‹”æ˜¾å¡ã€‚
  - ç¬”è®°æœ¬æœ‰é›·ç”µ3/4æˆ–è€…USB4æŽ¥å£å°±è¡Œï¼ŒRTX4080ä¼šæœ‰æ€§èƒ½æŸå¤±ï¼Œä½†æ˜¯èƒ½æŽ¥å—ï¼Œæ¯•ç«Ÿæ€Žä¹ˆéƒ½æ¯”ç§»åŠ¨ç«¯å¼º
- ç¬¬ä¸‰ä¸ªæ–¹æ¡ˆå°±æ˜¯æ”¾å¼ƒç¹æ–‡ç¼›èŠ‚ï¼Œç›´æŽ¥ä¸Šå°å¼æœºå§ã€‚

- ## [çº ç»“é€‰å“ªæ¬¾ç¬”è®°æœ¬ç”µè„‘ï¼Ÿä¸»è¦ç”¨äºŽstable diffusion? - çŸ¥ä¹Ž](https://www.zhihu.com/question/620893866)
- çœ‹åˆ°æ¥¼ä¸‹æœ‰ä¸ªå¥½ç‚¹çš„å»ºè®®ï¼Œé›·ç”µæŽ¥å£çš„ç¬”è®°æœ¬+æ˜¾å¡æ‹“å±•åž+ç‹¬ç«‹æ˜¾å¡
  - è¿™ä¸ªæ–¹æ¡ˆçš„è¯ï¼Œæ‹“å±•åžä¸åšæŽ¨èç¡®å®žä¸çŸ¥é“æ€Žä¹ˆé€‰ï¼Œä½†æ˜¾å¡4090æ™®é10000ä»¥ä¸Šäº†

- ## [AIç»˜ç”»ï¼ˆStable Diffusionï¼‰ç”¨ä»€ä¹ˆæ˜¾å¡æ¯”è¾ƒå¥½ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/638915747)
- åœ¨ä½ èƒ½æ‰¿å—çš„èŒƒå›´å†…ï¼Œé€‰æ˜¾å­˜æœ€å¤§çš„

- ç›®å‰çš„æ¡ä»¶ä¸‹åªæœ‰Nå¡èƒ½æ­£å¸¸çŽ©AIã€‚
- æƒ³è¦ä½Žä»·æ‹‰æ»¡AIã€‚å°±ç”¨RTX TITAN 24GBï¼ˆä¸åˆ°5000ï¼Œä½†éœ€è¦åŠ æ°´å†·åŽ‹ï¼Œæˆ–è€…é­”æ”¹çš„RTX 2080Ti 22Gï¼ˆä¸åˆ°3000ï¼‰éžæ¶¡è½®å¡çš„ç‰ˆæœ¬ã€‚ä½†çŽ°åœ¨ç›®å‰çœ‹24Gçš„3090æ€§ä»·æ¯”æœ€é«˜ã€‚

- æŽ¨èä¸€å—æ€§ä»·æ¯”é«˜çš„æ˜¾å¡ï¼ŒRTX 2080ti 22gã€‚aiç”»å›¾æ€§èƒ½æŽ¥è¿‘RTX 4090çš„ä¸€åŠï¼Œä»·æ ¼åªè¦äº”åˆ†ä¹‹ä¸€ã€‚è€Œä¸”22gå¤§å†…å­˜ï¼Œå¯¹æ¨¡åž‹è®­ç»ƒä¹Ÿå¾ˆå‹å¥½ã€‚ä¸è¿‡RTX 2080ti å·²ç»ä¸Šå¸‚å¾ˆå¤šå¹´äº†ï¼Œè¦æ·˜åˆ°ä¸€å—å¥½å¡ä¸å®¹æ˜“ï¼Œæœ€å¥½æœ‰å‡ å¹´ä¿ä¿®çš„æ›´å¥½

- è·‘4Kä»¥ä¸Šç¨³ç¨³çš„ï¼Œæ˜¾å­˜ä¸º32Gçš„æ˜¾å¡ä¸€å®šæ˜¯é¦–é€‰ï¼Œä¸æ˜¯é­”æ”¹æ¬¾ï¼Œé‚£å°±åªæœ‰å³å°†ä¸Šæž¶çš„5090äº†ã€‚
  - è·‘2Kä»¥ä¸Šçš„è¯ï¼Œ12G-16Gçš„å¡éƒ½å¯ä»¥ï¼Œä¸è¿‡12Gè·‘æŸäº›å¤§æ¨¡åž‹å¯èƒ½ä¸å¤Ÿç”¨
  - 2Kå°†å°±ç”¨ï¼Œç›®å‰é€‰4060TI 16Gçš„ç”¨æˆ·å¤šç‚¹ï¼Œä¸è¿‡è¿™æ¬¾æ˜¾å¡åªæ˜¯é¢„ç®—å°‘çš„é€‰æ‹©ï¼Œæ¯•ç«Ÿæ˜¾å­˜ä½å®½è¢«é˜‰å‰²ï¼ŒGPUæ€§èƒ½ä¹Ÿä¸€èˆ¬ã€‚
  - æ²¡çŸ­æ¿ï¼Œå‡ºå›¾å¿«ï¼Œé¦–æŽ¨4070TIS 16Gï¼Œè¿™æ¬¾å¡ï¼Œæˆ‘ç”¨ä¸‹æ¥å¾ˆæ»¡æ„ï¼Œç¼ºç‚¹å°±æ˜¯æº¢ä»·é«˜ã€‚
  - è·‘1Kä»¥ä¸Šçš„è¯ï¼Œ3060 12Gï¼Œ2060 12Gï¼Œéƒ½å·²ç»å¯ä»¥è·‘äº†

- ç»è¿‡ä¸æ–­çš„ä¼˜åŒ–ï¼ŒçŽ°åœ¨çš„Stable Diffusionå¯¹æ˜¾å¡è¦æ±‚ä¸ç®—å¤ªé«˜ï¼Œ
  - å¦‚æžœåªæ˜¯è·‘å›¾ï¼Œ4060Ti 16Gå°±å¤Ÿç”¨ï¼Œç‚¼ä¸¹çš„è¯ï¼Œ4090ä¹Ÿè¶³å¤Ÿäº†ã€‚

- è‡³äºŽä¹Ÿæ˜¯3000å¤šçš„2080Ti-22Gï¼Œé­”æ”¹çš„æœ‰é£Žé™©ï¼Œå¤šå‡ Gæ˜¾å­˜å¯¹è¿™ä¸ªè½¯ä»¶æ¥è¯´ç”¨å¤„ä¸å¤§ï¼Œæœ‰æ–°è¿˜æ˜¯ä¹°æ–°ã€‚
  - ä¹‹åŽå°±æ˜¯7000è¿™ä¸€æ¡£çš„ï¼Œ5070Tiï¼Œä¸ºä»€ä¹ˆä¸æ˜¯4070Tiså‘¢ï¼Œå› ä¸º50ç³»æ˜¾å¡å¯ä»¥ç”¨4ä½æ¨¡åž‹ï¼Œ40ç³»åªèƒ½8ä½ã€‚

- 10ç³»æ˜¾å¡ä¸æ”¯æŒ4bitï¼ˆå…¶å®žä¹Ÿä¸æ”¯æŒ8bitã€16bitï¼‰ï¼Œä½†æ˜¯Q4èƒ½è·‘å•Šï¼Œå°±æ˜¯æ…¢å‘—ã€‚å·¥ä½œåŽŸç†æ˜¯æŒ‰åŽŸä½æ•°å¤§å°è£…æ˜¾å­˜ä¸­ï¼Œè·‘çš„æ—¶å€™åˆ†æ®µè½¬æ¢æˆfp32æ¥è·‘ã€‚

- ## [å¦‚ä½•è¯„ä»·HPæœ€æ–°å‘å¸ƒçš„æ­è½½AI MAX 300ç³»åˆ—å¤„ç†å™¨çš„æˆ˜99 Ultraï¼Ÿ â€œæˆ˜ 99 Ultraâ€ç§»åŠ¨å·¥ä½œç«™å·²äºŽ3æœˆ17å·ä¸Šæž¶äº¬ä¸œ  - çŸ¥ä¹Ž](https://www.zhihu.com/question/15255805038)
- ä»Šå¹´å”¯äºŒçš„Strix Haloç¬”è®°æœ¬ï¼ˆå¦ä¸€ä¸ªæ˜¯å¹»Xï¼‰ï¼ŒåŒæ—¶å¯èƒ½æ˜¯å”¯ä¸€çš„å¸¸è§„å½¢æ€äº§å“ã€‚
  - è¿™æœºå™¨åœ¨æµ·å¤–çš„åç§°æ˜¯Zbook Ultra G1aï¼Œå®žè´¨ä¸Šæ˜¯EliteBook X G1açš„å¤ç”¨æ¨¡å…·ä½†åŠ åŽš+å¢žå¼ºæ•£çƒ­çš„ç‰ˆæœ¬ã€‚å®šä½å°±æ˜¯æ——èˆ°è½»è–„ç§»åŠ¨å·¥ä½œç«™çš„å°å°ºå¯¸ç‰ˆæœ¬ï¼Œç±»ä¼¼ThinkPad P1ï¼Œä½†æ˜¯åšäº†14å‹çš„ç‰ˆæœ¬ã€‚
  - CPUæ–¹é¢ï¼Œé™¤äº†å’Œä¹‹å‰å·²ç»ä¸Šå¸‚çš„å¹»Xä¸€æ ·çš„AI MAX 390/395ï¼ˆåˆ†åˆ«å¯¹åº”16C+40CU/12C+32CUï¼‰ä¹‹å¤–ï¼Œè¿˜å¤šäº†ä¸€é«˜ä¸€ä½Žä¸¤ä¸ªæ–°çš„é…ç½®ï¼Œæ›´ä½Žçš„AI MAX 385æ˜¯8C+32CUçš„è§„æ ¼ï¼ŒåŒæ—¶è¿˜æœ‰ä¸ªé¡¶é…çš„å•†ç”¨ç‰ˆAI MAX+ Pro 395ï¼Œè¿™é¢—CPUæ˜¯æƒ æ™®ç‹¬å çš„ã€‚
- å…¶ä»–åœ°æ–¹å°±åŸºæœ¬å’ŒåŽŸç‰ˆçš„EliteBookä¸€è‡´äº†ï¼š
  - 2.8k 120hzçš„OLEDè§¦æ‘¸å±
  - 74.5whç”µæ± ï¼Œæ”¯æŒPD 3.1å¿«å……
  - å•ç¡¬ç›˜ä½

- è¿™ä»·æ ¼åªèƒ½è¯´æ˜¯å¥½å®¶ä¼™äº†ï¼Œ55wæ€§èƒ½é‡Šæ”¾çš„å¸¸è§„å½¢æ€æœºå™¨ï¼Œå–çš„æ¯”éš”å£å¹»Xçš„å¹³æ¿å½¢æ€+80wæ€§èƒ½çš„è¿˜è´µ... å¦‚æžœä¸€å®šä¹°è€ƒè™‘ï¼ŒåªæŽ¨èé¡¶é…ç‰ˆæœ¬ï¼Œèµ·ç è¿˜æ˜¯æœ‰ç‹¬å CPUçš„

- å¦‚æžœä¸»è¦æ˜¯å†²ç€Strix Haloè¿™é¢—CPUæ¥çš„ï¼Œé‚£è¿˜æ˜¯æ›´æŽ¨èå¹»Xï¼Œå› ä¸ºæ€§ä»·æ¯”æ›´é«˜ï¼ŒAI MAX+ 395+128/1Tçš„ç‰ˆæœ¬ä¹Ÿå°±20999ï¼Œå¦‚æžœæ˜¯32Gçš„ç‰ˆæœ¬ï¼Œå°±åªè¦14999äº†ã€‚

- ä¸ºä»€ä¹ˆSTX Haloè¿™é¢—CPUçœ‹èµ·æ¥å¾ˆå¥½ï¼Œä½†å®žé™…ä¸Šæ— OEMæ„¿æ„ç”¨ï¼Ÿä¸ªäººè®¤ä¸ºä¸»è¦åŽŸå› æ˜¯ä¸¤ç‚¹ï¼š
  - ä¸€ä¸ªæ˜¯è¿™é¢—å¤„ç†å™¨åŽŸæœ¬åº”è¯¥åœ¨2024å¹´å’ŒSTX Pointä¸€èµ·ä¸Šï¼Œå´å› ä¸ºç§ç§åŽŸå› å»¶è¯¯åˆ°äº†ä»Šå¹´ï¼Œå› æ­¤å¯¹æ ‡çš„å¯¹è±¡ä¹Ÿä»ŽåŽŸæ¥çš„RTX 4060å˜æˆäº†RTX 5050ï¼Œè¿™æ—¶å€™STX Haloçš„æ ¸æ˜¾æ€§èƒ½å®žé™…ä¸Šå°±æ²¡æœ‰å¤ªå¤§çš„å¸å¼•åŠ›äº†
  - å¦ä¸€ç‚¹åœ¨äºŽSTX Haloäº§ç”Ÿçš„æœ€å¤§æ„ä¹‰åœ¨äºŽåœ¨ç©ºé—´å°ºå¯¸å—é™çš„å¹³å°ä¸Šåšåˆ°å°½å¯èƒ½é«˜çš„æ€§èƒ½ï¼Œä½†çŽ°åœ¨ROGå·²ç»åœ¨14.0å‹çš„è½»è–„å¹³å°ä¸Šåšå‡ºæ¥BD1çš„å¡äº†ï¼ˆRTX 5080 on å¹»14 Airï¼‰ï¼Œå¹»Xçš„ä¸Šä¸€ä»£ä¹Ÿæ—©å·²ç»æŒ‘æˆ˜è¿‡åœ¨13å‹çš„å¹³æ¿ä¸ŠåšH45+BD2æ˜¾å¡
- STX Haloè¿™ä¹ˆä¸ªæ€ªç‰©CPUæœ¬èº«å­˜åœ¨çš„æ„ä¹‰å°±å·²ç»å—åˆ°äº†ä¸¥é‡çš„åŠ¨æ‘‡äº†ã€‚ç»§ç»­å¾€å°å°ºå¯¸åšï¼Ÿé‚£æ•£çƒ­æ›´å®Œè›‹ï¼Œæ€§èƒ½ä¹Ÿè·Ÿç€å¯„ã€‚ç»§ç»­å¾€å¤§å°ºå¯¸åšï¼Ÿåšåˆ°15å‹åŠä»¥ä¸Šçš„å¹³å°ä¸Šï¼Œä¼ ç»Ÿçš„CPU+GPUæ–¹æ¡ˆæˆæœ¬ä½Žï¼Œæ•£çƒ­æ›´å¥½åšï¼Œæ•´ä½“æ•ˆæžœè¿˜æ›´å¥½
  - ä¸ä¼šæœ‰äººçœŸçš„è§‰å¾—Aå¡æ¸¸æˆä½“éªŒå¥½å§ï¼Œå°¤å…¶æ˜¯ç§»åŠ¨ç«¯Aå¡

- æœ€å¤§çš„ç¼ºç‚¹è¿˜æ˜¯ä»·æ ¼ã€‚2.5ä¸‡çš„ä»·æ ¼ï¼Œå¦‚æžœä»¥ä»–å¯¹æ ‡çš„7945HX+RTX 4060çš„ç¬”è®°æœ¬ç”µè„‘ï¼Œéƒ½å¯ä»¥ä¹°3å°äº†ï¼Œé€‰æ‹©R9000Pä¹Ÿå°±8000å¤šå‡ºå¤´ã€‚é‚£å°±çœ‹ä½ æ„¿ä¸æ„¿æ„ä¸ºäº†è½»è–„ä»˜å‡ºæº¢ä»·äº†ã€‚

- æƒ æ™®æˆ˜99 Ultraï¼Œæµ·å¤–å¯¹åº”åž‹å·Zbook Ultra G1aï¼Œä¾¿æºç§»åŠ¨å·¥ä½œç«™å®šä½ã€‚å¸¸è§„çš„é…ç½®ä¾‹å¦‚å…¨é‡‘å±žæœºèº«ã€2.8K OLEDå±å¹•ã€æƒ æ™®å·¥ä½œç«™çš„ç¥–ä¼ æŽ¥å£3C+HDMI+1Aã€74.5Whç”µæ± å°±ä¸å†èµ˜è¿°äº†ã€‚
  - æœ€å¤§çš„äº®ç‚¹å°±æ˜¯AMDé”é¾™AI MAX 300ç³»åˆ—çš„å¤„ç†å™¨ã€‚AI MAX+ 395å¤„ç†å™¨æ˜¯æƒ æ™®ç‹¬å ï¼ŒCPUè§„æ ¼å’Œæ¡Œé¢ç«¯9950Xç›¸å½“ï¼Œåªä¸è¿‡å—åˆ¶äºŽç¬”è®°æœ¬ç”µè„‘æ•£çƒ­ä¸èƒ½å®Œå…¨å‘æŒ¥ï¼›è¯´æ˜¯é›†æ˜¾ï¼Œä½†æ˜¯æ€§èƒ½å ªæ¯”RTX 4060çš„ç‹¬æ˜¾ã€‚
  - åŒæ—¶å¦ä¸€å¤§å¥½å¤„åœ¨äºŽå®žçŽ°ç±»ä¼¼äºŽè‹¹æžœä¸€æ ·çš„128GBç»Ÿä¸€å†…å­˜ï¼Œæœ€å¤šå¯ä»¥åˆ†é…96GBç»™æ˜¾å­˜ã€‚128GBå†…å­˜ç‰ˆæœ¬ä¸º4é€šé“ï¼Œå†…å­˜åžåé€Ÿåº¦èƒ½å¤Ÿè¾¾åˆ°200GB/så‡ºå¤´ï¼Œæ¯”å¸¸è§„çš„åŒé€šé“100GB/sç›´æŽ¥ç¿»å€äº†
- 14å¯¸çš„ç¬”è®°æœ¬ç”µè„‘ï¼Œé‡é‡åˆ°äº†1.6kgï¼Œå±žäºŽæ˜¯åé‡çš„ã€‚æ€§èƒ½é‡Šæ”¾ä¹Ÿå°±åœ¨55Wï¼Œä¸èƒ½å‘æŒ¥å‡ºå®Œæ•´æ€§èƒ½ã€‚ä½œä¸ºç§»åŠ¨å·¥ä½œç«™åªæœ‰å•ç¡¬ç›˜ä½ã€‚

- é—®é¢˜æ˜¯æ€§èƒ½é‡Šæ”¾è¿˜ä¸å¦‚å¹»xï¼Œè¿™ä¸ªåªæœ‰55wã€‚

- ## [ROGå¹»X 2025å¯¹äºŽè¿è¡ŒAIåº”ç”¨ï¼ˆå¦‚æœ¬åœ°å¤§æ¨¡åž‹ï¼‰æœ‰æ²¡æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Ÿèƒ½å¦åŠ©åŠ›ç”¨æˆ·æå‡AIä½“éªŒï¼Ÿ - çŸ¥ä¹Ž _202503](https://www.zhihu.com/question/14670046303/answers/updated)
- å±žäºŽä»€ä¹ˆéƒ½èƒ½å¹²ï¼Œä»€ä¹ˆéƒ½å¹²ä¸å¥½çš„å¯Œå“¥çŽ©å…·ã€‚
  - ä¾¿æºå’Œç¦»ç”µæ€§èƒ½æ¯”ä¸è¿‡å‡ åƒå—çš„mac airã€‚
  - æ¸¸æˆæ€§èƒ½æ¯”ä¸è¿‡åŒä»·ä½çš„4080mï¼ˆé©¬ä¸Šå°±5080mäº†ï¼‰
  - å¤§æ¨¡åž‹è¢«åŒä»·ä½mac studio m4æ‰“çˆ†ã€‚

- è¿™çŽ©æ„è·‘å¤§æ¨¡åž‹çš„èƒ½åŠ›å°±æ˜¯ä¸ª3060 12gæˆ–è€…æœ€å¤š4060ti 16gçš„æ°´å¹³ï¼Œåæ­£12gï½ž16gæ˜¾å­˜è·‘ä¸èµ·æ¥çš„ä¸œè¥¿395ä¹Ÿæ²¡é€Ÿåº¦äº†ï¼Œè€Œåªè¦ç”¨æ˜¾å­˜èƒ½è·‘èµ·æ¥ï¼Œé€Ÿåº¦ç»å¯¹åŠæ‰“395ã€‚
- æŒ‰æˆ‘ç†è§£è¿™çŽ©æ„çš„æ„ä¹‰æ˜¯å…·å¤‡è½»è–„æœ¬å°‘æœ‰çš„åŒæ—¶å…·å¤‡64gä»¥ä¸Šå†…å­˜ã€ä¸å°¿å´©çš„ç»­èˆªã€è¶³å¤Ÿå¼ºçš„æ˜¾å¡ä»¥åº”ä»˜å›¾ç‰‡å’Œè§†é¢‘ç¼–è¾‘ã€‚ç„¶è€Œåœ¨è¿™ä¸ªåœºåˆä¸‹ï¼Œå´è¢«MacBook proå…¨æ–¹ä½çˆ†æ€ã€‚

- [ç‹¬å®¶é¦–å‘AI Max+395å¤„ç†å™¨ ROG å¹»X 2025è·‘åˆ†è§£ç¦ï¼Œæ˜¯å¦å€¼å¾—è´­ä¹°ï¼Ÿ - çŸ¥ä¹Ž _202502](https://www.zhihu.com/question/12616419565)
- æœ€è¿‘æˆ‘çœ‹åˆ°ä¸šå†…æ–°å‡ºçŽ°äº†2ç§æ¡Œé¢çº§AIè®¡ç®—/PCç±»äº§å“ï¼Œä¸€ä¸ªæ˜¯åœ¨NVIDIA GTCå¤§ä¼šä¸Šæ­£å¼å‘å¸ƒçš„DGX Sparkï¼ˆèŠ¯ç‰‡ä»£å·GB10ï¼‰ï¼Œè¿˜æœ‰åŸºäºŽAMD Ryzen AI MAX PROå¤„ç†å™¨çš„ç¬”è®°æœ¬/ç§»åŠ¨å·¥ä½œç«™/å°å¼æœºï¼Œéƒ½å®£ç§°èƒ½æ”¯æŒ70Bä¹ƒè‡³æ›´é«˜å‚æ•°çš„æ¨¡åž‹ã€‚
  - NVIDIA DGX Sparkå·ç§°â€œæœ€å°çš„ AI è¶…çº§è®¡ç®—æœºâ€ï¼Œå®ƒçš„å¤„ç†å™¨æœ‰ç‚¹åƒå¾®ç¼©ç‰ˆçš„DGXè®¡ç®—ç³»ç»Ÿï¼ˆå‚è€ƒä¸‹å›¾ï¼‰ï¼Œåœ¨GB10å•èŠ¯ç‰‡ä¸Šé›†æˆäº†Grace CPUâ€”â€”20ä¸ªArm Coreï¼Œä»¥åŠBlackwellæž¶æž„çš„GPUã€‚
  - AMD Ryzen AI MAX PROç³»åˆ—ï¼ˆä»£å·Stirx Haloï¼‰ï¼Œæ›´æŽ¥è¿‘ä¼ ç»Ÿé›†æˆæ˜¾å¡çš„x86 CPUï¼Œä½†æ•´åˆGPUçš„æ€§èƒ½å´æ¯”è¾ƒå¼ºã€‚å…¶é»˜è®¤TDPåŠŸè€—55Wï¼Œæ ¹æ®ä¸åŒç³»ç»Ÿè®¾è®¡ï¼ŒcTDPå¯è°ƒåŠŸè€—åœ¨45-120WèŒƒå›´ã€‚
  - æ— è®ºä½¿ç”¨CPUè¿˜æ˜¯GPUåšAIè®¡ç®—ï¼Œåœ¨LLMæŽ¨ç†çš„Prefillï¼ˆå†…å®¹è¾“å…¥ç†è§£ï¼‰é˜¶æ®µçš„ç“¶é¢ˆæ˜¯ç®—åŠ›ï¼›è€Œåœ¨Decodeè¾“å‡ºæ—¶çš„æ€§èƒ½ï¼ˆToken/sï¼‰åˆ™ä¸»è¦å—åˆ¶äºŽå†…å­˜å¸¦å®½ã€‚
  - æˆ‘ä»¬çœ‹åˆ°ä¸Šé¢2æ¬¾äº§å“éƒ½ä½¿ç”¨äº†256ä½LPDDR5x-8533å†…å­˜ï¼ˆAMDçš„å®žé™…è¿è¡Œé€ŸçŽ‡ä¸º8000ï¼‰ï¼Œæ¯”ä¼ ç»ŸAI PCçš„64ä½åŒé€šé“å†…å­˜æé«˜äº†ä¸€å€ï¼Œç›¸å½“äºŽ4é€šé“ã€‚
- ç”±äºŽGrace ARM CPUåªè®¤è¯äº†DGXâ„¢ OSæ“ä½œç³»ç»Ÿï¼Œåº”è¯¥åªèƒ½è·‘Linuxï¼ˆä¸å…¼å®¹Windowsï¼‰ï¼Œæ‰€ä»¥DGX Sparkä¸»è¦å°±æ˜¯ç”¨äºŽè®¡ç®—ï¼Œå›¾å½¢æ€§èƒ½æ–¹é¢ä¸çŸ¥æ˜¯å¦åšäº†ä¼˜åŒ–ï¼Ÿ
  - DGX Sparkçš„AIæ€§èƒ½ï¼Œä¸ŽGeForce RTX 5070æ¡Œé¢æ˜¾å¡è¾ƒä¸ºæŽ¥è¿‘ã€‚ä¸è¿‡æœ‰ä¸€ç‚¹ï¼Œ5070çš„æ˜¾å­˜å¸¦å®½é«˜è¾¾672GB/sï¼Œè¿™ä¸€ç‚¹å³ä½¿æ˜¯256bit LPDDR5xå†…å­˜çš„é›†æ˜¾ä¹Ÿå¿˜å°˜èŽ«åŠã€‚æ¯•ç«Ÿä¸€å—5070ç‹¬æ˜¾å°±æ˜¯250W TGPåŠŸè€—ï¼Œå…¶ç©ºé—´å ç”¨ä¹Ÿå¾ˆéš¾åšåˆ°Miniæœºç®±/è½»è–„ç¬”è®°æœ¬é‡Œé¢ã€‚

- ## [AIç»˜ç”»ï¼ˆStable Diffusionï¼‰ç”¨ä»€ä¹ˆæ˜¾å¡æ¯”è¾ƒå¥½ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/638915747)

- ## [ä¸è®¡é¢„ç®—ï¼Œå¸®æˆ‘ä¹°ä¸€å°æ€§èƒ½è¶…å¼ºï¼Œå¤–è§‚ç®€çº¦çš„ç¬”è®°æœ¬ç”µè„‘ï¼Ÿç”¨äºŽæœ¬åœ°éƒ¨ç½²å„ç§å¤§æ¨¡åž‹ï¼Œæš‚å®šå¾®è½¯ï¼Œè¿˜æœ‰åˆ«çš„é€‰å—ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/624402976)
- Windowsç¬”è®°æœ¬è¿™è¾¹çš„æ€§èƒ½å¤©èŠ±æ¿æ˜¯ i9-13980HX/R9-7945HX +RTX4090ï¼ˆ175Wï¼‰
  - è¿™ä¿©CPUæ€§èƒ½å·®ä¸å¤šï¼Œ7945HSä¾¿å®œç‚¹
  - æŽ¨èä½ é€‰i9-13980HXï¼Œå› ä¸ºIntelå¯¹å„ç§ç”Ÿäº§åŠ›å·¥å…·çš„å…¼å®¹æ€§æ›´å¥½ã€‚
  - ç§»åŠ¨ç«¯RTX4090çš„æ€§èƒ½ç›¸å½“äºŽæ¡Œé¢ç«¯çš„4070Tiï¼Œä½†æ˜¯å®ƒæœ‰16Gæ˜¾å­˜ï¼Œæ¯”12Gæ˜¾å­˜çš„4070Tiæ›´é€‚åˆè·‘æ¨¡åž‹ã€‚
  - ç›®å‰ï¼Œæ­è½½13980HSå’ŒRTX 4090ç¬”è®°æœ¬çš„ä»·æ ¼æ™®éåœ¨22000å…ƒä»¥ä¸Šã€‚æ¯”å¦‚ROGæžªç¥ž7å’Œå¾®æ˜ŸGP78HS
  - åŒæ ·çš„ä»·æ ¼ä½ å¯ä»¥ä¹°åˆ°i7 13700Kå’ŒRTX4090 24Gçš„å°å¼æœºï¼ˆæƒ æ™®æš—å½±ç²¾çµ9plusï¼‰

- å½“å‰ç¬”è®°æœ¬ç«¯æœ€å¼ºçš„4090ç¬”è®°æœ¬æ˜¾å¡ï¼Œè§„æ ¼ä¸ŠæŒå¹³æ¡Œé¢4080ï¼Œè·‘åˆ†æ€§èƒ½ä¸Šä¸Žæ¡Œé¢4070tiç›¸å½“
  - ç¬”è®°æœ¬ç«¯æ¬¡å¼ºçš„4080ç¬”è®°æœ¬æ˜¾å¡ï¼Œè§„æ ¼ä¸ŠæŽ¥è¿‘äºŽæ¡Œé¢4070tiï¼Œè·‘åˆ†æ€§èƒ½ä¸Žæ¡Œé¢3090ç›¸å½“

- å»ºè®®è¿˜æ˜¯æˆ´å°”ï¼Œæƒ æ™®ï¼Œè”æƒ³è¿™ä¸‰å®¶çš„å·¥ä½œç«™ç¬”è®°æœ¬å§ã€‚å·¥ä½œç«™é…ç½®çš„ç‹¬ç«‹å›¾å½¢æ˜¾å¡é€‚åˆçš„è¦æ±‚çš„å¤§é‡æ¨¡åž‹ï¼Œå†å°±æ˜¯å·¥ä½œç«™çš„å†…éƒ¨ç»“æž„ã€é…ç½®éƒ½æ˜¯é’ˆå¯¹å¤„ç†å¤§åž‹3Dæ¨¡åž‹åšäº†åŠ å¼ºã€ä¼˜åŒ–çš„ï¼Œå…¶å·¥ä½œç¨³å®šæ€§æ˜¯æ™®é€šç¬”è®°æœ¬æ— æ³•æ¯”æ‹Ÿçš„ã€‚

- ## [amdå‘å¸ƒæ–°çš„èŠ¯ç‰‡ï¼Œè¿™æ¬¡èŠ¯ç‰‡è·Ÿè‹¹æžœçš„m4ä¸€æ ·ï¼Œå°†gpuå’Œnpué›†æˆåˆ°åŒä¸€å—èŠ¯ç‰‡ä¸ŠåŽ»ï¼Œè¯´æ˜Žäº†ä»€ä¹ˆï¼Ÿ - çŸ¥ä¹Ž _202501](https://www.zhihu.com/question/9253691862)
  - AMD åœ¨ CES 2025 ä¸Šå‘å¸ƒäº†é”é¾™ AI Max 300â€œStrix Haloâ€ç³»åˆ— APUï¼Œæ­è½½äº†æœ€é«˜ 40CU çš„è¶…å¼ºæ ¸æ˜¾ï¼Œæ­¤å¤–é›†æˆäº† 50 TOPSâ€œXDNA 2â€ NPUã€‚
  - è¿™ç§å°†å¼ºåŠ› CPUã€GPUã€NPU ç­‰é›†æˆåˆ°ä¸€ä¸ªèŠ¯ç‰‡çš„åšæ³•ï¼Œçœ‹èµ·æ¥æœ‰ç‚¹åƒè‹¹æžœåœ¨ M ç³»åˆ—èŠ¯ç‰‡ä¸­çš„è®¾è®¡ã€‚

- è‹å¦ˆçœ‹åˆ°apple Mç³»åˆ—èŠ¯ç‰‡è¢«æ‹¿æ¥è·‘AIå¤§æ¨¡åž‹æŽ¨ç†çš„æ—¶å€™ï¼Œä¹Ÿé¼“æ£äº†ä¸€ä¸ªRyzen AI Max 300 ç³»åˆ—å¤„ç†å™¨è§„æ ¼æ›å…‰ï¼Œæœ€é«˜16æ ¸å¿ƒã€40CUæ ¸æ˜¾ ã€‚æœ€é«˜å¯ä»¥ä»Žå†…å­˜ä¸­åˆ†é…96GBè¶…å¤§æ˜¾å­˜ï¼Œç»“åˆROCmï¼ˆå¼€æ”¾è®¡ç®—å¹³å°ï¼‰ç³»ç»Ÿæ”¯æŒï¼Œæˆ–èƒ½å˜æˆæ–°ä¸€ä»£å°åž‹å·¥ä½œç«™ç¥žU

- ## [å¦‚ä½•çœ‹å¾…è‹±ä¼Ÿè¾¾å…¬å¸å‘å¸ƒçš„æ¡Œé¢çº§AIè¶…ç®—? - çŸ¥ä¹Ž](https://www.zhihu.com/question/8970511370)
- Project Digits çŽ°åœ¨æ”¹åå«ï¼šNVIDIA DGXâ„¢ Spark ã€‚
  - å…¶å®šä½æ˜¯ï¼šä¸ªäººæ¡Œé¢ç«¯çš„ AI è¶…çº§è®¡ç®—æœºã€‚
  - ç”± GB10 è¶…çº§èŠ¯ç‰‡é©±åŠ¨
  - ä½¿ç”¨ FP4ï¼ŒAI æ€§èƒ½è¾¾ 1000 TOPS
  - é…å¤‡ NVIDIA Blackwell GPUï¼Œâ½€æŒç¬¬äº”ä»£ Tensor Core æŠ€æœ¯
  - NVIDIA Grace CPU å®žçŽ°ï¼Œé‡‡ç”¨ 20-core é«˜æ€§èƒ½ Arm æž¶æž„
  - 128 GB ç»Ÿä¸€å¯»å€ç³»ç»Ÿå†…å­˜
  - æ”¯æŒé«˜è¾¾ 4 TB çš„ NVMe å­˜å‚¨
  - æ”¯æŒé«˜è¾¾ 200B å‚æ•°çš„å¤§è¯­è¨€æ¨¡åž‹
  - é€šè¿‡ NVIDIA Connect-X ç½‘ç»œè¿›è¡Œè¿žæŽ¥ï¼Œå¯è¿žæŽ¥ä¸¤ä¸ª DGX Sparkï¼Œæ”¯æŒé«˜è¾¾ 405B å‚æ•°çš„æ¨¡åž‹

- ## ðŸš€ [å¦‚ä½•è¯„ä»·è‹±ä¼Ÿè¾¾æ–°å‘å¸ƒçš„æ¡Œé¢ AI è¶…çº§ç”µè„‘ Project Digitsï¼Ÿ - çŸ¥ä¹Ž _202501](https://www.zhihu.com/question/8953765123)
- ä¸Šåˆè¿˜åœ¨çœ‹AMD strix haloï¼Œä¸‹åˆNvidiaçªç„¶å°±æ”¾äº†ä¸€ä¸ªç›¸åŒå®šä½çš„...

- æƒ³ä¹°çš„åŒå­¦æ³¨æ„ä¸‹è¿™ä¸ªè®¾å¤‡çš„å†…å­˜ï¼Œå®ƒæ˜¯ç»Ÿä¸€å†…å­˜ï¼Œå³CPUå’ŒGPUå…±äº«LPDDR5X. å®ƒä¸æ˜¯GDDR6ï¼Œä¹Ÿä¸æ˜¯HBM2çš„ã€‚
  - è™½ç„¶æœ‰ 128GBï¼Œä½†æ˜¯æ ¹æ® Grace æž¶æž„ CPU çš„ Product Briefï¼Œå• CPU çš„å†…å­˜å¸¦å®½æœ€å¤§åªæœ‰512GB/s
  - æ‰€ä»¥å¦‚æžœç”¨è¿™ä¸ªè®¾å¤‡æ¥è¿è¡Œå¤§è¯­è¨€æ¨¡åž‹ï¼Œç“¶é¢ˆå°±ä¼šå˜æˆè¿™ä¸ªå†…å­˜å¸¦å®½ã€‚
  - ç®€å•æ¥è®²ï¼Œå¤§è¯­è¨€æ¨¡åž‹æ¯ç”Ÿæˆä¸€ä¸ªtokenï¼Œå°±éœ€è¦å°†æ•´ä¸ªæ¨¡åž‹æ‰«ä¸€éè¿›è¡Œè®¡ç®—ï¼ˆå®žé™…ä¸Šæ¯”è¿™ä¸ªæè¿°å¤æ‚å¾ˆå¤šï¼‰ã€‚è¿™æ„å‘³ç€ï¼Œå½“æµ®ç‚¹ç®—åŠ›å……è£•çš„æ—¶å€™ï¼Œæ‰«æçš„é€Ÿåº¦å°±å†³å®šäº†ç”Ÿæˆæ–‡æœ¬çš„é€Ÿåº¦ä¸Šé™ã€‚
  - ç›®å‰è¿™ä¸ªè®¾å¤‡çš„å†…å­˜å¸¦å®½æ°´å¹³è·Ÿ M4 Max çš„ MacBook æ²¡ä»€ä¹ˆåŒºåˆ«ï¼ˆApple MacBook Pro M4 Max 128GB å†…å­˜å¸¦å®½æ˜¯546GB/sï¼‰
- æ‹¿ [Llama-3.3-70b-instruct-4bit] ä¸¾ä¾‹ï¼Œè¿™ä¸ª4bité‡åŒ–æ¨¡åž‹å¤§å°çº¦ä¸º40GBï¼Œé‚£ä¹ˆæ‰«ä¸€éå°±æ„å‘³ç€GPUè¦å¤„ç†40GBçš„æ•°æ®ï¼Œå¦‚æžœæƒ³è¦æ¯ç§’é’Ÿç”Ÿæˆ10 tokenï¼Œç®€å•è®¡ç®—å¯å¾—ï¼Œ40GB\*10 = 400GB, è¿™æ„å‘³ç€å†…å­˜å¸¦å®½è‡³å°‘æœ‰ 400GB/s æ‰èƒ½ä¿è¯æ¯ç§’é’Ÿèƒ½ç”Ÿæˆ 10 token.
  - å›žåˆ° digits è¿™ä¸ªè®¾å¤‡ï¼Œåœ¨512GB/s çš„æƒ…å†µä¸‹ï¼Œ**è¿è¡Œ 70b-4bit è§„æ¨¡çš„æ¨¡åž‹ï¼Œç”Ÿæˆé€Ÿåº¦ç†è®ºæœ€å¤§å€¼æ˜¯ 512/40 = 12.8 token/s**

- nvç‰ˆçš„mac miniã€‚å½“ç„¶mac miniæœ‰macosï¼Œproject digitsåªæœ‰linuxï¼Œæ“ä½œç³»ç»Ÿç”Ÿæ€ä¸Šä»¥åŠæ¡Œé¢çº§å®šä½ä¸Šä¼°è®¡ä¼šå¯¼è‡´æ‹‰èƒ¯æŽ‰ï¼Œnvè™½ç„¶æœ‰cudaç”Ÿæ€ï¼Œä½†æ˜¯åœ¨æ¡Œé¢çº§ç›¸æ¯”osçš„ç”Ÿæ€ï¼Œè¿˜æ˜¯æœ‰ç‚¹å›°éš¾çš„ã€‚
- å¤§æ¨¡åž‹æŽ¨ç†å…¶å®žæ˜¯ä¸ªå¾ˆå¾®å¦™çš„äº§å“éœ€æ±‚ï¼Œå¤§æ˜¾å­˜å®¹é‡å¾ˆé‡è¦ï¼Œmemory boundä¹Ÿæ˜¯äº‹å®žã€‚
  - æ€»ä½“æ¥è®²ï¼Œå®¹é‡æ¯”å¸¦å®½é‡è¦ï¼Œæ¯•ç«Ÿå®¹é‡å†³å®šäº†yes/noï¼Œå¸¦å®½å†³å®šäº†token/sçš„ä½“éªŒã€‚ä½†æ˜¯ä½“éªŒå·®åˆ°ä¸€å®šç¨‹åº¦ä¹Ÿæ˜¯ä¸ªyes/noçš„é—®é¢˜ã€‚
- ä»¥ai pcä»Šå¤©äº‹å®žä¸Šçš„è¶…çº§åº”ç”¨ä¸ºä¾‹aiç¼–ç¨‹è€Œè¨€ï¼Œ10 token/sä»¥ä¸‹åŸºæœ¬å°±æ˜¯çŽ©ç¥¨ï¼ŒåŠ ä¸Šaiå•°å“©å•°å—¦è¦åˆ†æžä¸€å¤§å †ï¼ŒåŸºæœ¬è¦åšåˆ°å¯ç”¨è¿˜æ˜¯å¾—30ï½ž40 token/s
  - æŒ‰ç…§æ¿€æ´»é‡ç®—ï¼Œ30ï½ž40token/sï¼Œå¦‚æžœ10GBçš„æ¿€æ´»é‡å°±300ï½ž400GB/sçš„å†…å­˜å¸¦å®½
  - denseæ¨¡åž‹10Bä¸Šä¸‹åšaiç¼–ç¨‹å‡ ä¹Žæ²¡æ³•ç”¨ï¼Œmoeå¯ä»¥æä¸€æã€‚
  - ç›®å‰çš„æ¨¡åž‹ä¸»æµçš„åŸºæœ¬éƒ½æ˜¯70bä»¥ä¸‹çš„denseï¼Œä»¥åŠ200bä»¥ä¸Šçš„moeï¼Œ70bä»¥ä¸‹çš„denseå¾ˆå°´å°¬ï¼Œæ•ˆæžœä¸Šæ¯”è¾ƒéš¾æŽ¥è¿‘200bä»¥ä¸Šçš„moeï¼Œå®¹é‡éœ€æ±‚å°ï¼Œä½†å¸¦å®½éœ€æ±‚å¯æ˜¯å®žæ‰“å®žçš„è¶…çº§é«˜ã€‚æ¯”è¾ƒé€‚é…[gddræ˜¾å­˜] çš„æ­£ç»æ¸¸æˆå¡ã€‚

- GB10çš„èŠ¯ç‰‡ï¼Œåº”è¯¥æ˜¯ä»ŽæœåŠ¡å™¨çš„GB100å½“ä¸­ç ä¸€åˆ€ä¸‹æ¥ç”¨çš„ã€‚CPUæ˜¯è”å‘ç§‘å®šåˆ¶çš„ä¸€é¢—ARMï¼ŒGPUéƒ¨åˆ†ç®—åŠ›è¾¾åˆ°1ä¸ªPï¼Œfpç®—åŠ›ã€‚æœ€å¤§çš„äº®ç‚¹ç›´æŽ¥æ‹¿äº†128GBçš„ LPDDR 5xå†…å­˜åšæ˜¾å­˜ã€‚
  - å¾ˆå¤šäººå…¶å®žä¸çŸ¥é“ï¼ŒçŽ°åœ¨è·‘å¤§æ¨¡åž‹æ— è®ºæ˜¯è®­ç»ƒè¿˜æ˜¯æŽ¨ç†ï¼Œæœ€å¤§çš„ç“¶é¢ˆæ˜¯æ˜¾å­˜å®¹é‡ä¸è¶³ï¼ˆMemory boundï¼‰ï¼Œè€Œä¸æ˜¯ç®—åŠ›ä¸è¶³(Compute bound)ã€‚
  - æ¯”å¦‚ä¸€ä¸ª200Bçš„æ¨¡åž‹ï¼Œåœ¨fp4æˆ–è€…int 4çš„å‰æä¸‹ï¼Œå…‰æ˜¯æ˜¾å­˜å ç”¨å°±è¦æœ‰100GBå¤§å°ã€‚è¿è¡Œèµ·æ¥ä¹‹åŽè¿˜è¦æœ‰kv cacheéšç€ä¸Šä¸‹æ–‡é•¿åº¦å ç”¨è€Œå¢žå¤§ã€‚ä¸€å¼ æ˜¾å¡è£…ä¸ä¸‹ï¼Œå°±è¦åˆ†å¸ƒåœ¨å¤šå¼ å¡ä¸Šï¼Œé‚£ä¹ˆå°±ä¼šäº§ç”Ÿé€šä¿¡å¼€é”€ä»Žè€Œå¯¼è‡´ç®—åŠ›æ— æ³•è¢«å……åˆ†åˆ©ç”¨ï¼Œä¸å¾—ä¸ç­‰å¾…é€šä¿¡å®Œæˆä¹‹åŽå†è¿›è¡Œè®¡ç®—ã€‚
  - ä¹‹å‰æ¶ˆè´¹çº§çš„RTX 4090ï¼Œæœ€å¤§çš„æ˜¾å­˜åªæœ‰24GBã€‚RTX 5090ï¼Œä¹Ÿåªæœ‰32GBæ˜¾å­˜è€Œå·²ã€‚æ•°æ®ä¸­å¿ƒå¡ä¾‹å¦‚A100æœ‰40Gå’Œ80Gï¼Œä½†ä»·æ ¼åˆä¼šæ˜¾è‘—æ¯”æ¶ˆè´¹çº§æ˜¾å¡è´µã€‚
  - æ‰€ä»¥çŽ°åœ¨è¿™ä¸ª128GBçš„å†…å­˜ä½œä¸ºç»Ÿä¸€æ˜¾å­˜ä½¿ç”¨ï¼Œè‡³å°‘è§£å†³äº†æ˜¾å­˜ä¸å¤Ÿç”¨çš„é—®é¢˜ã€‚3000ç¾Žå…ƒçš„å”®ä»·ï¼Œç”šè‡³å¯ä»¥è¯´è‰¯å¿ƒäº†ã€‚

- CPUæ˜¯è”å‘ç§‘å®šåˆ¶çš„ä¸€é¢—ARMï¼Œè·‘LinuxçŽ©æ¯›æ¸¸æˆ

- å…¶å®žå‰ä¸¤å¹´AIåˆšå¼€å§‹èµ·å¤´çš„æ—¶å€™ï¼Œlocal LLMå’Œæ–‡ç”Ÿå›¾çˆ±å¥½è€…å°±å‘çŽ°å¤šæ•°ä»»åŠ¡éƒ½æ˜¯memory boundçš„äº†ï¼Œå¸‚é¢ä¸Šé™¤äº†æ¯”æ±½è½¦è¿˜è´µNå®¶æŽ¨ç†å¡ï¼Œåªæœ‰Macçš„ç»Ÿä¸€å†…å­˜èƒ½è£…çš„ä¸‹ã€‚
- è¿™ä¸ªå…·æœ‰å¯ç”¨æ€§ï¼Œcudaç”Ÿæ€ä¸Žæ€§èƒ½æ˜¯ä¸ç”¨æ‹…å¿ƒçš„ï¼Œmacè·‘aiå°±æ˜¯è¡Œä¸ºè‰ºæœ¯ï¼Œé€Ÿåº¦æ…¢åˆ°çˆ†ç‚¸ï¼Œç”Ÿæ€ä¹Ÿæ˜¯æ®‹ç¼ºçš„
- åªæ˜¯ä¸ºäº† 128G ç»Ÿä¸€å†…å­˜çŽ°åœ¨ä¹Ÿä¸éœ€è¦ä¹°è¿™çŽ©æ„å„¿å•Š.. $4799 çš„ Mac Studio æˆ–è€… $4999 çš„ MacBook Pro å°±è¡Œ. å½“ç„¶åªæ˜¯ä¸ºäº† AI ç›®çš„çš„è¯, è€é»„è¿™ä¸ªç›’å­ç¡®å®žæ›´æœ‰æ€§ä»·æ¯”.

- ä¸‰åƒåˆ€ï¼Œ128GBï¼Œè¿™ä¸ªä»·æ ¼å…¶å®žä¸æ¯”è‹¹æžœå¥½å¤šå°‘ã€‚è€Œä¸”ä¸‰åƒåˆ€æ˜¯starting price

- ç»å…¸çš„72Bçš„Llamaæ¨¡åž‹ï¼Œ8æ¯”ç‰¹ç²¾åº¦éœ€è¦84GBçš„æ˜¾å­˜ï¼Œé‚£å°±éœ€è¦2å—A100æˆ–è€…4å—24GBçš„4090/3090ï¼Œè¿™ä¸¤ç§æ–¹æ¡ˆéƒ½è¦æ¯”3000ç¾Žå…ƒå¤šä¸”å¤æ‚ã€‚
  - è¦çŸ¥é“Project digitsæ˜¯ä¸€æ•´ä¸ªæœºå™¨ï¼Œ72Bçš„ç»å…¸æ¨¡åž‹å¯ä»¥ç›´æŽ¥è·‘ï¼Œè¿™æ ·å°±åŸºæœ¬ä¸Šå¯ä»¥åšç»å¤§å¤šæ•°çš„å¾®è°ƒå·¥ä½œã€‚
  - ç”šè‡³ä¸¤å°æœºå™¨ï¼Œå°±å¯ä»¥è·‘4æ¯”ç‰¹ç²¾åº¦çš„200Bæ¨¡åž‹ï¼Œè¿™ä¹ˆå¤§çš„æ¨¡åž‹æ”¾åˆ°ä¹‹å‰åŸºæœ¬ä¸Šåªæœ‰å¤§çš„å…¬å¸æˆ–è€…å®žéªŒå®¤æ‰æœ‰å¯èƒ½è·‘çš„èµ·æ¥ï¼Œè€ŒçŽ°åœ¨6000ç¾Žå…ƒå°±èƒ½å®Œç¾Žè§£å†³ï¼Œè¿™å¯¹äºŽç»å¤§å¤šæ•°çš„ç©·Labæ¥è¯´éƒ½æ˜¯å¤©å¤§çš„ç¦éŸ³ã€‚

- Strix Haloå’ŒM4 Maxæ˜¯é«˜è§„æ ¼çš„æ¶ˆè´¹çº§äº§å“ï¼Œæ­è½½Strix Haloçš„æ˜¯å„ç§å“ç‰Œå¼€å‘çš„ç¬”è®°æœ¬ç”µè„‘ã€SFFä¸»æœºï¼Œç”šè‡³æ˜¯å‡†ç³»ç»Ÿã€MoDTä¸»æ¿ï¼Œå®ƒä»¬æ­è½½Windows 11æ“ä½œç³»ç»Ÿï¼Œä¹Ÿå¯ä»¥å®‰è£…ä»»æ„GNU/Linuxæ“ä½œç³»ç»Ÿï¼Œå°±åƒä¸€ä¸ªæ™®é€šçš„x86ç”µè„‘ä¸€æ ·
  - Project Digitsçš„CPUï¼Œæ˜¯è”å‘ç§‘å®šåˆ¶çš„20æ ¸ARM CPUï¼Œ10å¤§æ ¸ä¸ºCortex-X925ï¼Œ10ä¸­æ ¸ä¸ºCortex-A725ã€‚A725å’ŒM4å°æ ¸å¤§æ€§èƒ½æŽ¥è¿‘ï¼Œè€ŒX925åˆ™ä¸å¦‚M4å¤§æ ¸å’ŒZen5ã€‚å¦ä¸€æ–¹é¢ï¼ŒARM Linuxçš„ç”Ÿæ€å¹¶ä¸å¦‚x86ï¼Œè¿™å’ŒARM macOSå®Œå…¨ä¸åŒã€‚Strix Haloçš„16æ ¸32çº¿ç¨‹çš„zen5 CPUï¼ŒåŸºæœ¬ä¸Šæ˜¯é¡¶çº§çš„CPUé…ç½®ï¼Œå…¶å¤šçº¿ç¨‹æ€§èƒ½æ˜¯æ‹‰æ»¡çš„ã€‚
  - Project Digitsçš„å†…å­˜ï¼Œè™½ç„¶å®˜æ–¹æ²¡æœ‰è¯´æ˜Žï¼Œä½†å¾ˆå¤§å¯èƒ½ä¹Ÿæ˜¯256ä½çš„ï¼Œæ­¤æ—¶Project Digitsåœ¨ä½¿ç”¨LPDDR5Xçš„8533MT/sçš„å†…å­˜æ—¶ï¼Œå…¶é€ŸçŽ‡åŒæ ·ä¸º272GB/sï¼Œè€Œè¿™ä¸€å¸¦å®½ï¼Œä»…ä¸ŽStrix Halo/M4 Proç›¸åŒï¼Œæ˜¯M4 Maxçš„ä¸€åŠï¼›å¦‚æžœæ˜¯512ä½ï¼Œåˆ™å¼ºäºŽStrix Haloä¸€å€ï¼Œå¹¶ä¸ŽM4 MaxæŒå¹³ã€‚
- haloçš„npuæ€»å…±å°±50topsï¼Œ8060sä¹Ÿæ²¡æœ‰ç¡¬ä»¶wmmaï¼Œ2.5ghzä¸‹ä¹Ÿå°±51.2topsï¼ŒåŠ èµ·æ¥ä¸åˆ°gb10çš„1/4
- å¯æƒœhaloä¸æ˜¯ç»Ÿä¸€å†…å­˜æž¶æž„
  - haloæ˜¯umaæž¶æž„ï¼Œ15å¹´å‰åˆä»£apuå°±å·²ç»æ˜¯umaæž¶æž„äº†

- è¿™ä¸ªä¸œè¥¿3000åˆ€æ˜¯çœŸçš„å¾ˆè´µï¼Œä¸è¿‡project digitsæ˜¯æŒ‘æˆ˜å†¯è¯ºä¾æ›¼æž¶æž„ï¼ŒCPU è®¿é—®å†…å­˜ã€ç¡¬ç›˜ï¼Œæ˜¾å¡å¤„ç†æ•°æ®éœ€è¦æŠŠæ•°æ®å…ˆä¼ åˆ°æ˜¾å­˜ã€‚ç»Ÿä¸€å†…å­˜æž¶æž„å°±æ˜¯æŠŠGPUæ ¸å¿ƒç›´æŽ¥ä¸Žå†…å­˜ç›¸è¿žï¼Œå¼„å¤§å†…å­˜ã€‚
  - ç›®å‰é™¤äº†å¤§å…¬å¸æœ‰é’±ä¹°å‡ ç™¾ä¸Šåƒå¡è·‘è®­ç»ƒï¼Œæ™®é€šäººçœŸè·‘ä¸èµ·LLMå¤§æ¨¡åž‹ã€‚å¯¹äºŽæ™®é€šäººæ¥è¯´ï¼Œæ ¸å¿ƒç®—åŠ›ä¸é‡è¦ï¼Œé—®é¢˜æ˜¯æ€Žä¹ˆåœ¨æ˜¾å¡loadå¤§æ¨¡åž‹ã€‚è€Œç»Ÿä¸€å†…å­˜å°±æ˜¯ç”¨è¶…é«˜æ€§ä»·æ¯”çš„å†…å­˜ä»£æ›¿æ˜¾å­˜ï¼Œä¸ç”¨GDDR7ï¼Œç”¨DDR5 ã€‚
# discuss-gpu
- tips-gpu
  - ä½¿ç”¨åœºæ™¯çš„è¦æ±‚: ðŸ¤” æ–‡å¤šè¿˜æ˜¯å›¾å¤š, æ˜¾å­˜å¤§(VRAM), é€Ÿåº¦å¿«(å¸¦å®½)
    - å¤§æ˜¾å­˜çš„æ–¹æ¡ˆ: mac, amd-ai-max, nvidia, intel-arc
    - Nå¡å‚è€ƒèµ„æ–™å¤šï¼Œèƒ½å‡å°‘åŽæœŸè°ƒå‚çš„å·¥ä½œé‡
    - 32GB/48GBå¤§æ˜¾å­˜å•å¡èƒ½å‡å°‘è¿ç»´çš„å·¥ä½œé‡, ðŸ‘€ comfyuiä½¿ç”¨å¤šgpuå˜å¤æ‚
  - æ˜¾å­˜ã€å¸¦å®½ã€ä½å®½, æ˜¾å­˜å¤Ÿå¤§æ‰èƒ½è¿è¡Œæ¨¡åž‹ï¼Œè¿è¡Œæ¨¡åž‹æ—¶çš„é€Ÿåº¦ä¸»è¦è€ƒè™‘å†…å­˜å¸¦å®½
  - ä¼°ç®—æ–‡æœ¬æ¨¡åž‹é€Ÿåº¦ç”¨ `å†…å­˜å¸¦å®½å¦‚260GBpSec / æ¨¡åž‹å®žé™…ä½“ç§¯å¦‚13GB`, è¿˜è¦è€ƒè™‘contextçš„å½±å“
    - MoEæ¨¡åž‹å¯¹å†…å­˜å¸¦å®½çš„è¦æ±‚ä¼šä½Žå¾ˆå¤š, ä¸»æµæ¨¡åž‹å¦‚deepseek-v3/Qwen3-235B-A22B/glm-4.5-355b-a32béƒ½æ˜¯moeæž¶æž„
    - æ–‡æœ¬å¤§æ¨¡åž‹çš„å…è´¹apiæ›´å®¹æ˜“èŽ·å–
  - â“ æ–‡ç”Ÿå›¾çš„åœºæ™¯æ˜¯å¦ä¹Ÿç”¨æ­¤å…¬å¼è®¡ç®—, 
    - æ³¨æ„æ–‡ç”Ÿå›¾èƒ½é€šè¿‡loraåŠ é€Ÿï¼Œæ‰€ä»¥å†…å­˜å¸¦å®½é‡è¦æ€§é™ä½Ž
    - æ–‡ç”Ÿå›¾æ—¶ç»å¸¸éœ€è¦VLMè§†è§‰æ¨¡åž‹è¾…åŠ©ï¼Œæ‰€ä»¥VRAMè¶Šå¤§è¶Šå¥½
    - å¸¸è§æ–‡ç”Ÿå›¾æ¨¡åž‹çš„å¤§å°åœ¨20GBå·¦å³ï¼Œå¤§æ˜¾å­˜çš„å•å¡ä¹Ÿå¯è¿è¡Œ
  - è€ƒè™‘è½¯ä»¶æ”¯æŒåº¦, comfyuiåœ¨arm/linuxå¹³å°çš„æ”¯æŒåº¦, dgx-sparké»˜è®¤linux
  - è®¡ç®—é›†ç¾¤: nvlink
  - ä¸»åŠ›å·¥å…·ä¸è¦ç”¨AMDçš„CPU/GPU, å› ä¸ºlinuxéœ€è¦ç‰¹æ®Šé…ç½®, éƒ¨åˆ†è½¯ä»¶ä¹Ÿéœ€è¦ç‰¹æ®Šé…ç½®å¦‚pytorch
  - æ¨¡åž‹é€‰æ‹©: æ”¯æŒint4ã€fp8ã€fp4ï¼Œèƒ½å¦ç”¨nanchakuåŠ é€Ÿ, æ”¯æŒflash-attentionã€bf16ã€awqã€sglang

- å¤šæ˜¾å¡
  - å¤šæ˜¾å¡çš„æœºç®±å¤ªå¤§ï¼Œä¸ä¾¿æº, é…ç½®å’Œç»´æŠ¤æˆæœ¬é«˜ï¼Œä¸å¦‚ç”¨ä¸»æµå°å¼æœºç®±æˆ–æŸå®æˆå“å¯å®šåˆ¶å·¥ä½œç«™
  - å¤šæ˜¾å¡/å¤šç¡¬ç›˜éƒ½éœ€è¦å¤§ä½“ç§¯çš„æœºç®±ï¼Œitxä¸€èˆ¬ä¸èƒ½æ»¡è¶³ï¼Œéœ€è¦ä½¿ç”¨matx
  - é…ç½®nvlinkéœ€è¦å•ç‹¬çš„bridgeè¿žæŽ¥çº¿
  - é€‰æ˜¾å¡è¦æ³¨æ„å°ºå¯¸ï¼Œå…¬ç‰ˆä¸€èˆ¬å°ºå¯¸é€‚ä¸­ï¼Œå…¶ä»–åœºæ™¯çš„å®šåˆ¶æ˜¾å¡æœ‰çš„é•¿å®½æ¯”è¾ƒå¤§ï¼Œå¦‚ä¸‰é£Žæ‰‡å¡ä¼šæ˜Žæ˜¾å¤§é›¨æ¶¡è½®å¡

- å¯è€ƒè™‘ç”¨å¤§å®¹é‡å•å¡å¦‚4090-48gbé…åˆå°æœºç®±, 
  - ðŸ‘€ å¤§æœºç®±ä¸æ–¹ä¾¿æºå¸¦æˆ–æ”¾è¿›èƒŒåŒ…(åŠŸèƒ½ vs æˆæœ¬), 
    - ðŸŽ’ ç‰¹å¤§å·çš„åŒè‚©åŒ…çš„é«˜åº¦å¯ä»¥æ»¡è¶³450mm, åº•éƒ¨é•¿å®½éš¾ä»¥æ»¡è¶³ 205x403
  - 4090å…¬ç‰ˆå°ºå¯¸304x137mm, æ¶¡è½®ç‰ˆ267x111x38mm, âš¡ï¸ ä¸‰é£Žæ‰‡ç‰ˆ350x140x53mm
  - å¯è€ƒè™‘itxæœºç®±åŒ…æ‹¬, æœºæ¢°å¤§å¸ˆc28(18)/cmax(20), é—ªé³žg300(17)/g350(20), ä¹”æ€ä¼¯z20(20)
  - æœºç®±æ•£çƒ­è¦æ³¨æ„cpuåŠŸè€—å’Œæ˜¾å¡åŠŸè€—ï¼Œå¯é€‰ç”¨ä½ŽåŠŸè€—cpu+é«˜åŠŸè€—æ˜¾å¡ï¼ŒåŒå¡”é£Žå†·, å°½é‡é€‰meshç½‘å­”ç‰ˆ
  - æš‚æ—¶é€‰æ‹©æœºæ¢°å¤§å¸ˆcmax(392*185*284mm, 20.5L), å› ä¸ºèƒ½æ”¯æŒè¾ƒé•¿çš„ä¸‰é£Žæ‰‡æ˜¾å¡ï¼Œæ˜¾å¡æ”¯æŒ 385*160mm ä»¥å†…
    - ä¹”æ€ä¼¯, å…¬å¼€èµ„æ–™æœ€å¤š, t6(13.6L), tk-o(16.45L),c6(18.4L), z20(20.2L)
  - æƒ³è¦128GBçš„å†…å­˜ï¼Œæœºç®±çš„ç©ºé—´å¤Ÿå¤§ä¸”æ»¡è¶³æ•£çƒ­éœ€æ±‚æ˜¯å‰æï¼Œè¿˜éœ€è¦ä¸»æ¿æä¾›4ä¸ªå†…å­˜æ’æ§½ï¼Œcpuçš„å’Œå†…å­˜çš„é¢‘çŽ‡æ˜¯èƒ½å’Œè°å·¥ä½œï¼Œé¢‘çŽ‡éƒ½ä¸èƒ½å¤ªé«˜
    - å†…å­˜æ¡çš„é¢‘çŽ‡è¦è€ƒè™‘cpuæ”¯æŒã€ä¸»æ¿æ”¯æŒ
    - å¤§å†…å­˜å¯¹è·‘MoEæ¨¡åž‹æœ‰ç”¨

- mac
  - ultraçš„å†…å­˜å¸¦å®½æœ€é«˜è¾¾åˆ°800, ä½†ä¸è¦æ€¥, amd strix haloçš„ä¸‹ä¸€ä»£å’Œmac studioçš„ä¸‹ä¸€ä»£éƒ½ä¼šå‡çº§, é€‰æ‹©256GBç‰ˆæœ¬åˆé€‚çš„
  - [Performance of llama.cpp on Apple Silicon M-series Â· ggml-org/llama.cpp _202311](https://github.com/ggml-org/llama.cpp/discussions/4167)

- nvidiaæ€§èƒ½å¯¹æ¯”
  - [å¤§æ¨¡åž‹GPUç®—åŠ›å¡æ±‡æ€» - çŸ¥ä¹Ž](https://zhuanlan.zhihu.com/p/1904206218748236301)
  - [Sable Diffusion WebUI Benchmark Data: nvidia/amd/torch](https://vladmandic.github.io/sd-extension-system-info/pages/benchmark.html)
  - [Which GPU should I buy for ComfyUI Â· comfyanonymous/ComfyUI Wiki](https://github.com/comfyanonymous/ComfyUI/wiki/Which-GPU-should-I-buy-for-ComfyUI)
  - https://www.zhihu.com/question/615946801/answer/3156016610

- amd
  - [ROCm Compatibility matrix](https://rocm.docs.amd.com/en/latest/compatibility/compatibility-matrix.html)
  - [Linux support matrices by ROCm version](https://rocm.docs.amd.com/projects/radeon-ryzen/en/latest/docs/compatibility/compatibilityrad/native_linux/native_linux_compatibility.html)

- ðŸ†šðŸ”¥ [è‹±ä¼Ÿè¾¾çƒ­é—¨ GPU å¯¹æ¯”ï¼šH100ã€A6000ã€L40Sã€A100 - çŸ¥ä¹Ž](https://zhuanlan.zhihu.com/p/5041686924)
  - [Memory Bandwidth Comparisons - Planning Ahead : r/LocalLLaMA _202402](https://www.reddit.com/r/LocalLLaMA/comments/1amepgy/memory_bandwidth_comparisons_planning_ahead/)

- å‚æ•°å¯¹æ¯”
  - gpu-arch: 2020-ampere(a100/a6000), 2022-ada-Lovelace(L20/L40s/6000ada/4090/4090d), 2022-hopper(h100), 2024-blackwell(5090)
  - fp16/tflops
  - 3090æ˜¯æœ€åŽä¸€ä»£æ”¯æŒnvlinkçš„æ¶ˆè´¹çº§æ˜¾å¡ï¼Œä½Žç«¯ä¸“ä¸šçº§æ˜¾å¡å¦‚5880/L20ä¹Ÿä¸æ”¯æŒnvlink

- gpu-specs

- Memory Bandwidth:
  - Nvidia DGX Spark: 273 GB/s
  - AMD AI Max 300: 256GB/s
  - M1(68)/M2/M3: 100 GB/s
  - M4: 120 GB/, 10-cpu, 10-gpu, 16-neural
  - M1/M2/M3 Pro: 150/200 GB/s
  - M1/M2/M3 Max: 300/400 GB/s
  - M4 Max: 546 GB/s
  - M1/M2/M3 Ultra: 819 GB/s
  - RTX 5090: ~1.8 TB/s
  - RTX PRO 6000 Blackwell: ~1.8 TB/s

```markdown
| GPU    | VRAM       | fp16 | v-bandwidth | v-bit | cu-core | power | note                          |
|--------|------------|------|-------------|-------|---------|-------|-------------------------------|
| A100   | 40GB HBM2  | 312  | 2039gb/s    | ?     | ?       | 400W  | 40g-9w                        |
| A6000  | 48GB GDDR6 | 77   | 768gb/s     | ?     | ?       | 300W  | 48g-3w3                       |
| 6000ad | 48GB GDDR? | ?    | 960/s       | ?     | ?       | ?     | 48g-4.8w                      |
| PR6000 | 96GB GDDR7 | ?    | 1792/s      | ?     | ?       | 600W  | 96g-6.6w                      |
| L20    | 48GB GDDR6 | 119  | 854gb/s     | 384   | 1.02w   | 350W  | no-nvlink                     |
| L40    | 48GB GDDR6 | 147  | ?           | ?     | ?       | 350W  | ee                            |
| L40s   | 48GB GDDR6 | 731  | 864gb/s     | ?     | ?       | 350W  | 48g-4.4w                      |
| 5880ad | 48GB GDDR6 | 69   | 960/s       | 384   | 1.28w   | 285w  | 48g-2.8w,no-nvlik,6000Adé˜‰å‰²  |
| 5000ad | 32GB GDDR6 | 65   | 576/s       | 256   | 1.41w   | 250w  | no-nvlink                     |
| 5090   | 32GB GDDR7 | 3352 | 1800gb/s    | 512   | 2.18w   | 450W  | 32g-2.3w, no-nvlink           |
| 4090   | 24GB GDDR6X| 330  | 1008gb/s    | 384   | 1.64w   | 450W  | 48g-2.4wðŸŒ¹, no-nvlink, 850wP  |
| 4090d  | 24GB GDDR6X| 330  | 1008gb/s    | 384   | 1.46w   | 425W  | 48g-1.9w,é¢‘çŽ‡é”ä¸”ä¸è¶…é¢‘         |
| 3090   | 24GB GDDR6X| ?    | 912gb/s     | 384   | 1.05w   | 350W  | 24g-8.3k, nvlk/VulkRT/OpenGL4 |
| 3090ti | 24GB GDDR6X| ?    | ?gb/s       | 384   | 1.08w   | 750W  | 24g-8.3k, nvlink              |
```

- ## 

- ## 

- ## 

- ## 

- ## [Do any comparison between 4x 3090 and a single RTX 6000 Blackwell gpu exist? : r/LocalLLM _202512](https://www.reddit.com/r/LocalLLM/comments/1pu62uz/do_any_comparison_between_4x_3090_and_a_single/)
- Just got here. 
  - Setup on Blackwell is still a bit of a pain, by comparison the 3090s are easy peasy
  - Prompt Processing performance - using GLM 4.6 quants in llama.cpp I get 3.5x the speed with the blackwell than I do with the 3090
  - Token Generation - essentially no difference (I think I can get a little better performance here from the Pro 6000 but between system differences and kernel differences the raw power of the Pro doesn't make up the difference in perf)
  - Power consumption - baseline consumption is very similar, with the pro sitting at around 3.5x one 3090. Under single query load the pro has been hitting 200 W
  - Sound - The pro is in my living room, I can barely hear it. The 3090s are in my office.... I can *really* hear it. Not horrible but I know when it's running.
  - I haven't played with vLLM much but for models that can be fully resident in 96 GB VRAM the Pro tentatively ran at 2x for both generation and prompt processing.
- My conclusion is:
  * For models fully resident in 96GB the Pro wins hands down (ignoring pricing)
  * For models partially resident in 96GB the Pro wins on processing but not prompt generation
  * When factoring in price, the 3090 is a great contender
  * When factoring in future improvements and the ability to easily go to 2 or 4 gpus I think the Blackwell wins.

- The 3090's will not give you 96gb of useable memory. There is VRAM overhead space being taken up to manage the communication between the cards, so you will only have about 88gb of actual useable VRAM. In addition it will run slower because it has to send information between cards.
  - Not true. I have yet to see a benchmark where the Pro 6000 wins. 4x3090 with TP and vLLM is faster, especially at long context, than anything on the Pro 6000.

- ## [Got me a 32GB RTX 4080 Super : r/LocalLLaMA _202512](https://www.reddit.com/r/LocalLLaMA/comments/1pstaoo/got_me_a_32gb_rtx_4080_super/)
  - I took a risk and bought a modified RTX 4080 Super from the Chinese market for around 1200 USD / 1000 EUR. Which for me because I live in Europe, the cheapest RTX 5090 I can find is around 2500 USD / 2100 EUR.
  - It's maybe not the best card for price per GB of VRAM considering the RTX 3090 is dropping a lot, but 32GB on one card for about half the price of a 5090 is nice. I do a lot of Diffusion model stuff, so it's great for that too.
  - It works with the stock Nvidia driver, no messing around, it was just literally plug and play. Card seems really good quality, metal back plate and metal case. Fan sounds like a small jet engine.
  - But running it around a month now and zero issues at all.
  - I got mine from this seller, price went up 1000 RMB though since i bought it though. I used Superbuy to handle forwarding.

- How is the temperature and what power limit. I am eyeing it for quite a while. It is about S$2400 in where i living.
  - It gets around 70C max under load, seems to hit around 300W under full load. Hasn't been an issue, the blower is pretty loud though.

- howâ€™s the speed? 
  - Same as a stock RTX 4080 super.

- Look like they doubled the NAND chip on that GPU. Curious about how you set up the driver to receive all the VRAM.
  - I didn't touch the driver, it's stock. I guess the RTX 4080 is special in that way, if you add bigger ~~NAND~~ GDDR VRAM chips, it gets recognized without much fuss.
- the reason for this is that there is a 4090 Mobile with less vram for the gaming laptop market, and it uses the same chip as the desktop 4080. The 4080 super is just a more performant gpu compared to the stock 4080. The idea is that the vram size is "changeable" , so technically NVIDIA could put more vram in such cards, and they actually did it in professional gpu like the rtx 6000 ada series (same core as rtx 4090 desktop gpu with more vram). And such that the driver must be able to recognize the vram to function properly.

- I hope NVIDIA doesn't disable it in the GPU mainboard in the future like Apple did in the mac studio ssd slot (mac studio has a ssd slot but it refuse to recognize any ssd even from other mac studio.)

- it's not nand... it's gddr dram

- ## [NVIDIA RTX PRO 5000 Blackwell GPU with 72GB GDDR7 memory is now released : r/comfyui _202512](https://www.reddit.com/r/comfyui/comments/1prz95a/nvidia_rtx_pro_5000_blackwell_gpu_with_72gb_gddr7/)
- Nvidia seems to have settled on $100/GB of vram. AMD will sell you a 7900xtx w/ 48gb of vram for $65/GB. But it's a triple slot and as far as rocm has come, the biggest improvements are kept back for the mi instinct series.

- That might be great news for the LLM community. But we image guys here are usually compute bound. I.e. a 5090 might be more worth to us than a VRAM extended 5000

- some of the WAN models go OOM even on a 6000 PRO for 1080p resolution and 1600+ frames, so this dosen't seem so interesting now.

- Only 14k cuda cores, guys, that's a solid meh.

- several hundred cheaper than the Max-Q RTX Pro with 24GB less RAM...

- Stupid question, if you just had a stupid amount of money could you use this card for gaming and blow away a 5090 or does it not work like that?
  - Yes you could, but not with the PRO 5000. PRO 6000 with 96GB is the one you want if you wanna beat the 5090. That one has the fully unlocked GB202 with 24064 cores, instead of "only" 21760 on the 5090, and it beats the 5090 in gaming by about 10%. But it starts at $7k.

- Memory bus on these GPUs is only 384-bit, not 512-bit as the Nvidia datasheet claims.
- I mean, the 5090 has 512-bit and GDDR7. So even with the higher memory capacity, itâ€™ll be slower, but just have more Ram to work on larger models?
  - Yes, bandwidth is severely reduced from 1792GB/s (512-bit) to 1344GB/s (384-bit).

- ## [AMD Radeon AI PRO R9700 benchmarks with ROCm and Vulkan and llama.cpp : r/LocalLLaMA _202512](https://www.reddit.com/r/LocalLLaMA/comments/1prgi41/amd_radeon_ai_pro_r9700_benchmarks_with_rocm_and/)
  - Spec: AMD Ryzen 7 5800X (16) @ 5.363 GHz, 64 GiB DDR4 RAM @ 3600 MHz, AMD Radeon AI PRO R9700.
  - Software is running on Arch Linux with ROCm 7.1.1 (my Comfy install is still using a slightly older PyTorch nightly release with ROCm 7.0).
  - The LLM is instructed to summarise each chapter of a 120k-word novel individually, with a script parallelising calls to the local API to take advantage of batched inference. 
  - Mistral Small: batch=3; 479s total time; ~14k output words
  - gpt-oss 20B: batch=32; 113s; 18k output words (exluding reasoning)
  - TLDR is that ROCm usually has slightly faster prompt processing and takes less performance hit from long context, while Vulkan usually has slightly faster tg.
  - All using ComfyUI. 
  - Z-image, prompt cached, 9 steps, 1024Ã—1024: 7.5 s (6.3 s with torch compile), ~8.1 s with prompt processing.
  - SDXL, v-pred model, 1024Ã—1024, 50 steps, Euler ancestral cfg++, batch 4: 44.5 s (Comfy shows 1.18 it/s, so 4.72 it/s after normalising for batch size and without counting VAE decode). With torch compile I get 41.2 s and 5 it/s after normalising for batch count.
  - Flux 2 dev fp8. Keep in mind that Comfy is unoptimised regarding RAM usage, and 64 GiB is simply not enough for such a large model â€” without --no-cache it tried to load Flux weights for half an hour, using most of my swap, until I gave up.
  - I also successfully finished full LoRA training of Gemma 2 9B using Unsloth. It was surprisingly quick, but perhaps that should be expected given the small dataset (about 70 samples and 4 epochs). While I donâ€™t remember exactly how long it took, it was definitely measured in minutes rather than hours. 

- A lot of people considering 5080's/4090's for LLMs would probably be happier with this card. It's 32GB in a single slot with very reasonable prompt-processing speeds and good enough token-gen.
  - also it's not bad at all with diffusion models, even with ROCm in its early days. Quite promising.

- 4-bit quant/qlora support for Radeon cards just got merged into Unsloth a day or 2 ago. It's been added to Bitsandbytes for some time now, feel free to check it out 

- ## [They're finally here (Radeon 9700) : r/LocalLLaMA _202512](https://www.reddit.com/r/LocalLLaMA/comments/1pnd5uf/theyre_finally_here_radeon_9700/)
- Fuck, I'm old. Radeon 9700 was a top tier GPU back in the 2000's. They have used all the code names and started a new loop
  - Yeah search results are annoying. And AMD now has a 9700x CPU as well.

- I have one R9700 and planning to get another (or whatever comes next--PRO 36GB or 72GB sku). The benefits of the R9700 isn't really for performance/price. The benefits I see:
  - blower fan design lets you pack them side by side no no slot gaps needed
  - 32GB per 300W GPU means fewer GPUs/lesser PSU for given total VRAM
  - also fewer needed PCIe lanes to GPUs for given VRAM
  - ECC memory operation can be enabled on Linux for longer/reliable operation
  - PRO sku meant to be running continuously (with sufficient cooling)
  - RDNA4 should have better long-term support than older gens.

- ## ðŸ†š [Is it better to upgrade from 3080 to 3090 or 5080 for video generation? : r/StableDiffusion](https://www.reddit.com/r/StableDiffusion/comments/1pjfmrw/is_it_better_to_upgrade_from_3080_to_3090_or_5080/)
- I have both the 3090 and 5080 hooked up to my computer as I am typing this. For majority of the task, including wan 720p 480p, qwen edit, z-image, and illustrious + 4k hires fix, 
  - I find myself only use 5080 and vram has not been an issue unless I'm running a very large batch size. 
  - The 5080 is twice as fast with support for fp8 and fp4. Since buying the 5080, the 3090 has only been used for llm when i need better prompt or gaming concurrently with running the workflow.

- Just a headsup 3090 doest support 8bit calculation. You would be using fp16 versions or anything lower than 16bit will be transformed to fp16
  - It does support INT8, just not FP8.

- My vote is for more vram. Best advantage of the 5080 is speed, but with vram it opens up so much more possibilities (and that speed won't matter if it wont fit into memory).

- ## [Does ComfyUI work flawlessly with AMD graphics cards too? Which card is more stable? Is there anything that can be done with Nvidia but not with AMD? : r/comfyui _202512](https://www.reddit.com/r/comfyui/comments/1pi94ix/does_comfyui_work_flawlessly_with_amd_graphics/)
- Using an AMD Graphics card is the difficult and treacherous road currently in the world of AI (I know, I primarily use a Radeon Pro w7800 32GB). Even installing basic Custom Nodes is fraught with dangers. One must examine each requirements.txt file to make sure it is not trying to install torch, torchaudio, and/or torchvision (which is rather unnecessary to put into the requirements file for a custom_node anyway.) Those lines will need to be commented out or erased after cloning the Git. If not done, then upon ComfyUI's next startup, it will uninstall the ROCm version of pytorch and install the Nvidia one instead breaking all inference functionality (this has happened to me a couple of times before. Blast my laziness!). 
  - Furthermore, some attention algorithms currently are not compatible with AMD cards. It's a cold, hard AI world for AMD GPU users. However, it is getting better. ROCm is getting better. 
  - Many AMD cards are great, especially for gaming. 
  - However, for the time being, if you have a choice, I recommend using a Nvidia card for AI.

- ## [Can M1/M2 Macbooks use ANY eGPU as a docking station? : r/eGPU _202212](https://www.reddit.com/r/eGPU/comments/zk8yzv/can_m1m2_macbooks_use_any_egpu_as_a_docking/)
- unfortunately. The M2 MacBook Air only supports one external display up to 6K resolution. The only option is to use DisplayLink adapters/docking stations if you want more than one external display.

- eGPUs work on Apple Silicon but the driver support on macOS is nonexistent because Apple no longer has any reason to listen to GPU manufacturers since they make their own now. You'd need to install Asahi Linux and wait for Thunderbolt support to be ready, but yes theoretically it should be doable

- ## ðŸ†š [V100 vs 5060ti vs 3090 - Some numbers : r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/comments/1p4b6ti/v100_vs_5060ti_vs_3090_some_numbers/)
- Speed specs put the 3090 in first place in raw compute
  - 3090 - 35.6 TFlops FP16 (936Gb/s bandwidth)
  - V100 - 31.3 TFlops FP16 (897 Gb/s bandwidth)
  - 5060ti - 23.7 TFlops FP16 (448 Gb/s bandwidth)
- Machines:
  - 8x V100 SXM2 16G. This was the machine that I started on Vast with. Picked it up post ETH mining craze for dirt cheap. 2x E5-2690 v4 (56 threads) 512G RAM
  - 8x 5060ti 16G. Got the board and processors from a guy in the CPU mining community. Cards are running via MCIO cables and risers - Gen 5x8. 2x EPYC 9654 (384 threads) 384G RAM
  - 4x 3090, 2 NVLINK Pairs. Older processors 2x E5-2695 v3 (56 threads) 512G RAM
- Ran llama-bench with llama3.1 70B Instruct Q4 model with n_gen set to 256 (ran n_prompt numbers as well but they are just silly)

| Card    | T/s   | Relative | TFlops | Relative |
|---------|-------|----------|--------|----------|
| 3090    | 19.09 | 100%     | 36.6   | 100%     |
| V100    | 16.68 | 87.4%    | 31.3   | 87.9%    |
| 5060ti  | 9.66  | 50.6%    | 23.7   | 66.6%    |

- llm generation mostly scale with memory bandwidth rather than compute capability, for dense mode, if u use vllm and enable tensor parallel, u will get double that speed
- TG numbers do not depend much on compute capacity but almost completely on memory bandwidth

- Need prompt processing speed. Batch speeds. Tensor parallelism? Just post the raw llama bench tables and settings you used to run it. Also would be useful to have power numbers.

- ## ðŸ ðŸ¤” [1x 6000 pro 96gb or 3x 5090 32gb? : r/LocalLLaMA _202511](https://www.reddit.com/r/LocalLLaMA/comments/1p2540n/1x_6000_pro_96gb_or_3x_5090_32gb/)
- 1x 6000 not 3x 5090. 
  - A single chunk of vram is always better than a divided one - unless your intention is to run multiple concurrent small models, then the 5090s give you more compute. 
  - And Epyc 9xxx over Threadripper for more ram channels, as long as you go for the high clockspeed versions (F). Go for 9575F, 64 cores, high clockspeed, 12 channels. Only disadvantage is having to use a server board.
- RTX 6000 Pro has the ability to split into (up to) 7 independent virtual graphics cards. There is really no advantage to 3x 5090.
  - There is. Since if you run TP, then those 2x 5090s can be faster. The 3rd 5090 will have to wait for a partner.
- That is absolutely wrong. Maybe because you havent used vLLM in tensor parallel and only have used llama.cpp or Ollama? 2x5090 or 4x5090 is way faster than 1x rtx 6000 if used in tensor parallel (which Ollamas and other hoobyist inference engines cant do)

- people dont realize that bandwidth between GPU and memory IS the bottleneck. a model can not load efficiently into separate cards. you end up with three tines only 32gb usable memory
  - No, thats not true. In tensor parallel 2 or 4 pcie 5.0 16x is enough for most of the tasks. So 2 or 4 5090 connected with pcie 5.0 16x is enough fast pcie link between gpus. I have tested this and was never able to fill the full bandwidth totally. The speed does not increase lineary but 2nd gpu gives 60% more inference speed when enough simultaneous requests.

- Canâ€™t -tp 3 with vllm
  - Pp3(Pipeline parallelism w 3 cards) works fine and is better with consumer gpus anyways since it requires less communication between cards. Data center card are connected with infinity band so tp is better

- I have 3x 5090 and 1x Pro 6000 as well as a Threadripper with 512GB RAM (and a second Threadripper and 3 3090), and my recommendation for running LLMs of that size locally is: Don't.
  - At least don't expect it to be good value or fast. 
  -  I use local for parallel workloads. 10k t/s throughput - now we are talking.

- A lot of people here are assuming the 5090 behaves like a normal single-GPU setup. It doesnâ€™t â€” not with the current software stack.
  - If your workload needs contiguous VRAM (anything 70B+, large context, MoE with large expert blocks, diffusion XL, video gen, etc.), a single 96 GB slab always beats 3Ã— 32 GB islands, regardless of raw TFLOPs.
  - Multi-GPU only wins if youâ€™re bulk-processing smaller jobs in parallel. 

- why I vote Epyc instead of Threadripper:
  - The higher singlethread perf of Threadripper isnt worth the extra cost.
  - EPYC DDR4 platform could save you a couple thousand over DDR5. 
- Why RtX 6000 Pro and not 3x5090:
  - The convenience and simplicity of a having 1 x GPU with less wiring and less grief with management and maintenance, PCIE risers and cases and PSU selections and power draw etc its worth the little bit extra spend. (Plus with 3x GPU you cant use tensor parallel in VLLM)

- I have both a 6000 Pro (typically using llama.cpp) and a 2x3090 setup (using vllm). 
  - 3 is an awkward number since I don't think you can run tensor parallel. Moving to 4 you'd definitely want the Epyc/TR/Xeon4+ type platform and may need things like PCIe extensions and a mining rig chassis, etc.
  - If you are just using naive layer splitting (llama.cpp) you only really get the speed of what a single 5090 bandwidth is limiting you to and poor GPU utilization, and you should think seriously about getting sufficient PCIe lanes/bandwidth to a power of 2 number of GPUs (2, 4, 8) to use tensor parallel in VLLM if you are messing with this as it unlocks utilizing all the GPUs more fully. I also tested llama.cpp on the 2x3090 setup but it was substantially slower than using vllm with tensor parallel and GPU utilization hovers around 50%, which is sort of expected, still taking full power according to nvtop. VLLM with tensor parallel I peg both GPUs and even setting them down all the way to ~200W costs very little performance. I'd probably want to confirm with power draw at the wall but I think this is ultimately very wasteful not to try to use tensor parallel plus the massive performance difference.
  - tldr: as a RTX 6000 enjoyer myself having also worked on multi-gpu setups, I'd probably push you more toward 3x5090, then you have a good upgrade path later if you want to Epyc/TR + 4x5090 and that will ultimately be far superior and at least roughly similar in total cost. It is more complicated, you need to move off llama.cpp to vllm, you need a giant mining chassis and maybe PCIe extensions, more PSUs (even if you set power down, you need to physically connect everything), etc. One RTX 6000 is "simpler."

- Also, come the future selling 5090s will be easier than a single 6000.

- 5090s will give ~3x the heat, ~3x the power, ~3x the memory bandwidth, ~3x the flops and will require ~3x the physical space.

- ## [Ollares one: miniPC with RTX 5090 mobile (24GB VRAM) + Intel 275HX (96GB RAM) : r/LocalLLaMA _202511](https://www.reddit.com/r/LocalLLaMA/comments/1ov3x0m/ollares_one_minipc_with_rtx_5090_mobile_24gb_vram/)
  - Processor: IntelÂ® Ultra 9 275HX 24 Cores, 5.4GHz
  - GPU: NVIDIA GeForce RTX 5090 Mobile 24GB GDDR7
  - Memory: 96GB RAM (2Ã—48GB) DDR5 5600MHz
  - Initial price seems it would be around $4000

- the 5090 mobile is based on the 5080 desktop chip, is a bit less compute and bandwidth than a 5080 desktop owing to being a mobile part, but with 24GB instead of 16GB. The 5080 desktop is already about half the speed of a 5090. The system is still a dual channel DDR5 system after you run out of VRAM, just like a normal desktop. 
  - It feels to me like a very narrow market for the particular combination of very tiny form factor, good diffusion and smaller LLM performance (<32B), and low power usage. 
  - Otherwise, a better value is probably found for large (80-120B) MOE LLM in the 395/Spark, or a desktop 5090 which you can at least cram into a "smallish" mini ITX case like the Corsair 2000D.

- it cant compete with unified memory machines since its ram is slower by 4-8x compared to them. 

- ## ðŸ†š [Why Ampere Workstation/Datacenter/Server GPUs are still so expensive after 5+ years? : r/LocalLLaMA _202511](https://www.reddit.com/r/LocalLLaMA/comments/1ove1px/why_ampere_workstationdatacenterserver_gpus_are/)
- ada
  RTX 6000 Ada (48GB), on ebay for about 5000 USD.
  RTX 5000 Ada (32GB), on ebay for about 2800-3000 USD.
  RTX 4000 Ada (24GB), on ebay for about 1200 USD.
  NVIDIA L40 (48GB), on ebay for about 7000 USD.
  NVIDIA L40S (48GB), on ebay for about 7000USD.
  NVIDIA L4 (24 GB), on ebay for about 2200 to 2800 USD.

- ampere
  RTX A6000 (48GB), on ebay for about 4000-4500 USD.
  RTX A5000 (24GB), on ebay for about 1400 USD.
  RTX A4000 (16GB), on ebay for about 750 USD.
  NVIDIA A40 (48GB), on ebay for about 4000 USD.
  NVIDIA A100 (40GB) PCIe, on ebay for about 4000 USD.
  NVIDIA A100 (80GB) PCIe, on ebay for about 7000 USD.
  NVIDIA A10 (24GB), on ebat for about 1800 USD.

- ADA generation killed nvlink for pro level gpus. This means for multi-gpu training particularly bandwidth intensive tasks the ampere generation is superior.
  - Blackwell is also a big leap over ADA generation in both compute, but crucially VRAM as well.
  - As a result if you want multi-gpu ampere can often win, and if you want single GPU Blackwell is a no brainer vs Ada, so ADA doesn't have a market niche.

- Ampere cards are slower (about half perf compared to Ada), some less VRAM and don't support FP8.

- Their memory bandwidth is stil above what is available for the consumer market + their power consumption is even lower.

- What MOBO do you recommend for 5-6 cards? If possible AMD AM5.
  - Threadripper/threadripper pro/xeon workstation or server motherboard like amd epyc or intel xeon.
  - Only workstation/server motherboards have enough pcie lanes to satisfy your needs.
  - Consumer motherboards won't properly support that much gpus A z790-p supports 4 gpu, 1 with x16 lanes from the cpu and 3 x4 from the chipset (acting link a switch).
  - You could split the x16 (if bifurcation is supported). But still this is x4 pcie 4.0, could be a bottleneck.

- Ampere cards are still pretty good all-rounders that can handle AI workloads well, they support BF16 training and inference and that's not dead.

- ## [Does AMD AI Max 395+ have 8 channel memory like image says it does? : r/LocalLLaMA _202511](https://www.reddit.com/r/LocalLLaMA/comments/1os6t6w/does_amd_ai_max_395_have_8_channel_memory_like/)
- 4 channels * 64-bit interface * 8000 MT/s = 256 GB/s.
  - Itâ€™s LPDDR5x not DDR5 so itâ€™s technically 8 channels at 32 bit, but the effective bit width and bandwidth is the same.

- Probably a typo, but technically DDR5 has 2 32 bit channels per module x four dimm channels would make 8 *32-bit* channels, but it would be disingenuous to advertise it that way.

- My understanding is Halo Strix has quad channel DDR5.

- ## [AMD R9700: yea or nay? : r/LocalLLaMA _202511](https://www.reddit.com/r/LocalLLaMA/comments/1os2756/amd_r9700_yea_or_nay/)
- It's slower than a 3090 and doesn't offer fp4. 3090 can emulate fp8 and it's almost twice as fast. Also less of a headache...
- 3090 doesn't offer FP4 nor FP8, needs emulator and the perf tanks doing so. INT4, FP16, BF16, INT8, INT4.
  - Only Blackwell supports FP4, FP32, FP16, BF16, INT8, INT4, FP8.
- On R9700 FP8 and BF8 are fully supported, with improved perf.
  - FYI, FSR4 is FP8.

- ## [AMD Officially Prices Radeon AI PRO R9700 At $1299 - 32GB VRAM - Launch Date Oct 27 : r/LocalLLaMA _202510](https://www.reddit.com/r/LocalLLaMA/comments/1oeg2g6/amd_officially_prices_radeon_ai_pro_r9700_at_1299/)
- 640GB/s
  - yes, for the same price, i can get 2x3090 for 900 gb/s and 48gb vram and cuda compatibility
- Specs sheet says int4 only, not Fp4...
- 640 GB/s Memory Bandwidth - slower than the 5 year old rtx 3090 and 1/3rd of a 5090. No FP4 or CUDA.

- They're Rx 9070's with blower fans and twice the VRAM.

- FYI R9700 is slim 300W card with ECC VRAM, can easily fit 2 on any motherboard.
  - Also make no sense to buy â‚¬750 RTX3090 when R9700 is â‚¬1000 if you can deduct the sales tax (normal price â‚¬1250-â‚¬1300) in Europe.

- Used 3090 are 500-550$. Even good ones from asus or msi.

- All the AMD pro series GPUs have official ROCm support.
  - Oh I know. I just mean Vulkan actually works.
- Full ROCm works and they have ECC VRAM.

- MI50s are good after fresh updates, although R9700 has lots of new things - FP8, matrix cores, etc.

- 70% slower than 5090
- Fp16 seems much closer
  - Only when sparse

- 4 of these in parallel is a compelling alternative to an RTX Pro 6000
  - Wins on VRAM Quantity 128GB VRAM vs. 96GB VRAM
  - Wins on Price ~5200 vs ~8200
  - Wins on Collective Bandwidth (if you user tensor parallel) 640x4=2.56TB/s vs 1.8TB/s
  - Only obvious loss is power usage 300x4 = 1200W vs 600x2 or 300x2 (600 or 1200W depending which model)
  - And upgradability. Few cases/motherboards are going to support more than 4 cards unless you start getting jank with it.

- ## [8å¹´äº†ï¼Œä¸ºä½•eGPUå¤–ç½®æ˜¾å¡ä¸èƒ½è¢«çŽ©å®¶æŽ¥å— - çŸ¥ä¹Ž _202507](https://zhuanlan.zhihu.com/p/1930776574258549666)
- åˆä»£å¤–ç½®æ˜¾å¡ï¼ˆeGPUï¼‰æ›¾è®¸ä¸‹è¯¸å¤šè±ªè¨€å£®è¯­ã€‚è¿™äº›çœ‹ä¼¼æ–°é¢–ç‚«é…·çš„æ˜¾å¡å¤–ç½®ç›’æœ¬åº”å½»åº•æ”¹å˜æ¸¸æˆæœ¬å¸‚åœº
  - å¦‚ä»Šï¼Œè·ç¦»é¢å‘æ™®é€šæ¶ˆè´¹è€…çš„ç¬¬ä¸€ä»£å¤–ç½®æ˜¾å¡é—®ä¸–ï¼Œå·²è¿‡åŽ»äº†å…«å¹´ï¼Œå¯ç¬”è®°æœ¬ç”µè„‘å¸‚åœºå´æ²¡å¤šå¤§å˜åŒ–ã€‚
- é›·è›‡Coreå¹¶éžé¦–æ¬¾å¤–ç½®æ˜¾å¡ï¼ˆç¬¬ä¸€æ¬¾çœŸæ­£æ„ä¹‰ä¸Šçš„ç¬”è®°æœ¬ä¸“ç”¨eGPUæ˜¯2008å¹´åŽç¡•æŽ¨å‡ºçš„XG Stationï¼‰ï¼Œä½†é›·è›‡Coreæ˜¯ç¬¬ä¸€æ¬¾å¼•èµ·è½°åŠ¨çš„äº§å“ã€‚
- å¤–ç½®æ˜¾å¡ç»ˆç©¶æ˜¯ä¸€ä»¶éœ€è¦é¢å¤–éšèº«æºå¸¦çš„è®¾å¤‡ã€‚èƒŒåŒ…é‡Œçš„ç©ºé—´æœ¬æ¥å°±å®è´µï¼Œå®Œå…¨å¯ä»¥ç”¨æ¥è£…å…¶ä»–é…ä»¶ã€‚æ›´ä½•å†µï¼Œè¿˜å¾—æŠ˜è…¾åŠå¤©è®¾ç½®é€‰é¡¹ï¼Œç¡®ä¿æ¸¸æˆèƒ½è¯†åˆ«å¤–ç½®æ˜¾å¡å¹¶è°ƒç”¨å®ƒæ¥æ¸²æŸ“ç”»é¢ï¼Œè¿™æ— ç–‘å¢žåŠ äº†ä¸å°‘éº»çƒ¦ã€‚æ€»çš„æ¥è¯´ï¼Œè¿˜ä¸å¦‚é™ä½Žç”»è´¨è¦æ±‚ï¼Œç”¨ç”µè„‘è‡ªå¸¦æ˜¾å¡æ¥å¾—ä¾¿æ·ã€‚
- 2025å¹´ï¼ŒåŽç¡•ã€é›·è›‡å’ŒæŠ€å˜‰éƒ½æŽ¨å‡ºäº†æ–°æ¬¾å¤–ç½®æ˜¾å¡ã€‚ä»Šå¹´çš„å„ç±»ç§‘æŠ€å±•å’Œæ¸¸æˆå±•ä¸Šï¼Œä¸»æµåŽ‚å•†ä¸€ä¸‹å­æ‹¿å‡ºäº†å››æ¬¾æ–°çš„å¤–ç½®æ˜¾å¡ã€‚
  - è¿™æ¬¡ç®—æ˜¯æ—¶éš”8å¹´åŽï¼ŒåŽ‚å•†ä»¬å¯¹å¤–ç½®æ˜¾å¡å¸‚åœºæœ€å¤§è§„æ¨¡çš„ä¸€æ¬¡å‘åŠ›ã€‚è¿™ä¸€åˆ‡éƒ½è¦å½’åŠŸäºŽé›·ç”µ5æŽ¥å£

- egpuçš„çœŸæ­£ä»·å€¼åœ¨äºŽä½ å’Œä½ çš„å®¶äººå¯ä»¥å…±äº«ä¸€å—æ˜¾å¡ï¼Œè¿™æ ·ä½ ä»¬å°±å¯ä»¥æŠŠé’±æ”’èµ·æ¥ä¹°ä¸€ä¸ª5070ä¸€èµ·ç”¨ï¼Œè€Œä¸æ˜¯æ¯ä¸ªäººéƒ½åŽ»ä¹°ä¸€ä¸ª5090æ˜¾å¡ã€‚

- ç½‘ä¸Šé‚£äº›åšå¤–æŽ¥æ˜¾å¡è§†é¢‘çš„ï¼Œå‡ ä¹Žé€éœ²å‡ºå…¼å®¹å·®ã€ç¨³å®šæ€§å·®çš„é—®é¢˜ï¼Œç›¸æ¯”èµ·æ¥æ€§èƒ½æŸè€—éƒ½æ˜¯å°é—®é¢˜ã€‚ä¸èƒ½æ™®åŠæ˜¾è€Œæ˜“è§ã€‚

- ä½“éªŒè¿‡ä¸€æ¬¡ï¼Œå†ä¹Ÿæ²¡ä¹°è¿‡ã€‚å½“æ—¶xps15é…äº†ä¸ª1080çš„egpuï¼Œç»“æžœæ€§èƒ½è¿˜æ¯”å¦‚å°å¼æœºç›´æ’çš„1060ç›´æŽ¥å¿ƒæ€å´©äº†
  - é›·ç”µ3æ€§èƒ½ç¼©æ°´30%æ˜¯å°æ„æ€

- ## [Dual GPU, AMD & Nvidia together? : r/losslessscaling _202504](https://www.reddit.com/r/losslessscaling/comments/1jpelqr/dual_gpu_amd_nvidia_together/)
- I tested a 4090 (4.0x16) with rx6600 (4.0x4) setup a while ago. While i was too lazy to find the perfect settings for it, i did not see any issues with drivers.
  - I just tested it for a day or two and couldn't overcome some issues with the performance. I think that it had something to do with using the chipset 4x4 line rather than cpu's.

- I rock a 4090 with 6600XT. I have both full drivers installed and run win 11. They donâ€™t clash.

- The main limitation is Nvidia's lower FP16 performance, but a 3080 TI is very good (30 TFLOPs), enough for 4k. Driver conflicts are a possibility, but nowadays everything conflicts with everything already. I've not heard of issues so far and it wouldn't do l so stop me from using the 3080. I would just get the minimal drivers for each GPU if possible.

- [Is it possible to use both and nVidia and AMD GPU? : r/LocalLLaMA _202407](https://www.reddit.com/r/LocalLLaMA/comments/1dt367v/is_it_possible_to_use_both_and_nvidia_and_amd_gpu/)
- Tested RX 7900 XTX and 4060 Ti (16GB) running together in LM Studio via Vulkan. Tried it with two models:
  - DS r1 70B Q5 â€” 10.05 tok/sec
  - QWQ 32b â€” 15.67 tok/sec
  - For comparison, RX 7900 XTX solo gets around 24.55 tok/sec in QWQ 32b.
- So you saying that dual is slower?
  - Exactly â€” a single 7900 XTX is better than a 7900 XTX + RTX 4060 Ti combo when the model requires less than 24GB of VRAM. In my configuration ofc, mb I did something wrong)

- [AMD + NVIDIA GPU : r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/comments/1obgm8u/amd_nvidia_gpu/)
- I've got a RTX 5070 Ti (PCIe 5.0x16, CPU) and a RX 5500 XT (PCIe 4.0x4, CPU) in my AM5 PC. Is there a way to use both GPUs and the CPU to run the same gguf model?
  - You can compile multiple backends into Llamacpp and use them all at once.
  - Yup, the easiest way is to use Vulkan. Any llama.cpp-based software can do this (ie Lmstudio). Ollama not yet - experimental.

- [Is it possible to run my 9070 XT with my old RTX 3070? : r/losslessscaling _202511](https://www.reddit.com/r/losslessscaling/comments/1osolqu/is_it_possible_to_run_my_9070_xt_with_my_old_rtx/)
  - You can, but the top card will roast. And youâ€™ll lose the AMD specific 9070XT features.
  - when mixing Nvidia and AMD GPUs, since the monitor is always connected to the 2nd GPU(3070 in your case), on desktop you will only be able to use Nvidia App for stuff like color profiles, but in game it will be using FSR4 upscaling.
  - Personally I have used all combinations, AMD 1st GPU and Nvidia 2nd GPU, vise versa, and now im using 5070ti + 3060ti. I gotta say there is no real difference, all the small features like anti lag, RSR, make negligible differences.
  - Right now my setup is 3440x1440 HDR 165hz with 5070ti and 3060ti(PCIE4.0 x4). I can comfortably boost from 50-80fps to 160fps with 3060ti usage no more than 75%.

- ## ðŸ’¡ðŸ§© [AMD and Nvidia GPUs in the same machine. IT WORKS. : r/linuxhardware _202006](https://www.reddit.com/r/linuxhardware/comments/he9nhe/amd_and_nvidia_gpus_in_the_same_machine_it_works/)
  - TLDR: Nvidia Card in slot 2 with proprietary driver (v. 440xx) + AMD card in slot 1 open source driver (mesa v20.1), no configuration needed, just prime-run what you need to run with Nvidia card as the back-end renderer. Enjoy the smooth desktop and Nvidia/proprietary bond applications
  - The solution is a simple prime-run command. No messy xorg config files. In fact no manual configuration at all.

- What software requires proprietary Nvidia drivers?
  - In my case it's Davinci Resolve. A video editing software. It only runs with proprietary driver (AMD and Nvidia). I paid for the studio version.

- My laptop has an Intel iGPU and a GTX 1650, and I use an RX 5700 XT in an eGPU enclosure. I also use Mesa and the Nvidia proprietary driver simultaneously or alternating without issues (mostly).
  - It's a little different on a laptop trying to push external graphics but it still works
- So I suppose you use hybrid driver? iGPU as default OpenGL renderer and DRI_PRIME to use dGPU or eGPU? I'm curious how you access different GPUs.
  - I have pop OS, which includes a super handy GPU mode switcher tool (Integrated/Hybrid/Dedicated). You have to reboot each time (unless doing Hybrid and telling applications to run using dGPU).
  - I also installed the gswitch tool from egpu.io, and use it to switch between internal and external graphics when connected to my Thunderbolt 3 dock.
  - The only thing that really doesn't work is staying in "internal" graphics mode and trying to drive the external monitor (or vice versa; can't drive the internal display with external GPU). It "works" but the performance hit is so bad that even GNOME's desktop is unusable.
  - Other than that the whole setup is so easy that it takes me maybe 5 minutes to do on a fresh popOS install (or Ubuntu 20.04 with system76-power tool installed).
  - I highly recommend this setup if you ever plan on going the Nvidia laptop route and don't mind needing to use the prop drivers (even if your egpu is Nvidia it works perfectly).

- Iâ€™m trying to do the same - XPS 9500 with i7 CPU and GTX1650ti dGPUâ€¦ i have a razer core X enclosure and want to try an AMD RX 6600
  - basically plug and play, the drivers auto-installed and everything works smoothly!

- ## ðŸ¤” [1x4090 24GB or 3x3060 12Gb for Comfy? : r/comfyui _202409](https://www.reddit.com/r/comfyui/comments/1fql7if/1x4090_24gb_or_3x3060_12gb_for_comfy/)
- 3x3060 wonâ€™t give you 36GB. The model canâ€™t be split. There are variations of putting the T5 or clip into another card, but the multi GPU aspect will complicate it so much, it will drive you nuts. Especially since you say yourself you are a beginner. Donâ€™t do it. Go for 4090, comfy ui is complicated enough, you donâ€™t want to deal with anymore hardware setup issues on top of that. If you are tight on cash, go for a used 3090.

- In terms of AI a 4090 would still kill 3x 3060 and VRAM does not work as you think it does, you will not get 36GB VRAM with 3x 3060s

- 3x 3060 only if you're in production and your workflow can fit into 12GB VRAM and you're doing loads of parallel generations.

- 4090, speed is the key point, and there are many ways to reduce VRAM needs.

- ## [Sanity check: Using multiple GPUs in one PC via ComfyUI-MultiGPU. Will it be a benefit? : r/comfyui _202504](https://www.reddit.com/r/comfyui/comments/1k4xjxh/sanity_check_using_multiple_gpus_in_one_pc_via/)
- I own the ComfyUI-MultiGPU custom node. The two most common ways I see ComfyUI-MultiGPU are the following:
  - Moving parts of the process to a secondary GPU - typically CLIP/VAE
  - Using Distorch to offload the entirety of the UNet to another GPU or CPU (preferred).
  - In doing those two things, most people can get to a "naked" compute card, giving users the most latent space at the cost of speed. It is the way I use ComfyUI most of the time with a 2x3090 NVLink setup.
  - "Naked" in the sense that there is nothing taking up VRAM on the main compute card other than latent space. In a typical one-GPU setup, VAE, CLIP, and UNet are all resident on the card and take up VRAM that cant't be used for generations. Even a highly-quantized Q3 GGUF takes up (mostly) dead space in your card's VRAM as only one part of it is being dequantized at a time to be used actively during inference, then discarded until the next inference step.
  - In an optimal MultiGPU setup, all three componenets have been moved off the compute video card's VRAM entirely, allowing the card to be completely filled by latent spece. In this case, a 12G VRAM card can do video that fills that entire 12G of latent space, meaning either higher resolution or longer generations than if half (or more) of that VRAM was being used for component storage.

- ## [æœ‰å“ªäº›äºŒæ‰‹æ˜¾å¡å€¼å¾—çŽ©? - çŸ¥ä¹Ž](https://www.zhihu.com/question/1955229739569619499)
- çº¯çŽ©æ¸¸æˆè¿˜å¯ä»¥åŠ ä¸ªmi50åˆ·é•­7biosï¼Œæ¯”vega64æ–°ä¸€ç‚¹

- 2080tiï¼Œåˆšåˆšè·Œäº†ä¸€å¤§æ³¢ï¼Œdyå åˆ¸æœ€ä¾¿å®œ1100-1200å°±èƒ½æ”¶ä¸€å¼ ï¼Œä½ èƒ½å¾—åˆ°ï¼šé»˜è®¤5060/3070ï¼Œè¶…é¢‘5060tiï¼Œæžé™æ‘¸3080å±è‚¡çš„æ¸¸æˆæ€§èƒ½
  - ç›¸æ¯”æ›´æ—©çš„å¡å¦‚v100ï¼Œæœ‰DLSS4ï¼Œæœ‰å…‰è¿½ï¼Œå¯ä»¥è·‘æ¸²æŸ“å™¨ï¼Œç”šè‡³å¯ä»¥4kDLSSè¶…çº§æ€§èƒ½+æ’å¸§modï¼Œ60-70å¸§çŽ©ä¸€çŽ©2077è·¯å¾„è¿½è¸ª
  - å‡ ä¹Žæœ€å®Œç¾Žçš„æ˜¾å­˜æ‰©å®¹ä½“éªŒï¼Œ20ç³»æ˜¾å¡æ˜¾å­˜æ‰©å®¹åªéœ€è¦æŠŠæ˜¾å­˜é¢—ç²’ä»Ž1G GDDR6æ¢æˆ2Gå°±å¯ä»¥
  - è¿™ä¸€ä»£çš„vbiosè¿˜æ²¡æœ‰ä¸Šé”ï¼Œæ‰©å®¹æ²¡æœ‰é©±åŠ¨bugï¼ˆ3070 16gæœ‰ï¼‰ï¼Œæ— éœ€æ‹†BGAï¼ˆ3080ã€4090éœ€è¦ï¼‰ï¼Œæ‰€æœ‰å“ç‰Œvbiosä»»æ„äº’åˆ·ï¼ˆ3080ã€4090éœ€è¦ç‰¹åˆ¶vbiosï¼‰ï¼Œå®Œå…¨ä¸å½±å“è¶…é¢‘ï¼ˆ3080ã€4090æ”¹åŽé”åŠŸè€—ï¼‰ï¼Œå®Œå…¨ä¸å½±å“æ•£çƒ­ï¼ˆ3080ã€4090æ”¹è£…åŽå˜æˆåŒé¢æ˜¾å­˜å¤§ç«ç‚‰ï¼‰
  - æ²¡æœ‰vegaç³»åˆ—HBMç¼©è‚›é—®é¢˜ï¼Œæ²¡æœ‰6800ç³»åˆ—ç‚¸æ ¸å¿ƒé—®é¢˜
  - å”¯ä¸€è¦æ‹…å¿ƒçš„å°±æ˜¯åˆ«ä¹°åˆ°æ—©æœŸé•å…‰æ˜¾å­˜å’Œé»„çš®è‚¡å¤§ä¿®å¡
- è¯´å®žè¯ä¸å¦‚ç›´æŽ¥ä¹°5060ï¼Œè¿™çŽ©æ„åŠŸè€—å¿«åˆ°5060ä¸¤å€äº†ï¼ŒäºŒæ‰‹èƒ½ç”¨å¤šä¹…ä¹Ÿå¾ˆéš¾è¯´ã€‚

- ä¸ºä»€ä¹ˆ3060è¿˜èƒ½å–1300å—ï¼Ÿæˆ‘è§‰å¾—è¿™ä¸ªç ´å¡æ ¹æœ¬ä¸å€¼é’±ï¼ŒçŽ°åœ¨3070ä¹Ÿæ˜¯1300
  - 2gå¤§æ˜¾å­˜ï¼Œ2k3aæ–°æ¸¸æˆèƒ½åæ€4060æŒå¹³5060è¿™ç§8gçš„å¡
  - AIç»˜å›¾å…¥é—¨å¡ï¼Œå·²ç»æ²¡æœ‰æ¯”å®ƒæ€§ä»·æ¯”è¿˜é«˜çš„å¡äº†ï¼Œå¦å¤–3060ä¸å»ºè®®ä¹°äºŒæ‰‹ï¼ŒçŸ¿å¡å¤ªå¤šï¼Œå»ºè®®è¿˜æ˜¯ä¹°ä¸ªæ­£è§„ç‰Œå­çš„2000å·¦å³çš„æ–°å¡

- v100 32g çŽ°åœ¨çº¦2100 ï¼›æœŸç›¼é™åˆ°1500 ã€‚
  - v100 16gçº¦500ï¼›é…ä¸€å¥—æ°´å†· 900å—ã€‚
  - x99 e5ä¸€å¥—åŒæ˜¾å¡æ§½ä¸»æœºä¸è¿‡åƒå…ƒã€‚
  - 3500æ­ä¸€å¥—32gå•å¡ä¸»æœºï¼›
  - ä½†åŠŸè€—éš¾ç»·300-600wï¼Œæ‰€ä»¥æœ€åŽç”¨macçŽ©apiäº†ï¼›

- åˆ«æŠ˜è…¾V100è¿™ç§åžƒåœ¾äº†ï¼ŒçŽ°åœ¨è¶Šæ¥è¶Šå¤šçš„æ–°æ¨¡åž‹ï¼Œéƒ½ä½¿ç”¨BF16ã€FP8ç”šè‡³NVFP4è®­ç»ƒæ¨¡åž‹äº†ï¼Œå°±ç®—æŽ¨ç†ï¼Œç®—åŠ›è¦æ±‚ä¹Ÿæ˜¯8.0èµ·æ­¥ï¼Œæœ‰AIéœ€æ±‚ï¼Œè€è€å®žå®žä¹°æ–°å¡ã€‚

- ## [AMD å‘å¸ƒ AI æ˜¾å¡ R9700ï¼Œæ€§èƒ½å·ç§°åŒçº§ 5 å€ï¼Œå®žé™…è¡¨çŽ°å¦‚ä½•ï¼Ÿ - çŸ¥ä¹Ž _202509](https://www.zhihu.com/question/1946144571521234533)
  - R9700çš„AIæ€§èƒ½è¡¨çŽ°å´å¼•èµ·äº†å¤§å®¶çš„å…³æ³¨ï¼Œä½œä¸ºä¸€æ¬¾RDNA4æž¶æž„çš„æ˜¾å¡ï¼Œæ‹¥æœ‰32GB GDDR6ã€256-bitä½å®½ã€å³°å€¼å¸¦å®½çº¦640 GB/sã€300W TDPï¼Œä»¥åŠæœ€å¤šçº¦1531 TOPSï¼ˆINT4ï¼‰å’ŒFP16çº¦96 TFLOPSçš„AI/çŸ©é˜µè¿ç®—èƒ½åŠ›ã€‚

- è¿™ä¸ªæ˜¯RDNA4åº”è¯¥æ¯”395maxé‚£ä¸ªRDNA3.5çš„é­”æ”¹å¼ºä¸å°‘å§

- [AMDå‘å¸ƒAIç¥žå¡R9700ï¼æ€§èƒ½æ˜¯åŒçº§5å€ï¼Œè‹±ä¼Ÿ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/68c58dcb000000001c008551?xsec_token=ABxWJEP3Vpkb636xx2y79C0FRNAwvEq6parZO6uJSDPkM=&xsec_source=pc_search&source=web_search_result_notes)
- äººè¯ï¼š32gç‰ˆæœ¬9070
- æ²¡æœ‰ CUDA ç”Ÿæ€æ”¯æŒï¼Œä¹Ÿå°±çŽ©çŽ©çŽ°æˆçš„ toy model
  - ç”¨vulkanæˆ–è€…ZLUDAæˆ–è€…HIPè·‘å‘—ï¼Œåæ­£8kå—çš„å¡è‚¯å®šæ˜¯ä¸ªäººç”¨ï¼Œä¸éœ€è¦é›†ç¾¤ï¼Œä¸è€ƒè™‘å¤šå¹¶å‘æˆ–è€…äº¤ç«å•¥çš„ï¼Œèƒ½çŽ©

- åªèƒ½åœ¨Linuxå¹³å°ç”¨ï¼Œllmå¯èƒ½è¿˜è¡Œï¼ŒAIGCä¼°è®¡æ˜¯å„ç§ä¸å…¼å®¹æŠ¥é”™ã€‚å›¾ä¾¿å®œ6000çš„3090å°±æŒºå¥½çš„ã€‚r9700è·Œåˆ°6000ä¹Ÿè¿˜æ˜¯åªæŽ¨è3090ã€‚
  - è¡¥å……ä¸€ç‚¹ï¼Œr9700æ€§èƒ½åŒç­‰çº§çš„æ¸¸æˆæ˜¾å¡æ˜¯5070ï¼Œè·Ÿ5080ä¸æ˜¯ä¸€ä¸ªçº§åˆ«äº§å“ï¼Œæ˜¾å­˜å¤§ç¡®å®žæ˜¯ä¸ªäº®ç‚¹ï¼Œä½†åˆä¸å¤Ÿå¤§åªæœ‰32GBï¼Œè®°å¾—ä¸é”™wançš„æƒé‡å¥½åƒæ˜¯35GBï¼ŒæŠ˜è…¾ä¸€åœˆåˆ°æœ€åŽè¿˜æ˜¯åªèƒ½é€‰48GBçš„4090ã€‚
  - ä¸è¦ä¸ºäº†æŽ¨ç†llmï¼Œé€‰æ¥é€‰åŽ»åªèƒ½é€‰m4 maxï¼Œ128GB 400å¤šçš„å¸¦å®½ï¼Œè‹¹æžœå¤´ä¸€æ¬¡æœ‰æ€§ä»·æ¯”ã€‚

- æ²¡æ„ä¹‰ï¼Œaå¡çš„aiå¡å¦‚æžœæ€§ä»·æ¯”å¹²ä¸è¿‡2080ti 22gæ ¹æœ¬æ²¡å‡ºè·¯

- å¿…é¡»ç”¨HBMï¼Œè¯•é—®æŒ‰æ‘©åº—2019å¹´çš„HBMæ˜¾å­˜ä¸ºä»€ä¹ˆæ‚„å’ªå’ªçš„è·‘åˆ°è€é»„ä¸“ä¸šå¡ä¸Šäº†ï¼Ÿä¸ºä»€ä¹ˆä¹‹åŽæŒ‰æ‘©åº—ä¸ºä»€ä¹ˆä¸å‡ºHBMæ˜¾å­˜çš„æ˜¾å¡â€¦â€¦è¿™ç¾¤å¹•åŽäº¤æ˜“â€¦â€¦å‘µå‘µå‘µï¼è¿˜æ˜¯èµ„æœ¬ä¼šçŽ©

- ## [RTX 4080 SUPER 32 GBé‡äº§ï¼Ÿæ˜¾å¡æ—¥æŠ¥10æœˆ6æ—¥ - çŸ¥ä¹Ž _202510](https://zhuanlan.zhihu.com/p/1958257251954452012)

- [è‹±ä¼Ÿè¾¾RTX4080S 32Gæ¶¡è½®æ˜¾å¡æ–°é²œå‡ºç‚‰ - å°çº¢ä¹¦ _202510](https://www.xiaohongshu.com/explore/68dc7ac30000000005031f93?xsec_token=ABF5bwSFkHhKX5sU6IgENqtkol2WzQxpTy_DJscw_OC8M=&xsec_source=pc_search&source=web_explore_feed)
- é‚£4080sæ˜¯ä¸æ˜¯è¦æ¶¨ä»·äº†
  - å¤šåŠä¸ä¼šï¼Œ4090æ¶¨ä»·è™½ç„¶ä¸€æ–¹é¢æœ‰æ˜¾å­˜é­”æ”¹çš„åŽŸå› ï¼Œä½†æœ€ä¸»è¦ç¦å”®ï¼Œè€Œä¸”ä¹Ÿä¸äº§äº†ï¼Œå­˜é‡æŸç§ç¨‹åº¦è‚¯å®šå°‘, ä½†4080å¸‚é¢ä¸Šè¿˜æ˜¯å¾ˆå¤šçš„
- è¦æ˜¯æœ‰ä¸‰é£Žæ‰‡ç‰ˆçš„å°±å¥½äº†ï¼Œæ¶¡è½®çš„å£°éŸ³å—ä¸äº†

- [çŽ°åœ¨ä¸Š4080superæ˜¯ä¸æ˜¯49å¹´å…¥å›½å†›ï¼Ÿ - çŸ¥ä¹Ž _202408](https://www.zhihu.com/question/664986798)
  - é™¤éž4080s è·Œå€’6k ä¸ç„¶çœŸçš„ä¸å€¼å¾—è´­ä¹°äº†ï¼Œé¡¶å¤©ä¹Ÿå°±5070tiçš„æ€§èƒ½ï¼Œ é—®é¢˜äººå®¶æœ‰ å¤§åŠ›æ°´æ‰‹4å•Šã€‚

- [4080Superä¹°å“ªä¸ªå¥½ï¼Ÿä¸è¶…é¢‘ï¼Œä½†æ±‚çœå¿ƒä¸æŠ˜è…¾? - çŸ¥ä¹Ž](https://www.zhihu.com/question/651409618)
- åŒºåˆ«ä¸»è¦å°±æ˜¯ç”¨æ–™ã€å¤–è§‚ã€å“ç‰Œå’Œå”®åŽ

- ä¸»è¦è®¾è®¡å¤„åŒºåˆ«ï¼šä¾›ç”µã€æ•£çƒ­è§„æ ¼
  - åŽç¡• ROG çŒ›ç¦½ï¼š18+3 70Aä¾›ç”µï¼Œå•16PINä¾›ç”µï¼Œ4*8mm+3*6mmé“œç®¡ï¼Œå‡çƒ­æ¿
  - åŽç¡• TUF ç”µç«žç‰¹å·¥ï¼š12+2 50Aä¾›ç”µï¼Œå•16PINä¾›ç”µï¼Œ5*8mm+3*6mmé“œç®¡ï¼Œåˆ†ä½“å¼é•œé¢é“œåº•
- æ•´ä½“è€Œè¨€ï¼ŒåŽç¡•æº¢ä»·ä¸¥é‡ï¼Œè§„æ ¼ä¸€èˆ¬ï¼Œè€Œå¾®æ˜Ÿåªæœ‰æ——èˆ°åž‹å·èƒ½çœ‹ï¼Œä¸ƒå½©è™¹çš„å…¨ç³»ç”¨æ–™éƒ½ä¸é”™ï¼Œå½±é©°æ˜¾å¡çš„æ€§ä»·æ¯”é«˜ï¼Œè¿˜æœ‰å½±é©°HOFåäººå ‚æ˜¯RTX4080Superè§„æ ¼é‡Œé¢ä¾›ç”µæœ€é«˜çš„åž‹å·ï¼Œè¿˜æœ‰ï¼Œä¸‡ä¸½ç›–æ‹‰å¤šè™½ç„¶æ˜¯ä»·æ ¼æœ€ä½Žçš„ï¼Œä½†ä¸æ˜¯ç”¨æ–™æœ€ä¸çš„ã€‚
  - ä¸‹é¢ä¸¤æ¬¾ä¸ºè‰¯å¿ƒåž‹å·ï¼Œå¯æ— è„‘å…¥ï¼š 
  - **å½±é©°RTX4080 SUPER æ˜Ÿè€€OCï¼Œä¸ƒå½©è™¹RTX4080 SUPER AD OC**
  - æ——èˆ°åž‹å·æŽ¨èï¼šä¸ƒå½©è™¹ç«ç¥žå’Œæ°´ç¥žã€å¾®æ˜Ÿè¶…é¾™ï¼ˆé™ä»·é«˜å¯è€ƒè™‘ï¼‰ã€å½±é©°åäººå ‚

- æ¯ä¸ªå“ç‰Œä¹Ÿæœ‰æ——èˆ°å’Œæ¬¡æ——èˆ°ä¹‹åˆ†
  - æ¯”å¦‚å¾®æ˜Ÿå°±æœ‰ä¸‡å›¾å¸ˆï¼Œé­”é¾™ï¼Œè¶…é¾™ä¹‹åˆ†ï¼Œåˆ†åˆ«å¯¹åº”çš„å…¥é—¨æ¬¾ï¼Œè¿›é˜¶å’ŒæœŸé—´ï¼Œä»·æ ¼ç›¸å·®å‡ ç™¾ã€‚
  - å¦å¤–å°±æ˜¯æ”¯æŒä¸ªäººé€ä¿çš„ä¸ƒå½©è™¹ï¼Œå¯¹äºŽå”®åŽè¿™å—æ¥è¯´ç®€ç›´ä¸è¦å¤ªçœå¿ƒäº†ï¼Œ ä¸ƒå½©è™¹ä¸€æ¬¾Ultra W OCï¼Œå¦å¤–ä¸€æ¬¾AD OC åŒºåˆ«ä¸æ˜¯å¾ˆå¤§ï¼Œä¸»è¦æ˜¯å¤–è§‚åŒºåˆ«

- å¾ˆå¤šéƒ½æ˜¯æŽ¨èå¾®æ˜Ÿã€åŽç¡•ã€ä¸ƒå½©è™¹çš„ï¼ŒæŠŠå¾¡ä¸‰å®¶çš„æŠ€å˜‰ç»™æ¼äº†ï¼Ÿ
  - å› ä¸ºæŠ€å˜‰è¾±åŽå•Š

- ## [å¦‚ä½•è¯„ä»·RTX2080Ti 22Gé­”æ”¹ç‰ˆï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/8164944069)
  - è¿™å¼ å¡çš„ä»·æ ¼åœ¨2600ä¸Šä¸‹ã€‚åŒä»·ä½æˆ–é¢„ç®—å†…çš„Nå¡è¿˜æœ‰RTX 4060 8Gï¼ˆä»·æ ¼å·®ä¸å¤šï¼‰ï¼ŒTESLA P100ï¼ˆè¿™å¼ åªè¦1600å·¦å³ï¼‰

- [æˆ‘ä¹°è®¡ç®—å¡æ—¶åšçš„åŠŸè¯¾ å¯¹æ¯”è¡¨](https://www.zhihu.com/question/8164944069/answer/1940267056307077954)

- [What are your /r/LocalLLaMA "hot-takes"? : r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/comments/1obb4c4/what_are_your_rlocalllama_hottakes/)
  - Currently, no so-called AI PC or unified memory device can match the performance of a similarly priced combination of GPUs and server CPUs.
  - vLLM and CUDA 13 are dropping support for GPUs with SM7.5 and below, so buying any pre-Ampere GPU (e.g., 2080 Ti, V100) is not a sustainable long-term choice. In my opinion, only NVIDIA's Ampere (and newer) architectures and AMD's RDNA 4 are truly viable for AI workloads.

- 2080Ti~22gï¼šç›®å‰(2024å¹´12æœˆåº•)ï¼Œå¯ä»¥æ‰¾åˆ°2400-2500åº—ä¿ä¸€å¹´çš„ï¼Œå°½é‡é€‰å£ç¢‘å¥½çš„ã€‚
  - è¿™å¼ å¡èƒ½åŠ›å‡è¡¡ï¼Œæ˜¯å¹³æ°‘/åžƒåœ¾ä½¬çš„Aiç¥žå™¨ï¼ŒåŒæ ·ä¹Ÿæ˜¯æ¥è·¯ä¸æ˜Žnvéª‘å£«çš„å…¸èŒƒï¼Œç”Ÿäº§åŠ›è€æ‰‹ã€‚
  - å¤§æ˜¾å­˜ï¼Œé«˜ç®—åŠ›ï¼Œé«˜å¸¦å®½ï¼ŒåŠŸè€—åˆç†ï¼Œå™ªéŸ³æ•£çƒ­å¯æŽ¥å—ï¼Œè¿˜æ”¯æŒnvlinkæ‰©å±•ã€‚
  - å®ƒçš„å”¯ä¸€ç¼ºç‚¹å°±æ˜¯Turingæž¶æž„æœ‰ä¸€ä¸¢ä¸¢è€äº†ï¼Œä½†æ¯”voltaåˆè¦å¥½ä¸€ä¸¢ä¸¢ã€‚è‡³äºŽçŸ¿ä¸çŸ¿

- 2500é™„è¿‘çš„åŒä¸€ä»·ä½ï¼Œèƒ½ä¹°åˆ°ï¼š
  - V100-sxm2-16g~PCIe(è½¬æŽ¥å¡ï¼Œè®­ç»ƒå‘)
  - V100-pcie-16g-å®šåˆ¶(æ ¸å¿ƒæ¬æ¿ï¼Œè®­ç»ƒå‘)
  - 2080Ti~22g(æ˜¾å­˜æ‰©å®¹ï¼Œè®­ç»ƒæŽ¨ç†å…¼é¡¾)
  - 3070~16g(æ˜¾å­˜æ‰©å®¹ï¼ŒæŽ¨ç†æ—¥å¸¸å…¼é¡¾)
  - 4060ti-8g(16gè¦æ¡æ¼ï¼ŒæŽ¨ç†æ—¥å¸¸çŽ¯ä¿)
- 2025å¹´5æœˆåŠ å‡ å—å¡
  - A3000m~pcie(12Gæ˜¾å­˜ï¼Œç§»åŠ¨ç‰ˆé­”æ”¹ï¼ŒæŒ‘ä¸»æ¿ï¼Œ Â¥1400)
  - T10(16Gæ˜¾å­˜ï¼ŒæŽ¨ç†æ€§ä»·æ¯”é«˜ï¼Œä¸€å®šè¦æžå¥½æ•£çƒ­ï¼Œ Â¥1400)
  - 3080~20G(æ¬æ¿æ‰©å®¹ï¼Œåº”å¯¹3090æ¶¨ä»·ï¼Œæ³¨æ„æ•£çƒ­ï¼ŒÂ¥3500)
  - 5060Ti-16G(ä»£æ›¿4060tiï¼Œå…¼å®¹æ€§é€æ¸å¥½è½¬ï¼Œ Â¥3500)

- æˆ‘è®¤ä¸ºï¼Œæ·±åº¦å­¦ä¹ çš„ç”Ÿäº§åŠ›æå‡å…³é”®åœ¨äºŽæ··åˆç²¾åº¦è®­ç»ƒ(mixed-precision-training)å’Œä½Žç²¾åº¦æŽ¨ç†
  - é™¤éžä½ æœ‰éžå¸¸æ˜Žç¡®çš„ç›®æ ‡ï¼Œæ¯”å¦‚ä¾èµ–æ˜¾å­˜å¤§å°çš„ä¼ ç»Ÿå•ç²¾åº¦è®¡ç®—ï¼Œå¹¶ä¸”æœ‰ä¸¥æ ¼çš„é¢„ç®—ï¼Œæ‰è€ƒè™‘p100/p40
  - V100å¯ä»¥æä¾›è¶…è¶Š3090/4080çš„æ··åˆç²¾åº¦ç®—åŠ›ï¼Œé€‚åˆæ·±åº¦å­¦ä¹ è®­ç»ƒï¼Œä½†å› ä¸ºvoltaä½œä¸ºæœ€åˆä»£tensor coreï¼Œä¸æ”¯æŒint8/int4åŠ é€Ÿï¼Œé‡åŒ–æŽ¨ç†æ²¡æœ‰ä¼˜åŠ¿ã€‚ç›®å‰SXMç‰ˆæœ¬ä»·æ ¼ä¸é”™ï¼Œä½†è½¬æŽ¥pcieéœ€è¦æŠ˜è…¾ã€‚
  - 2080Ti~22gï¼Œç‰¹ç‚¹å¦‚å‰ï¼ŒæŽ¨èã€‚ç²¾åº¦ä¸æ”¯æŒtf32/bf16/fp8/fp4ï¼Œåº“ä¸æ”¯æŒflash-attn:2+(å·²æœ‰ç§»æ¤ç‰ˆæœ¬å¯è§)ï¼Œå½±å“éœ€è¦æ ¹æ®å®žé™…ç ”åˆ¤ã€‚
  - 3070~16gæˆ–è€…æ‹©æœºæ¡æ¼ä¸Š4060ti-16gï¼Œæ›´é€‚åˆå…¥é—¨é€‰æ‰‹ï¼Œä»€ä¹ˆéƒ½æƒ³è¯•è¯•ï¼ŒæŽ¨èæ–°æž¶æž„ã€‚è¿™ä¸ªä»·ä½ä¸Šç›®å‰è¿˜èƒ½ä¹°åˆ°A2ï¼Œä½†åªæœ‰3050çš„æ€§èƒ½æ˜Žæ˜¾ä¸å¤ªå¤Ÿçœ‹
- Ampereå’ŒAdaæž¶æž„ç›¸æ¯”Turingçš„ä¼˜åŠ¿ï¼Œä¸€æ˜¯å·¥è‰ºæ”¹è¿›å¸¦æ¥çš„èƒ½è€—ä¼˜åŒ–ï¼ŒäºŒæ˜¯æ”¯æŒæ›´å¤šçš„æ•°æ®ç±»åž‹åœ¨tensoråŠ é€Ÿï¼Œæ¯”å¦‚bf16ç”šè‡³fp8ï¼Œé™„å¸¦å°±æ˜¯flash-attention(2+)ä¾èµ–ç¡¬ä»¶æž¶æž„
- ä»ŽCUDA **12.8**å¼€å§‹ï¼Œè‹±ä¼Ÿè¾¾å®˜æ–¹ä¸å†å¯¹maxwell(cc 5.2/5.3)ã€pascal(cc 6.0/6.1)ã€volta(cc 7.0) æä¾›æ›´æ–°ï¼Œ**é©±åŠ¨è¿˜å¯ä»¥æ­£å¸¸å®‰è£…ï¼ŒåŠ é€Ÿå¡ä¹Ÿå¯ä»¥æ­£å¸¸ä½¿ç”¨**ï¼Œä½†å®ƒä»¬è¢«æ ‡è®°ä¸ºè¿‡æ—¶æž¶æž„ï¼Œé€‰æ‹©æ—¶éœ€è¦è¯„ä¼°ã€‚

- é­”æ”¹æŠ€æœ¯å·²ç»éžå¸¸æˆç†Ÿäº†ï¼Œç¨³çš„ä¸€æ‰¹ï¼Œæˆ‘ä¸Šäº†4å—æ¶¡è½®æ•£çƒ­çš„ï¼Œå–å®¶é€äº†NVlink, ä¸åˆ°1wå—é’±ï¼ŒæœåŠ¡å™¨å°±æœ‰äº†88Gæ˜¾å­˜

- åªèƒ½ç›¸é‚»ä¸¤å¼ å¡äº’è”ï¼Œè€Œä¸”ä¸¤æ¡nvlinké€ŸçŽ‡ä¸€èˆ¬~å½“ç„¶æ¯”PCIeè¿˜æ˜¯å¥½å¤šäº†
  - å®žé™…è·‘ollamaæŽ¨ç†ï¼Œnvlinkæ²¡èµ·ä»€ä¹ˆä½œç”¨

- cuda12 ç”¨ä¸äº†è¿™ä¸ª2080ti
  - èƒ½ç”¨ï¼Œ20ç³»è¦è¯´æœ‰å•¥å¼Šç«¯é‚£å°±æ˜¯ä¸æ”¯æŒbf16ï¼Œè€Œä¸”è¿™å¡çŽ°åœ¨çœ‹æ€§èƒ½ä¹Ÿä¸è¡Œäº†ï¼Œä¹Ÿå°±5060çš„æ€§èƒ½
- p106è¿™ä¸ª10ç³»çš„éƒ½èƒ½è£…cuda12
- åˆ«è¯´pæž¶æž„äº†ï¼Œæˆ‘tesla m40éƒ½è£…ä¸Šäº†12

- 20ç³»ä¸æ”¯æŒbf16å’Œfp8ï¼Œæœ‰äº›æ–°æ¨¡åž‹æ ¹æœ¬å°±è·‘ä¸äº†
  - æˆ‘ç”¨çš„2080åæ­£çŽ°åœ¨å•¥æ¨¡åž‹éƒ½èƒ½è·‘ï¼Œä¸»è¦æ˜¯ç»˜ç”»

- æŽ¨èï¼Œæ€§ä»·æ¯”æ˜¯çœŸçš„é«˜ï¼Œä½œä¸ºæŽ¨ç†å¡ååˆ†ä¼˜ç§€ï¼Œä½†è®­ç»ƒçš„è¯è¦æ…Žé‡ã€‚å‰æ®µæ—¶é—´ä¹°äº†å…­å¼ åœ¨å®¶æ­äº†ä¸€ä¸ªå…­å¡æœºå™¨ï¼Œç”¨äº†å¿«ä¸€å¹´äº†æ²¡å‡ºè¿‡é—®é¢˜ï¼Œæ€»å…±åŠ èµ·æ¥132gæ˜¾å­˜æœ€ç»ˆèŠ±è´¹æ‰ä¸åˆ°2wã€‚
  - ç¼ºç‚¹ä¹Ÿæ˜¯æœ‰çš„ï¼Œæœ€å¤§çš„é—®é¢˜å°±æ˜¯æž¶æž„æ¯”è¾ƒè€ï¼Œä¸æ”¯æŒbf16ä»¥åŠä¸€äº›æ¯”è¾ƒæ–°çš„ç®—æ³•ã€‚ç›®å‰å‡†å¤‡æ¢æˆ3080æ”¹20gæˆ–è€…æžä¸¤å¼ 4090æ”¹48gè·‘è·‘è®­ç»ƒï¼Œé¡ºä¾¿æŠŠä¹‹å‰2080tiçš„nvlinkæ­ä¸Š
  - æœ€åŽï¼Œå¦‚æžœè¦æžè®­ç»ƒï¼Œå»ºè®®è¿˜æ˜¯ä¸Š30ç³»ä»¥ä¸Šçš„ã€‚ä¸ç„¶ä¼šå› ä¸ºæž¶æž„å¤ªè€é‡åˆ°å¾ˆå¤šå‘ã€‚
  - å¾…æœºæ¯å¤©5åº¦ç”µï¼Œç«åŠ›å…¨å¼€æ¯å¼ å¡250wï¼Œä¸€å°æ—¶å°±1.5åº¦

- 2080tiæ˜¯äºŒä»£NVLinkï¼Œå’Œ3090ä¸‰ä»£nvlinkä¸é€šç”¨å§ã€‚

- 4090æ²¡æœ‰sliæˆ–è€…nvlink
  - lzçš„å…­å¡æœºä¹Ÿæ²¡æœ‰å¾€SLIä¸Šæ’ä¸œè¥¿å•Šã€‚

- Turingæž¶æž„çš„tensor coreèƒ½è·‘fp16å’Œint8ï¼Œä½†æ˜¯ç›®å‰çœ‹bf16æ˜¯è¶‹åŠ¿ï¼Œè¿˜æ˜¯å¾—æ…Žé‡
  - 30ç³»ä»¥ä¸Šçš„å¯ä»¥è·‘flash attention

- 4090 48GæœåŠ¡å™¨éƒ½æœ‰äº†ï¼Œæˆ‘çŽ°åœ¨å°±åœ¨ç”¨8å¡çš„
  - å¤§è‡´è®²ä¸‹ä½“éªŒï¼Œæ”¯æŒbf16çš„æ··å’Œç²¾åº¦æ¨¡åž‹è®­ç»ƒåœ¨å‚ç…§80GA100çš„batch-sizeçš„æƒ…å†µä¸‹ï¼Œè™½ç„¶4090è¦å¼€grad_accumulation=2ï¼Œä½†æ˜¯é€Ÿåº¦æ¯”a100å¿«ä¸€äº›ï¼Œèƒ½åˆ°5.5:7.3 s/stepã€‚ ä¸æ”¯æŒæ··å’Œç²¾åº¦çš„æ¨¡åž‹å°±è¦æ…¢a100ä¸€å€äº†
  - æ²¡nvlink, è·‘çš„æ˜¯VLAçš„è®­ç»ƒï¼Œä¸€ä¸ªæ˜¯RDTï¼Œä¸€ä¸ªpi0ï¼Œæ ¹æœ¬ä¸èƒ½å…¨å‚æ•°ï¼Œè™½ç„¶ioæ²¡å¡ä½ï¼Œä½†æ˜¯å¦‚æžœæ¨¡åž‹æ²¡å¼€bf16çš„æ··å’Œç²¾åº¦è®­ç»ƒçš„è¯æ…¢ä¸€å€å¤šäº†

- é­”æ”¹çš„2080tiä½ è®°å¾—ä¹°ä¸‰é£Žä¸è¦ä¹°æ¶¡è½®å¡ï¼Œæ¸©åº¦é«˜ï¼Œå™ªéŸ³å¤§ï¼Œå®¹æ˜“å—ä¸äº†çš„ï¼Œæˆ‘å°±æ˜¯ä»Žæ¶¡è½®å¡æ¢æˆäº†ä¸‰é£Žï¼Œå™ªéŸ³é—®é¢˜åŸºæœ¬è§£å†³

- 3000ä»¥å†…é­”æ”¹çš„2080tiç¡®å®žå°±æ˜¯æœ€ä½³é€‰æ‹©ï¼Œ
  - è¿™å°ä¸€å¹´ç¾¤é‡Œå‡ ç™¾å·äººç¿»æ¥è¦†åŽ»è®¨è®ºè¿‡æ— æ•°æ¬¡ï¼Œæœ€ç»ˆç»“è®ºéƒ½æ˜¯é­”æ”¹2080tiæ€§ä»·æ¯”æœ€é«˜
  - è¿™æ˜¯ä½ èƒ½å¾—åˆ°çš„æœ€ä¾¿å®œçš„20gä»¥ä¸Šæ˜¾å­˜ä¸”æ€§èƒ½è¿‡å¾—åŽ»çš„å¡äº†ï¼Œæˆ‘è‡ªå·±ä¹Ÿç‚¼ä¸¹çŽ©å„¿ï¼Œå¡é’±æ˜¯èµšå›žæ¥äº†çš„

- ä¸æ”¯æŒbf16æ˜¯ç¡¬ä¼¤ï¼Œå‰©ä¸‹çš„å°±æ˜¯ä½ ä¹°äº†å¤§æ¦‚çŽ‡å°±æ˜¯æŽ¥ç›˜ä¾ äº†ï¼Œè¿™å¡åœ¨æœªæ¥ä¸ä»…æ‰“æ¸¸æˆçš„çœ‹ä¸ä¸Šï¼Œç‚¼ä¸¹çš„ä¹Ÿçœ‹ä¸ä¸Šã€‚

- åœ¨2kå‡ºå¤´çš„ä»·ä½ä¸ç®—å·®ï¼Œä½†æ˜¯V100 16GBå’Œ3080 20GBçš„æ€§ä»·æ¯”æ›´é«˜

- 3080 20gè¦3åƒå¤šäº†
  - èƒ½è·‘BF16å°±å€¼å›žå¤šçš„600-700äº†ã€‚å¦‚æžœä¸è¦ä¿ä¿®çš„è¯é—²é±¼æœ‰2600å·¦å³çš„

- ## [2025å¹´AIæœ¬åœ°éƒ¨ç½²æ€§ä»·æ¯”ä¹‹çŽ‹ï¼åŒå¡V100ï¼32Gæ˜¾å­˜ï¼Œä½Žä»·é«˜èƒ½ï¼Œç¢¾åŽ‹2080Ti 22G - çŸ¥ä¹Ž](https://zhuanlan.zhihu.com/p/1927666998030078159)
- åƒé—®3 32Bæ¨¡åž‹åœ¨V100ä¸Šçš„tokenç”Ÿæˆé€Ÿåº¦ä¸ºæ¯ç§’20.34ä¸ªï¼Œ2080Tiåˆ™ä¸º13.43ä¸ªï¼›DeepSeek R1 32Bæ¨¡åž‹åœ¨V100ä¸Šçš„é€Ÿåº¦ä¸ºæ¯ç§’21.28ä¸ªï¼Œ2080Tiä¸º18ä¸ªã€‚

- V100ä¸æ”¯æŒflash- attentionã€bf16ã€awqã€sglangæ–°ç‰ˆæœ¬ä¹Ÿä¸æ”¯æŒv100äº†ï¼Œæ˜¾å¡å¤ªè€äº†ï¼Œæ–°çš„åŠ é€Ÿç­–ç•¥ç”¨ä¸äº†ï¼Œé€Ÿåº¦è¿˜ä¸å¦‚æ¶ˆè´¹å¡å‘¢ã€‚
- å¯¹SDè·‘å›¾æ¥è¯´ï¼Œä¸æ”¯æŒint4ã€fp8ã€fp4ï¼Œä¸èƒ½ç”¨nanchakuåŠ é€Ÿã€‚SDä¹Ÿä¸èƒ½å¤šå¡æ˜¾å­˜å åŠ ã€‚
- stable Diffusionè·‘å›¾ï¼Œå¾ˆå¤šæ¨¡åž‹éƒ½ç”¨ä¸äº†çš„ã€‚æ²¡å•¥æ„æ€

- å¾ˆå¤šæŽ¨ç†ç‰¹æ€§ä¸æ”¯æŒï¼Œè¿œè¿œæ²¡æœ‰2080tiå¥½

- V100ç¡®å®šä¸€åƒå°±èƒ½ä¹°åˆ°ï¼Ÿ
  - æ ¸å¿ƒæ¿å§ï¼Œæ•£çƒ­è½¬æŽ¥åŠ èµ·æ¥16gçš„3kï¼Œ32gçš„5kï¼Œæ¯•ç«Ÿæ˜¯6å¹´å‰çš„ä¸œè¥¿äº†
- å¤§æ¦‚1000å·¦å³å¯ä»¥æžå®šçš„ã€‚æˆ‘éƒ½1000ä¸€å¥—å–çš„ï¼Œè¿˜æ˜¯æ”¹çš„æ°´å†·ã€‚nvlink 32gï¼Œä¹Ÿå°±2300å–äº†

- ## [èŠä¸€èŠMi50è¿™å¼ æ˜¾å¡ï¼ˆè‡ªè´¹è´­å…¥ï¼‰ - çŸ¥ä¹Ž _202508](https://zhuanlan.zhihu.com/p/1935428196653838934)
- åœ¨500å…ƒä»·ä½ï¼Œè¿™å¼ å¡æ‹¥æœ‰å…¶ç‹¬æœ‰çš„16Gå¤§æ˜¾å­˜ï¼Œæƒ³æœ¬åœ°éƒ¨ç½²LLMçš„å¯ä»¥å†²ä¸€å†²ã€‚è´´å¿ƒçš„å–å®¶å·²ç»å¸®æˆ‘åˆ·å¥½äº†RadeonProVllçš„vbiosï¼ˆæç¤ºï¼šè¿™å¼ å¡åªæœ‰åœ¨é•­7çš„vbiosä¸‹æ‰ä¼šä¸»åŠ¨è¿›è¡Œè§†é¢‘è¾“å‡ºï¼Œå¾ˆé‡è¦ï¼ï¼‰ï¼Œ
  - æœ¬åœ°éƒ¨ç½²DeepSeek32Bçš„æ¨¡åž‹ç•¥æ˜¾åƒåŠ›ï¼Œæ¯•ç«Ÿæž¶æž„æŒºè€äº†è€Œä¸”æˆ‘åªæœ‰ä¸€å¼ å¡ï¼Œæœ‰æ¡ä»¶çš„å¯ä»¥å¤šå¡äº¤ç«ï¼ˆæ”¯æŒçš„ï¼Œæœ‰æŽ¥å£ï¼‰ï¼Œ
  - æ¸¸æˆæ–¹é¢æµç•…è¿è¡Œå€’æ˜¯ä¸èµ–ï¼Œ1080Pä¸‹ï¼Œæ­é…E5-2680V4ã€DDR4 2400çš„æƒ…å†µä¸‹ï¼ŒCS2é«˜ç”»è´¨å…¨å±€ç¨³å®š150å¸§ï¼Œæµç•…è¿è¡Œè‚¯å®šç§°å¾—ä¸Šï¼Œ
- å¯¹æˆ‘æœ€æœ‰å½±å“çš„åº”è¯¥å°±æ˜¯è¿™ä¸ªæ²ƒä¼¦å¡çš„ å™ªï¼éŸ³ï¼ çœŸçš„å¾ˆTMåµï¼Œè·Ÿä½“è‚²è€å¸ˆä¸åœå¹å£å“¨ä¸€æ ·
  - ä½†å¥½åœ¨å·²ç»æœ‰åŒé£Žæ‰‡ç‰ˆæœ¬ï¼Œå½“æ—¶å›¾ä¾¿å®œåŠ ä¸Šæ²¡ä¹°è¿‡æ¶¡è½®å¡ï¼Œè„‘å­ä¸€çƒ­ï¼Œä¸€å¤±è¶³æˆåƒå¤æ¨å•Š 
- æ˜¾å¡å…‰æœ‰ç¡¬ä»¶æ˜¯ä¸è¡Œçš„ï¼Œè½¯ä»¶å±‚é¢ä¹Ÿå¾—æ‰“ç£¨æ‰“ç£¨
  - è¿™å¼ å¡åœ¨è¿™ä¸ªä»·ä½æ®µï¼Œå°±ä½œä¸ºä¸€å¼ ä¸“ä¸šç”Ÿäº§åŠ›å¡æ¥è¯´ï¼Œæˆ‘å¯ä»¥æ‹ç€èƒ¸è„¯è¯´å‡ºAMD YESï¼æ¯•ç«Ÿè¿™ä¸ªä»·ä½çš„Nå¡ä¸æ˜¯1065ã€1063å°±æ˜¯40hxè¿™ç§è¦ä¹ˆæ˜¾å­˜å°ï¼Œè¦ä¹ˆè§†é¢‘ç¼–è§£ç èƒ½åŠ›è¢«ç å¾—æ¯”è·¯æ˜“åå…­è¿˜æƒ¨å†æˆ–è€…æ˜¯é­”æ”¹é”é©±ï¼Œæˆ‘æ˜¯å–œæ¬¢å°æœºç®±çš„äººï¼Œå°æ¿è¿™ç§åªæœ‰ä¸€ä¸‹x16æ§½çš„æ— å¤´éª‘å£«å¯ç”¨ä¸äº†

- è¿™å¡çš„minidpå¥½åƒä¸å¸¦éŸ³é¢‘è¾“å‡º
  - æˆ‘æ’è€³æœºç”¨çš„

- åŠŸè€—å¤ªé«˜äº†ï¼Œä¸é€‚åˆçœ‹è§†é¢‘ä¸Šç½‘ç”¨ã€‚

- https://www.zhihu.com/question/628771017/answer/1928750084457230617
  - å…³äºŽLLMæ¨¡åž‹ç”Ÿæˆé€Ÿåº¦ï¼šNå¡CUDAå¼ºï¼ŒAå¡ä¸€èˆ¬ã€‚ä¸ªäººç”¨é€”ä¸€èˆ¬æ›´åœ¨ä¹Žæ¨¡åž‹æ™ºå•†æ°´å¹³è€Œä¸åœ¨ä¹Žç”Ÿæˆé€Ÿåº¦ï¼Œå› æ­¤æ˜¾å­˜å¤§å°å°±æ˜¯çŽ‹é“ï¼Œæ— è„‘é€‰å¤§æ˜¾å­˜/å†…å­˜é…ç½®ï¼ŒCPUæŽ¨ç†æ€§ä»·æ¯”æ›´é«˜ï¼Œå¯ä»¥è¿è¡Œè¶…é«˜å‚æ•°ï¼Œå¦‚deepseek 671Bï¼ŒCPUæŽ¨ç†åƒå†…å­˜å¸¦å®½ï¼Œé€šé“æ•°ä¸€å®šè¦æ»¡ã€‚å¦‚æœ‰ç”Ÿäº§åŠ›é€Ÿåº¦éœ€æ±‚ï¼Œæ— è„‘é€‰4090 48Gã€‚
  - AMD MI50 32Gä¸€ä»£ç¥žå¡ï¼Œåœ¨windowsä¸‹åªèƒ½ç”¨Vulkanè·‘ï¼Œåœ¨linuxä¸‹å¯ä»¥ç”¨ROCmï¼Œ70Bq4ç”Ÿæˆé€Ÿåº¦10tk/sï¼Œæ€§ä»·æ¯”éžå¸¸é«˜ï¼Œå¯æƒœè·‘ä¸äº†comfyUIï¼Œæƒ³è¦ç”»å›¾å¿…é¡»è‡ªå·±æ‰‹ç»„æ•£è£…webuiã€‚
  - SDXLæ¨¡åž‹å ç”¨æ˜¾å­˜ä¸å¤§ï¼Œä»ç„¶æ˜¯8GBå¤Ÿè·‘ã€‚ä½†æ˜¯åªèƒ½åœ¨Nå¡ä¸Šè·‘çš„å¥½ï¼ŒAå¡ä¼˜åŒ–å¾ˆå·®ã€‚
  - æ–‡ç”Ÿè§†é¢‘æ¨¡åž‹å ç”¨æ˜¾å­˜å·¨å¤§ï¼Œä¸€èˆ¬æ¶ˆè´¹çº§æ˜¾å¡åªèƒ½ç”Ÿæˆ480pæ¸…æ™°åº¦1åˆ†é’Ÿä»¥å†…æ—¶é•¿çš„è§†é¢‘ï¼Œ720påŠä»¥ä¸Šå¿…é¡»ç”¨å¤§äºŽ48Gæ˜¾å­˜çš„Nå¡ã€‚

- [å¤§èˆ¹é å²¸ï¼ŒAMD MI50 16/32Gæ˜¾å¡æ™šæ¥ä¸€æ­¥ - çŸ¥ä¹Ž](https://zhuanlan.zhihu.com/p/1896388031436530191)

- [MI50 32g æˆ‘è¯´è¿™ä¸ªå°±æ˜¯å² - çŸ¥ä¹Ž _202504](https://zhuanlan.zhihu.com/p/1893227599272067712)
- ä»·æ ¼æ˜¯720åŒ…åœ†ï¼ŒçŽ°åœ¨è¢«jsqç‚’ä½œè€é«˜äº†
- è¿™ä¸ªå¡åˆ·ä¸äº†biosï¼Œä¸å¯èƒ½ æ˜¾ç¤ºè¾“å‡º
- amdé€šç—…ï¼Œä½ æƒ³çŽ©aiç”Ÿæ€æ”¯æŒç¨€çƒ‚
- æ€»ç»“ï¼šé¸¡è‚‹ä¸­çš„é¸¡è‚‹ï¼Œä¸å¦‚mi50ï¼Œ2080ti 22g
- è²Œä¼¼åè½¬äº†ï¼Œè¿™ä¸ªå¡å¬è¯´èƒ½åˆ·biosæœ‰è§†é¢‘è¾“å‡ºï¼Œè¿™ä¸ªç‰¹æ€§å¯¼è‡´ä»–å¯èƒ½ä¸ä¼šå¤ªfwï¼Œä½†æ˜¯æˆ‘è§‰å¾—32gçš„æ˜¾å­˜è¿˜æ˜¯å¤ªå¤§äº†æ²¡å¿…è¦ï¼Œä½œä¸ºä½Žå»‰ç®—åŠ›å¡æ¥è¯´ç¡®å®žè¿˜å¯ä»¥
  - 2080Ti 22gåœ¨å‰é¢é¡¶ç€å‘¢ã€‚GCNæž¶æž„çŽ©æ¸¸æˆçœŸçš„ä¸é”™ä½†è®¡ç®—æ€§èƒ½å¤ªä½Žï¼Œå³ä¾¿ä¸è€ƒè™‘åŠŸè€—æ•£çƒ­å™ªéŸ³ï¼ŒçŽ©æ¸¸æˆ16Gç‰ˆå¤Ÿå¤Ÿçš„

- å¦‚æžœç”Ÿæ€å¥½çš„è¯ 32g æ˜¾å­˜æ€Žä¹ˆå¯èƒ½æ‰ä¸åˆ°ä¸€åƒï¼Œ2080 ti 22g çŽ°åœ¨éƒ½è¦å¿«ä¸‰åƒäº†ã€‚ä¸€å¼  2080 ti 22gèƒ½ä¹°ä¸‰å¼  mi 50 32gã€‚

- ä½ å¿˜äº†æä¸€ä¸ªå¼±ç‚¹ï¼Œ300ç“¦çš„åŠŸè€—ï¼Œ100ç“¦çš„æ€§èƒ½
  - å€’ä¸åªæ˜¯ç”µè´¹çš„é—®é¢˜ï¼Œè¿™æ ·ç”µæºæ•£çƒ­å™ªéŸ³éƒ½ä¼šå¢žåŠ ï¼Œå¤ªéº»çƒ¦äº†

- ROCmçš„æ”¯æŒè¯´ä¸å®šå•¥æ—¶å€™å°±æ²¡äº†ï¼Œåˆ°æ—¶å€™å¹²çžªçœ¼

- æˆ‘çš„ç»“è®ºæ˜¯ç›®å‰å•å¡è¿è¡Œ gemma3 27B æˆ–è€… qwq 32Bï¼ŒMi 50 32G æ˜¾å¡å°±æ˜¯ç­”æ¡ˆã€‚1000 å…ƒæ˜¾å¡å¸¦æ¥ 20tokens/sï¼Œè¿˜æœ‰è°ï¼Ÿ
  - æŒ‰ AMD å®˜æ–¹æ•™ç¨‹å®‰è£…ä¸€ä¸‹ rocm å’Œé©±åŠ¨ï¼Œrocm ç‰ˆæœ¬ 6.3.3 å·²ç»éªŒè¯ï¼Œ ä¸€å®šæ˜¯å¯ä»¥çš„ã€‚
  - æŒ‰ ollama å®˜æ–¹æ•™ç¨‹ï¼Œæ‰‹åŠ¨å®‰è£… ollama å’Œ ollama-rocmã€‚
- ç”¨LMStudioçš„VulkanåŽç«¯å³å¯ï¼Œå…æŠ˜è…¾ROCmï¼ŒQwen3å’ŒGemma3éƒ½èƒ½è·‘ï¼Œé€Ÿåº¦æ¯”ROCmæ‰“ä¸ƒæŠ˜

- çŽ°åœ¨ktransformeræ”¯æŒamdæ˜¾å¡äº†ï¼Œå¼„ä¸ª512çš„ddr4å†…å­˜+å››å¼ MI50åº”è¯¥å¯ä»¥è·‘é€šDeepseek671bï¼Œç­‰ä¸€æ‰‹æœ€å¼ºæ€§ä»·æ¯”çš„Deepseekæ»¡è¡€ç‰ˆæ–¹æ¡ˆï¼Œå¸Œæœ›å¤§ä½¬å¯ä»¥è¯•è¯•

- 32Gçš„ï¼ŒåŒå¡å¯ä»¥è¿è¡Œ70Bæ¨¡åž‹ï¼Œ6-8tokens/Sï¼ŒåŸºæœ¬ä¸Šå±žäºŽå¯ä»¥ç”¨çš„èŒƒç•´äº†ï¼Œå¦‚æžœæ˜¯VLLMä¼°è®¡è¿˜èƒ½æ›´å¿«ï¼Œæˆ‘ç”¨çš„ollamaï¼Œå°±æ˜¯æ•£çƒ­è¦æžå¥½ï¼Œæˆ‘é‡Œé¢æ’æ¶¡è½®ï¼Œå¤–é¢é£Žæ‰‡å¸ï¼Œå‹‰å¼ºå¯ä»¥æŽ§åˆ¶

- æˆ‘è§‰å¾—å…¶å®žè›®å¥½çš„, å¤§å®¹é‡å¹¶ä¸”å¤§å¸¦å®½çš„æ˜¾å­˜, å¹¶ä¸”è¿˜æœ‰æœåŠ¡å™¨çš„ç¨³å®šæ€§, è¿™ä¸ªå¡çš„32 64ç®—åŠ›é«˜çš„å¤¸å¼ , å’ŒV100ä¸€æ ·, ä½œä¸ºä¸€å¼ ä¸“ä¸šå¡æ˜¯ç›¸å½“å¤Ÿç”¨çš„

- ## [32GB Mi50's were getting so expensive that I ended up buying a 32GB w6800 for about the same price instead : r/LocalLLaMA _202512](https://www.reddit.com/r/LocalLLaMA/comments/1pob44f/32gb_mi50s_were_getting_so_expensive_that_i_ended/)
  - Much better prompt-processing than the Vega iGPU's
  - 512GB/s vs 1TB/s memory bandwidth on the Mi50. Per benchmarks the mi50 doesn't actually get 2x performance on token-gen, but it's definitely something. If TG is your highest priority this is reason to consider the Vega cards
- What is the performance difference? Mi50 vs 6800. Mi50 is not very useful, outside of text inferencing, which is does great. RDNA actually has compute capability, and is supported going forward CDNA looks more and more like RDNA5 or 6.
- the w6800 does pretty good. Its much faster in prompt processing. 6800 has more compute and modern design supported by amd, and works in windows without hacks. Its the much better generalist card.
- where?
  - eBay. Follow a bunch of the bigger hardware reseller accounts and you'll eventually find short-lived deals on workstation cards.

- ## [NVLINK port support for RTX 3090 Ti, RTX 4080/4090 - Gaming and Visualization Technologies / Raytracing - NVIDIA Developer Forums _202210](https://forums.developer.nvidia.com/t/nvlink-port-support-for-rtx-3090-ti-rtx-4080-4090/231140)
- I just checked RTX 3090 Ti, that also does not have NVlink port. Am I right?
  - Yes, still there is no support but data transmission over PCIe board

- Until NVIDIA thinks about bringing NVlink bridge back, RTX 3090 is the last gpu of this tech.

- ## [3090 and 3090ti sli/nvlink : r/nvidia _202203](https://www.reddit.com/r/nvidia/comments/tslbxy/3090_and_3090ti_slinvlink/)
- Nope, SLI/ NVLink needs the exact same card to be paired with in order for it to work and pool the memory. I meant to say that you need the exact same series of card, cant mix and match a 3090 with a 3090ti. But yeah it doesnt matter which brand of a particular series you get. 

  - ## [AMD MI50 32GB better buy than MI100? : r/LocalLLaMA _202510](https://www.reddit.com/r/LocalLLaMA/comments/1o2x0bv/amd_mi50_32gb_better_buy_than_mi100/)
  - While it's officially dropped from ROCm 7, we can still get it to work if we copy some files manually.. obviously this will sooner or later stop working but then we'll have Vulkan.. which (with llama.cpp at least) seems to be almost at a performance-parity with ROCm (or faster?).
- Mi100 is still too expensive. I thought they all have vulkan support.

- As Mi50 owner, I would say this: ROCm is a pain in the ass. I see no reasons to buy better AMD cards cause you'll will constantly search for solutions for some software bugs. Vulcan won't save you on Mi50, as performance is equal or worse - vulcan seem do be not as optimized for that chip. With Mi100, you'll be in ever rpugher shape because this card is not popular amongst the enthusiasts, so nobody will optimize the software for it. Given that Mi50 33GB costs $120, buying Mi100 over it is a useless waste of money; Mi100 should go down in price significantly before it becomes reasonable for a homelabber.

- ## [rtx 4090 vs rtx 5090 vs rtx 4090 48gb vram? : r/StableDiffusion _202505](https://www.reddit.com/r/StableDiffusion/comments/1km4snx/rtx_4090_vs_rtx_5090_vs_rtx_4090_48gb_vram/)
- across various benchmarks rtx5090 is around 30% faster than rtx4090 in terms of "raw power". It also has native FP4 support, which can increase speed by ~x2 and reduce memory usage ~x2 for use-cases where fp4 models available.
  - So, choice depends really on your use-case.
  - If you run repetitive tasks and it fits into rtx5090 32GB VRAM, especially in fp4 format, then, this is the way.
  - as an all rounder and for different experiments, rtx4090 with 48GB can be more interesting.

- If you have a workflow with multiples models, vram is king as it allows you to avoid loading / unloading models. It's the slowest part of the process in generation. With enough vram, you can keep all models loaded, gaining a tremendous amount of time each generation.
  - Example: generating with model A which has very good prompt understanding but shit styles, glossy skin etc...then inpainting / upscaling with model B which has better style and so on.

- ## ðŸ†š [RTX 5090 vs RTX 4090 48GB (or RTX 6000) : r/LocalLLaMA _202508](https://www.reddit.com/r/LocalLLaMA/comments/1mo92ou/rtx_5090_vs_rtx_4090_48gb_or_rtx_6000/)
- The jump from 32GB to 48GB is a big jump, but the question is whether it's actually relevant today. 
  - With 32GB, you can run 24B, 27B, and 30B MoE at 8 bit and blazing fast speeds. You can run 32B at Q6, and even 49B at Q4. You can run basically any diffusion model as fast as possible with no limits at 8 bit.
  - 48GB lets you run the same models with higher context length, or lets you run 70B at Q4KM. The problem with this however, is that the 70B class of models has been stagnant for a very long time, so it's questionable if there's actually any benefit of running models in that size class right now. Any model larger than that is generally an MoE and will need partial offloading to RAM anyway. For example, if running GLM Air 106B, there's not going to be a massive speed difference between 32-48GB, because the bottleneck is the RAM.
  - The RTX 6000 Pro 96GB is an amazing card, but it generally has the same problem as the 48GB. With 96GB, that opens up the path for 70B and 100B, but not really any larger. You still won't be able to run 200B+ without partial offloading, which means that again, RAM is the bottleneck.

- One question I have is the context length. Using this calculator, for a 32B model at Q8, I'd have less than 4K context even with the KV cache at Q8. So if I'm adding files of any significant length to the context, then that also skews for more VRAM? Or can the context also be offloaded to RAM?
  - Yes, context does take up VRAM, and VRAM consumption scales linearly in proportion to context length. The exact amount of VRAM for a certain amount of context varies based on the size of the model, and architectural choices like Sliding Window Attention and Grouped Query Attention. Hence, the exact memory usage footprint is unique to the exact model, so that website is likely not perfectly accurate. That said, the context length takes up VRAM whether you use it or not, and does not increase automatically if you exceed it.
  - You can offload context to RAM, but that will cause a massive slowdown overall, and I can't really recommend it except for very specific use cases.

- If you're running multiple AI applications simultaneously, then yeah probably.

- FLUX for image generation needs something like 12GB.
  - WAN2.2 for video generation can be ran on as little as 8GB.
  - Qwen3-30B at Q4 requires 18.6GB, the Q8 is 36GB.
  - Blender for 3D assets recommends >8GB.
  - Photoshop recommends >4GB.

- ## [å•å¡åŒèŠ¯48GB é“­ç‘„Arc Pro B60 Dual Turboä¸“ä¸šå¡è§„æ ¼è¯¦è§£ - çŸ¥ä¹Ž _202505](https://zhuanlan.zhihu.com/p/1908505488590636946)
- ç¬¬äºŒä»£é”ç‚«Proä¸“ä¸šå¡ï¼ŒåŒæ ·åŸºäºŽâ€œBattleMageæˆ˜æ–—æ³•å¸ˆâ€æž¶æž„ï¼Œæœ‰ä¸¤æ¬¾äº§å“
  - Pro B50 16GBï¼Œ16ç»„Xeæ ¸å¿ƒï¼Œ2048spï¼Œ128bitæ˜¾å­˜å¸¦å®½ï¼ŒTBPæ•´å¡åŠŸè€—70w
  - Pro B60 24GBï¼Œ20ç»„Xeæ ¸å¿ƒï¼Œ2560spï¼Œ192bitæ˜¾å­˜å¸¦å®½ï¼ŒTBPæ•´å¡åŠŸè€—120-200w

- B580 24GBçš„ä¼ é—»å·²ä¹…ï¼Œä¸ç®—æ–°é²œï¼›æœ€å‡ºäººæ„æ–™çš„æ˜¯é“­ç‘„ï¼Œæ‹¿å‡ºæ¥çš„Pro B60äº§å“æ˜¯å•å¡åŒèŠ¯
  - åŒDP 2.1 + åŒHDMI 2.1aæ»¡è¡€è¾“å‡ºï¼Œå‡å¯æ”¯æŒ8K 60hzæˆ–4K 240hzï¼›ç”±ä¸Šè‡³ä¸‹ï¼Œåˆ†å±žäºŽä¸¤ä¸ªä¸åŒçš„GPU
  - è¿™å¼ æ˜¾å¡å¹¶æœªé›†æˆPCIeæ¡¥æŽ¥èŠ¯ç‰‡ï¼ŒPCIe Gen5 x8 + PCIe Gen5 x8ï¼Œéœ€è¦ä¸»æ¿æœ¬èº«æ”¯æŒPCIe x16é€šé“æ‹†åˆ†ã€‚
  - æ‰€ä»¥ç”µè„‘è®¾å¤‡ç®¡ç†å™¨å†…æ˜¾ç¤ºï¼Œåº”è¯¥æ˜¾ç¤ºä¸ºä¸¤å¼ Pro B60 24GBï¼Œè€Œéžå•å¼ Pro B60 48GBï¼Œåªæœ‰é€šè¿‡ç›¸åº”ç¨‹åºï¼Œæ‰èƒ½å®žçŽ°GPUã€æ˜¾å­˜ç»Ÿä¸€è°ƒç”¨ï¼Œæ–™æƒ³ä¸ä¼šæœ‰é©±åŠ¨ç¨‹åºå±‚é¢çš„ç‰¹æ®Šæ”¯æŒï¼Œå’Œå…¶ä»–å“ç‰Œçš„å•å¡å•èŠ¯æ— å¼‚ã€‚

- è¿™ä¹ˆè¯´å°±æ˜¯ä¸¤ä¸ªæ˜¾å¡ï¼Œæ’åœ¨ä¸€ä¸ªæ’æ§½ï¼Œå¹¶ä¸”ä¸¤ä¸ªå¡éƒ½æ˜¯pcie5.08 è¿™æ ·æ¯ä¸ªå¡çš„å¸¦å®½éƒ½ç æŽ‰äº†pcie 5.0 *16 çš„ä¸€åŠã€‚ è¿™ç§ä¸œè¥¿æœ‰é¬¼ç”¨å•Šã€‚è¿˜ä¸å¦‚æ’ä¸¤ä¸ªæ˜¾å¡
  - 1ï¼ŒçŽ°åœ¨çš„GPUæ€§èƒ½è·‘ä¸æ»¡å¸¦å®½ï¼ŒåŒ…æ‹¬5090ç”¨PCIE x8éƒ½æ²¡é—®é¢˜ï¼›
  - 2ï¼ŒAIæ¨¡åž‹æŽ¨ç†å…¶å®žå¯¹GPUæ€§èƒ½è¦æ±‚ä¸é«˜ï¼Œä¸»è¦æ˜¯å¡æ˜¾å­˜ã€‚
  - 3ï¼ŒB580åŽŸç”ŸGen4 x8ï¼ŒB60å‡åˆ°Gen5 x8ï¼Œä¸¤GPUé›†æˆåˆ°ä¸€å—å„¿å¹¶æ²¡é˜‰å‰²å¸¦å®½ã€‚

- åŽç»­æ‰€æœ‰çš„é”ç‚«ä¸­é«˜ç«¯å®¶ç”¨æ˜¾å¡éƒ½ä¼šå¤åˆ»ï¼ŒQ3å‘å¸ƒçš„B770 16GBå½“ç„¶ä¹Ÿä¼šæœ‰ç›¸åº”çš„32GBä¸“ä¸šå¡ï¼›è¿žAMDä¹Ÿè¡¨ç¤ºä¼šè·Ÿè¿›äº§å“ã€‚

- ç‰™è†è¦æ˜¯æœ‰ç±»ä¼¼nvlinkçš„ä¸œè¥¿é‚£ä»·å€¼è¿˜èƒ½ä¸Šå‡ï¼Œæ¯•ç«Ÿç”­ç®¡è®­ç»ƒè¿˜æ˜¯æŽ¨ç†ï¼Œç“¶é¢ˆéƒ½åœ¨è¿™ä¸ªpcie 5.0x16çš„64GB/s ä¸Šã€‚

- 48Gæ˜¾å­˜çŽ©SDç”»å›¾ä¸å¾—çˆ½æ­»ã€‚è¯è¯´çŽ°åœ¨SDå¯¹intelçš„æ”¯æŒå’‹æ ·äº†ï¼Ÿèƒ½çŽ©ä¸ï¼Ÿ
  - ä¸æ€Žä¹ˆè¡Œï¼Œåªèƒ½pf16å¦åˆ™åŠ loraå°±ä¼šé»‘å›¾ï¼Œè®­ç»ƒç›®å‰æˆ‘è¿˜æ²¡è·‘é€šè¿‡ã€‚è€Œä¸”åŒèŠ¯å¡å®žé™…æ˜¯ä¸¤å¼ å¡ï¼Œå¸¸è§çš„éƒ¨ç½²æ¡†æž¶comfyUIä¸æ”¯æŒå¤šå¡

- ## [æ˜¾å¡æ—¥æŠ¥10æœˆ8æ—¥ï½œç¬”ç”µRTX5090æ˜¾å­˜å®¹é‡24Gï¼Ÿ - çŸ¥ä¹Ž _202410](https://zhuanlan.zhihu.com/p/853223258)

- æ•´ç†ä¸‹ç¬”è®°æœ¬RTX5090çš„å¯èƒ½å‚æ•°ï¼Œå¯ä»¥çœ‹åˆ°ï¼Œå’Œå°å¼æœºçš„RTX5090å·®è·è¿˜æ˜¯æ¯”è¾ƒè¿œçš„ï¼Œè¿žå°å¼æœºæ˜¾å¡ä¸€åŠçš„è§„æ ¼éƒ½æ²¡æœ‰ï¼Œå¯èƒ½æ˜¯æœ‰å²ä»¥æ¥ç¬”è®°æœ¬å’Œå°å¼æœºå·®è·æœ€å¤§çš„ä¸€å¼ æ——èˆ°æ˜¾å¡
  - æ­¤å¤–ï¼Œç¬”è®°æœ¬RTX5090ç›¸æ¯”äºŽä¸Šä»£ç¬”è®°æœ¬RTX4090è¿›æ­¥ä¹Ÿä¸å¤§ï¼Œæœ€å¤§çš„è¿›æ­¥å¯èƒ½å°±æ˜¯æ¢äº†é•å…‰GDDR7æ˜¾å­˜ï¼Œæ˜¾å­˜å¸¦å®½æ˜Žæ˜¾æå‡

- CPUèƒ½åŠ ä¸ª12400ä¸å¸¦Kä¸ï¼Ÿ
  - å·²ç»ä¸å¸¦Käº†

- [ç¬”è®°æœ¬ç”µè„‘5090å’Œ5080æ¸¸æˆå·®è·è¾ƒå°ï½œæ˜¾å¡æ—¥æŠ¥4æœˆ3æ—¥ - çŸ¥ä¹Ž](https://zhuanlan.zhihu.com/p/1890877968840119676)
  - æ ¹æ®VideoCardZæŠ¥é“ï¼Œæœ€è¿‘è‘—åç¡¬ä»¶åª’ä½“Notebook Checkæµ‹è¯•äº†ç›¸åŒé…ç½®çš„RTX5090ç¬”è®°æœ¬å’ŒRTX5080ç¬”è®°æœ¬ï¼Œè¿™ä¸¤å°ç¬”è®°æœ¬ç”¨äº†ç›¸åŒçš„æ¨¡å…·ï¼Œæ˜¾å¡åŠŸè€—ä¸Šé™éƒ½æ˜¯175ç“¦ï¼Œéƒ½æ­é…é”é¾™9955HX CPUï¼Œæ®è¯´è¿™æ¬¾XMGæ˜¯æœºæ¢°é©å‘½çš„æµ·å¤–è´´ç‰ŒåŽ‚ã€‚
  - åœ¨ã€Šèµ›åšæœ‹å…‹2077ã€‹ä¸­ï¼Œ4Kåˆ†è¾¨çŽ‡ä¸‹ä¸¤æ¬¾ç¬”è®°æœ¬çš„å¹³å‡å¸§çŽ‡å·®è·ä»…ä¸º12%ï¼Œè¿œè¿œå°äºŽä¸¤è€…çš„ä»·æ ¼å·®è·
  - æ ¹æ®VideoCardZç»Ÿè®¡ï¼Œç›®å‰åŒ—ç¾Žå¸‚é¢ä¸Šæœ€ä¾¿å®œçš„RTX5090ç¬”è®°æœ¬æ¯”æœ€ä¾¿å®œçš„RTX5080ç¬”è®°æœ¬è¿˜è´µäº†72%ï¼Œæ‰€ä»¥åœ¨æ¸¸æˆå·®è·è¿™ä¹ˆå°çš„æƒ…å†µä¸‹ï¼Œæ¯«æ— ç–‘é—®RTX5080ç¬”è®°æœ¬æ›´å€¼å¾—å…¥æ‰‹ã€‚
- å¤š8gæ˜¾å­˜åˆ©å¥½ç”Ÿäº§åŠ›ï¼Œæ¸¸æˆæ€§èƒ½çš„è¯åŠŸçŽ‡ç»™ä¸è¶³çš„æƒ…å†µä¹Ÿä¸å¤§å¥½æå‡

- ## [å½“å‰4090ç¬”è®°æœ¬æ˜¾å­˜ä¸ºä»€ä¹ˆæ˜¯16gï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/599743802)
- ç§»åŠ¨ç‰ˆ4090çš„æœ¬è´¨: ç”¨äº†æ¡Œé¢4090çš„åå­—ï¼Œä½¿ç”¨äº†æ¡Œé¢4080çš„è§„æ ¼ï¼Œè·‘å‡ºäº†æ¡Œé¢4070 Tiçš„æ€§èƒ½

- ç§»åŠ¨ç‰ˆçš„4090ç¡¬ä»¶å‚æ•°åŸºæœ¬ä¸Šå°±æ˜¯å°å¼æœº4080
  - å°å¼æœºçš„4080æœ€é«˜åŠŸè€—åœ¨400wå·¦å³ï¼ˆä¸åŒå“ç‰Œåž‹å·ç•¥æœ‰å·®å¼‚ï¼‰ï¼Œç§»åŠ¨ç‰ˆçš„4090æœ€é«˜åŠŸè€—é™åˆ¶åœ¨175wå·¦å³ï¼ˆä¸åŒæ•£çƒ­è§„æ¨¡ç¬”è®°æœ¬å¯èƒ½ç•¥æœ‰å·®å¼‚ï¼‰

- 256Bitçš„æ˜¾å­˜ä½å®½å’‹ä¸Š24GBï¼Ÿ

- ## [ç¬”è®°æœ¬ç«¯RTX4090å’ŒRTX4080å·®è·åˆ°åº•æœ‰å¤šå¤§ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/581865855)
- 2024å¹´8æœˆæ›´æ–°ï¼Œä»¥åŽç¡•ROGæžªç¥ž8 è¶…ç«žç‰ˆç³»åˆ—ä½œä¸ºå‚è€ƒ
  - ä»Žå„é¡¹è·‘åˆ†ä¸­å¯ä»¥çœ‹åˆ°RTX4090ç›¸æ¯”RTX4080ï¼Œé«˜å‡º10-16%
  - RTX 4090 Laptopæ‹¥æœ‰å®Œæ•´çš„256ä½å¸¦å®½ï¼ŒRTX 4080 Laptopå…¶æ˜¾å­˜ä½å®½é™ä½Žåˆ°192

- ## [ç¬”è®°æœ¬çš„4090æ˜¾å¡ç›¸å½“äºŽå°å¼æœºçš„ä»€ä¹ˆæ˜¾å¡ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/594215351)
- è¯¥æ˜¾å¡ç”¨äº†å°å¼æœºRTX 4090çš„åå­—ï¼Œç¡¬ä»¶è§„æ ¼ä¸Šå’Œå°å¼æœºRTX 4080ç›¸ä¼¼ï¼Œæ€§èƒ½ä¸Šå’Œå°å¼æœºRTX 4070 TIç›¸è¿‘ã€‚
  - ç¡¬ä»¶è§„æ ¼ä¸Šï¼Œç¬”è®°æœ¬RTX 4090 Mobileä½¿ç”¨AD103æ ¸å¿ƒï¼Œé‡‡ç”¨å°ç§¯ç”µN4åˆ¶ç¨‹å·¥è‰ºï¼Œæ­è½½9728ä¸ªCUDAå•å…ƒï¼Œ16 GB GDDR6æ˜¾å­˜ï¼Œæ˜¾å­˜ä½å®½ä¸º256 bitï¼›
  - åŒæ ·çš„ï¼Œå°å¼æœºRTX 4080ä¹Ÿä½¿ç”¨AD103æ ¸å¿ƒï¼Œé‡‡ç”¨å°ç§¯ç”µN4åˆ¶ç¨‹å·¥è‰ºï¼Œæ­è½½9728ä¸ªCUDAå•å…ƒï¼Œ16 GB GDDR6Xæ˜¾å­˜ï¼Œæ˜¾å­˜ä½å®½ä¸º256 bitã€‚ä¸Žç¬”è®°æœ¬RTX 4090 Mobileåœ¨ç¡¬ä»¶è§„æ ¼ä¸Šä»£çš„åŒºåˆ«å°±æ˜¯ä¸€ä¸ªæ˜¯GDDR6ä¸€ä¸ªæ˜¯GDDR6Xæ˜¾å­˜ã€‚
- ä½†æ˜¯ï¼Œç¬”è®°æœ¬RTX 4090 Mobileçš„æ€§èƒ½è¿˜æ˜¯è¿œä¸å¦‚å°å¼æœºRTX 4080ï¼Œä¸»è¦å› ä¸ºåŠŸè€—å–‚ä¸é¥±ã€‚å°å¼æœºRTX 4080çš„TDPä¸º320 Wï¼Œå¯¹åº”çš„Boosté¢‘çŽ‡ä¸º2505 MHzï¼Œè€Œç¬”è®°æœ¬è¢«é”äº†åŠŸè€—å¢™ï¼Œä¸åŒåŠŸè€—é™åˆ¶ä¸‹RTX 4090çš„Boosté¢‘çŽ‡å¦‚ä¸‹ï¼š
  - RTX 4090 Mobile 120W = 1335-1695 MHz
  - RTX 4090 Mobile 130W = 1425-1815 MHz
  - RTX 4090 Mobile 140W = 1500-1950 MHz
  - RTX 4090 Mobile 150W = 1620-2040 MHz
  - RTX 4090 Mobile 175W = 2040-2040 MHz
- å› æ­¤ï¼Œæœ€åŽæ»¡è¡€çš„RTX 4090å•ç²¾åº¦æµ®ç‚¹ç®—åŠ›å¤§æ¦‚æ˜¯39.69 TFLOPSçš„æ°´å¹³ï¼Œå’Œå°å¼æœºRTX 4070 TIçš„40.09 TFLOPSå·®ä¸å¤šï¼Œæœªæ¥è¦æ˜¯RTX 4090 Mobileè§£é”200 WåŠŸè€—å¢™å¯èƒ½æœ‰å¸Œæœ›è¶…è¿‡å°å¼æœºRTX 4070 TI

- ## [èŠ¯åŠ¨ç§‘æŠ€å‘å¸ƒã€Œé£ŽåŽ 3 å·ã€å…¨åŠŸèƒ½ GPUï¼Œè¯¥äº§å“éƒ½æœ‰å“ªäº›äº®çœ¼æ€§èƒ½ï¼Ÿ - çŸ¥ä¹Ž _20250923](https://www.zhihu.com/question/1953762444674565105)
  - èŠ¯åŠ¨ç§‘æŠ€â€œé£ŽåŽ 3 å·â€å…¨åŠŸèƒ½ GPU æ˜¨æ—¥åœ¨ç æµ·é¦™å±±ä¼šè®®ä¸­å¿ƒæ­£å¼å‘å¸ƒï¼Œå…¶é‡‡ç”¨å…¨å›½äº§åº•å±‚è®¾è®¡ï¼ŒåŒæ—¶æ‹¥æœ‰ AI æ™ºç®—ç®—åŠ›å’Œ 8K é‡åº¦æ¸²æŸ“ç®—åŠ›ï¼Œå…¼å®¹ DirectX12ã€Vulkan1.2 ç­‰å›¾å½¢æŽ¥å£ï¼Œå¹¶é€‚é…ç»Ÿä¿¡ã€Windows ç­‰ç³»ç»Ÿã€‚
  - èŠ¯åŠ¨ç§‘æŠ€â€œé£ŽåŽ 3 å·â€å…¨åŠŸèƒ½ GPU åœ¨è¡Œä¸šå†…çŽ‡å…ˆå®žçŽ°å›½äº§å¼€æº RISC-V CPU ä¸Ž CUDA å…¼å®¹ GPU çš„æ·±åº¦èžåˆï¼Œå¯ä¸€ç«™å¼è¦†ç›–å¤§æ¨¡åž‹è®­æŽ¨ã€åž‚ç±»å¤šæ¨¡æ€åº”ç”¨ã€ç§‘å­¦è®¡ç®—ä¸Žé‡åº¦å›¾å½¢æ¸²æŸ“
  - åœ¨ç”Ÿæ€æ–¹é¢ï¼Œâ€œé£ŽåŽ 3 å·â€åœ¨è½¯ä»¶ç«¯å…¼å®¹ PyTorchã€CUDAã€Tritonã€OpenCL ç­‰ä¸»æµ AI å’Œè®¡ç®—ç”Ÿæ€ã€å’Œ DirectXã€OpenGLã€VulKan ç­‰æ¸²æŸ“ç”Ÿæ€ï¼Œé€‚é…ç»Ÿä¿¡ã€éº’éºŸã€Windowsã€Android ç­‰æ“ä½œç³»ç»Ÿã€‚
  - åœ¨å¤§æ¨¡åž‹æ–¹é¢ï¼Œâ€œé£ŽåŽ 3 å·â€æ˜¯å›½å†…é¦–æ¬¾å•å¡é…å¤‡ 112GB + å¤§å®¹é‡é«˜å¸¦å®½æ˜¾å­˜å’Œè‡ªç ” IP çš„å…¨åŠŸèƒ½ GPUï¼Œçªç ´ç›®å‰å›½äº§ GPU æ˜¾å­˜å’Œå¤šå¡æ¬è¿çš„ä¸Šé™ï¼Œå•å¡å¯æ”¯æŒå¤šç”¨æˆ· 32B / 72B å¤§æ¨¡åž‹ï¼›å•æœºå…«å¡èƒ½ç›´é©± DeepSeek 671B / 685B æ»¡è¡€ç‰ˆå¤§æ¨¡åž‹ã€‚

- [GPU Fenghua No.3, 112GB HBM, DX12, Vulcan 1.2, Claims to Support CUDA : r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/comments/1noru3p/gpu_fenghua_no3_112gb_hbm_dx12_vulcan_12_claims/)

- ## [å¦‚ä½•ä½¿ç”¨intelçš„gpuå’Œnpuè·‘å¤§æ¨¡åž‹ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/5293002844)
- åŽ»ä¸‹è½½ollama intelç‰ˆï¼Œè¿è¡Œï¼Œç„¶åŽå°±èƒ½è°ƒç”¨æ ¸æ˜¾è·‘æ¨¡åž‹äº†ï¼Œä½†32gæœ¬å­æ ¸æ˜¾åªèƒ½è°ƒç”¨20G

- ç›®å‰æ¯”è¾ƒé€‚åˆåŠå°ç™½çš„åŠžæ³•ï¼Œå°±æ˜¯ä¸‹è½½intelçš„ollama portable zip
  - ä»¥ä¸Šè¿™ä¿©åº”è¯¥éƒ½æ˜¯åŸºäºŽllama.cppçš„syclåŽç«¯ä¼˜åŒ–çš„ã€‚
  - å…¶å®žåœ¨NPUæˆ–GPUä¸Šè¿è¡Œå¤§è¯­è¨€æ¨¡åž‹è¿˜å¯ä»¥ç”¨OpenVINOã€‚ä½†ä¸æ˜¯å¾ˆé€‚åˆå°ç™½ï¼ŒOpenVINOæ›´é€‚åˆæœ‰ä¸€å®šå¼€å‘èƒ½åŠ›çš„ç”¨æˆ·ã€‚

- ä½ éœ€è¦ç”¨openvinoï¼ŒæŽ¨ç†çš„æ—¶å€™æŒ‡å®šæŽ¨ç†çš„è®¾å¤‡npuï¼Œgpuè¿˜æ˜¯cpuï¼Œå°±å¯ä»¥æŠŠæŽ¨ç†è¿è¡Œåˆ°ä½ æƒ³è¦çš„è®¾å¤‡ä¸Šã€‚ä½ å¯ä»¥åˆ°openvinoçš„notebookæ‰¾åˆ°å¾ˆå¤šä¾‹å­ã€‚

- intelè‡ªå¸¦çš„gpuä¸æ˜¯æ™®é€šæ˜¾å¡ï¼Œä¸èƒ½ç”¨gpuè¿™ä¸ªé€‰é¡¹ï¼Œ

- ## [3090 ç›¸å½“äºŽ 40 ç³»çš„ä»€ä¹ˆæ˜¾å¡å‘¢ï¼Ÿè¿™æ¬¾äº§å“çš„ä¼˜ç¼ºç‚¹åˆ†åˆ«æ˜¯ä»€ä¹ˆå‘¢ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/681021828)
- 3090èµ„æ·±ç”¨æˆ·ï¼Œé¦–å‘è´­å…¥ä¸€ç›´ç”¨åˆ°4090é¦–å‘, 
  - 3090ç†è®ºè·‘åˆ†æ€§èƒ½ç­‰äºŽ4070tis superã€‚
  - ä½†æ˜¯3090æ˜¾å­˜æ›´å¤§ï¼Œåœ¨aiæ–¹é¢æ€§èƒ½æ›´å¼ºï¼Œå¯ä»¥è·‘ä¸€äº›é‡åŒ–å¤§æ¨¡åž‹ï¼Œ4090èƒ½è·‘çš„3090éƒ½èƒ½è·‘ã€‚
  - 3090çš„<èƒ½è€—æ¯”>æ¯”4090å·®å¾ˆå¤šï¼Œå› ä¸º3090æ˜¯ä¸‰æ˜Ÿ8nmå·¥è‰ºï¼Œç›¸å¯¹å°ç§¯ç”µ5nmå·®è·éžå¸¸å¤§ã€‚ç›¸åŒåŠŸè€—ä¸‹4090æ€§èƒ½è¶…3090 60%ã€‚
  - 3090åŠŸè€—ä¸Šé™éžå¸¸é«˜ï¼Œæœ€é«˜åŠŸè€—äº§å“ä¸ºevga 1000ç“¦æ°´å†·æ¬¾ï¼Œä»Ž400ç“¦åˆ°1000ç“¦æ€§èƒ½æå‡10%ã€‚ç”±æ­¤å¯è§èƒ½è€—æ¯”ä¹‹å·®ã€‚

- AIç®—åŠ›æ¥è¯´ï¼Œcudeç®—åŠ›è¡¨çŽ°ï¼Œè·ŸRTX4070å·®ä¸å¤šï¼›

- ## [3090 24gå’Œ3090ti 24gä»Žå“ªèƒ½ä¹°åˆ°æ–°çš„? - çŸ¥ä¹Ž](https://www.zhihu.com/question/585256727)
- 3090/tiåŸºæœ¬ä¸Šä¸ä¼šæœ‰æ–°çš„äº†ï¼Œtiè¿˜å¥½ç‚¹ï¼Œä½†æ˜¯è´§æœ¬æ¥ä¹Ÿä¸å¤šï¼Œæ ‡æ–°çš„åº—ä»·æ ¼éƒ½é«˜ï¼Œç”šè‡³é«˜è¿‡4080é’™ä¸­é’™
  - ä½ çš„æƒ…å†µï¼Œè¦ä¹ˆ4080ï¼Œè¦ä¹ˆ4090ï¼Œè¦ä¹ˆäºŒæ‰‹3090/tiå°†å°±ç‚¹ï¼Œ4070tiçš„å¸¦å®½å¤ªä½Žäº†ï¼Œæ˜¾å­˜12Gå…¶å®žä¹Ÿèƒ½ç”¨ã€‚
  - å…¶å®ž3070ã€3080/tiä¹Ÿéƒ½æ˜¯å¯ä»¥ç”Ÿäº§åŠ›ã€æ¸²æŸ“çš„ã€‚éžç‰¹æ®Šåœºæ™¯ä¸ä¼šéšéšä¾¿ä¾¿çˆ†æ˜¾å­˜çš„ã€‚åªæ˜¯4070tiçš„æ˜¾å­˜ä½Žã€å¸¦å®½ä½Žäº†ä¸è¯´ï¼Œcudaæ ¸å¿ƒè¾ƒ3090å°‘äº†30%

- ## [2x4090 vs 6000 ada vs L20 vs L40s: what is the bottleneck for llm inference/finetuning? : r/LocalLLaMA _202408](https://www.reddit.com/r/LocalLLaMA/comments/1exwc04/2x4090_vs_6000_ada_vs_l20_vs_l40s_what_is_the/)
- a 6000 > 4090, less power, no moving data between PCI bus/CPU/cache to GPUs. 1 48gb will often beat 2 24gb for fine tuning.

- The l40s is essentially the 4090 with more vram. It is exactly the same chip. Nvidia released the l40s because the 4090 chips were available and demand on H100 was too high / H100 production volume too low. The 4090 has transformer engine which boosts fp8 performance. If you want inference speed on fp8 and don't need advance nccl support I would go for the 4090s

- ## [ç½‘ä¸Šä¼ çš„æ²¸æ²¸æ‰¬æ‰¬çš„96GBæ˜¾å­˜çš„4090é­”æ”¹ç‰ˆæ˜¯çœŸå®žå­˜åœ¨çš„ä¹ˆï¼Ÿæ˜¯æ€Žä¹ˆåšåˆ°çš„å‘¢ï¼Œæœ‰äººç”¨è¿‡ä¹ˆï¼Ÿ - çŸ¥ä¹Ž _202502](https://www.zhihu.com/question/13164350111)
- å› ä¸ºæœ‰å…¨æ–°L20 48Gï¼ˆå¯è¿‘ä¼¼å½“ä½œ4090D 48Gï¼‰åœ¨2.5ä¸‡çš„ä»·ä½åŽ‹ç€ï¼Œå®žé™…ä¸ŠçŽ°åœ¨4090çš„ä»·æ ¼å·²ç»æ¶¨æ— å¯æ¶¨ã€‚
  - ðŸ‘€ L20ä¸æ”¯æŒnvlink

- ä»¥ä¸Šè¿™äº›ä¸œè¥¿ä½ éƒ½è§£å†³äº†ï¼Œé‚£ä½ å‡†å¤‡æ€Žä¹ˆè¿‡VBIOSæ£€æµ‹ï¼Ÿ

- ## [2wå·¦å³çš„é¢„ç®—ç‚¼ä¸¹ï¼Œ2å¼ 3090çŸ¿å¡è¿˜æ˜¯ä¸€å¼ 4090? - çŸ¥ä¹Ž](https://www.zhihu.com/question/592038342)
- ä¸¤å¹´å‰å¸®åŒå­¦è£…è¿‡åŒè·¯RTX 3090ç‚¼ä¸¹ç‚‰ï¼Œä¸ªäººå»ºè®®è¿˜æ˜¯ç”¨å•å¡RTX 4090ã€‚
  - åŒå¡RTX 3090çŸ¿æ¸£ä¸å®¹æ˜“å®‰è£…ï¼Œå¸‚é¢ä¸Šå¼€æ”¾å¼æ•£çƒ­çš„RTX 3090çš„åŽšåº¦æ™®éæŽ¥è¿‘3-slotï¼Œè‡³å°‘è¦é¢„ç•™1-slotçš„æ•£çƒ­ç©ºé—´ï¼Œä¹Ÿå°±æ˜¯è¯´æ¯å¼ æ˜¾å¡è¦å ç”¨4-slotï¼Œç›®å‰æ¶ˆè´¹çº§ä¸»æ¿å¸¸è§çš„PCIeåŒºåŸŸå®½åº¦æ˜¯7-slotï¼Œå®‰è£…ä¸¤å¼ RTX 3090æœ‰ç‚¹å›°éš¾ã€‚è€Œä¸”æ¡¥æŽ¥å™¨NVLink Bridgeçš„å¸¸è§è§„æ ¼æ˜¯2-slotæˆ–è€…3-slotï¼Œå’Œä¸Šé¢è¯´çš„4-slotå ç”¨ç©ºé—´æœ‰çŸ›ç›¾
  - æ‰€ä»¥ï¼Œè¦ç»„åŒå¡RTX 3090ä¼˜å…ˆè€ƒè™‘æ¶¡è½®ç‰ˆï¼Œä¸€èˆ¬åŽšåº¦åªæœ‰2-slotï¼Œä½“ç§¯æ›´å°ï¼Œä½†æ˜¯RTX 3090æ¶¡è½®ç‰ˆçŸ¿æ¸£çš„ä»·æ ¼æ¯”éžå…¬ç‰ˆè´µäº†1000å…ƒï¼Œå†åŠ ä¸ŠNVLink Bridgeçš„ä»·æ ¼ï¼Œå³ä¾¿ä½ æ¡çŸ¿æ¸£ï¼Œä¸¤å¼ æ¶¡è½®RTX 3090çš„æˆæœ¬ä¹Ÿè¶…è¿‡å•å¼ å…¨æ–°RTX 4090äº†ã€‚
  - å¦å¤–ï¼ŒåŒå¡RTX 3090çŸ¿æ¸£éœ€è¦çš„é¢å®šåŠŸçŽ‡æ›´å¤§ã€‚å•å¡RTX 4090çš„TDPæ˜¯450 Wï¼ŒåŒå¡RTX 3090çš„TDPæ˜¯700 Wï¼Œç”µæºæˆæœ¬ä¹Ÿæ˜¯è¦è€ƒè™‘çš„ï¼Œè€Œä¸”å¤§åŠŸçŽ‡ç”µæºæ»¡è½½çš„æ—¶å€™æŒºåµã€‚

- ä¸¤å¼ 3090çŸ¿å¡+nvlink (ç›¸å¯¹äºŽpcieï¼Œå¤§æ¨¡åž‹DP TP 2-3å€é€Ÿåº¦æå‡)
  - æ€§èƒ½å¯¹æ¯”ï¼ˆgpt2 1.3B 8batch 2TPï¼Œæµ‹è¯•çŽ¯å¢ƒalpa/jaxï¼‰
  - TPæ¨¡å¼ï¼šç»“è®ºå¸¦nvlinkåœ¨148ä¸ªall reduceçš„æ¡ä»¶ä¸‹ï¼Œå¯ä»¥æå‡200%çš„é€Ÿåº¦ 12.95s vs 38.53
  - DPæ¨¡å¼ï¼šç»“è®ºå¸¦nvlinkçš„æ¡ä»¶ä¸‹ï¼Œå¯ä»¥æå‡150%çš„é€Ÿåº¦ 12.03s vs 31.15s

- 2å¼ 3090è¦ç»„å»ºå¸¦nvlinkçš„å¹³å°æ¯”ä½ æƒ³åƒçš„è¿˜è¦éº»çƒ¦ï¼Œå’Œå•å¡4090æ¯”è¾ƒä¸€ä¸‹
  - ä¸»æ¿: åŒå¡3090éœ€è¦ä¸€ä¸ªè‡³å°‘atxçš„å¸¦åŒPCIEx16æ’æ§½çš„ä¸»æ¿ï¼Œè€Œä¸”ä¸¤ä¸ªæ˜¾å¡æ’æ§½è·ç¦»è¦æ˜¯æ ‡å‡†çš„3æ§½é—´è·æ‰è¡Œï¼Œè€Œæ˜¾å¡åŽ‚å•†ä¸ä¼šç»™ä½ è¯´è¿™äº›æ•°æ®å¾ˆéº»çƒ¦ï¼Œå¾ˆå®¹æ˜“ä¹°é”™ï¼Œ4090å°±ä¸€èˆ¬çš„matxå°±è¡Œï¼Œä¸»æ¿ä»·æ ¼å°±èƒ½ä¾¿å®œå‡ ç™¾
  - ç”µæº: åŒå¡3090ä¸€èˆ¬è¦ä¹°1400wå·¦å³çš„ç”µæºï¼Œ4090ä¸€èˆ¬850wå°±å¾ˆå¤Ÿäº†ï¼Œä»·æ ¼ä¼°è®¡å·®ä»·300åˆ°500å·¦å³
  - æ˜¾å¡: è¦ç»„åŒå¡è€ƒè™‘åˆ°nvlinkä¸€èˆ¬æœ€å¤§3æ§½ï¼Œåªèƒ½é€‰æ¶¡è½®ç‰ˆæˆ–æ°´å†·ç‰ˆï¼Œæ¯”ä¸€èˆ¬3é£Žæ‰‡é£Žå†·å•å¡è´µ2000ä»¥ä¸Š
  - æœºç®±: åŒå¡3090ä¸€èˆ¬è¦æ”¯æŒatxçš„å¤§æœºç®±æ‰èƒ½ä¿è¯æ‰‡çƒ­, 4090ä¸€èˆ¬çš„matxæœºç®±å°±è¡Œï¼Œå·®ä»·ä¸€èˆ¬ä¸ä¼šç‰¹åˆ«å¤§
- å¦å¤–nvlinkä¹Ÿè¦1500å·¦å³
  - ä»·æ ¼: å®žé™…ä¸Šè¦æ¯”å•å¡4090çš„ä»·æ ¼è´µå¤§æ¦‚4000ä»¥ä¸Š
  - åŠŸè€—: åŒå¡3090çƒ¤é¸¡åŠŸè€—ä¼°è®¡è¦è¶…è¿‡800wè¦è¿œè¿œå¤§äºŽå•å¡4090çš„450wï¼Œæ•´æœºåŒçƒ¤ä¼°è®¡è¦çªç ´1000w
  - è´¨ä¿: åŒå¡3090éƒ½æ˜¯çŸ¿å¡æ— è´¨ä¿ï¼Œèƒ½ç”¨å¤šä¹…çœ‹è„¸ï¼Œè€Œ4090å…¨æ–°å¸¦è´¨ä¿
  - ä¿å€¼:30ç³»é»˜è®¤çŸ¿ï¼Œ30ç³»å·²ç»è‡­å¤§è¡—äº†ï¼Œä»¥åŽå¦‚æžœç”¨ä¸ä¸Šäº†è¦å‡ºæŽ‰ï¼Œ30ç³»ä¸å¥½å‡ºæ‰‹ï¼Œè€Œ40ç³»åå£°å¥½è¦æ¯”30ç³»ä¿å€¼å¤šäº†

- ä¸¤å¼ 3090éƒ½æ²¡æœ‰ä¸€å¼ 4090è´µï¼Œä¸€å¼ 4090æ˜¯ä¸€å¼ 3090çš„ä¸‰å€æœ‰å¤šã€‚

- 4090æ²¡æœ‰nvlinkï¼Œå¤§æ˜¾å­˜è¿˜æ˜¯é€‰3090tiå¤šå¡

- æœ‰æ— nvlinkåˆ°åº•æœ‰å¤šå¤§åŒºåˆ«
  - æ¨¡åž‹å¤§å°ä¸è¶…è¿‡24g åŒºåˆ«ä¸å¤§ã€‚ 2å—4090ä¸€èˆ¬ç›¸å½“äºŽ2å€çš„batch size, Nvlinkè§£å†³çš„ä¸»è¦æ˜¯â€”â€”èƒ½ä¸èƒ½çš„é—®é¢˜ã€‚ æ¯”å¦‚æ¨¡åž‹å¤§å°è¶…24gæ—¶
- nvlinkåªæ˜¯å¢žå¤§å¸¦å®½ï¼Œå¹¶ä¸ä¼šå¢žå¤§æ˜¾å­˜ï¼Œå¦‚æžœä½ ä¸äººä¸ºæŠŠæ¨¡åž‹å†™åˆ°ä¸¤å¼ å¡ä¸Šï¼Œæ¯ä¸ªiterationä¸¤å¼ å¡å„è·‘ä¸ªçš„ï¼Œç„¶åŽæ¢¯åº¦å›žä¼ çš„æ—¶å€™ä¸¤å¼ å¡è¦åŒæ­¥æ¢¯åº¦ï¼Œæœ‰äº†nvlinkè¿™ä¸ªè¿‡ç¨‹ä¼šæ›´å¿«ã€‚å¦‚æžœ24gä¸å¤Ÿï¼Œä½ ä¸äººä¸ºå†™åˆ°ä¸¤å¼ å¡ä¸Šï¼Œä¸¤å¼ å¡ä¹Ÿè·‘ä¸äº†ã€‚

- 3090åªèƒ½åŒå¡ä¸‹nvlinkï¼Œæ²¡æœ‰nvlinkçš„å¡æˆ–è·¨ä¸¤ç»„ç”¨nvlinkè¿žæŽ¥çš„å¡ä¼šèµ°pcieåˆ°cpuè¿›è¡Œæ•°æ®äº¤äº’ã€‚ä½ ç”¨çš„pytorchä¼šç”¨ncclè‡ªåŠ¨é€‰æ‹©åˆé€‚çš„æ–¹å¼äº¤äº’ã€‚

- å…³äºŽâ€œ3090åªèƒ½åŒå¡ä¸‹nvlinkâ€ï¼Œè¿™ä¸ªèµ„æ–™æ‚¨æ˜¯ä»Žæ¥çœ‹åˆ°çš„ï¼Ÿ
  - å½“ç„¶æ‰€æœ‰PCIE GPUåº”è¯¥éƒ½å—è¿™ä¸ªé™åˆ¶ï¼Œå”¯ä¸€ä¾‹å¤–å¯èƒ½æ˜¯DGX stationä¸Šçš„å››å—A100
  - 3090åªæœ‰åŒå¡çš„bridge

- ## [NVIDIA Tesla V100 SXM2 - 2025å¹´AIæœ¬åœ°éƒ¨ç½²æ€§ä»·æ¯”ä¹‹çŽ‹ï¼åŒå¡V100ï¼32Gæ˜¾å­˜ï¼Œä½Žä»·é«˜èƒ½ï¼Œç¢¾åŽ‹2080Ti 22G - çŸ¥ä¹Ž](https://zhuanlan.zhihu.com/p/1927666998030078159)
- å¹´åˆ16GBæ˜¾å­˜çš„V100å”®ä»·1000å…ƒï¼Œå¦‚ä»Šå·²é™è‡³600å…ƒï¼Œè¿œè¶…Mai50æˆä¸ºæ€§ä»·æ¯”ä¹‹çŽ‹ã€‚å…¶ç®—åŠ›å¯ä¸Ž1500å…ƒå·¦å³çš„RTX 2080 Ti 22Gç›¸åª²ç¾Žã€‚
  - å”¯ä¸€çš„é—¨æ§›åœ¨äºŽå…¶æŽ¥å£è®¾è®¡ï¼šV100é‡‡ç”¨æœåŠ¡å™¨ä¸“ç”¨çš„SXM2æŽ¥å£ï¼Œè€Œéžå¸¸è§çš„PCIe x16é‡‘æ‰‹æŒ‡ã€‚SXM2æŽ¥å£ä¸€ä¾§ä¸ºPCIeï¼Œå¦ä¸€ä¾§ä¸ºNVLinkï¼Œæ”¯æŒå¤šå¡äº’è”ã€‚
  - é€šè¿‡200å…ƒå·¦å³çš„è½¬æŽ¥æ¿å’Œ80å…ƒçš„æ•£çƒ­å™¨æ”¹è£…ï¼Œä»…éœ€900å…ƒå³å¯èŽ·å¾—2080 Tiçº§åˆ«çš„æ€§èƒ½ã€‚
- å•å¼ V100æ˜¾å¡çš„æ˜¾å­˜ä¸º16GBï¼ŒåŒå¡é…ç½®å¯è¾¾32GBã€‚ç›®å‰æ¶ˆè´¹çº§æ˜¾å¡ä¸­ä»…æœ‰RTX 5090å…·å¤‡32GBæ˜¾å­˜ï¼Œä½†ä»·æ ¼é«˜è¾¾2ä¸‡å…ƒèµ·ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒåŒV100æ–¹æ¡ˆä»…éœ€2000ä½™å…ƒï¼Œä½¿å¾—22Gæ˜¾å­˜çš„2080Tiçž¬é—´å¤±åŽ»æ€§ä»·æ¯”ä¼˜åŠ¿ã€‚

- æµ‹è¯•å¹³å°é‡‡ç”¨åŽæ“ŽB650Mä¸»æ¿ï¼Œå› å…¶ä»…æœ‰ä¸€ä¸ªPCIeæ’æ§½ï¼Œéœ€åœ¨BIOSä¸­å¯ç”¨é€šé“æ‹†åˆ†åŠŸèƒ½ä»¥æ”¯æŒåŒæ˜¾å¡ã€‚å®‰è£…å®ŒæˆåŽï¼Œæˆ‘ä»¬å°†å¯¹åŒV100ç³»ç»Ÿè¿›è¡Œæ€§èƒ½æµ‹è¯•ã€‚
  - é€šè¿‡NVIDIA SMIå·¥å…·æ£€æµ‹NVLINKçŠ¶æ€ï¼Œå¯è§GPU0ä¸ŽGPU1çš„é“¾æŽ¥çŠ¶æ€å‡æ˜¾ç¤ºç›¸åŒå¸¦å®½å€¼ï¼Œè¡¨æ˜Žä¸¤ç‰‡GPUå·²æˆåŠŸäº’è”ä¸”NVLINKåŠŸèƒ½æ­£å¸¸å¯ç”¨ã€‚
  - åœ¨å‚æ•°ç›¸åŒçš„æƒ…å†µä¸‹ï¼Œ2080Tiçš„æ¯æ¬¡è¿­ä»£è€—æ—¶çº¦ä¸º2.17ç§’ï¼Œè€ŒV100çš„æ¯æ¬¡è¿­ä»£è€—æ—¶çº¦ä¸º1.39ç§’ã€‚

- V100ä¸æ”¯æŒflash- attentionã€bf16ã€awqã€sglangæ–°ç‰ˆæœ¬ä¹Ÿä¸æ”¯æŒv100äº†ï¼Œæ˜¾å¡å¤ªè€äº†ï¼Œæ–°çš„åŠ é€Ÿç­–ç•¥ç”¨ä¸äº†ï¼Œé€Ÿåº¦è¿˜ä¸å¦‚æ¶ˆè´¹å¡å‘¢ã€‚
  - å¯¹SDè·‘å›¾æ¥è¯´ï¼Œä¸æ”¯æŒint4ã€fp8ã€fp4ï¼Œä¸èƒ½ç”¨nanchakuåŠ é€Ÿã€‚SDä¹Ÿä¸èƒ½å¤šå¡æ˜¾å­˜å åŠ ã€‚

- æœ¬è´¨ä¸Šè¿˜æ˜¯å•å¡16Gï¼Œæ²¡ä»€ä¹ˆåµç”¨ï¼Œè€Œä¸”å¾ˆå¤šæŽ¨ç†ç‰¹æ€§ä¸æ”¯æŒï¼Œè¿œè¿œæ²¡æœ‰2080tiå¥½

- ## [ä¸»è¦åšç”Ÿæˆæ¨¡åž‹ï¼Œè‡ªç”¨æ·±åº¦å­¦ä¹ æœåŠ¡å™¨ä¹°åŒå¡3090è¿˜æ˜¯ä¹°å•å¡4090ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/9062530414)

- å¯¹äºŽä½Žç®—åŠ›åœºæ™¯ï¼Œæœ€å¤§çš„æ€§èƒ½ç“¶é¢ˆæ°¸è¿œæ˜¯æµ®ç‚¹æ€§èƒ½ï¼Œå› ä¸ºè¿™ä¼šå†³å®šä½ çš„è®­ç»ƒæ—¶é•¿ã€‚
  - RTX3090çš„æµ®ç‚¹æ€§èƒ½ï¼ˆFP32/FP16ï¼‰35.6TFLOPSï¼ŒRTX4090åˆ™é«˜è¾¾82.6TFLOPSï¼Œå‡ ä¹Žé«˜å‡ºäº†3090ä¸€å€ï¼Œæ˜¾å­˜å¸¦å®½ä¹Ÿç•¥é«˜ï¼ŒåŒæ—¶TensorCoreçš„ç‰ˆæœ¬ä¹Ÿæ›´æ–°æ”¯æŒæ›´å¤šæ•°æ®æ ¼å¼ã€‚
  - RTX3090çœ‹èµ·æ¥æœ‰NV LINKï¼Œä½†åªæ˜¯ä¸ªé˜‰å‰²ç‰ˆï¼Œç”¨æˆ·ç¡®å®žå¯ä»¥åœ¨ä»£ç ä¸­å°†æ•´ä¸ªæ¨¡åž‹åˆ†é…åœ¨ä¸¤å¼ å¡ä¸Šï¼ˆéœ€è¦å®Œå…¨æ‰‹åŠ¨å®žçŽ°ï¼‰ï¼Œä½†æ˜¯å…¶å¸¦å®½åªæœ‰112.5Gbpsï¼Œä¸åˆ°æ˜¾å­˜å¸¦å®½çš„1/8ï¼Œè®­ç»ƒæ—¶ä¼šå‡ºçŽ°ä¸¥é‡çš„æ€§èƒ½ç“¶é¢ˆã€‚ä¹°2å¼ RTX3090 24GBå¹¶ä½¿ç”¨NVLINKæ¡¥è¿žæŽ¥å¹¶ä¸æ„å‘³ç€ä½ èƒ½å°†å…¶å½“ä½œä¸€å¼ 48GBæ˜¾å­˜çš„å¡ä½¿ç”¨ã€‚
  - å¦å¤–RTX3090æ˜¯æŒ–çŸ¿é‡ç¾åŒºï¼Œç”šè‡³æ›¾ç»æœ‰ä¸€æ®µæ—¶é—´å•å¡æ—¥æ”¶å…¥èƒ½åˆ°120RMBï¼Œå¾ˆå®¹æ˜“ä¹°åˆ°çŸ¿å¡ã€‚

- åŒå¡ç®—åŠ›æ˜¯é€¼è¿‘å•å¡çš„ï¼Œè™½ç„¶æœ‰ä»£å·®ï¼Œç†Ÿæ‚‰åŒå¡åŽï¼Œå¯¹å¤šå¡ä¹Ÿæœ‰äº†ç»éªŒï¼Œå¾ˆå®¹æ˜“æ‰©å±•åˆ°å¤šæœºå¤šå¡ã€‚ç”Ÿæˆæ¨¡åž‹çš„è®­ç»ƒç¦»ä¸å¼€å¤šæœºå¤šå¡ã€‚

- 3090tiæ²¡æœ‰æ€§ä»·æ¯”ï¼ŒåŒå¡3090åŠ nvlinkä¹Ÿä¸é”™çš„è®°å¾—å†…å­˜é…å°½é‡å¤§ã€‚4090ä¸æ”¯æŒnvlinkçš„ï¼Œè®­ç»ƒä¸æŽ¨èã€‚

- 2080ti 22gbä¹Ÿæ˜¯é¦™çš„ä¸è¡Œã€‚è¿½æ±‚ä»·æ ¼ï¼Œå°±ä¹°4å¼ 2080ti 22gbçš„æ›´çˆ½ã€‚ä¸è¿‡ä¸æ”¯æŒflash attentionå’Œbf16æ•°æ®æ ¼å¼ã€‚

- å¦‚æžœæ˜¯è®­ç»ƒä¸ºä¸»ï¼Œæ¯«æ— ç–‘é—®é€‰3090x2ã€‚
  - å¦‚æžœæ˜¯æŽ¨ç†ä¸ºä¸»ï¼Œä¸”æ˜¾å­˜å ç”¨è¶…è¿‡24Gï¼Œé€‰3090x2ï¼›æ˜¾å­˜å ç”¨å°äºŽ24Gï¼Œé€‰4090ã€‚

- åŒå¡å§ï¼Œæ€Žä¹ˆä¹Ÿå¾—è®©è‡ªå·±çš„ä»£ç æ”¯æŒä¸€ä¸‹ddpï¼Œä¸ç„¶ä»¥åŽå¡å¤šäº†è¿˜å¾—é‡æ–°è¸©å‘ã€‚

- åŽ»å¹´æˆ‘ç»™æŸé«˜æ ¡å®žéªŒå®¤æ”’æœºé‚£ä¼šå„¿ï¼Œæ°å·§æŠŠä¸¤å¥—é…ç½®éƒ½æŠ˜è…¾è¿‡ã€‚
- å…ˆè¯´åŒ3090è¿™èŒ¬å„¿ï¼Œä¹çœ‹æ˜¾å­˜æ€¼åˆ°48GæŒºå”¬äººï¼Œä½†æ‚¨çŸ¥é“è·‘Stable Diffusionæ—¶æ˜¾å­˜å¸¦å®½è¢«PCIEé€šé“å¡è„–å­çš„æ»‹å‘³å—ï¼Ÿ
  - ä¸Šä¸ªæœˆæ‹¿åŒå¡è·‘1280x720å›¾ç”Ÿè§†é¢‘ï¼Œæ˜¾å­˜å€’æ˜¯å¯Œè£•å¾—èƒ½å…»é±¼ï¼Œå¯å®žé™…åžåé‡æ¯”å•å¡å°±å¤šå‡º23%ï¼ŒGPUåˆ©ç”¨çŽ‡æ›²çº¿è·Ÿè¿‡å±±è½¦ä¼¼çš„â€¦
- ä¸è¿‡æ‚¨è¦æ˜¯æžå¤§è¯­è¨€æ¨¡åž‹å¾®è°ƒï¼Œå•å¼ 4090çš„24Gç¡®å®žå®¹æ˜“æŠŠè£¤å­å¡åˆ°è„šè„–å­ã€‚å¯åˆ«å¬è®ºå›é‚£å¸®æ•²é”£è¾¹å„¿çš„çžŽå¿½æ‚ ï¼Œå®žæµ‹ç”¨QLoRAæŠ€æœ¯èƒ½æŠŠ70äº¿å‚æ•°æ¨¡åž‹åŽ‹è¿›18Gæ˜¾å­˜ï¼Œè¿™èŠ‚éª¨çœ¼å„¿ä¸Š4090çš„ç¬¬ä¸‰ä»£Tensor Coreç›´æŽ¥è®©è®­ç»ƒé€Ÿåº¦é£žèµ·ï½ž
- å‰äº›å¤©ç»™æŸç¾Žé™¢åŠ¨ç”»ç³»é‚£å¸®å“¥ä»¬è£…æœºå™¨ï¼Œä»–ä»¬æ‹¿åŒ3090è·‘æ¸²æŸ“ä»¥ä¸ºæ¡ç€å®ï¼Œç»“æžœç”µæºä¸‰å¤©ä¸¤å¤´è·³é—¸â€”â€”æ•´æœº850Wç”µæºæ»¡è½½æ—¶æ»‹å•¦ä½œå“çš„åŠ¨é™ï¼Œè·ŸäºŒè¸¢è„šåœ¨æœºç®±é‡Œå¼€partyä¼¼çš„
- è¦æ˜¯é“äº†å¿ƒçŽ©åˆ†å¸ƒå¼è®­ç»ƒä¸”é¢„ç®—ç»·å¾—ä½ç”µè´¹ï¼ŒåŒå¡èƒ½çœä¸‹17%çš„è¿­ä»£æ—¶é—´ï¼›å¯è¦æ˜¯å°±å›¾ä¸ªç—›å¿«è·‘å•å¡å¤§æ¨¡åž‹ï¼Œ4090é‚£9%çš„FP32æ€§èƒ½æå‡é…ä¸ŠDlss3æŠ€æœ¯ï¼Œæ¸²æŸ“è¾“å‡ºæ—¶ç»å¯¹èƒ½è®©æ‚¨ä½“éªŒä»€ä¹ˆå« åŽŸåœ°èµ·é£ž

- NVLinkæ¡¥æŽ¥å™¨å¯å®žçŽ°ç›¸é‚»ä¸¤å¼ 3090çš„å¹¶è”ï¼ŒåŒå‘å¸¦å®½æœ€é«˜600 Gbit/sï¼ˆçº¦75 GB/sï¼‰ï¼Œä½†ä»…æ”¯æŒä¸¤å¡é—´ç‚¹å¯¹ç‚¹é€šä¿¡ï¼Œæ— æ³•å®žçŽ°å¤šå¡å…¨äº’è”ï¼ˆå¦‚GPU0ä¸ŽGPU1äº’è”åŽï¼ŒGPU1ä¸ŽGPU2ä»éœ€é€šè¿‡PCIeé€šä¿¡ï¼‰ï¼›
  - å¯ä¹°ä¸“ç”¨NVLinkæ¡¥æŽ¥å™¨ï¼ˆå¦‚åŽç¡•ROG NVLink Bridgeï¼‰å¹¶ç¡®ä¿ä¸»æ¿æ”¯æŒï¼›åŒæ—¶éœ€åœ¨Linuxç³»ç»Ÿä¸­å¯ç”¨TCCæ¨¡å¼ï¼ˆå…³é—­æ˜¾ç¤ºè¾“å‡ºï¼‰ï¼Œå¹¶ä¾èµ–ç¬¬ä¸‰æ–¹æ˜¾å­˜ç®¡ç†å·¥å…·ï¼ˆå¦‚NVIDIA MPSï¼‰ã€‚

- ## [å·²æœ‰3090Tiä¸€å¼ ï¼Œå†å¢žåŠ ä¸€å¼ å¡ï¼Œæ˜¯é€‰æ‹©å¢žåŠ 3090Ti+NVLINKï¼Œè¿˜æ˜¯å¢žåŠ 4090ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/623563385)
- 3090.nvlink, æå‰å­¦ä¹ ä¸€ä¸‹åŒå¡æ€Žä¹ˆç”¨ï¼Œæœªæ¥å¤§é¡¹ç›®éƒ½æ˜¯å¤šå¡ï¼Œçº¯ç²¹çš„å•å¡åšä¸äº†ä»€ä¹ˆç‰¹åˆ«å¤§çš„é¡¹ç›®ï¼Œçºµä½¿H100ä¹Ÿæ˜¯å¤§æŠŠäººç”¨8å¡ã€‚

- ç‚¼ä¸¹æ˜¯è‡ªå¨±è‡ªä¹è¿˜æ˜¯å°†æ¥æƒ³æ‹¿æ¥è°‹ç”Ÿï¼Ÿè°‹ç”Ÿçš„è¯å¤§æ˜¾å­˜å¤šå¡ä»»åŠ¡ååŒæ˜¯å¿…ä¿®è¯¾ï¼Œä¸€å¼ å¡æ€Žä¹ˆå­¦ï¼Ÿ

- 3090Tiçš„Nvlinkå’Œä¸“ä¸šç‰ˆçš„ä¸ä¸€æ ·ï¼Œå¸¦å®½å‡åŠ, ä¹Ÿæ²¡æœ‰æ˜¾å­˜çœŸæ­£æ± åŒ–

- ## [4090ä¸æ”¯æŒnvlinkï¼Œåœ¨è®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡åž‹æ—¶å…·ä½“çš„è¡¨çŽ°æ˜¯ä»€ä¹ˆï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/603522002)
- æ²¡æœ‰[NVLink] åŠŸèƒ½åªæ˜¯ä¸èƒ½é€šè¿‡æ¡¥æŽ¥å™¨è¿›è¡Œä¸¤ä¸¤äº’è”(å³ä¸èƒ½é€šè¿‡NVLinkä¸¤ä¸¤è¿›è¡Œp2p)ï¼Œä½†æ˜¯å¯¹äºŽå¤šå¡å¹¶è¡Œè®­ç»ƒæ˜¯æ”¯æŒçš„ï¼Œå¯ä»¥é€šè¿‡device to host to deviceè¿™ç§èµ°[PCIeé“¾è·¯] è¿›è¡Œæ•°æ®å¹¶è¡Œå¤„ç†.
  - nvlinkæœ€é«˜å¯ä»¥åšåˆ°800GB/Sï¼ŒPCIEåªæœ‰128GB/S
- pcieæ…¢å¾ˆå¤šè€Œä¸”å—åˆ¶äºŽä¸»æ¿

- ## ðŸ‘· [4090 48Gæ¶¡è½®ç‰ˆæ·±åº¦ä½“éªŒ - çŸ¥ä¹Ž _202502](https://zhuanlan.zhihu.com/p/22691935175)
  - ComfyUIè·‘flux fp16æ¨¡åž‹ï¼Œå›¾åƒå®½é«˜1000*1000ï¼Œstep20ï¼Œè·‘å®Œ22ç§’å·¦å³ï¼Œæ˜¾å­˜å ç”¨36Gï¼Œå¤§æ˜¾å­˜å°±æ˜¯å¥½ã€‚

- èƒ½ä¸èƒ½æµ‹ä¸€ä¸‹ä¸ŽåŒ3090 NVlinkçš„å·®è·
  - çœ‹æ‹¼å‡ å—3090å§ï¼Œä½ è¦2å—è‚¯å®šæ¯”ä¸è¿‡4090 48Gï¼ŒNVLINkæ‹¼æ˜¾å¡è¿˜æ˜¯æœ‰æŸè€—çš„

- çŽ°åœ¨æœ‰4090 48gä¸‰é£Žæ‰‡ç‰ˆä¸åµäº†
- ä¸€ç›´æ­£å¸¸ç”¨ï¼Œå°±æ˜¯æ˜¾å¡æ¸©åº¦ä¸€ç›´ä¸Š90åº¦ï¼Œæš´åŠ›é£Žæ‰‡è½¬é€Ÿæ²¡æ³•è°ƒå°

- æ”¹å®Œè¿˜èƒ½æ‰“æ¸¸æˆå—
  - å¯ä»¥æ­£å¸¸æ‰“æ¸¸æˆ

- å“ªæœ‰é è°±é”€å”®æ¸ é“å•Šï¼Ÿ
  - æƒ³çŽ©é­”æ”¹ å“ªä¼šæœ‰å”®åŽå•Š ä¸éƒ½æ˜¯è‡ªå·±çŽ©å—

- æ€§ä»·æ¯”æœ€é«˜çš„æ˜¯2080ti 22gï¼Œä¸è¿‡è¦æ¢ç”µæº

- è¿™ç§å”®åŽæ€Žä¹ˆæžå‘¢
  - æˆ‘æ˜¯æ‹¿è‡ªå·±çš„4090åŽ»æ”¹çš„ï¼ŒèŠ±äº†5åƒ5ï¼Œ åº—å®¶è¯´æœ‰ä¸‰å¹´è´¨ä¿å“Ž

- bç«™ä¿®ç”µè„‘çš„å¼ å“¥èƒ½ä¿®ï¼Œåªè¦ä¸æ˜¯æ ¸å¿ƒåäº†éƒ½èƒ½ä¿®

- [é­”æ”¹çš„RTX 4090 48Gå¡å€¼å¾—é€‰å—ï¼Ÿ - çŸ¥ä¹Ž](https://zhuanlan.zhihu.com/p/1888965700464406937)
  - è¿™å¡æˆ‘ä¹°äº†ä¸€å¼ ç”¨äº†ä¸€ä¸ªæœˆäº†ï¼Œåˆ†äº†540gddr5å†…å­˜è·‘äº†æ»¡è¡€ç‰ˆq2åŠä¸ªæœˆäº†ï¼Œæ²¡å•¥é—®é¢˜ï¼ŒåŸºæœ¬åœ¨15åˆ°20tokens

- [æŠ€å˜‰RTX4090æ¶¡è½®å¡å¤ªåµæ€Žä¹ˆåŠžï¼Ÿæ”¹è¿™ä¸ªæ°´å†· - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/6713b9e70000000026037edd?xsec_token=AB3p2aSFwZpNJgLEWUwjbY4ZRQfalBGT1nX8ghdKLP2ls=&xsec_source=pc_search&source=unknown)
  - æ¶¡è½®å¡ï¼Œéƒ½æ”¾åœ¨æœåŠ¡å™¨é‡Œé¢ç”¨çš„ï¼Œå¦‚è¿‡ä½ æƒ³æ”¾åˆ°PCæœºç®±é‡Œé¢ä½¿ç”¨ï¼Œé‚£è¦åšçš„ç”Ÿç†å…‹æœé¦–å…ˆå°±æ˜¯å™ªéŸ³
- é‚£ä½ æŠŠè½¬é€Ÿè°ƒä½Žå‘—
  - æ¶¡è½®ç‰ˆæœ¬èº«æ•£çƒ­å°±ä¸å¦‚é£Žæ‰‡çš„ï¼Œè°ƒä½Žæœ‰é£Žé™©å•Š

- ## [ä¸å¡å€¼ä¸å€¼å¾—ä¹°? - çŸ¥ä¹Ž](https://www.zhihu.com/question/596939079)
- è¦çœ‹å…·ä½“åž‹å·ã€‚ ä¸¾ä¸ªä¾‹å­ï¼ŒRTX 40ç³»é¦–å‘RTX 4090ã€RTX 4080ã€RTX 4070 TIä¸‰æ¬¾åž‹å·ï¼Œæ•£çƒ­æ¨¡å…·éƒ½è¶…è§„æ ¼äº†ï¼Œå³ä¾¿æ˜¯ä¸ç‰ˆåž‹å·éƒ½ç”¨æ–™åè¶³ï¼Œæ‰€ä»¥ä¸€äºŒçº¿å“ç‰Œçš„ä¸å¡æ˜¯æœ€å€¼å¾—ä¹°çš„
  - ä½†æ˜¯ï¼Œä»ŽRTX 4070å¼€å§‹æƒ…å†µå‘ç”Ÿäº†å˜åŒ–ï¼Œâ€œRTX 40ç³»æ˜¾å¡æ•£çƒ­è¿‡å‰©â€çš„è§„å¾‹ä¹Ÿè¢«æ‰“ç ´äº†ã€‚å¸‚é¢ä¸Šçš„ä¸ç‰ˆRTX 4070æ™®éé‡‡ç”¨ä½Žå»‰çš„æ‚¬è‡‚å¼æ•£çƒ­æ–¹æ¡ˆï¼Œè¿™ç§æ•£çƒ­ä¸èƒ½å®Œå…¨è¦†ç›–ä¾›ç”µåŒºåŸŸï¼Œå®¹æ˜“å¯¼è‡´VRMçš„ä¸ªåˆ«åœ°æ–¹è¿‡çƒ­ã€‚

- å½“æ—¶åˆè¡·ä¹Ÿæ˜¯æƒ³çœ‹çœ‹ä¸ç‰ˆç©¶ç«Ÿå¤Ÿä¸å¤Ÿç”¨ï¼Œé«˜é˜¶ç‰ˆæœ¬æ‹¥æœ‰æ›´å¸…æ°”çš„å¤–è§‚ï¼ˆæè´¨ï¼‰ï¼Œæ›´å¥½çš„æ•£çƒ­ï¼ˆé£Žæ‰‡ã€çƒ­ç®¡çš„æ•°é‡ç­‰ï¼‰ã€æ›´å¥½çš„è¶…é¢‘æ€§èƒ½ï¼ˆbenchmarkå¯èƒ½è¿˜èƒ½çœ‹ï¼Œå…·ä½“åˆ°æ¸¸æˆå¸§æ•°åªèƒ½è¯´ï¼šä½ æ‡‚çš„ï¼‰ï¼Œä½†çœŸæ­£å½±å“æ˜¾å¡æ€§èƒ½çš„ï¼Œæ˜¯GPUå’Œæ˜¾å­˜ã€‚ä¸è¿‡ï¼Œå¦‚æžœé«˜é˜¶ç‰ˆæœ¬æº¢ä»·å¯ä»¥æŽ¥å—ï¼Œå¯ä»¥é€‰ï¼Œæ¯”å¦‚æ›´å¥½çš„æ•£çƒ­æ€§èƒ½å¸¦æ¥çš„æ˜¯æ¸©åº¦çš„é™ä½Žï¼Œæ¸©åº¦çš„é™ä½Žæ›´æœ‰åˆ©äºŽæ•´æœºçš„ç¨³å®šæ€§ã€‚

- å¾®æ˜Ÿä¹°ä¸‡å›¾å¸ˆã€‚çŽ°åœ¨ä¸‡å›¾å¸ˆæ¯”è¶…é¾™æ€§èƒ½ä½Žä¸åˆ°3%ä»·æ ¼æ•´æ•´å¤šä¸€åƒã€‚å¾®æ˜Ÿä¸‡å›¾å¸ˆå’Œ[å¾®æ˜Ÿè¶…é¾™] å·®è·å°±æ˜¯æ¸¸æˆæ»¡è½½æ¸©åº¦é«˜13â„ƒã€‚

- ä¸€å®šè¦ç›¸ä¿¡è€é»„å’Œè‹å¦ˆçš„åˆ€æ³•ï¼Œ4070ä½ å°±æ˜¯èŠ¯ç‰‡ä½“è´¨å†å¥½ã€ä¾›ç”µå†å¼ºã€æ•£çƒ­å†ç¨³ï¼Œç»™å®ƒè¶…å†’çƒŸäº†æœ€å¤šèƒ½åˆšåˆšå¥½èµ¶ä¸Šé»˜é¢‘çš„4070Ti
  - æ˜¾å¡æœ€é‡è¦çš„æ˜¯é‡Œé¢çš„PCBé‚£ä¸€å°éƒ¨åˆ†ï¼Œæ ¸å¿ƒã€æ˜¾å­˜ç­‰ç­‰ï¼Œå¤–é¢é‚£3På¤§ç©ºè°ƒä¹‹ç±»çš„ï¼Œå¯¹äºŽçº¯ç²¹çš„æ€§ä»·æ¯”çˆ±å¥½è€…æ¥è¯´ï¼Œåº”è¯¥æ”¾åˆ°æœ€æ¬¡ä¸€çº§æ¥è€ƒè™‘

- æˆ‘åªçŸ¥é“ç¬¬ä¸€æ¬¡ä¹°æ˜¾å¡ä¹°æœ€ä¾¿å®œçš„ä¸å›¾å¸ˆï¼Œç›´æŽ¥è®©æˆ‘æ¡Œå­é™„è¿‘æ¸©åº¦ä»Žæ˜¥å¤©å˜æˆå¤å¤©ã€‚è‡ªæ­¤ä¸‹å¼ æ˜¾å¡çš„æ¸©åº¦æ˜¯æˆ‘è€ƒè™‘çš„å› ç´ ä¹‹ä¸€ã€‚

- ä¸å¡å†ä¸ï¼Œç†è®ºæ€§èƒ½éƒ½è¶…è¶Šä¸‹çº§[æ˜¾å¡]ï¼Œæ— éžæ˜¯ä¾›ç”µå’Œæ•£çƒ­åšçš„å·®ç‚¹ï¼Œè¾¾ä¸åˆ°[åŠŸè€—å¢™]æ²¡æ³•è¶…é¢‘ï¼Œä½†æ˜¯èŠ¯ç‰‡æ€»å½’è¿˜æ˜¯é‚£é¢—èŠ¯ç‰‡ã€‚
  - åè¿‡æ¥è¯´4070åšçš„å†å¥½ï¼Œå†å †ç”¨æ–™éƒ½ä¸å¯èƒ½è¶…è¶Š[4070ti]ã€‚åªè¦å”®åŽè´¨ä¿èƒ½ä¿è¯ï¼Œåœ¨é‡‘é¢é¢„ç®—é‡Œé¢ï¼Œä¹°ä¸€å—é«˜çº§çš„ä¸å¡ä¹Ÿæ˜¯å¯ä»¥è€ƒè™‘çš„ã€‚

- å¤Ÿç”¨å°±å¥½å§ï¼Œæˆ‘ä¹°çš„4070sä¸‡å›¾å¸ˆçš„å¡ï¼Œæ„Ÿè§‰ä»·ä½æŒºåˆé€‚çš„ï¼Œç”¨ç€ä¹Ÿç¨³å®šã€‚

- ## ðŸ’¡ [ä¸ºä»€ä¹ˆ50ç³»åˆ—æ˜¾å¡å‡ºæ¥ï¼Œæ€§ä»·æ¯”æ²¡æœ‰æå‡åè€Œ40ç³»åˆ—æ˜¾å¡æ¶¨ä»·äº†ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/1902322217175463161)
- - 40ç³»æ¶¨ä»·æ˜¯å› ä¸ºå•†å®¶éƒ½åœ¨æ¸…åº“å­˜ï¼Œåº“å­˜å‡å°‘ã€‚ä»…å‰©çš„40ç³»æ˜¾å¡é›†ä¸­åˆ°å°‘æ•°å‡ ä¸ªå•†å®¶æ‰‹ä¸­ã€‚ä½†æ˜¯å¸‚åœºçš„éœ€æ±‚æ²¡æœ‰å‡å°‘ã€‚éœ€æ±‚ä¸å˜ï¼Œä¾›åº”å‡å°‘ï¼Œä»·æ ¼å¿…ç„¶æé«˜ã€‚è€Œä¸”è¿™å‡ ä¸ªå•†å®¶çš„æœ€ä½³ç­–ç•¥å°±æ˜¯æ¶¨ä»·ï¼Œå› ä¸ºä»¥åŽè‚¯å®šæ˜¯è¦è·Œçš„ï¼Œè¶çŽ°åœ¨èƒ½å–é«˜ä»·å¿…é¡»å–é«˜ä»·ã€‚
  - 40ç³»æ˜¯ä¸å¯èƒ½å†å¤§é™ä»·äº†ã€‚å› ä¸ºæ²¡æœ‰å·¨é‡çš„æ˜¾å¡ä¸‹æ¥å‡»ç©¿å•†å®¶çš„åº“å­˜ã€‚çŽ°åœ¨åè€Œæ˜¯å•†å®¶é‚£é‡Œæ²¡æœ‰åº“å­˜ï¼Œå‰©ä¸‹çš„æ˜¾å¡åªèƒ½æƒœå”®ã€‚

- ä»¥å‰è€é»„çš„äº§èƒ½å…¨éƒ¨ç”±æ¶ˆè´¹çº§å¸‚åœºæ‰¿æ‹…ï¼Œæ‰€ä»¥æ¯æ¬¡æ–°å¡ä¸€å‘å¸ƒï¼Œå°±ä¼šæœ‰æµ·é‡çš„æ–°å¡ç ¸ç›˜ï¼Œæ—§å¡å¿…é¡»é™ä»·æ¸…ä»“å¦åˆ™ä¼šçƒ‚æ‰‹é‡Œã€‚
  - çŽ°åœ¨å¯ä¸ä¸€æ ·äº†ï¼Œè€é»„8æˆçš„äº§èƒ½è¢«AIè®¡ç®—å¡åƒæŽ‰ï¼ŒæŠ•æ”¾ç»™æ¶ˆè´¹çº§å¸‚åœºçš„äº§èƒ½å¯¥å¯¥æ— å‡ ï¼Œæ–°å¡åˆ«è¯´ç ¸ç›˜äº†ï¼Œå¡«è¡¥å¸‚åœºç¼ºå£éƒ½ä¸å¤Ÿï¼Œæ‰€ä»¥è€å¡å°±æœ‰äº†å¥‡è´§å¯å±…çš„ä»·å€¼ï¼Œæ¶¨ä»·ä¹Ÿæ˜¯ç†æ‰€å½“ç„¶çš„äº†ã€‚
- ä¸ºä»€ä¹ˆä¸å¢žåŠ äº§èƒ½ï¼Ÿ
  - è€é»„æ˜¯fablessï¼Œè‡ªå·±æ²¡æœ‰å·¥åŽ‚ï¼Œå®Œå…¨ä¾èµ–ä»£å·¥ï¼Œä¸»è¦æ˜¯æ‰¾å°ç§¯ç”µï¼Œç„¶è€Œå°ç§¯ç”µæ¯å¹´çš„äº§èƒ½æ˜¯å›ºå®šçš„ï¼Œå…¨çƒå¤§å®¢æˆ·é‚£ä¹ˆå¤šï¼Œå°±ç®—æ˜¯è€é»„ä¹Ÿåšä¸åˆ°äº§èƒ½åŒ…åœ†ï¼Œæ‰€ä»¥è€é»„èƒ½åˆ†åˆ°çš„äº§èƒ½æ˜¯æœ‰é™çš„ï¼Œä»–æƒ³å¢žäº§ä¹Ÿåšä¸åˆ°ã€‚
  - è¿™ä¹Ÿèƒ½è§£é‡Šä¸ºä»€ä¹ˆæœ‰æ—¶å€™è€é»„ä¼šæ‰¾ä»£å·¥ï¼Œæœ€ä¸»è¦çš„åŽŸå› æ˜¯å°ç§¯ç”µé‚£è¾¹åˆ†åˆ°çš„äº§èƒ½ä¸è¶³ä»¥è¦†ç›–äº§å“çº¿ã€‚
- æ‹¿ç€è®¾è®¡å›¾çº¸å¤šæ‰¾å‡ å®¶ä»£å·¥åŽ‚ä¸å°±æœ‰äº§èƒ½äº†å—ï¼Ÿ
  - èŠ¯ç‰‡è¿™ä¸œè¥¿ï¼Œæ¯”è¾ƒç‰¹æ®Šï¼Œä»–å¿…é¡»åœ¨è®¾è®¡ç«‹é¡¹çš„æ—¶å€™å°±æ•²å®šä»£å·¥åŽ‚ã€‚
  - æƒ³è¦æ‰¾ä»£å·¥åŽ‚ä»£å·¥ï¼Œè‡ªå·±æ˜¯å¿…é¡»è®¾è®¡åˆ°é—¨ç”µè·¯ä¸€çº§çš„å¸ƒçº¿ï¼Œç„¶è€Œä¸åŒçš„ä»£å·¥åŽ‚ï¼Œä»–çš„å…ƒä»¶å¸ƒå±€æ˜¯ä¸ä¸€æ ·çš„ï¼Œæ¯”å¦‚AåŽ‚çš„ä¸Žéžé—¨æ˜¯2x2å¸ƒå±€ï¼Œé‚£BåŽ‚çš„ä¸Žéžé—¨å¸ƒå±€å¯èƒ½å°±æ˜¯1x4äº†ï¼Œæ¢åŽ‚å°±æ²¡æ³•åšï¼Œå› æ­¤ä¸€æ¬¾èŠ¯ç‰‡å¿…é¡»åœ¨ç«‹é¡¹çš„æ—¶å€™å°±å†³å®šå¥½æ‰¾å“ªå®¶ä»£å·¥ï¼Œè®¾è®¡å¥½åŽŸç†å›¾ï¼Œç„¶åŽä½¿ç”¨ä»£å·¥åŽ‚æä¾›çš„EDAè½¯ä»¶è¿›è¡Œå¸ƒçº¿ã€‚
  - å¤§å®¶æƒ³è±¡ä¸­çš„åƒæœºåŠ å·¥ä¸€æ ·ï¼Œæœ‰äº†è®¾è®¡å›¾å°±èƒ½éšä¾¿æ‰¾ä¸ªå·¥åŽ‚åŠ å·¥ï¼Œåœ¨èŠ¯ç‰‡é¢†åŸŸæ˜¯ä¸å­˜åœ¨çš„ï¼Œå“ªæ€•ä½ æ‹¿åˆ°äº†å®Œæ•´çš„4090å¸ƒçº¿å›¾ï¼Œæ‰¾ä¸­èŠ¯ä»£å·¥ï¼Œä¹Ÿæ˜¯åšä¸äº†çš„ï¼Œé™¤éžä½ æ„¿æ„é‡æ–°è®¾è®¡å¸ƒçº¿ï¼Œé‚£å°±è¦å…ˆæŽå‡ åƒä¸‡ç¾Žå…ƒçš„è®¾è®¡è´¹ï¼Œå†æŽä¸Šäº¿ç¾Žå…ƒçš„æµç‰‡è´¹ç”¨ï¼Œå¹¶ä¸”æœ‰æµç‰‡å¤±è´¥å…¨éƒ¨è´¹ç”¨æ‰“æ°´æ¼‚çš„é£Žé™©ï¼Œéžå¸¸åˆ’ä¸æ¥ã€‚

- åŽŸåˆ™ä¸Šæ˜¯è¿™æ ·çš„ï¼Œä¸è¿‡æ¢åŽ‚ä¹Ÿæœªå¿…å°±ä»£ä»·å¾ˆå¤§ã€‚8Gen1å’Œ8+å°±æ˜¯ä¸€å¹´å†…ä»Žä¸‰æ˜Ÿæ¢æˆäº†å°ç§¯ç”µã€‚
  - æ—©å°±æ›å…‰äº†ï¼ŒæŒ‰å°ç§¯ç”µçš„ç”Ÿäº§å‘¨æœŸï¼Œ8gen1æ‰¾å°ç§¯ç”µåšï¼Œé«˜é€šä¼šæœ‰å¤§åŠå¹´çš„äº§å“çœŸç©ºæœŸï¼Œæ‰€ä»¥ä»–ä¸€å¼€å§‹å°±ç«‹é¡¹åšä¸¤æ¬¾ï¼Œä¸‰æ˜Ÿå·¥è‰ºçš„8gen1å…ˆé¡¶ä¸Šï¼ŒåŠå¹´åŽå†æŽ¨å‡º8+ã€‚å°ç§¯ç”µçš„äº§èƒ½é¢„å®šèµ·ç æå‰2å¹´ï¼Œå‘çŽ°8gen1ä¸è¡Œå†æ”¹8+ä½ è¿™äº§èƒ½éƒ½æŽ’åˆ°2å¹´ä»¥åŽåŽ»äº†ã€‚
  - å¥½åƒæ˜¯ç»†èŠ‚è®°ä¸æ¸…æ¥šäº†ï¼Œåˆšå¼€å§‹é«˜é€šå°±æ˜¯æ‰¾äº†å°ç§¯ç”µå’Œä¸‰æ˜Ÿåˆ†åˆ«åšä¸€éƒ¨åˆ†ï¼Œå“ªçŸ¥é“ä¸‰æ˜Ÿåšçš„å‘çƒ­é‡ä¸¥é‡ï¼Œæœ€åŽä¸å¾—å·²è®¢å•å…¨ç»™å°ç§¯ç”µäº†.
- è‹¹æžœ6Sä¸Šçš„A9å¤„ç†å™¨ç›´æŽ¥ä¿©ç‰ˆæœ¬ï¼Œä¸‰æ˜Ÿå’Œå°ç§¯ç”µçš„éƒ½æœ‰

- å›½å†…è¿˜ç®—æ˜¯æœ‰è‰¯å¿ƒçš„ï¼Œ50ç³»å‡ºæ¥ä»¥åŽï¼Œ40ç³»å¯ä»¥ä¹°åˆ°ï¼Œç¨æ¶¨ä¸€ç‚¹ä»·ä½†è¿˜ç®—æœ‰æ€§ä»·æ¯”ã€‚
  - ç¾Žå›½å¸‚åœºè‡ªä»Ž50ç³»ä¸Šå¸‚ä»¥åŽï¼Œæ­£ä»·çš„40ç³»ä¸€å¤œä¹‹é—´å…¨ä¸‹æž¶äº†ï¼Œåªæœ‰é»„ç‰›çš„é«˜ä»·å¡åœ¨å–ã€‚
  - åœ¨ç¾Žå›½ï¼ŒNV 50ç³»å’ŒAMD 9070/9070xtä¸Šå¸‚ä»¥æ¥ä¸€ç›´å¤„äºŽç¼ºè´§çŠ¶æ€ï¼Œéƒ½è¢«é»„ç‰›ç”¨botä¹°èµ°äº†ï¼Œæ™®é€šäººå¾ˆéš¾ä¹°åˆ°ã€‚æ¯”å¦‚Amazonä¸Šé¢æ­£å¸¸ä»·æ ¼çš„ä¸€ç›´ç¼ºè´§ï¼Œä¸€å †éžè‡ªè¥é»„ç‰›æŒ‚é«˜ä»·ã€‚
- æ™®é€šå•†å®¶ä¹Ÿä¸å…è®¸å–å—
  - æ™®é€šå•†å®¶çš„éƒ½è¢«é»„ç‰›ä¹°å®Œäº†

- 40ç³»å‡ºæ¥çš„æ—¶å€™AIçƒ­åˆšåˆšå…´èµ·ï¼Œ[4090] ä¹‹æ‰€ä»¥ä»·æ ¼çˆ†ç‚¸ï¼Œä¹Ÿæ˜¯å› ä¸ºå¾ˆå¤šäººéƒ½æ‹¿4090å½“ç”Ÿäº§åŠ›å¡ç”¨ï¼Œç‚¼AI
  - è€é»„æ˜¯çœ‹åˆ°äº†40ç³»ï¼Œå°¤å…¶æ˜¯4090å–çˆ†äº†çš„æƒ…å†µä¸‹ï¼Œæ‰å†³å®š50ç³»æŒ¤ç‰™è†ï¼Œå…¨åŠ›æŠ¼å®è®¡ç®—å¡ä¸Š
  - AIå¡å–çš„æ¯”æ¸¸æˆå¡è´µå¤šäº†ï¼Œä»·æ ¼å¯ä»¥è¯´çªç ´å¤©é™…
  - äººå®¶èµ„æœ¬ä¹Ÿä¸æ˜¯å‚»å­ï¼Œæ¯”èµ·èŠ±çœŸé‡‘ç™½é“¶ä¹°ç®—åŠ›å¡ï¼ˆè¿˜å¯èƒ½ç”¨ä¸äº†å‡ å¹´å°±è¢«æ·˜æ±°ï¼‰ï¼Œè¿˜ä¸å¦‚å·ä¸€å·ç®—åŠ›ï¼Œç”¨ä¾¿å®œå¡æžå¤§æ¨¡åž‹ã€‚

- ## [5090Dæ˜¾å¡æ¯”4090å¼ºçš„è¯ä¸ºä½•æ²¡æœ‰è¢«ç¦ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/9802980796)
- 5090dæ˜¯nvidiaåˆ›ç«‹ä»¥æ¥æ€§ä»·æ¯”æœ€å·®çš„æ˜¾å¡ã€‚
  - 5090då’Œ4090dç®—åŠ›ä¸€æ ·ï¼Œä½†æ¯”4090dè¿˜å·®ï¼Œå› ä¸º4090då¯ä»¥é­”æ”¹48gæ˜¾å­˜ï¼Œ5090dä¸ä»…ä¸èƒ½æ‰©æ˜¾å­˜è¿˜ç¦æ­¢å¤šå¡äº’è”ï¼Œè·‘aiè½¯ä»¶3ç§’é”æ­»ï¼Œè¦é‡å¯æ‰èƒ½ç»§ç»­ç”¨ï¼Œå¯ä»¥è¯´åªèƒ½çŽ©æ¸¸æˆ

- ä¸­å›½ç‰¹ä¾›ç‰ˆæ——èˆ°æ˜¾å¡RTX 5090Dï¼Œè™½ç„¶å…¶AIç®—åŠ›å‰Šå‡äº†çº¦29%ï¼Œä½†æ˜¯æ¸¸æˆæ€§èƒ½å´å‡ ä¹Žå¹¶æœªç¼©æ°´ï¼Œä»·æ ¼ä¸º16, 499å…ƒèµ·ï¼ˆç•¥é«˜äºŽRTX 5090çš„1999ç¾Žå…ƒï¼Œå³çº¦14648å…ƒçš„ä»·æ ¼ï¼‰ï¼Œå°†äºŽ1æœˆ30æ—¥ä¸Šå¸‚ã€‚ï¼Ÿæ€§èƒ½å·®äº›ï¼Œä»·æ ¼è¿˜è´µäº›

- ## ðŸš€ [å¦‚ä½•çœ‹å¾…æ–°æŽ¨å‡ºçš„NvidiaæŽ¨å‡ºçš„4090dï¼Ÿ - çŸ¥ä¹Ž _202312](https://www.zhihu.com/question/637218617)
  - 12999å’Œ4090ä»·æ ¼ä¸€æ ·ã€‚çœ‹äº†cudaè§„æ ¼æ˜¯å®Œæ•´çš„ad102çš„ç™¾åˆ†80

- è€é»„çš„åˆ€æ³•è¿˜æ˜¯å¾ˆç²¾å‡†çš„ï¼Œè¿™æ¬¡RTX 4090Dåˆšå¥½å¡åœ¨3A090å‡ºå£ç®¡åˆ¶æ¡ä¾‹çš„ç•Œé™ä¸Šã€‚
  - â€œæ•°æ®ä¸­å¿ƒèŠ¯ç‰‡â€ç”Ÿæ•ˆèŒƒå›´æ¯”è¾ƒå¤æ‚ï¼Œä½†æ˜¯â€œéžæ•°æ®ä¸­å¿ƒèŠ¯ç‰‡â€ä¸€åˆ€åˆ‡åœ¨TPP = 4800ä¸Šï¼Œä¹Ÿå°±æ˜¯è¯´å¯¹æ¶ˆè´¹çº§RTX 40æ˜¾å¡ï¼ŒTPPé™åˆ¶æ˜¯4800ä¸Šã€‚
  - è€Œè¿™å¼ RTX 4090 Dï¼Œè¯¥æ˜¾å¡æ­è½½14592ä¸ªCUDA æ ¸å¿ƒï¼ŒåŠ é€Ÿé¢‘çŽ‡ 2.52GHzï¼Œè¯¥æ˜¾å¡æ­è½½14592ä¸ªCUDA æ ¸å¿ƒï¼ŒåŠ é€Ÿé¢‘çŽ‡ 2.52GHzï¼Œæ˜¾å­˜ä¸º 24GB 384bit GDDR6Xï¼Œæ˜¾å¡æ€»åŠŸè€— 425Wï¼Œå¸¸è§„æ¸¸æˆåŠŸè€— 302Wã€‚

- è¿™çŽ©æ„æœ‰4090ä¹æˆè§„æ ¼ï¼Œåº”è¯¥è¿˜æ˜¯åœ¨ç¦å”®èŒƒå›´å†…çš„ï¼ˆæ‰€ä»¥nvè¿˜é™åˆ¶äº†è¶…é¢‘ï¼‰

- 4090Dè¿™å¼ å¡æœ¬èº«ï¼Œæµå¤„ç†å™¨è§„æ¨¡æ˜¯4090çš„89%ï¼ŒTensor Coreå’ŒRT Coreä¹Ÿæ˜¯ç­‰æ¯”ä½Žå‰Šå‡ï¼Œå¹¶æœªä¸“é—¨ç¼©æŽ‰äº†Tensor Coreçš„è§„æ¨¡ï¼Œæ˜¾å­˜ä¹Ÿæœªé˜‰å‰²ï¼ŒL2ç”šè‡³å¯èƒ½ä¸å˜ï¼Œä¼°è®¡ç»¼åˆæ¸¸æˆæ€§èƒ½å¯ä»¥è¾¾åˆ°4090çš„90%-95%å§

- éƒ½2023å¹´äº†ï¼Œè¿˜èƒ½åœ¨æ¶ˆè´¹å¸‚åœºä¸Šè§åˆ°å¤§å…¬å¸å‡é‡ä¸å‡ä»·çš„æ“ä½œï¼Œåªèƒ½è¯´åž„æ–­è¿˜æ˜¯åŽ‰å®³
  - æŠ€æœ¯æ€§åž„æ–­æ€»æ¯”æ”¿ç­–æ€§åž„æ–­è¦å¥½ï¼Œæœ€èµ·ç äººå®¶æ˜¯å‡­çœŸæœ¬äº‹åž„æ–­çš„

- è¿™å°ç ä¸€åˆ€æ— ä¼¤å¤§é›…ï¼Œä¾ç„¶æœ‰73.54TFLOPsâž•CUDAâž•24GB GDDR6Xï¼ŒåŠæ‰“7900XTXè·Ÿ4080ä»¥åŠæ–°çš„4080S

- å…¨çƒèŠ¯ç‰‡å¼€å§‹è½¬å‘Riscç»“æž„ï¼Œç¾Žå›½çš„å¤§éƒ¨åˆ†ä¼ä¸šé€‰æ‹©armï¼Œ åªæœ‰NVDIAç›®å‰çš„GPUå’Œè°·æ­Œçš„TPUä¸æ˜¯ï¼Œä½†è°·æ­Œä¼¼ä¹Žä¹Ÿæ‹¥æŠ±armï¼Œ è‡³å°‘æ˜¯ç”¨åœ¨å…¶æ‰‹æœºéƒ¨åˆ†ã€‚ ä¸­å›½å¤§ä¼ä¸šå´æ˜¯æ‹¥æŠ±RISC-Vï¼Œè¿™ç§å¼€æºçš„ç¡¬ä½“æž¶æž„è§„æ ¼ï¼Œå› ä¸ºä¸éœ€è¦ç»™armä¸“åˆ©ã€‚è‹±ç‰¹å°”ä¹Ÿæ‹¥æŠ±RISC-Vï¼Œ è¡¨ç¤ºä¸Žarmç«žäº‰ã€‚

- ## [é­”æ”¹ç‰ˆ4090 48Gæ˜¾å¡æ€§ä»·æ¯”å¤§æŽ¢è®¨ï¼šçœŸçš„å€¼å¾—å…¥æ‰‹å—ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/14343647195)
- 40ç³»æ˜¾å¡çš„ä¸»è¦æ€§èƒ½ç“¶é¢ˆæ˜¯[æ˜¾å­˜ä½å®½] ï¼Œå’Œæ˜¾å­˜å®¹é‡å…³ç³»ä¸å¤§ã€‚è¿™ä¸€ç‚¹æˆ‘ä»¬å¯ä»¥ä»Ž4090å’Œrtx6000adaä¸¤å¼ å¡å¾—åˆ°éªŒè¯ã€‚
  - è¿™ä¸€ç‚¹æˆ‘ä»¬å¯ä»¥ä»Ž4090å’Œrtx6000adaä¸¤å¼ å¡å¾—åˆ°éªŒè¯ã€‚
  - 4090å’Œrtx6000adaæ‹¥æœ‰ç›¸åŒçš„æž¶æž„çš„gpuæ ¸å¿ƒï¼ŒåŸºæœ¬ç›¸ç­‰çš„cudaæ ¸å¿ƒæ•°é‡ï¼ˆä¸€ä¸ªæ˜¯16384çš„cudaæ ¸å¿ƒï¼Œä¸€ä¸ªæ˜¯18176çš„cudaæ ¸å¿ƒï¼‰ï¼ŒåŸºæœ¬ç›¸åŒçš„æ˜¾å­˜ä½å®½ï¼ˆ4090æ˜¯1008GB/Sï¼Œrtx6000adaæ˜¯960GB/Sï¼‰ã€‚
  - ä¸¤å¼ å¡åªæœ‰æ˜¾å­˜å®¹é‡ä¸åŒï¼ˆ4090çš„æ˜¾å­˜æœ‰24gï¼Œrtx6000adaæ˜¾å­˜48gï¼‰ã€‚ç»è¿‡æµ‹è¯•ï¼Œä¸¤å¼ å¡æ— è®ºæ˜¯æ¸¸æˆæ€§èƒ½ï¼ŒaiæŽ¨ç†ï¼Œç»“æžœéƒ½æ˜¯å·®ä¸å¤šçš„ã€‚rtx6000adaå¹¶æ²¡æœ‰å› ä¸º48gçš„æ˜¾å­˜å®¹é‡è€Œæœ‰æ›´åŠ ä¼˜ç§€çš„æ€§èƒ½ã€‚
  - åŒæ ·çš„ç»“è®ºè¿˜å¯ä»¥åˆ†æž4090å’Œ4070å¾—åˆ°ã€‚4090æ‹¥æœ‰16384çš„cudaæ ¸å¿ƒï¼Œ4070æ‹¥æœ‰5880ä¸ªcudaæ ¸å¿ƒã€‚4090çš„cudaæ ¸å¿ƒæ•°é‡æ˜¯4070çš„å°†è¿‘ä¸‰å€ã€‚æŒ‰ç†è¯´ï¼Œå°†è¿‘ä¸‰å€çš„æ˜¾å­˜å®¹é‡åº”è¯¥å¸¦æ¥ä¸‰å€çš„æ€§èƒ½ï¼Œä½†æ˜¯4090çš„å®žæµ‹æ€§èƒ½åªæœ‰4070çš„å°†è¿‘2å€ã€‚4090çš„ä½å®½384bitï¼Œ4070çš„ä½å®½192bitã€‚4090åˆšå¥½æ˜¯4070çš„ä¸¤å€ã€‚

- ç²—ç•¥è®¡ç®—ï¼Œæ¯10äº¿ä¸ªå‚æ•°å¤§çº¦éœ€è¦4Gæ˜¾å­˜æ¥åŠ è½½ï¼Œæ‰€ä»¥48Gæ˜¾å­˜èƒ½è·‘120äº¿å‚æ•°çš„å¤§æ¨¡åž‹ï¼Œå¦‚æžœæ˜¯åŠç²¾åº¦çš„æœ€å¤šå¯ä»¥è·‘240äº¿å‚æ•°çš„æ¨¡åž‹ï¼Œæ˜¾å­˜ä¸å¤Ÿå¤§ï¼Œæ¨¡åž‹éƒ½åŠ è½½ä¸è¿›åŽ»ï¼Œ48Gé­”æ”¹å‡ºæ¥çš„éƒ½æ˜¯æ¶¡è½®å¡ï¼Œæ’æœºæž¶æœåŠ¡å™¨ç”¨çš„ï¼Œå°±ä¸æ˜¯ç»™æ¸¸æˆçŽ©å®¶æŠ˜è…¾å‡ºæ¥çš„

- æˆ‘ä¸‹å‘¨åŽ»æ‰¾ä¸ªå·¥åŽ‚åšä¸€ä¸‹æµ‹è¯•ï¼Œé­”æ”¹çš„åŽŸç†å°±æ˜¯åœ¨[4090ä¸»æ¿] ä¸ŠåŠ [æ˜¾å­˜ç²’] ï¼Œè¿™ä¸ªåˆ†ä¸¤ç§ä¸€ç§æ˜¯ä»–ä»¬ä¹°çš„[3090ä¸»æ¿]ï¼Œæ¢æˆ4090èŠ¯ç‰‡ï¼Œç„¶åŽåŠ ç„ŠæŽ¥24Gæ˜¾å­˜ç²’ï¼ŒåŠ ä¸¤ä¸ªã€‚è¿™ç§ä¿—ç§°æ¶ˆè´¹çº§ï¼Œå°±æ˜¯éœ€è¦æ¯å¤©å…³æœºä¸€æ¬¡ï¼Œè¦ä¸ç„¶ä¼°è®¡ä¸»æ¿é¡¶ä¸ä½ï¼Œæ¯•ç«Ÿæ˜¯ç‰¹ä¹ˆçš„3090æ”¹
  - å¦å¤–ä¸€ç§å°±æ˜¯åŸºäºŽ4090ä¸»æ¿ï¼ŒåŠ ç„Šæ˜¾å­˜ç²’ï¼Œè¿™ç§ç†è®ºä¸Šæ¯”è¾ƒOKï¼Œä½†æ˜¯è¿˜æ²¡æœ‰å®žæµ‹ï¼Œå‡†å¤‡å¸¦ä¸Šæ˜¾å¡åŽ»æ·±åœ³æ‰¾äººé­”æ”¹ä¸€ä¸‹ï¼Œè¦æ˜¯èƒ½æˆäº†ï¼Œé‚£å°±æˆ‘å°±å¼€è¾Ÿä¸€ä¸ªé­”æ”¹ä¸šåŠ¡ï¼Œæœ¬æ¥å—äº¬ä¹Ÿæœ‰ï¼Œä½†æ˜¯å—äº¬æ²¡æœ‰å®¶é‡Œåˆ›å•Šï¼Œäº§ä¸šé“¾æœ‰ç‚¹æ‹‰ã€‚åªèƒ½æ‹›è˜é‚£äº›ä¿®æ‰‹æœºæ¥å¹²

- ## [å¯¼å¸ˆç»™30wé¢„ç®—è£…4-6å¡æœåŠ¡å™¨ï¼Œç›®å‰æ‰“ç®—ä¸Š5880adaï¼Œè¦å™ªéŸ³è¾ƒä½Žã€ä¸è¦æ¶²å†·ï¼Œæ±‚åˆé€‚æ–¹æ¡ˆï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/1939707476724389292)
- 5880æ»¡è½½åŠŸè€—ä»…285wï¼Œæ¯”3090éƒ½ä½Žï¼Œæ¶¡è½®ä¹Ÿå¾ˆé™éŸ³ã€‚

- https://zhuanlan.zhihu.com/p/1939741761053364343
  - ä¹‹å‰æˆ‘åˆ†äº«è¿‡ï¼Œåœ¨RTX Pro 6000 ä¸Šæ‰§è¡Œollamaä¸Žgpt-oss-120bï¼Œæ•ˆçŽ‡éº»éº»å“‹ï¼Œä¸è¿‡ï¼Œç”¨å®ƒæ¥è¿è¡ŒvLLMå´æ˜¯ä¸€æŠŠå¥½æ‰‹ï¼Œç‰¹åˆ«æ˜¯ä¸»æµçš„32Bæ¨¡åž‹: Qwen3-32Bï¼Œèƒ½è¾¾åˆ°22 token/sçš„é€Ÿåº¦ï¼Œ
  - å¯¹æ¯”ä¸Šä¸€ä»£å¡çš‡5880(6000 adaçš„å°å…„å¼Ÿ)æ€Žä¹ˆæ ·å‘¢ï¼Ÿå®žæµ‹è¿‡ï¼Œ2x5880ä¹Ÿå°±æ‰24 token/sã€‚

- [è‹±ä¼Ÿè¾¾ä¸­å›½ç‰¹ä¾›ç‰ˆRTX 5880å‘å¸ƒï¼æ€§èƒ½æ¯”æ——èˆ°å¤§ç è¿‘25%ï¼Œæ¯”RTX 5000åªé«˜6% - çŸ¥ä¹Ž _202401](https://zhuanlan.zhihu.com/p/676491377)
  - ç›¸æ¯”äºŽæ——èˆ°çº§RTX 6000ï¼Œå®šåˆ¶ç‰ˆ5880åœ¨æ€§èƒ½æ–¹é¢å¯è°“æ˜¯å¤§å¹…é™çº§â€”â€”CUDAæ ¸å¿ƒå°‘äº†23%ï¼Œå•ç²¾åº¦æµ®ç‚¹æ€§èƒ½ä½Žäº†24%ã€‚
  - å®žé™…ä¸Šï¼Œå®ƒçš„è¡¨çŽ°æ›´åŠ æŽ¥è¿‘RTX 5000â€”â€”ä¸¤é¡¹å‚æ•°åˆ†åˆ«æå‡äº†10%å’Œ6%ã€‚

- ## [åŒRTX A6000æ˜¾å¡åšæ·±åº¦å­¦ä¹ ï¼Œä½¿ç”¨nvlinkæ¡¥æŽ¥å™¨èƒ½å®žçŽ°æ˜¾å­˜å…±äº«æˆ96Gå—ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/455953236)
  - åŒRTX A6000ï¼ˆæ˜¾å­˜æ˜¯48Gï¼‰æ˜¾å¡åšæ·±åº¦å­¦ä¹ ï¼Œä½¿ç”¨nvlinkæ¡¥æŽ¥å™¨èƒ½å®žçŽ°æ˜¾å­˜å…±äº«æˆ96Gå—ï¼Ÿæ’ä¸Šäº†A6000çš„å®‰åŸ¹æž¶æž„çš„æ¡¥æŽ¥å™¨ï¼Œè¾“å…¥nvidia-smi nvlink -i 0 -s æ˜¾ç¤ºçš„æ˜¯é€Ÿåº¦14GB/Sï¼Œä¸æ˜¯æ˜¾ç¤ºçš„activeï¼Œç„¶åŽè·‘è®­ç»ƒï¼Œè¿˜æ˜¯åªèƒ½ä½¿ç”¨48Gçš„æ˜¾å­˜ã€‚
- NVçš„æ¡¥æŽ¥å™¨åŠŸèƒ½å…¶å®žåœ¨å®£ä¼ ä¸Šæœ‰äº›é—®é¢˜ï¼ŒåŠ äº†æ¡¥æŽ¥å™¨å…¶å®žä¹Ÿå®Œå…¨ä¸å¯èƒ½äºŒå¡åˆä¸€ã€æ˜¾å­˜å€å¢žï¼Œè¿˜æ˜¯ä¸¤å—å®Œå…¨ç‹¬ç«‹çš„æ˜¾å¡ï¼Œæ¡¥æŽ¥å™¨åªæ˜¯è®©ä¸¤å—æ˜¾å¡ä¹‹é—´å¯ä»¥å¿«é€Ÿäº¤æ¢æ•°æ®ï¼Œä¸ç”¨å†ä»ŽCPUé‚£è¾¹ç»•ä¸€å¤§åœˆï¼›è‡³äºŽç”¨äº†åŒå¡ä»¥åŽæå‡äº†å¤šå°‘æ€§èƒ½ï¼Œä¸»è¦çœ‹åº”ç”¨è½¯ä»¶æœ¬èº«å¯¹å¤šGPUä¼˜åŒ–çš„æ€Žæ ·ï¼Œä¸åŒçš„åº”ç”¨è½¯ä»¶çš„è¡¨çŽ°å®Œå…¨ä¸ä¸€æ ·ï¼Œå¯èƒ½1+1æŽ¥è¿‘2ï¼Œä¹Ÿå¯èƒ½1+1â‰ˆ1.5, ä¹Ÿå¯èƒ½1+1=1ï¼Œç”šè‡³å¯èƒ½1+1<1ã€‚
  - æœ€æ–°ä¸€ä»£çš„Ada Lovelaceæž¶æž„çš„æ——èˆ°å¡RTX4090, RTX6000Adaå’ŒL40å¹²è„†æŠŠå¯¹NVLinkçš„æ”¯æŒå½»åº•å–æ¶ˆäº†ï¼Œå¯è§ç›®å‰è¿™ä¸ªåŠŸèƒ½åœ¨å›¾å½¢ç±»åº”ç”¨çš„é¢†åŸŸæœ‰å¤šæ‹‰èƒ¯ï¼Œè¿™ä¸ªåŠŸèƒ½çŽ°åœ¨æˆäº†aiè®¡ç®—é¢†åŸŸçš„ä¸“æœ‰åŠŸèƒ½äº†

- å¯ä»¥ç›´æŽ¥åœ¨æ˜¾å­˜é—´ä¼ è¾“æ•°æ®ï¼Œä¸éœ€è¦å†ç»è¿‡å†…å­˜äº†æ˜¯å—
  - ç†è®ºä¸Šæ˜¯ï¼Œä½†æ˜¯ä¹Ÿéœ€è¦åº”ç”¨è½¯ä»¶æ”¯æŒæ­¤åŠŸèƒ½æ‰è¡Œï¼Œè¿™ä¸ªè¦çœ‹ç®—æ³•çš„ï¼Œå®žé™…ä¸Šå¤šå¡çš„ç®—æ³•æ²¡é‚£ä¹ˆç®€å•

- NVLinkä¸æ˜¯å•çº¯çš„æ˜¾å­˜å åŠ ï¼Œ48Gå˜96Gï¼Œè€Œæ˜¯ä¼šå¢žåŠ ä¸¤å¼ æ˜¾å¡ä¹‹é—´çš„æ˜¾å­˜äº¤äº’å¸¦å®½ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œå¤šå¡è·‘æ·±åº¦å­¦ä¹ ï¼Œä¸€èˆ¬æ˜¯æŒ‡æ•°æ®å¹¶è¡Œï¼Œå³æ¯ä¸ªæ˜¾å¡å¤„ç†ä¸€éƒ¨åˆ†æ•°æ®ã€‚

- ## ðŸš€ [å¦‚ä½•è¯„ä»·Nvidia A6000æ˜¾å¡ï¼Ÿ - çŸ¥ä¹Ž _202010](https://www.zhihu.com/question/424306404)
  - å–æ¶ˆQuadroå‘½åï¼Œé‡‡ç”¨10752 CUDAæ»¡è¡€GA102æ ¸å¿ƒï¼Œ48GBçš„GDDR6ä¸å¸¦Xæ˜¾å­˜ï¼Œä¾›ç”µæŽ¥å£ä¸ºæ–°8PinæŽ¥å£ï¼ˆEPS-12Vä¸Žä¼ ç»ŸPcie-8Pinæ˜¾å¡ä¾›ç”µå£ä¸å…¼å®¹ï¼‰

- è™½ç„¶è¯´å–æ¶ˆäº†Quadroå¡çš„å‘½åï¼Œä½†æ˜¯è¿™ä¸œè¥¿çœ‹èµ·æ¥ä¾æ—§æ˜¯å’ŒQuadroä¸€è„‰ç›¸ä¼ ï¼Œå½“ç„¶å«ä»–â€œä¸“ä¸šå¡â€æˆ–è®¸æ›´ç›´è§‚ï¼Œ
  - ä¸€ç›´ä»¥æ¥ï¼Œæ¸¸æˆå¡å’Œä¸“ä¸šå¡éƒ½æœ‰ç€ä¸€é“éžå¸¸æ˜Žæ˜¾çš„åŒºåˆ«ï¼Œé‚£å°±æ˜¯OpenGLé©±åŠ¨ï¼Œä¸“ä¸šå¡èƒ½æ‰“ï¼Œä½†æ˜¯æ¸¸æˆå¡ä¸èƒ½æ‰“ï¼Œè™½ç„¶è€é»„æœ‰æ”¾å‡ºè¿‡Studioé©±åŠ¨å‡ºæ¥ï¼Œä½†æ˜¯ä¾æ—§æ˜¯æ— æ³•å–ä»£OpenGLé©±åŠ¨çš„åœ°ä½

- A6000é‡‡ç”¨çš„è¿˜æ˜¯Nå¡30ç³»çš„å®‰åŸ¹æž¶æž„ï¼Œæ‰€ä»¥æ³¨æ„å®‰è£…cudaè¿˜æ˜¯éœ€è¦cuda11.1åŠä»¥ä¸Šç‰ˆæœ¬ã€‚
  - ä¸€ä¸ªæœ‰æ„æ€çš„ç‚¹æ˜¯åŠŸçŽ‡300wï¼Œæ¯”3090çš„350wè¦ä½Žï¼Œå¯è°“æ˜¯ä½ŽåŠŸè€—é«˜æ•ˆèƒ½äº†ã€‚
  - A6000çš„48Gå¤§æ˜¾å­˜ä¸¤å€äºŽ3090è¿˜æ˜¯æ¯”è¾ƒé€‚åˆä¸Šå¤§æ¨¡åž‹çš„ï¼Œçœ‹è¿‡ç½‘ä¸Šè¯„ä»·A6000çš„æ€§èƒ½ä¼˜åŠ¿ä¸»è¦ä½“çŽ°åœ¨transformeråŒç²¾åº¦æŽ¨ç†å’Œåˆ†å¸ƒå¹¶å¡è®­ç»ƒï¼Œç”±äºŽç›®å‰ç‚¼ä¸¹çš„æ¨¡åž‹è¦æ±‚real-timeæ¯”è¾ƒå°ï¼Œå•å¡è¶³ä»¥

- ## [RTX A6000å­˜åœ¨çš„æ„ä¹‰æ˜¯ä»€ä¹ˆï¼Ÿ åŒæ ·çš„ä»·é’±ä¸ºä»€ä¹ˆä¸ä¹°ä¸¤å—3090äº¤ç«å‘¢ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/483799457)
- è‹±ä¼Ÿè¾¾æŠŠæ¶ˆè´¹çº§æ˜¾å¡å’Œä¸“ä¸šçº§æ˜¾å¡åŒºåˆ†å¾—è¿˜æ˜¯å¾ˆå¼€çš„ï¼Œæ¸¸æˆå¡ä¸æ”¯æŒå¤šè·¯NVENCæµã€ä¸æ”¯æŒvGPUï¼Œä¸æ”¯æŒECCè‡ªåŠ¨çº é”™ï¼ŒopenGLæ€§èƒ½è¾ƒå·®ã€‚
  - å¦‚æžœä½ æœ‰è·‘ç§‘å­¦è®¡ç®—çš„éœ€æ±‚çš„è¯ï¼ŒECCæ˜¾å­˜æ˜¯éžå¸¸é‡è¦çš„ï¼Œå¯ä»¥è¯´å¿…å¤‡ï¼Œè¿™ç§æƒ…å†µä¸‹ä½ åªèƒ½ç”¨ä¸“ä¸šå›¾å½¢å¡æˆ–è€…è®¡ç®—å¡æ¥è·‘ã€‚
  - å¤šè·¯NVENCä¹Ÿå¯ä»¥å¾ˆå¥½åœ°ç”¨åœ¨å¤§åž‹å¹¿æ’­æŽ§åˆ¶å°å†…ï¼Œç”¨äºŽå½•åˆ¶æŽ¨æµã€‚è¿™ä¹Ÿæ˜¯æ¸¸æˆå¡åº”ç”¨ä¸åˆ°çš„é¢†åŸŸã€‚

- RTX A6000æ˜¯åŸºäºŽNVIDIA Ampereæž¶æž„çš„è¶…é«˜ç«¯ä¸“ä¸šæ˜¾å¡ï¼Œæ­è½½æœ€æ–°ä¸€ä»£çš„ RT Coreã€Tensor Core å’Œ CUDA Core
  - å…¼å…· ECCæ ¡éªŒã€GPUDirect for Videoã€å¤šGPU æ”¯æŒã€å››é‡ç«‹ä½“ç¼“å†²ã€Mosaicå¤šæ˜¾ç¤ºå™¨ã€Quadro Syncç­‰åŠŸèƒ½ã€‚

- å› ä¸ºè€é»„ç¦æ­¢æ•°æ®ä¸­å¿ƒä½¿ç”¨æ¸¸æˆå¡

- ## [8wå·¦å³çš„åŒå¡4090æˆ–å•å¡A6000æœåŠ¡å™¨ï¼Œæœ‰ä»€ä¹ˆå¥½çš„æŽ¨èï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/646105848)
- è‡³å¼ºWçš„T7960å¡”å¼å·¥ä½œç«™ï¼Œä¿å®ˆæœ€å¤§4*A6000çš„æ”¯æŒã€‚
  - ä¸Šé™ä¸º56Cçš„W9-3495Xï¼›DDR5-4800å†…å­˜ï¼›PCIE 5.0ï¼›åº”è¯¥å¤Ÿç”¨çš„å­˜å‚¨ç©ºé—´ï¼ˆå¯é€‰RAID/NVMEç­‰é«˜çº§é€‰é¡¹ï¼‰
  - W7-3465X+128GBå†…å­˜+RTX4090*2/ä¸€ä¸ªA6000ï¼Œå’¬å’¬ç‰™ä¹Ÿä¸æ˜¯æžä¸å®šã€‚
- æ­è½½è‡³å¼ºå¯æ‰©å±•ä¸‰ä»£çš„åŒè·¯å¡”å¼T550æœåŠ¡å™¨ï¼Œæœ€å¤§ä¸¤ä¸ªA6000ã€‚
  - ä¸Šé™å°±ä¸è¯´äº†ï¼ŒDDR4-3200; PCIE 4.0ï¼›æ ‡é…ç‹¬ç«‹é˜µåˆ—å¡ä»¥åŠ150TB+å­˜å‚¨ç©ºé—´ä¹Ÿç›¸å½“ä¸é”™ã€‚
  - è¿™ä¸ªæ€§ä»·æ¯”è¾ƒä½Žï¼Œä¸æ˜¯å¾ˆæŽ¨èã€‚
- ä¸»æµçš„æœºæž¶å¼è§£å†³æ–¹æ¡ˆï¼Œä¹Ÿå°±æ˜¯PE R750æœåŠ¡å™¨ï¼Œæ”¯æŒæœ€å¤§3*A6000ï¼Œä½†æ˜¯å»ºè®®å°½é‡æŽ§åˆ¶åœ¨ä¸¤å¼ ï¼Œ
  - å®ƒæœ‰ä¸ªå§Šå¦¹åž‹å·å«åš750XAï¼Œå€’æ˜¯å¯ä»¥æ”¯æŒåˆ°4*A6000ï¼Œç›¸åº”çš„ä¹Ÿè¦ç¨å¾®è´µé‚£ä¹ˆä¸€ç‚¹ç‚¹ã€‚ã€‚ã€‚
- A6000ä¼˜åŠ¿åœ¨äºŽæ¡¥æŽ¥æ‰©å®¹æ˜¾å­˜ï¼Œæ‰€ä»¥è¿˜æ˜¯å°½é‡é€‰æ‹©å¡”å¼ï¼Œå¯èƒ½ç”¨ä¸ä¸Šï¼Œä½†æ˜¯å¿…é¡»è¦æ”¯æŒå¯¹ä¸å•¦ã€‚
  - æ‰€ä»¥æˆ‘è®¤ä¸ºæœ€ä¼˜é€‰æ‹©è¿˜æ˜¯å¡”å¼å·¥ä½œç«™T7960, 8é€šé“DDR5-4800+PCIE5.0å•Šï¼Œä½•å…¶å…ˆè¿›ã€‚

- 7960èƒ½åªä¹°æœºæž¶å’Œç”µæºå—, å…¶å®ƒçš„æƒ³è‡ªå·±é…
  - æœ€ä½Žæœ€ä½Žï¼Œå¾—å¸¦ä¸Šå¤„ç†å™¨ã€‚å†…å­˜ç¡¬ç›˜æ˜¾å¡è‡ªå·±é…åŽ»å§ã€‚

- [å¯¼å¸ˆç»™äº†10wä¹°æ·±åº¦å­¦ä¹ çš„æœåŠ¡å™¨ï¼Œåªè¦æ±‚2å¼ a6000çš„å¡ï¼Œå…¶ä»–é…ç½®æœ‰ä»€ä¹ˆæŽ¨èä¹ˆï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/628269514)
  - æŽ¨èç”¨å„ä¸ªåŽ‚å®¶çš„å•è·¯æ——èˆ°è§£å†³æ–¹æ¡ˆç›´æŽ¥é€‚é…ã€‚ ä¹Ÿå°±æ˜¯åŸºäºŽAMD Threadripper PROæˆ–è€…å…¨æ–°è‡³å¼ºWç›¸å…³çš„æœ€æ–°å¹³å°ã€‚
  - ä¾‹å¦‚ä¸šå†…éžå¸¸ä¼˜ç§€çš„æˆ´å°”Precision 7960 å¡”å¼ã€‚ æ€§èƒ½ä¸Šé™åº”è¯¥æ˜¯ 56C112Tï¼›4TB DDR5å†…å­˜ï¼ˆ16ä¸ªå†…å­˜æ’æ§½ï¼‰ï¼›æ»¡é…10ä¸ª3.5ç¡¬ç›˜æ§½ä½ï¼›æ»¡é…æœ€å¤§å››å¼ A6000, å±žå®žçš„ä¼˜ç§€
  - æˆ–è€…è¯´7960çš„å°å¼Ÿ5860ä¹Ÿä¸æ˜¯ä¸è¡Œ ï¼Œæ‰©å±•èƒ½åŠ›ç¨å·®ï¼Œä½†æ˜¯æ”¯æŒä¸¤å¼ A6000è¿è¡Œï¼Œåº”è¯¥ä¹Ÿæ˜¯æ²¡å•¥é—®é¢˜çš„ã€‚
  - æˆ–è€…ä¸Šä¸€ä»£Precision 7920ä¹Ÿè¡Œï¼Œè™½è¯´æ˜¯æœ«æœŸç¨æœ‰æ¶¨å¹…ï¼Œä½†æ˜¯æ€§ä»·æ¯”ä¾æ—§æ˜¯å¼ºæ— æ•Œï¼Œæ——èˆ°æ¯•ç«Ÿæ˜¯æ——èˆ°ï¼Œè™½ç„¶è¯´æ˜¯ä¸Šä¸€ä»£ã€‚ä¸è¿‡ä¸¤å¼ A6000ã€‚ã€‚ã€‚ã€‚ è‚¯å®šè¡Œã€‚

- ## [è£…æœºé…ç½®è®¨è®ºï¼Œå•å¡A6000oråŒå¡4090ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/599204652)
- 6000ADAå¤ªè´µï¼Œ6000æ„Ÿè§‰å¤ªè€ï¼Œ4090æ˜¾å­˜æ¯”è¾ƒç´§å¼ ï¼Œé©¬ä¸Š5090å‡ºæ¥ä¹‹åŽï¼Œè‚¯å®š6000å’Œ6000ADAä¼šé™ä»·ï¼Œç”šè‡³å±Šæ—¶5090è¯´ä¸å®šæœ‰32Gæ˜¾å­˜ï¼Œå¯èƒ½æ˜¯æ›´åˆé€‚çš„é€‰æ‹©ã€‚å¾ˆçº ç»“ï¼ŒäºŽæ˜¯ç›®å‰æ‹¿ä¹‹å‰å…¥é—¨æ—¶å€™è´­ä¹°çš„4060Ti16Gåœ¨é¡¶ç€ç”¨ã€‚

- æ®æˆ‘æ‰€çŸ¥ A6000å”¯ä¸€çš„ä¼˜åŠ¿å°±æ˜¯æ˜¾å­˜å¤§ï¼Œå®žé™…ä¸Šè€ƒè™‘å¤§æ˜¾å­˜éƒ½æ˜¯è€ƒè™‘é™ä½Žå¤šå¡å¹¶è¡Œé€šä¿¡å¼€é”€çš„ï¼Œä¸€å¼ ä¹Ÿä½“çŽ°ä¸äº†å¤§æ˜¾å­˜ä¼˜åŠ¿...

- ## [å®žéªŒå®¤é…ç½®æœåŠ¡å™¨ï¼Œ4090ï¼Œa100å’Œa800é€‰å“ªä¸ªï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/595107162/answer/4153401353)
- æµ‹è¯•å‘çŽ°ï¼ŒL40é€Ÿåº¦ä¸Ž4090Dç›¸å½“ï¼Œè¡¨çŽ°ä»¤äººæ»¡æ„ã€‚
  - A100, 40GB, 312 TFLOPS, Â¥90, 000+, 400W, 
  - A6000, 48GB GDDR6, 79 TFLOPS, 300W, Â¥33, 000, 300W
  - 4090, 24GB GDDR6X, 330 TFLOPS, Â¥12, 000, 450W
  - L40, 48GB GDDR6, 147 TFLOPS, Â¥44, 000+, 350W
  - åŽ‚å•†è§£é‡Šï¼Œç”±äºŽä¸­ç¾Žåšå¼ˆçš„åŽŸå› ï¼ŒL40å®£ä¼ ä¸Šæœªå®šä½ä¸ºè®­ç»ƒå¡ï¼Œä½†å®žé™…ç”¨äºŽè®­ç»ƒå®Œå…¨æ²¡é—®é¢˜ã€‚
- è™½ç„¶L40 çš„ FP16 æ€§èƒ½ï¼ˆçº¦ 147 TFLOPSï¼‰åœ¨ç†è®ºä¸Šä¼˜äºŽ A6000ï¼ˆçº¦ 78.75 TFLOPSï¼‰ï¼Œä½†åœ¨å®žé™…è®­ç»ƒå¤§åž‹æ¨¡åž‹æ—¶ï¼Œå®ƒå¹¶ä¸è¢«å¹¿æ³›æŽ¨èï¼ŒåŽŸå› å¦‚ä¸‹:
  - ä¼˜åŒ–ä¸Žè½¯ä»¶æ”¯æŒï¼šæ·±åº¦å­¦ä¹ æ¡†æž¶ï¼ˆå¦‚ TensorFlow å’Œ PyTorchï¼‰é€šå¸¸ä¼šé’ˆå¯¹ç‰¹å®šçš„ GPU è¿›è¡Œæ·±åº¦ä¼˜åŒ–ï¼Œç‰¹åˆ«æ˜¯ A100 å’Œ A6000ã€‚NVIDIA çš„ Ampere æž¶æž„ï¼ˆå¦‚ A100 å’Œ A6000ï¼‰åœ¨è®­ç»ƒæ€§èƒ½ä¸Šå¾—åˆ°äº†å¹¿æ³›è®¤å¯ï¼Œè®¸å¤šè®­ç»ƒç®—æ³•å’Œä¼˜åŒ–å™¨éƒ½é’ˆå¯¹è¿™äº›æ˜¾å¡è¿›è¡Œäº†è°ƒæ•´ã€‚è€Œ L40 çš„æŽ¨ç†ä¼˜åŒ–å¯èƒ½ä¸é€‚åˆè®­ç»ƒä»»åŠ¡ã€‚
  - è®¡ç®—æž¶æž„ï¼šå°½ç®¡ L40 çš„ FP16 æ€§èƒ½è¾ƒé«˜ï¼Œå…¶è®¡ç®—æž¶æž„å’Œç¡¬ä»¶è®¾è®¡å¯èƒ½ä¸å…·å¤‡ A6000 çš„ç‰¹æ€§ï¼Œä¾‹å¦‚ Tensor Cores çš„ä¼˜åŒ–ä½¿ç”¨ã€‚Tensor Cores å¯ä»¥å¤§å¹…æé«˜è®­ç»ƒè¿‡ç¨‹ä¸­çš„è®¡ç®—æ•ˆçŽ‡ï¼Œå°¤å…¶åœ¨å¤§åž‹æ·±åº¦å­¦ä¹ æ¨¡åž‹ä¸­ã€‚

- L40å•å¡è®­ç»ƒæ˜¯æ²¡é—®é¢˜ï¼Œæœ€å¤§é—®é¢˜æ˜¯ä¸æ”¯æŒNvlink
- a6000ä¸æ¯”4090é«˜å¤šå°‘ï¼Œä»·æ ¼é«˜è¿™ä¹ˆå¤š
  - æ˜¾å­˜å¤§

- 4090ä¸æ”¯æŒå¤šå¡å¹¶è”ï¼Œä¹Ÿå°±æ˜¯å¤§æ¨¡åž‹æ˜¯æ ¹æœ¬æ²¡æ³•è®­å¾—ï¼Œå®ƒæ˜¯å•å¡æ€§èƒ½å¼ºï¼ŒåŒæ—¶æ€§ä»·æ¯”é«˜(é˜‰å‰²NVLinkäº†ï¼Œå¤šå¡å¸¦å®½ä¸¥é‡ä¸è¶³)ã€‚
  - a800æ˜¯a100çš„é˜‰å‰²ç‰ˆï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œæœ‰a100é€‰ï¼Œè‚¯å®šä¼˜å…ˆa100ã€‚å› ä¸ºæ˜¯è¦è®­ç»ƒå¤§æ¨¡åž‹ï¼Œå»ºè®®è´­ä¹°sxmç‰ˆæœ¬çš„a100ã€‚

- è¦çŽ©stable diffusionï¼Œç›®å‰çš„ç‰ˆæœ¬4090è¶³å¤Ÿç”¨äº†ï¼Œå…¶ä»–å¤§æ¨¡åž‹å…ˆæ˜Žç™½æžä»€ä¹ˆï¼Œè‡ªå·±è®­ç»ƒè¿˜æ˜¯è·‘è·‘lammaï¼Œglm6bä¹‹ç±»çš„ï¼Œè‡ªå·±è®­ç»ƒç¨å¾®å¤§ç‚¹çš„æ¨¡åž‹åŸºæœ¬éƒ½ä¸å¤Ÿï¼Œå…ˆç®—æ¸…æ¥šå¯¹æ˜¾å­˜çš„éœ€æ±‚ä¸€èˆ¬å°±èƒ½æœ‰å†³å®šäº†ã€‚æ‰€ä»¥ä¸ªäººå»ºè®®ï¼Œä¸çŸ¥é“è·‘ä»€ä¹ˆæˆ–è€…åªè·‘stable diffusionå…ˆä¸Šä¸ª4090ï¼Œåæ­£ä¾¿å®œã€‚æ˜Žç¡®çŸ¥é“æžä»€ä¹ˆï¼Œæ ¹æ®éœ€è¦å¯ä»¥æµ‹ç®—å‡ºæ¥
- 4090ä»Žå¤´è®­ç»ƒå›¾ç‰‡ç”Ÿæˆå¤Ÿç”¨å—ï¼Ÿæœ‰äººå®žè·µè¿‡å—ã€‚è¿™äº›ã€‚
  - æŒ‰åŽŸç‰ˆæ¨¡åž‹åŽŸç‰ˆè®­ç»ƒæ–¹å¼ä»Ž0è®­ä¸å¤ªå¤Ÿï¼ŒåŽŸç‰ˆæ˜¯A100X8X32è®­äº†15ä¸‡GPU Hoursï¼Œæ¯å¼ å¡batch size=8ï¼Œæ€»æ‰¹æ¬¡8X256ï¼Œç²—æš´ç‚¹ç®—24gçš„4090ä¸€ä¸ªæ‰¹æ¬¡åªèƒ½2~3ï¼Œå°±ç®—ä¸è€ƒè™‘æ…¢çš„é—®é¢˜ï¼Œæ‰¹æ¬¡ä¾èµ–ä¹Ÿéœ€è¦å¦å¤–è§£å†³
- é—®é¢˜çš„å…³é”®æ˜¯ä¸ºä»€ä¹ˆè¦ä»Žå¤´è®­ç»ƒï¼ŒåŸºç¡€æ¨¡åž‹ä¸Šå¾®è°ƒè€—è´¹å¾ˆå°çš„èµ„æº
  - æœ‰åˆ›æ–°çš„è¯‰æ±‚ï¼Œç„¶åŽå¾®è°ƒä¸å¤Ÿç”¨(å…·ä½“é¢ä¸´çš„é—®é¢˜å¯èƒ½å’Œå¤§ç¥žä»¬çš„ä¸åŒ)

- ## [åŒa6000å’ŒåŒ4090å“ªä¸ªè®¡ç®—æ›´å¿«å‘¢ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/664827604)
- å°è§„æ¨¡æ•°æ®ï¼Œå•å¡èƒ½è·‘çš„æƒ…å†µï¼Œæ˜¾ç„¶4090æ¯”A6000å¿«çš„å¤šã€‚
  - æ•°æ®è§„æ¨¡å†å¤§ç‚¹ï¼Œè¶…å‡ºäº†åŒå¡çš„å­˜å‚¨ç©ºé—´ï¼Œ4090å°±è·‘ä¸äº†äº†ï¼Œæ¯•ç«ŸA6000ä¸€å—å°±èƒ½é¡¶2/4å—4090å•Šã€‚

- [æ¸²æŸ“å»ºæ¨¡ï¼Œæ˜¯ä¸€ä¸ªA6000ç‰›é€¼è¿˜æ˜¯ä¸¤ä¸ª4090ç‰›é€¼? - çŸ¥ä¹Ž](https://www.zhihu.com/question/658932305)
  - åœ¨ä¸æº¢å‡ºæ˜¾å­˜çš„æƒ…å†µä¸‹æ¸²æŸ“å•4090æ¯”A6000èµ·ç ç‰›é€¼2å€ï¼ŒåŒ4090å°±æ˜¯4å€ï¼Œ
  - gpu-zä¸Šé¢æœ‰æ•°æ®ï¼Œä¸€ä¸ª4090æ˜¯ä¸€ä¸ªa6000çš„140%

- ## [æ·±åº¦å­¦ä¹ ç”¨ä»€ä¹ˆå¡æ¯”è¾ƒç»™åŠ›ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/612568623)
- Nvidiaçš„PCæœºæ˜¾å¡ï¼Œåˆ†ä¸ºä¸‰ä¸ªç³»åˆ—ï¼ŒTeslaç³»åˆ—ï¼ŒQuadroç³»åˆ—ï¼ŒGeforceç³»åˆ—ã€‚ã€‚
  - åŽŸå…ˆåˆ†åˆ«å¯¹åº”ä¸“ä¸šç§‘å­¦è®¡ç®—ï¼Œä¸“ä¸šå›¾å½¢æ˜¾å¡ï¼Œä¸ªäººæ¶ˆè´¹çº§æ˜¾å¡é¢†åŸŸç­‰ã€‚
  - ä»Žä»·æ ¼ä¸Šçœ‹ï¼ŒåŒç­‰ç®—åŠ›çš„ä»·æ ¼å·®ä¸å¤šæ˜¯4ï¼š2ï¼š1ã€‚
- åœ¨ç®—åŠ›å·®ä¸å¤šçš„æƒ…å†µä¸‹ï¼ŒTeslaå’ŒQuadroç³»åˆ—çš„æº¢ä»·æº¢åœ¨å“ªé‡Œäº†å‘¢ï¼Ÿ
  - ä¸»è¦æ˜¯ç¨³å®šæ€§ï¼ˆåŠ äº†ECCçº é”™æœºåˆ¶ï¼‰ï¼Œæ˜¾å­˜æ•ˆçŽ‡æ›´é«˜ï¼ˆHBM2 vs GDDRï¼‰, æ˜¾å­˜å®¹é‡æ›´å¤§ï¼ˆä¸€èˆ¬Geforceå¡æ˜¾å­˜åœ¨10Gå·¦å³ï¼Œä½†Quadroå’ŒTeslaä¸€èˆ¬éƒ½æ˜¯24Gï¼Œç”šè‡³48Gï¼Œè¿˜æœ‰å¡é—´äº’è”æŠ€æœ¯NVlinkç­‰ï¼‰ã€‚
  - ä¸ªäººç”¨çš„è¯ï¼ŒGeforceå°±å·®ä¸å¤šäº†ï¼Œå¦‚ä¸Šä¸€ä»£çš„3090ï¼Œä»·æ ¼ï½ž13000Â¥ï¼Œç®—åŠ›ä¹Ÿè¶³
  - å¯ä»¥ä¸ŠA6000ï¼Œï½ž30000Â¥ï¼Œä¹Ÿè¿˜ä¸é”™
- åœ¨CES 2025å±•è§ˆä¼šä¸Šï¼Œè‹±ä¼Ÿè¾¾å‘å¸ƒçš„é‡‡ç”¨Blackwellæž¶æž„çš„æ˜¾å¡æ˜¯GeForce RTX 50ç³»åˆ—ï¼ŒåŒ…æ‹¬RTX 5090ã€RTX 5080ã€RTX 5070Tiå’ŒRTX 5070ç­‰åž‹å·ï¼Œå¯¹æ ‡40xxçš„æ˜¾å¡
  - Teslaç³»åˆ—ï¼ŒæŽ¨å‡ºäº†B200ï¼Œç»™æ•°æ®ä¸­å¿ƒç”¨çš„ï¼Œæ­»è´µæ­»è´µã€‚
  - ç›®å‰æš‚æœªæœ‰Quadroç³»åˆ—çš„æœ€æ–°æž¶æž„æ˜¾å¡å‘å¸ƒï¼Œè¿™ä¸ªç³»åˆ—å›½å†…å¯ç”¨çš„æœ€é«˜é…ç½®æ˜¯Ada5880, å¤§æ¦‚5ä¸‡å—ä¸€å¼ å§ï¼Œæ¬¡ä¸€ç‚¹å¯ç”¨Ada 5000, 3ä¸‡å¤šä¸€å¼ å§ã€‚ã€‚

- çŽ°åœ¨è¡Œæƒ…ä¸å¥½ï¼Œä»·æ ¼ä¸‘é™‹ã€‚åˆ«è¯´4090äº†ï¼Œå°±è¿ž3090ä¹Ÿæ¶¨ä»·äº†ä¸å°‘ã€‚å¹²è„†æžé­”æ”¹2080tiå§22Gçš„ã€‚æ”¹å¥½çš„ä¸€å¼ 2500å—é’±ï¼Œä¹°3å¼ ä¹Ÿå°±çŽ°åœ¨ï¼ˆ2023.11.4å·ï¼‰ä¸€å¼ 3090çš„é’±ã€‚ç„¶åŽä¸Šæ´‹åžƒåœ¾è‡³å¼ºx99å¹³å°ï¼ŒæœåŠ¡å™¨å†…å­˜éšä¾¿æ’æ»¡128gã€‚ç”µæºç”¨çŸ¿ç”µæº1600wï¼Œåæ­£æ”¾å®žéªŒå®¤ï¼Œä¸å¿ƒç–¼ã€‚
  - æˆ‘åŠä¸ªæœˆå‰æƒ³ä¹°4090ï¼Œå•†å®¶ä¸å‘è´§ã€‚åªèƒ½é€€æ¬¾ï¼Œå½“å¤©æ™šä¸Šç«‹é©¬åŽ»é—®rtx a6000èƒ½ä¸èƒ½å‘è´§ï¼Œå½“æ—¶2w6çš„ä»·æ ¼ã€‚é‚£ä¼šå•†å®¶è¿˜æ²¡ååº”è¿‡æ¥ã€‚åªæ˜¯æ™šä¸Šä¸å‘è´§ï¼Œå‡‰å‡‰ã€‚ç¬¬äºŒå¤©å•†å®¶å·²ç»æ”¹ä»·æˆ3wäº†ã€‚

- H100 ï¿¥23.5W, A100 ï¿¥13Wï¼Œä½†çŽ°åœ¨ä¸€èˆ¬äººæˆ–å…¬å¸ä¸å¥½ä¹°äº†ï¼Œå·²ç»è¢«ç¦è´­äº†

- ## [æœ‰æ²¡æœ‰ä¾¿å®œç‚¹çš„AIç®—åŠ›æ˜¾å¡? - çŸ¥ä¹Ž](https://www.zhihu.com/question/634145498)
- 2080ti 22Gï¼Œä»…éœ€2000å‡ºå¤´
- 3080 20Gï¼Œ3090 24G ä¾¿å®œä¸”æ”¯æŒbf16

- è¦ä¾¿å®œï¼Œå¤§æ˜¾å­˜ï¼ŒL40ç³»åˆ—çœ‹çœ‹ã€‚è‹±ä¼Ÿè¾¾Ada Lovelace æž¶æž„ï¼Œ48GBæ”¯æŒECCçš„GDDR6æ˜¾å­˜ï¼Œä¸¤è€…çš„æ˜¾å­˜å¸¦å®½éƒ½æ˜¯864GB/S, 
  - L40Sä½œä¸ºL40çš„å‡çº§ç‰ˆæœ¬ï¼Œä¸»è¦åœ¨FP32è¿ç®—èƒ½åŠ›æç¤ºå¹…åº¦ä¸º1.1TFLOPSï¼Œåœ¨TF32 Tensor Core TFLOPSã€FP16 Tensor Coreã€FP8 Tensor Coreã€INT8 Tensor Coreè¿ç®—èƒ½åŠ›å‡æå‡ ä¸€å€å·¦å³ã€‚

- è¦ä¾¿å®œï¼Œå¤§æ˜¾å­˜ï¼Œp40æœ€åˆé€‚ã€‚24gæ˜¾å­˜ï¼Œä»·æ ¼800å·¦å³å°±å¯ä»¥å…¥æ‰‹ã€‚è®°å¾—ä¸€èµ·ä¹°é£Žæ‰‡å’Œç”µæºè½¬æŽ¥çº¿ã€‚
  - 900å—æ‹¿ä¸‹è¿‡p100ï¼Œæ„Ÿè§‰å·²ç»æ˜¯å¹³æ°‘ä»·é‡Œé¢æœ€å¥½æ€§èƒ½çš„äº†ï¼Œè¿˜æœ‰hmbæ˜¾å­˜ã€‚

- ç§Ÿäº‘æœåŠ¡å‘€ï¼Œèƒ½é€‰çš„ä¸“ä¸šå¡å¤šè¿˜èƒ½å¼€ç¥¨è®©è€å¸ˆèµ°ç»è´¹

- ## [4090 é­”æ”¹ 48g æ˜¾å­˜æ˜¯æ€Žä¹ˆåšåˆ°çš„ï¼Ÿ - çŸ¥ä¹Ž _202502](https://www.zhihu.com/question/11803840385)
- 4090æ˜¾å¡æœ‰ä¸¤ä¸ªå…„å¼Ÿï¼Œå«åšl40så’Œa6000 adaï¼Œéƒ½ç”¨çš„ad102å†…æ ¸ï¼Œè¿™ä¸¤ä¸ªå…„å¼Ÿæ˜¾å­˜éƒ½æ˜¯48gçš„ã€‚
  - æ²¡æœ‰a6000 adaï¼Œè¦ä¹ˆæ˜¯30ç³»çš„a6000ï¼Œè¦ä¹ˆæ˜¯40ç³»çš„6000 adaã€‚æˆ‘ä¹‹å‰ä¹Ÿæžé”™è¿‡ã€‚

- é­”æ”¹çš„4090 48Gä»·æ ¼æ˜¯2ä¸‡2å·¦å³ï¼ˆç»™æ–™çš„åŠ å·¥è´¹æ˜¯5.5kå·¦å³ï¼‰ï¼ŒåŒä¸€ä»£ï¼ˆ40ç³»æ˜¾å¡ï¼‰æ ¸å¿ƒçš„6000 ada 48Gè¦5ä¸‡2å·¦å³ï¼Œä¸Šä¸€ä»£ï¼ˆ30ç³»æ˜¾å¡ï¼‰æ ¸å¿ƒçš„A6000 48Gæ˜¯3ä¸‡2å·¦å³

- 3090èŠ¯ç‰‡å‘å”®æ—¶ï¼Œæ˜¾å­˜é¢—ç²’æœ€å¤§1GBï¼Œ24GBæ˜¾å­˜éœ€è¦24é¢—ï¼ŒPCBæ¿æ­£åé¢éƒ½æœ‰ã€‚
  - 4090èŠ¯ç‰‡å‘å”®æ—¶ï¼Œæ˜¾å­˜é¢—ç²’è¾¾åˆ°2GBï¼Œ24GBæ˜¾å­˜åªéœ€è¦12é¢—ï¼ŒPCBæ¿åªæœ‰ä¸€é¢æœ‰ç„Šç›˜ã€‚
  - æµå‡ºçš„4090 48GBæ”¹ç‰ˆæ˜¾å¡biosï¼Œæ­£å¥½å‘çŽ°4090é’ˆè„šå®šä¹‰å’Œ3090ä¸€æ ·ï¼Œå¯ä»¥ç„Šåœ¨3090PCBä¸Š
  - è¿™æ ·4090èŠ¯ç‰‡+3090PCB+24é¢—2GBæ˜¾å­˜+æµå‡ºé­”æ”¹æ˜¾å¡bios=4090 48GBæ˜¾å¡ã€‚
  - æ˜¾å¡bioså¤§æ¦‚çŽ‡ä¸æ˜¯x86æŒ‡ä»¤ï¼Œå¦åˆ™æ—©å°±æœ‰ä¸ªäººé­”æ”¹ç‰ˆï¼Œè¯±æƒ‘å¤ªå¤§äº†ã€‚
- æœ‰èƒ½åŠ›æ”¹çš„ï¼Œå¤§æ¦‚çŽ‡ä¸æƒ³å¾—ç½ªè‹±ä¼Ÿè¾¾ã€‚æ‰€ä»¥è¿™ç§åªèƒ½å·å·æžï¼Œæ²¡ä¿éšœ

- å®ƒå°±æ˜¯ä¸ªæ··åˆä½“ï¼š4090æ ¸å¿ƒ+3090çš„PCBæ¿+24é¢—2GBæ˜¾å­˜é¢—ç²’ï¼Œè€Œä¸”è¿˜æœ‰ä¸‹é¢å‡ ä¸ªå·§åˆï¼Œä»»ä½•ä¸€ä¸ªå¤±æ•ˆéƒ½ä¸æˆç«‹ï¼š
  - 4090çš„æ ¸å¿ƒå’Œ3090çš„æ ¸å¿ƒé’ˆè„šä¸€æ ·ï¼Œæ‰€ä»¥å®ƒå¯ä»¥ç„Šåˆ°3090çš„PCBæ¿å­ä¸Šå¹¶è¢«è¯†åˆ«ï¼›
  - 3090ç”¨çš„æ˜¯24*1GBçš„æ˜¾å­˜é¢—ç²’ï¼Œæ¿å­æ²¡æœ‰é™åˆ¶æ˜¾å­˜é¢—ç²’å®¹é‡ï¼Œå¯ä»¥æ¢æˆ2GBçš„ï¼›
  - NåŽ‚å†…éƒ¨æµå‡ºäº†æ˜¾å­˜é©±åŠ¨ã€æ˜¾å¡å›ºä»¶å±…ç„¶èƒ½å®Œç¾Žæ”¯æŒã€‚

- ç½‘ä¸Šæµ‹è¯„æ˜¾ç¤º4090 48G æ˜¾å¡è¿˜å¯ä»¥æ”¯æŒ FP8ï¼Œç”šè‡³è¿™æ¬¾æ˜¾å¡ä¹Ÿå·²ç»å‡ºèµ°æµ·å¤–ï¼Œæ¥è‡ªåŠ æ‹¿å¤§çš„å°å“¥åœ¨å¹³å°ä¸Šæ™’å‡ºäº†è‡ªå·±åœ¨ eBay ä¸Šä¹°çš„ RTX 4090 48Gï¼Œå”®ä»·è¦ 3 ä¸‡äººæ°‘å¸èµ·æ­¥ã€‚

- ä¸å¾—ä¸ä½©æœçš®è¡£åˆ€å®¢çš„åˆ€æ³•äº†ã€‚ç§‘æŠ€æ˜¯ç¬¬ä¸€ç”Ÿäº§åŠ›ï¼Œåˆ€å®¢åœ¨é€†å¤©è€Œè¡Œã€‚
  - çš®åˆ€å®¢ç›®æ ‡åœ¨äºŽèµšé’±ï¼Œ å‘å±•ç”Ÿäº§åŠ›åªæ˜¯ä½ æƒ³æ³•è€Œå·²ï¼Œäººå®¶æ‰ä¸ç®¡ä½ å‘å±•ç‹—å±ç”Ÿäº§åŠ›å‘¢

- å’Œ3090åŒä¸€çº§åˆ«çš„ä¸“ä¸šå¡æ˜¯RTX A6000ï¼Œ48Gæ˜¾å­˜ï¼Œå…¶å®ƒå‚æ•°å’Œ3090å·®ä¸å¤šçš„ï¼ŒçŽ°åœ¨çš„å”®ä»·ä»ç„¶æ˜¯3ä¸‡å…ƒ
  - å’Œ4090åŒä¸€çº§åˆ«çš„ä¸“ä¸šå¡æ˜¯RTX 6000ADAï¼Œ48Gæ˜¾å­˜ï¼ŒCudaæ ¸å¿ƒæ¯”4090å¤šçº¦2000ä¸ªï¼Œå”®ä»·çŽ°åœ¨6ä¸‡å…ƒï¼›
  - ç•¥ä½Žä¸€ä¸ªçº§åˆ«çš„RTX 5880ADAï¼ŒCudaæ ¸å¿ƒæ¯”4090å°‘çº¦2000ä¸ªï¼Œå”®ä»·åœ¨5ä¸‡å·¦å³ï¼› 
  - æ‰€ä»¥4090 48G 2.3Wçš„å”®ä»·ï¼Œæ€§ä»·æ¯”æžé«˜

- a100æ€§èƒ½è¿œä¸å¦‚4090
  - 4090æŽ¨ç†çŽ‹è€…

- é©±åŠ¨ï¼Ÿå¡çš„biosæ‰æ›´é‡è¦
  - ä½ è¯´å¾—å¯¹

- å…¶å®žå°±æ˜¯ä¼ è¨€æµå‡ºæ¥é‚£ç‰ˆvbiosï¼Œæ²¡æœ‰é‚£ç‰ˆvbiosï¼Œå°±æ²¡æœ‰åŽç»­48Gã€‚
  - vbiosæœ‰æ•°å­—ç­¾åä¼šå’ŒèŠ¯ç‰‡å†…çš„å®‰å…¨èŠ¯ç‰‡ä½œç›¸äº’æ ¡éªŒï¼Œå› æ­¤ç»•ä¸è¿‡åŽ»ï¼Œè€Œåœ¨2023å¹´æµå‡ºæ¥äº†ä¸€ä¸ªå·¥å…·ï¼Œå¯ä»¥æŠŠä¸åŒå“ç‰Œçš„vbiosï¼ˆæœ‰æ•°å­—ç­¾åç‰ˆï¼‰äº’åˆ·ï¼Œæ‰€ä»¥æ‹¿åˆ°48Gçš„vbioså°±ç­‰äºŽæœ‰äº†48Gçš„4090ï¼Œæ— éžæ˜¯å¦‚ä½•æ¬æ¿ï¼Œç”šè‡³æœ‰èƒ½åŠ›å¯ä»¥é‡æ–°è®¾è®¡ä¸€å¼ pcbæ¥æ‰©å¼ ï¼Œæ¢å¥è¯è¯´ï¼Œå¦‚æžœæœªæ¥æœ‰æ›´å¤§æ˜¾å­˜å®¹é‡çš„biosæµå‡ºï¼ŒåŽŸåˆ™ä¸Šä¹Ÿå¯ä»¥åšæ›´å¤§æ˜¾å­˜çš„å¡ã€‚
  - vbiosç­¾åæ˜¯ä¸ŽGPUèŠ¯ç‰‡å†…å®‰å…¨ç»„ä»¶è¿›è¡Œæ ¡éªŒï¼Œæ ¡éªŒé€šè¿‡æ—¶ï¼ŒGPUæ‰ä¼šå®Œå…¨åˆå§‹åŒ–ã€‚

- æ—¢ç„¶4090 48Gæ˜¯ç”¨3090çš„PCBæ¿é­”æ”¹çš„ é‚£ä¸ºä»€ä¹ˆå¸‚é¢ä¸Šéƒ½æ²¡è§åˆ°é­”æ”¹3090 48Gçš„ï¼ŸæŒ‰ç†æ¥è¯´3090æˆæœ¬æ¯”4090ä½Žå¾—å¤šå•Š
  - 30ç³»æ²¡æœ‰å¯¹ä½çš„48gè®¡ç®—å¡ï¼Œbiosä¼šå¡ä½ç‚¹ä¸äº®ã€‚é—²é±¼ä¸Šæœ‰å¾ˆå¤š3090èŠ¯ç‰‡è½¬ç§»åˆ°4090pcbä¸Šçš„å¡ï¼Œä»·æ ¼è¿˜æŒºå®žæƒ ï¼Œæ•¢ä¹°çš„äººä¸å¤šã€‚
- å› ä¸º3090æ²¡æœ‰48Gçš„BIOSæµå‡ºã€‚4090çš„AD102æ ¸å¿ƒè¿˜ç”¨äºŽada6000ç­‰ä¸“ä¸šæ˜¾å¡ï¼Œå‡ºåŽ‚æ˜¾å­˜å°±æ˜¯48Gï¼Œè¯´æ˜ŽAD102æ˜¯å¯ä»¥å…¼å®¹48Gæ˜¾å­˜çš„ï¼Œ

- ## [ä¸ºä»€ä¹ˆNå¡ä¸€å®šè¦å¸¦cuda? - çŸ¥ä¹Ž](https://www.zhihu.com/question/592464568)
- cudaåˆä¸æ˜¯ç¡¬ä»¶â€¦â€¦toolkitæƒ³è£…å°±è£…ï¼Œä¸å¸¦ä¹Ÿä¸ä¼šå½±å“æ‰“æ¸¸æˆ
  - å¯¹äºŽnå¡æ¥è¯´ï¼Œcudaæœ¬æ¥å°±ç®—æ˜¯å¢žå€¼æœåŠ¡ï¼Œå¯¹äºŽå¾ˆå¤šå¼€å‘è€…æ¥è¯´æä¾›äº†å¥½ç”¨åˆé«˜æ•ˆçš„å¼€å‘æŽ¥å£ã€‚
  - æˆ‘æ˜¯ä¸è®¤åŒæŠŠnå¡å’Œcudaåˆ’ç­‰å·ã€‚ä½†æ˜¯cudaæ˜Žæ˜¾å·²ç»å½¢æˆäº†å¼€å‘è€…å¥½å¼€å‘-ä½¿ç”¨è€…ä½“éªŒé«˜-Nå¡å æœ‰çŽ‡é«˜çš„è‰¯æ€§å¾ªçŽ¯ã€‚

- å› ä¸ºçŽ°åœ¨çš„æ˜¾å¡çš„å¯ç¼–ç¨‹ç®¡çº¿éƒ½æ˜¯é€šç”¨çš„ã€‚é™¤åŽ»å…‰æ …å™¨ç­‰å°‘æ•°éƒ¨åˆ†ï¼Œåƒé¡¶ç‚¹ç€è‰²å™¨ç­‰ç­‰ï¼Œé©±åŠ¨åº•å±‚å’Œç¡¬ä»¶è®¡ç®—å•å…ƒå’ŒCUDAå…¶å®žéƒ½æ˜¯å…±ç”¨ä¸€å¥—ä¸œè¥¿ã€‚

- è‡³äºŽè¯´AMDæ²¡æœ‰CUDAï¼Œä½†æ˜¯AMDæœ‰ROCmå’ŒOpenCLå•Šã€‚åªä¸è¿‡å› ä¸ºè½¯ä»¶æ”¯æŒå·®ï¼Œä¸å¥½ç”¨ï¼Œç”¨çš„äººå°‘è€Œå·²ã€‚

- ## [æ˜¯å¦å­˜åœ¨æ”¯æŒcudaçš„æ ¸æ˜¾è½»è–„æœ¬ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/663409299)
- ä¸å­˜åœ¨ã€‚cudaæ˜¯è‹±ä¼Ÿè¾¾ç‹¬æ˜¾çš„ï¼ŒNå¡ç‹¬å ï¼Œæ˜¯ç‹¬æ˜¾çš„åŠŸèƒ½ã€‚æ ¸æ˜¾æ˜¯åŸºäºŽCPUçš„ï¼Œè€ŒCPUæ˜¯å› ç‰¹å°”å’ŒAMDè¿™ä¸¤å®¶çš„ã€‚
- ä¸å­˜åœ¨ã€‚Cudaæ˜¯è‹±ä¼Ÿè¾¾è‡ªç ”çš„åªæ”¯æŒè‡ªå®¶æ˜¾å¡çš„ç®—æ³•ã€‚æ ¸æ˜¾æ˜¯Intelå’ŒAMD CPUè‡ªå¸¦çš„ã€‚è‹±ä¼Ÿè¾¾å¹¶ä¸ç”Ÿäº§ç¬”è®°æœ¬çš„CPUã€‚

- CUDAæ˜¯è‹±ä¼Ÿè¾¾ç‹¬å®¶ï¼Œç›®å‰æ ¸æ˜¾è½»è–„æœ¬æ˜¯Intelå’ŒAMDï¼Œè‡ªç„¶çŽ°åœ¨å¸‚é¢ä¸Šæ‰¾ä¸åˆ°æ”¯æŒCUDAçš„æ ¸æ˜¾è½»è–„æœ¬ã€‚
  - çŽ°åœ¨çš„Intelã€AMDç”šè‡³é«˜é€šä¸»æŽ¨çš„AI PCå…¨é NPUï¼Œä½†æ˜¯ç›®å‰åº”ç”¨è½¯ä»¶å±‚é¢èƒ½å¤Ÿè°ƒç”¨NPUçš„å¯¥å¯¥æ— å‡ ã€‚
  - è€ŒCUDAæ”¯æŒå„ä¸ªè½¯ä»¶åº”ç”¨çš„æ”¯æŒæ˜¾ç„¶æ›´åŠ å¹¿æ³›ã€‚åˆ°æ—¶å€™å¤§æ¦‚çŽ‡ä¼šå‡ºçŽ°è‹±ä¼Ÿè¾¾çš„æ ¸æ˜¾æœ¬æ‰æ˜¯çœŸæ­£æ„ä¹‰ä¸Šçš„AI PCã€‚
  - ç›®å‰è‹±ä¼Ÿè¾¾çš„GPUä¸€å¤§é—®é¢˜æ˜¯æ˜¾å­˜å®¹é‡è¾ƒå°ï¼Œæ¯”å¦‚ä¸»æµçš„ç”œç‚¹æ¸¸æˆå¡RTX 4060å°±æ˜¯8GBæ˜¾å­˜ã€‚çŽ°é˜¶æ®µè·‘æœ¬åœ°çš„LLMã€Stable diffusionç“¶é¢ˆå¹¶ä¸åœ¨å¤šå°‘å¤šå°‘TOPSçš„ç®—åŠ›ï¼Œè€Œåœ¨äºŽå¾ˆå®¹æ˜“çˆ†æ˜¾å­˜ï¼Œä½ è¿žè·‘éƒ½è·‘ä¸èµ·æ¥ã€‚
  - æœªæ¥è‹±ä¼Ÿè¾¾è‡ªå·±çš„æ ¸æ˜¾æœ¬ï¼Œå¯ä»¥å…±äº«å†…å­˜ï¼Œæœ¬åœ°çš„å¤§æ¨¡åž‹å’ŒAIåº”ç”¨å¯èƒ½æ‰ä¼šçœŸæ­£å‘å±•èµ·æ¥ã€‚

- ## [ä¸ºä»€ä¹ˆè¯´CUDAæ˜¯NVIDIAçš„æŠ¤åŸŽæ²³? - çŸ¥ä¹Ž](https://www.zhihu.com/question/564812763)
- è‹±ä¼Ÿè¾¾ä»Žcudaé‡Œå­¦åˆ°çš„æœ€é‡è¦çš„ä¸€è¯¾ï¼Œå°±æ˜¯è½¯ç¡¬ä»¶æ†ç»‘ã€‚
  - è®¡ç®—ç•Œcudaä¹‹æ‰€ä»¥åŽ‰å®³ï¼Œä¸ä»…ä»…æ˜¯å› ä¸ºå®ƒå¯ä»¥è°ƒç”¨GPUè®¡ç®—ï¼Œè€Œæ˜¯å®ƒå¯ä»¥è°ƒç”¨GPUç¡¬ä»¶åŠ é€Ÿã€‚
  - physXä¹Ÿæ˜¯ï¼ŒNå¡é™å®šã€‚ ç”šè‡³äºŽè¯´ï¼Œå¦‚æžœéœ€æ±‚é‡å¤Ÿå¤§ï¼Œè‹±ä¼Ÿè¾¾æŠŠä¸‰ç»´ä½“ç§¯çš„æœ‰é™å·®åˆ†æ“ä½œï¼Œæœ‰é™å…ƒçš„æ£€æµ‹å‡½æ•°ç§¯åˆ†æ“ä½œï¼Œå…¨åšæˆâ€œç”µè·¯æ¿è®¡ç®—â€ä¹Ÿä¸æ˜¯ä¸å¯ä»¥ã€‚ åŒæ—¶é…åˆç€è‡ªå·±çš„è½¯ä»¶ä½“ç³»ä¸€èµ·å¾€å¤–æŽ¨ã€‚
  - è¿™æ‰æ˜¯è‹±ä¼Ÿè¾¾çœŸæ­£çš„ç»„åˆæ‹³ã€‚ åœ¨è¿™å¥—ç»„åˆæ‹³ä½“ç³»ä¸‹ï¼Œcudaæ‰®æ¼”ç€èƒ¶æ°´çº§æ ¸å¿ƒèˆªæ¯çš„è§’è‰²ã€‚è¿˜æœ‰å…¶å®ƒæŠ¤å«èˆ°ï¼Œè€Œè¿™äº›æŠ¤å«èˆ°éƒ½ç»•ä¸å¼€ã€‚

- 2007å¹´6æœˆï¼ŒCUDAå‘å¸ƒã€‚åœ¨Nvidiaçš„æŒç»­ç²¾è€•ç»†ä½œä¸‹ï¼ŒCUDAå·²ç»æˆäº†ç§‘å­¦è®¡ç®—é¢†åŸŸçš„äº‹å®žæ ‡å‡†ã€‚
  - ç­‰ç¥žç»ç½‘ç»œç®—æ³•ç«äº†ï¼ŒNvidiaåˆå¤§åŠ›æ”¯æŒï¼Œå„å¤§AIæ¡†æž¶å› æ­¤ä¼˜å…ˆæ”¯æŒCUDAï¼Œå½¢æˆäº†æ­£å¾ªçŽ¯ã€‚
  - ä¹‹åŽï¼ŒNvidiaåˆå‘åŠ›ä¸ŽAIå…³ç³»ç´§å¯†çš„è‡ªåŠ¨é©¾é©¶å’Œæœºå™¨äººé¢†åŸŸï¼ŒæŽ¨å‡ºäº†é’ˆå¯¹æ±½è½¦çš„Driveç³»åˆ—èŠ¯ç‰‡å’Œé’ˆå¯¹å·¥ä¸šæœºå™¨äººçš„Jetsonç³»åˆ—ã€‚
  - è¿™ä¸€åˆ‡ï¼Œéƒ½æ˜¯ä»¥CUDAä½œä¸ºè½¯ä»¶åˆ‡å…¥ç‚¹ï¼Œæœ€ç»ˆï¼ŒCUDAå°±æˆäº†ä»Šå¤©çš„æ ·å­ï¼Œå˜æˆäº†åˆæ·±åˆå®½çš„æŠ¤åŸŽæ²³ã€‚

- amdæŠ›å¼ƒopencläº†ï¼ŒæŽ¨ä»–è‡ªå®¶çš„rocm

- ç”¨fpgaã€ç”šè‡³æ˜¯æ›´å®šåˆ¶åŒ–çš„asicæ¥åŠ é€Ÿï¼Œæ—©å°±æœ‰äº†ï¼Œæ€§èƒ½è¶…è¿‡nvidiaçš„åŒç±»äº§å“æ¯”æ¯”çš†æ˜¯ï¼Œé—®é¢˜è¿˜æ˜¯ç”Ÿæ€å’Œæ€»æ‹¥æœ‰æˆæœ¬ã€‚googleä¹Ÿåšäº†TPUï¼Œåœ¨å†…éƒ¨ç”¨å¾—ä¹Ÿä¸å°‘ï¼Œç”Ÿæ€è¿˜æ˜¯å¹²ä¸è¿‡CUDAã€‚æ€§èƒ½æœ‰æ—¶å€™å¹¶ä¸æ˜¯å†³å®šæ€§å› ç´ ã€‚
# discuss-laptop-win/linux
- tips
  - é€‰æ‹©ç¬”è®°æœ¬çš„ä¸€ä¸ªé‡è¦å› ç´ æ˜¯å”®åŽç»´ä¿®ï¼Œå¤§åŽ‚ä¼šå®¹æ˜“å¾ˆå¤šå¦‚è”æƒ³ã€æƒ æ™®

- ## 

- ## 

- ## 

- ## 

- ## 

- ## 

- ## ðŸ§© [ä¸ºä»€ä¹ˆéƒ½æ²¡æœ‰äººæŽ¨èå‡†ç³»ç»Ÿç¬”è®°æœ¬ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/432305670)
- å…ˆè¯´ç»“è®ºï¼šå½“å‰çŽ¯å¢ƒä¸‹ï¼Œå·²ç»æ²¡å¿…è¦å†æŽ¨èå‡†ç³»ç»Ÿç¬”è®°æœ¬
  - å”®åŽç¨€çƒ‚ï¼Œå…¨çœ‹å•†å®¶è‰¯å¿ƒï¼Œå‡†ç³»ç»Ÿè¦æ±‚ç”¨æˆ·æœ‰ä¸€å®šè§£å†³é—®é¢˜çš„èƒ½åŠ›
  - CPUæ¥è·¯ä¸æ­£ï¼Œæš´åˆ©ä¸”ä¸ç¨³å®šï¼Œå‡†ç³»ç»Ÿå› ä¸ºä¸æ˜¯æ­£è§„çš„OEMåŽ‚å•†ï¼Œæ— æ³•ä»Žè‹±ç‰¹å°”é‡‡è´­æ­£è§„çš„ç¬”è®°æœ¬CPUï¼Œå› æ­¤åªèƒ½ä½¿ç”¨æµ‹è¯•ç‰ˆ
  - åŽ‚å®¶å‡†å¤‡äº²è‡ªä¸‹åœºè§’é€ï¼Œå½“æ—¶å‡†ç³»ç»Ÿä¸»è¦ä¸ºå¾®æ˜Ÿå’Œè“å¤©ä¸¤å®¶ï¼Œçœ‹åˆ°é«˜æ€§èƒ½ç¬”è®°æœ¬è¿™ä¹ˆä¸€å—å¤§è›‹ç³•ï¼Œæœ‰ç ”å‘å®žåŠ›åˆæœ‰æ¸ é“åˆæœ‰æŽ¨å¹¿èƒ½åŠ›çš„åŽ‚å®¶è‡ªç„¶ä¸ç”˜å¿ƒç»™äººåšå«è¡£ã€‚åŽæ¥çš„å¾®æ˜Ÿå¤§å®¶ä¹Ÿçœ‹åˆ°äº†ï¼Œå·²ç»æˆä¸ºå‡ å¤§Gamingç¬”è®°æœ¬å“ç‰Œä¹‹ä¸€ï¼Œè“å¤©åˆ™æŠ±ç´§ç¥žèˆŸå¤§è…¿ã€‚è¿™äº›åŽŸæœ¬çš„å‡†ç³»ç»Ÿä¾›è´§å•†å¼€å§‹æ›´æ–°è‡ªæœ‰å“ç‰Œï¼Œå¯¹å…¬æ¨¡çš„æŠ•å…¥è¶Šæ¥è¶Šå°‘ï¼Œä»¥è‡³é€æ¸è¡°è½ã€‚
  - ç¬”è®°æœ¬äº§å“çš„æ‹“å±•æ€§è¶‹è¿‘äºŽ0ï¼ŒçŽ°åœ¨é™¤æžå°‘æ•°ç¬”è®°æœ¬ï¼ŒCPUå’Œæ˜¾å¡å·²ç»ä¸å¯æ›´æ¢ï¼Œå‡†ç³»ç»Ÿä¹Ÿæ˜¯å¦‚æ­¤ï¼Œæ›¾ç»å¼•ä»¥ä¸ºå‚²çš„æ‹“å±•æ€§ä¹Ÿé£Žå…‰ä¸å†ã€‚
  - ä»·æ ¼ä¼˜åŠ¿ä¸å¤ï¼Œæ‹¿é¢˜ä¸»çš„å‚è€ƒï¼Œæˆ‘æ‰¾åˆ°äº†æ·˜å®æŸå‡†ç³»ç»Ÿåº—å®¶æ¨¡å…·ä¸ºNH55(æ˜¯åŒçº§åˆ«æ•£çƒ­æœ€å¥½çš„æ¨¡å…·ï¼Œå †çƒ­ç®¡åŠ æš´åŠ›æ‰‡å˜›)ï¼Œä»¥R7-3700Xï¼ˆ8æ ¸16çº¿ç¨‹ï¼Œå¯¹ä½R7-4800Hï¼‰ 16GBå†…å­˜ 512Gå›ºæ€ RTX 2060é…ç½®ä¸¾ä¾‹ï¼Œè¿™ä¸ªä»·ä½çš„äº§å“éƒ½æœ‰å“ªäº›å‘¢

- çŽ°åœ¨å›½å†…è“å¤©å‡†çš„ä»£ç†åªæœ‰èˆ¹å‡†å’ŒæŽç²ªå‡†ï¼Œå‰è€…åŒæ¨¡å…·ï¼Œç¥žèˆŸæ‹¼å¥½çš„skuæ¯”å‡†åˆ’ç®—ä¸å°‘ï¼Œç¥žèˆ¹è™½ç„¶ä¹Ÿæ˜¯å–œæ¬¢æŠ å›ºæ€ï¼Œä½†è‡³å°‘ä¹Ÿç»™ä½ ä¿ä¿®ã€‚tfå‡†å°±ä¸è¯´äº†åªæœ‰æ›´è´µã€‚
  - è¿™å¹´å¤´è‰¯å¿ƒå‡†å•†ä¸æ˜¯æ²¡æœ‰ï¼ŒæŸä¸ªæ¸©å·žèŒå¦¹å’Œå—äº¬æµ·é²œä¼¼ä¹Žè¿˜åœ¨åšæŒï¼Œä½†æ˜¯ä»·æ ¼ä½ ä¹Ÿçœ‹å¾—åˆ°ï¼Œå¤§å¤šæ•°å‡†å•†ç ´äº§çš„ç ´äº§è·‘è·¯çš„è·‘è·¯ï¼Œè½¬åž‹å°å¼æœºçš„ä¹Ÿæœ‰ï¼Œè‡ªå·±ç”³è¯·äº†ä¸€ä¸ªç‰Œå­è¯•å›¾æ´—ç™½çš„ä¹Ÿæœ‰ã€‚
  - æ€»è€Œè¨€ä¹‹ï¼Œå°±æ˜¯æ—¶ä»£å˜äº†ï¼Œæœ‰é è°±æ­£è§„è“å¤©ä»£ç†å•†ï¼Œä¸ºå•¥è¦åŽ»ä¹°è¿žç¨Žéƒ½ä¸äº¤çš„æ²¡æœ‰ä¿éšœçš„å°åº—äº§å“ã€‚ã€‚ã€‚

- å‡†ç³»ç»Ÿçš„æ­»äº¡é˜¶æ®µä¸»è¦ç»åŽ†äº†2æ¬¡æš´å‡»ã€‚
  - ç¬¬ä¸€æ¬¡æš´å‡»ï¼Œæ¥è‡ªèŠ¯ç‰‡åŽ‚å•†ã€‚æœ‰å¿ƒçš„çŽ©å®¶åº”è¯¥éƒ½çŸ¥é“ï¼Œä»Žé…·ç¿4ä»£ä¹‹åŽï¼Œå†æ— PGAå°è£…çš„CPUï¼Œå…¨éƒ¨ç„ŠæŽ¥åœ¨ä¸»æ¿ä¸Šï¼Œè€ŒMXMçš„æ˜¾å¡ï¼Œä»ŽGTX980Mä¹‹åŽï¼Œä¹Ÿæ…¢æ…¢é€€å‡ºäº†åŽ†å²çš„èˆžå°ã€‚
    - è™½ç„¶ä¹‹åŽè“å¤©å¦è¾Ÿè¹Šå¾„å°†æ¡Œé¢çº§CPUæžåˆ°äº†ç¬”è®°æœ¬ä¸Šï¼Œä½¿ç¬”è®°æœ¬æœ‰äº†LGAæ’æ§½ï¼Œç„¶è€Œå¹¶æ²¡æœ‰ä»€ä¹ˆåµç”¨ï¼Œè‹±ç‰¹å°”2å¹´ä¸€æ¢æŽ¥å£ï¼Œè¿™è°é¡¶å¾—ä½ã€‚ç¬”è®°æœ¬çš„BIOSæ›´æ–°è¿˜ä¸å¦‚å°å¼ä¸»æ¿æ¥çš„å¿«ã€‚çºµç„¶LGA1151æ’‘äº†6ã€7ã€8ã€9è¿™4ä»£ï¼Œä½†æ˜¯å…¶ä¸­çš„å¹ºè›¾å­ä¸Žéªšæ“ä½œï¼Œåªæœ‰ç»åŽ†çš„äººæ‰æ‡‚é‚£ç§ç—›ã€‚
    - è€Œè™½ç„¶10ç³»æ˜¾å¡è¿˜æœ‰MXMçš„ï¼Œä½†æ˜¯å¼‚åž‹å¡å¤§è¡Œå…¶é“ï¼Œå‡ ä¹Žæ²¡æœ‰æ ‡å‡†ç‰ˆçš„å¡åž‹äº†ã€‚ä»¥å‰å¯å‡çº§çš„æ˜¾å¡ä¸€åŽ»ä¸å¤è¿”ã€‚
  - ç¬¬äºŒä¸ªæš´å‡»ï¼Œæ¥è‡ªç¥žèˆ¹ã€‚ä»Žå‰çš„å‡†ç³»ç»ŸåŽ‚å•†ï¼Œä»¥æžè“å¤©å’Œå¾®æ˜Ÿå‡†ç³»ç»Ÿä¸ºä¸»ï¼Œå‡†ç³»ç»Ÿå•†å®¶çš„è“å¤©çš„è´§æºä¸»è¦æ¥è‡ªç¥žèˆ¹ä¸Žæœªæ¥äººç±»ï¼Œå¾®æ˜Ÿçš„å¤§æ¦‚å°±æ˜¯æ¥è‡ªå¾®ç›Ÿï¼Œè¿˜æœ‰ç‹¬ç«‹ä¸€æ´¾çš„é•­æ³¢ã€æµ·é²…ï¼ŒçŽ°åœ¨ä¹Ÿæ­»äº†å§ï¼Ÿæ²¡å’‹å…³æ³¨ã€‚
    - çºµç„¶å‡†å•†å¯ä»¥æä¾›çš„å®šåˆ¶åŒ–éœ€æ±‚å¤šæ ·ï¼Œä½†æ˜¯æž¶ä¸ä½ç¥žèˆ¹ä¸‹åœºæ‰“è¿™ä¸ªæž¶ã€‚å‡†å•†åªèƒ½é ç€æ¯”ç¥žèˆ¹æ›´å¥½çš„å±å¹•ã€ç½‘å¡ã€SSDæ¥æŠ—è¡¡ï¼Œä½†æ˜¯è¶Šç²¾ç»†çš„å®šåˆ¶ï¼Œè¶Šè¦èŠ±é’±ã€‚ç¥žèˆ¹å°±ç”¨ä¸€æ‹›ä¾¿å®œï¼Œæ‰“çš„å‡†å•†æ¯«æ— è¿˜æ‰‹ä¹‹åŠ›ã€‚ç¥žèˆ¹çš„æè´§é‡æœ¬èº«å°±åºžå¤§ï¼Œè‡ªç„¶ä¼šæ‹¿åˆ°æ›´å¥½çš„ä»·æ ¼ï¼Œç¥žèˆ¹è¿˜åƒç€è‹±ç‰¹å°”ç»™çš„é¥­ï¼Œå‡†å•†å“ªä¸ªæ‰“å¾—è¿‡ä»·æ ¼æˆ˜ï¼Ÿ
- ä¹°ä¸ªç¬”è®°æœ¬ï¼ŒèŠ±è¿™ä¹ˆå¤šé’±ï¼Œæ‰¿æ‹…è¿™ä¹ˆå¤§çš„é£Žé™©ï¼Œå“ªä¸ªå°ç™½æ„¿æ„é“¤è€Œèµ°é™©ï¼Ÿéš”å£ç¥žèˆ¹å¥½æ­¹è¿˜æœ‰ä¸ªå”®åŽï¼Œå¥½æ­¹è¿˜æ˜¯ä¸ªå›½å†…â€œçŸ¥åäºŒçº¿å“ç‰Œâ€ã€‚
- çŽ°é˜¶æ®µï¼Œç¥žèˆ¹ä¹Ÿç®—æ˜¯å§å‡†ç³»ç»Ÿçš„é‚£ç¢—é¥­æŠ¢è¿‡åŽ»äº†ã€‚é¢˜ä¸»è´´çš„å›¾ï¼Œæœ¬èº«é—®é¢˜ä¹Ÿä¸å°ã€‚è¿˜æ˜¯è€ç”Ÿå¸¸è°ˆçš„æ‚ç‰Œé…ä»¶é—®é¢˜ï¼Œä½†å‡¡æ ‡æ˜Žå¥½ç‚¹åž‹å·çš„ï¼Œéƒ½è¦åŠ é’±ã€‚å…¶å®žä¸€ç‚¹ä¸ç®—ä¾¿å®œã€‚
  - ç²¾æ‰“ç»†ç®—ä¸€ä¸‹ï¼Œç”šè‡³è·Ÿä¹°ä¸ªç¥žèˆ¹æ²¡å•¥åŒºåˆ«ï¼Œç¥žèˆ¹è‡³å°‘è¿˜æœ‰ä¸ª7å¤©15å¤©é€€æ¢å’Œç›¸å¯¹å®Œæ•´çš„å”®åŽæœåŠ¡ã€‚

- ä¸­è‚¯ï¼ŒçŽ°åœ¨æƒ³å…¥è“å¤©æ¨¡å…·æœ€å¥½å°±æ˜¯ä¸Šèˆ¹
  - ä½†æ˜¯ç¥žèˆ¹åŸºæœ¬éƒ½æ˜¯ä½Žç«¯æ¨¡å…·ä¸Šé«˜é…ã€‚ã€‚ã€‚å®žé™…æ€§èƒ½å¹¶ä¸è¡Œã€‚ã€‚ã€‚é«˜ç«¯æ¨¡å…·ç¥žèˆ¹ä»¥å‰æœ‰ï¼ŒçŽ°åœ¨åŸºæœ¬ç»è¿¹
- Gx10 x170ä¸è¿‡ä»·æ ¼å˜›æœ›è€Œå´æ­¥

- ## [ä¸ºä»€ä¹ˆæ‰€æœ‰ç¬”è®°æœ¬ç”µè„‘éƒ½è®¾è®¡æˆä¸èƒ½å‡çº§cpuï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/666682172/answers/updated)
- æœ€ç²¾é«“çš„ä¸¤æ¡ï¼Œä¸€æ˜¯ä¸çœç©ºé—´å¾ˆéš¾åŽ‹è–„ï¼›äºŒæ˜¯æœ‰é‡‘å±žç›–å¯¼çƒ­æ•ˆçŽ‡æ›´ä½Žã€‚

- ä¸åˆ’ç®—ï¼Œå°å¼åˆ°äº†æ¢cpuçš„æ—¶å€™åŸºæœ¬ä¸»æ¿å’Œuéƒ½ä¸€èµ·æ¢äº†ï¼Œ
  - ç¬”è®°æœ¬ä½ æ¢ä¸»æ¿ï¼Œæ¯ä¸ªç‰Œå­çš„ä¸»æ¿è¿˜è¦åŒ¹é…å¯¹åº”ç‰Œå­å¤–æ¨¡ï¼Œè€Œä¸”ä¸»æ¿æ‰©å±•æ€§å¾ˆä½Žï¼Œç¡¬ç›˜å†…å­˜æŽ¥å£å°±é‚£ä¹ˆå¤šï¼Œå‡çº§ä¹Ÿåªæ˜¯ç”¨å›žåŽŸæ¥çš„é…ä»¶ã€‚
  - å¦‚æžœåªæ˜¯å•çº¯æ¢cpuï¼Œç›¸å½“äºŽä¸ºäº†é†‹åŒ…é¥ºå­ã€‚ä¸åƒå°å¼ä½ ä¸€ä¸ªæœºç®±ä»€ä¹ˆä¸»æ¿éƒ½èƒ½å®‰è£…ã€‚

- ä»¥å‰æ˜¯å¯ä»¥çš„ï¼ŒåŽæ¥å‘çŽ°æ²¡æ„ä¹‰ï¼Œä½ çœ‹çŽ°åœ¨å¤§å®¶å‡çº§å°å¼æœºï¼Œéƒ½ä¸åƒä»¥å‰ï¼Œæ…¢æ…¢å‡çº§äº†ã€‚åŸºæœ¬ä¸Šæ¢å°±æ˜¯ä¸€å¥—å…¨æ¢äº†ã€‚

- å…¶å®žå°å¼æœºä¹Ÿä¸èƒ½ï¼Œå› ä¸ºæ¯å‡ ä»£[CPUæž¶æž„]ä¼šæ¢ï¼Œç­‰ä½ æƒ³æ¢äº†CPUäº†ï¼Œå¤šåŠä¸»æ¿ä¸Šçš„ [CPUæ’æ§½] å·²ç»ä¸é€‚é…æœ€æ–°çš„CPUäº†ï¼Œè€Œä¸”CPUå¾ˆå¯èƒ½æ˜¯ç”µè„‘æœ€ä¸å®¹æ˜“åçš„çŽ©æ„å„¿äº†

- ä»¥å‰çš„å¾ˆå¤šç¬”è®°æœ¬ç”µè„‘éƒ½èƒ½æ¢cpuã€‚æˆ‘å¤§å­¦çš„æ—¶å€™æœ¬æ¥æƒ³ä¹°å°å¼ç”µè„‘ï¼Œä½†æ˜¯å¯å®¤ç©ºé—´å¤ªå°è€Œä¸”å°å¼ç”µè„‘ä¸æ–¹ä¾¿æºå¸¦ï¼Œè€ƒè™‘å†ä¸‰å…¥äº†å‡†ç³»ç»Ÿç¬”è®°æœ¬çš„å‘ã€‚
  - å½“æ—¶ä¹°çš„æ˜¯ç¥žèˆŸæˆ˜ç¥žzx7sp5d1ï¼Œè“å¤©æ¨¡å…·å‡†ç³»ç»Ÿç¬”è®°æœ¬ç”µè„‘ã€‚å¤§å­¦æœŸé—´æˆ‘ç»™è¿™å°ç”µè„‘åŠ äº†ä¸ªå›ºæ€ç¡¬ç›˜å½“ç³»ç»Ÿç›˜ï¼ŒåŠ äº†æ¡8gå†…å­˜æ¡ï¼ŒåˆåŠ äº†ä¸ª1Tæœºæ¢°ç¡¬ç›˜ç”¨æ¥ç»™è€å¸ˆä»¬å®‰å®¶ï¼ˆè¿™ä¸ªç¬”è®°æœ¬ç”µè„‘æœ‰ä¸¤ä¸ªå›ºæ€æŽ¥å£ï¼Œä¸¤ä¸ªæœºæ¢°ç¡¬ç›˜æŽ¥å£ï¼Œå››ä¸ªå†…å­˜æ¡æŽ¥å£ï¼‰ã€‚
  - è¿™å°ç¬”è®°æœ¬ç”µè„‘æˆ‘ä¸€ç›´ç”¨åˆ°çŽ°åœ¨ï¼Œ1060æ˜¾å¡çŽ©å·«å¸ˆ3ã€è€å¤´çŽ¯è¿˜éƒ½å¯ä»¥ä¸­ä½Žç”»è´¨60å¸§ï¼Œå› ä¸ºå¤ªè€ç”¨äº†å¯¼è‡´æˆ‘ç»„å°å¼ç”µè„‘çš„è®¡åˆ’ä¸€ç›´æ²¡èƒ½è½å®žã€‚

- 2020å¹´å·¦å³ï¼Œæˆ‘ä¹°çš„ç‚«é¾™M7ï¼Œcpuæ˜¯å°å¼æœºçš„ cpuï¼Œå¯ä»¥æ›´æ¢çš„ã€‚

- å½“å¹´è“å¤©æ¨¡å…·å¯æ˜¯æ•´è¿‡é€†å¤©æ“ä½œçš„ï¼Œè®¾è®¡äº†å¸¦CPUæ’æ§½çš„ä¸»æ¿ï¼Œç¬”è®°æœ¬è‡ªå¸¦ï¼Œç”¨æˆ·å¯ä»¥ä¹°åˆ°æ‰‹ä»¥åŽæ›´æ¢i5-9400
  - æ›´å¤šçš„åŽŸå› æ˜¯è‹±ç‰¹å°”å¤ªé¸¡è´¼äº†ã€‚ä¾‹å¦‚æ–°å‡º12ä»£å¤„ç†å™¨ï¼Œå°±è¦ç”¨æ–°çš„ï¼Œå’Œæ—§çš„ä¸é€šç”¨ã€‚ä¾‹å¦‚ä½ çœŸçš„å¼„åˆ°æ‰‹ä¸€ä¸ªç¬”è®°æœ¬ï¼Œå¤„ç†å™¨æ˜¯11400ï¼Œä½ æƒ³æŠŠå¤„ç†å™¨æ¢æˆ12400ï¼Ÿæ²¡é—¨ï¼

- 2014å¹´ä¹‹å‰ï¼Œå¤§éƒ¨åˆ†ç¬”è®°æœ¬ç”µè„‘éƒ½æ˜¯å¯å‡çº§CPUçš„
  - çœŸæ­£æŠŠè¡Œä¸šå–æ¶ˆå¯æ›´æ¢æ’æ§½å¼CPUçš„ï¼Œä¸€æ˜¯ä¸Šæ¸¸çš„æŽ¨åŠ¨ï¼ŒäºŒæ˜¯ç¬”è®°æœ¬æ•´ä½“è®¾è®¡è¶‹å‘äºŽè½»è–„åŒ–
  - ä¸Šæ¸¸çš„æŽ¨åŠ¨å¾ˆç®€å•ç²—æš´ï¼Œä»Žé…·ç¿5ä»£å¼€å§‹ï¼Œè‹±ç‰¹å°”å°±å–æ¶ˆäº†ç¬”è®°æœ¬äº§å“çº¿æ‰€æœ‰çš„PGAå°è£…æ’æ§½å¼CPUï¼Œå…¨éƒ¨æ”¹ç”¨[BGAå°è£…] ï¼Œç›´æŽ¥ç„Šåœ¨ä¸»æ¿ä¸Š
  - AMDä¹Ÿåœ¨ç±»ä¼¼çš„æ—¶é—´ç‚¹ç æŽ‰äº†æ‰€æœ‰æ’æ§½å¼äº§å“çº¿
  - è¿™æ—¶å€™æ‰åªå‰©ä¸‹è“å¤©ã€å¾®æ˜Ÿç­‰å…·å¤‡LGA/PGAæ’æ§½ï¼Œä½¿ç”¨æ¡Œé¢å¤„ç†å™¨çš„å‡†ç³»ç»Ÿæœºåž‹
  - å¦ä¸€æ–¹é¢ï¼Œè¿™ç§å¯æ›´æ¢çš„è®¾è®¡éœ€è¦åœ¨ä¸»æ¿ä¸Šè®¾ç½®ä¸€ä¸ªåŸºåº§ï¼Œå†æŠŠCPUè£…åˆ°ä¸Šé¢ï¼Œæ•´ä½“å ç”¨çš„åŽšåº¦å°±ä¼šæœ‰æ‰€å¢žåŠ 

- 2015å¹´ä¹‹å‰çš„è¿˜æ˜¯éƒ½æ˜¯å¯ä»¥æ¢cpuçš„ï¼Œè‹±ç‰¹å°”æœ€åŽä¸€ä»£ç§»åŠ¨ç«¯å¯æ¢CPUæ˜¯ç¬¬å››ä»£é…·ç¿ï¼Œé‡‡ç”¨äº†FCPGA946æ’æ§½

- è“å¤©ä»¥å‰æœ‰çš„æ˜¯ã€‚ä¸åšçš„åŽŸå› æœ‰å¾ˆå¤šï¼Œä¸€æ˜¯Intelå’ŒAMDå¼ºæŽ¨hx55å–ä»£äº†åŽŸæ¥æ¡Œé¢uç”Ÿæ€ä½ï¼Œä¸ç»™ç¬”è®°æœ¬åŽ‚æ’æ§½äº†ï¼ŒäºŒæ˜¯è“å¤©ä¸€æ¡æ‡’ç‹—æ‘†çƒ‚åŸºæœ¬ä¸Šä¸æ›´biosï¼Œå‡ºåŽç»­uä¹Ÿä¸æ”¯æŒã€‚

- å‡†ç³»ç»Ÿç¬”è®°æœ¬éƒ½æ˜¯å¯ä»¥çš„
  - ä¸å…‰CPUï¼Œæ˜¾å¡éƒ½èƒ½æ¢
  - ä½†ä¸ç®¡æ˜¯æ¢CPUè¿˜æ˜¯æ¢æ˜¾å¡ï¼Œè¿™æ ·çš„å‡†ç³»ç»Ÿçš„ç¬”è®°æœ¬ï¼ŒåŒ…æ‹¬IBMçš„è€æœ¬å­ï¼Œæ¨¡å—åŒ–è®¾è®¡çš„éƒ½æœ‰ä¸€ä¸ªå…±åŒç‰¹ç‚¹å°±æ˜¯åŽšã€æ²‰

- ## [æœ‰æ²¡æœ‰ä»€ä¹ˆç¬”è®°æœ¬æ˜¯å’Œå°å¼æœºä¸€æ ·å¯ä»¥è¿›è¡Œæ‰©å±•å‡çº§çš„ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/567261427)
- è“å¤©NH50JNRäº†è§£ä¸€ä¸‹ï¼ŸX170äº†è§£ä¸€ä¸‹ï¼Ÿ
  - è¿™æ‰å«å’Œå°å¼æœºä¸€æ ·ï¼šCPU [æ˜¾å¡] å†…å­˜ç¡¬ç›˜å…¨éƒ½å¯ä»¥æ¢ï¼Œç”šè‡³ä½ å¤Ÿé—²å¤Ÿæœ‰é’±ï¼Œè¿˜å¯ä»¥æŠŠé£Žæ‰‡æ¢äº†ï¼Œæ•£çƒ­æ”¹VCç”šè‡³ä¸Šæ°´ï¼Œå½“ç„¶ï¼ŒåŽé¢é‚£äº›è¦è‡ªå·±åŽ»å®šåˆ¶/DIYã€‚
  - è¯è¯´X170çš„æ­£ç»Ÿç»§ä»»è€…æ˜¯å•¥ï¼Ÿä¼¼ä¹Žæ²¡ä¸‹æ–‡äº†ï¼Ÿï¼ˆå¥½ä¹…æ²¡åŽ»äº†è§£å‡†äº†ï¼‰åˆ«è¯´æ˜¯X270ï¼Œé‚£ç ´çƒ‚ä¸é…ã€‚
- å¯æƒœæ˜¾å¡è¿™å—ï¼Œè€é»„å·²ç»ä¸ç»™åšMXMäº†ï¼Œæ˜¾å¡å¯æ›´æ¢å¤§æ¦‚è¦æˆä¸ºåŽ†å²äº†ã€‚

- X170ä¹‹åŽç¡®å®žå°±å†ä¹Ÿæ²¡æœ‰é¡¶çº§å‡†ç³»ç»Ÿæœºäº†è€é»„æ¯•ç«Ÿä¸åšmxmäº†ã€‚
  - äº‹å®žä¸Šæˆ‘è§‰å¾—åº”è¯¥è¯´ï¼Œè¶…çº§è‚Œè‚‰æœ¬è¿™ç§äº§å“æœ¬èº«å°±å·²ç»å¯ä»¥è¯´æ¿’ä¸´æ­»äº¡äº†ï¼Œæ¯•ç«Ÿå—ä¼—åªæœ‰ç”Ÿäº§åŠ›ç‹‚äººå’ŒçŽ©æœºä½¬ã€‚
- ä¸€çœ¼æœ›åŽ»ï¼ŒçŽ°åœ¨è¿˜èƒ½åšæŒåšå‡ºçœŸæ­£å¼ºå¤§çš„è¶…çº§è‚Œè‚‰æœ¬çš„ä¹Ÿåªæœ‰å¾®æ˜Ÿä¸€å®¶äº†ï¼Œè€Œå°½ç®¡å¦‚æ­¤ä»Šå¹´çš„è¶…çº§æ——èˆ°GT77è™½ç„¶å ªæ¯”X170ï¼Œä½†æ˜¯å¤©ç”Ÿ330Wå•å­”ç”µæºç›´æŽ¥å°±é™åˆ¶äº†ä¸é¢å¤–æ‰©é€‚é…å™¨çš„æƒ…å†µä¸‹å¥¹çš„ä¸Šé™ï¼Œæ›´ä¸è¦è¯´GT77çš„æ ¸å¿ƒç»„ä»¶éƒ½æ²¡æ³•æ›´æ¢äº†ï¼Œä¸€ä»£æœ«ä»£æœºçš‡çš„ç—›å•Šã€‚

- å¸‚åœºå†³å®šäº†åŽšé‡çš„æ¨¡å…·è¶Šæ¥è¶Šå°‘ï¼Œä¸ç®¡æ˜¯è“å¤©çš„åŽšé‡x170è®¾è®¡ï¼Œrogçš„è¶…ç¥žï¼Œå¾®æ˜Ÿçš„gt8ï¼Œéƒ½å·²ç»æ²¡æœ‰æ–°å“å¥½å¤šå¹´äº†
  - è“å¤©æ–°æ¨¡å…·è¶Šæ¥è¶Šå€¾å‘äºŽè–„ï¼Œrogé«˜ç«¯äº¤ç»™äº†è½»è–„çš„å†°åˆƒç³»åˆ—ï¼Œå¾®æ˜Ÿåªæœ‰gt7ç³»åˆ—ï¼Œrogä¹Ÿæ²¡æœ‰åŽšé‡è®¾è®¡äº†ï¼Œä¼°è®¡æ—¥åŽä¹Ÿä¸ä¼šæœ‰äº†
  - ä¸»è¦æ˜¯æˆæœ¬å¤ªå¤§ é”€é‡å¤ªå·®ï¼Œè¿™ç§é¡¶çº§æœ¬åŠ¨è¾„ä¸‰ä¸‡å¾€ä¸Šï¼Œæœ¬æ¥å¸‚åœºå°±å°ï¼ŒæŠ•å…¥è¿›åŽ»åŸºæœ¬å›žä¸æ¥

- ä¸€èˆ¬çš„è½»è–„æœ¬ã€è¶…æžæœ¬éƒ¨åˆ†å¯ä»¥æ›¿æ¢ç¡¬ç›˜ï¼Œæˆ–è€…æ·»åŠ å†…å­˜ã€‚
  - æ ‡åŽ‹ç¬”è®°æœ¬ç”µè„‘åŸºæœ¬éƒ½å¯ä»¥è‡ªè¡Œæ›¿æ¢ç¡¬ç›˜ï¼Œéƒ¨åˆ†å¯ä»¥æ·»åŠ å†…å­˜ã€‚æ—©æœŸCPUä¸º[BGAæŽ¥å£]ï¼Œèƒ½å¤Ÿè‡ªè¡Œæ›¿æ¢ï¼Œè¿‘å¹´çš„å·²ç»æ”¹æˆæ¿è½½ï¼Œä¸èƒ½æ›¿æ¢ã€‚
- ä½¿ç”¨æ¡Œé¢CPUçš„è‚Œè‚‰æœ¬ï¼Œå¯ä»¥åŸºäºŽä¸»æ¿ï¼Œè‡ªå·±æ›´æ¢CPUã€[MXMæ˜¾å¡] ã€ç¡¬ç›˜å’Œå†…å­˜æ¡ã€‚è¿™ç§è‚Œè‚‰æœ¬å¯ä»¥ä¹°æˆå“ï¼Œå…¸åž‹ä¾‹å¦‚ç¥žèˆŸç¬”è®°æœ¬çš„GXã€TXã€Kç³»åˆ—ç­‰ã€‚
- è¿˜æœ‰ä¸€äº›åªæœ‰ä¸»æ¿å’Œå¤–å£³ï¼Œä¸€èˆ¬ç§°ä¸º[å‡†ç³»ç»Ÿç¬”è®°æœ¬]ï¼Œè¦è‡ªå·±é€‰é…æ¡Œé¢CPUã€MXMæ˜¾å¡ã€ç¡¬ç›˜ã€å†…å­˜æ¡ã€å±å¹•ç­‰ç­‰ã€‚
- é‡‡ç”¨è“å¤©æ¨¡å…·çš„æ¸¸æˆæœ¬åŽ‚å•†æœ‰é›•ç‰Œï¼Œæœªæ¥äººç±»ï¼Œç¥žèˆŸæˆ˜ç¥žï¼Œç‚«é¾™ï¼Œé›·ç¥žï¼ˆæµ·å°”ï¼‰ï¼Œæœºæ¢°å¸ˆï¼ˆæµ·å°”ï¼‰ç­‰ç­‰ã€‚
  - è€Œé‡‡ç”¨å¾®æ˜Ÿæ¨¡å…·çš„åˆ™æœ‰æœºæ¢°é©å‘½ï¼ˆæ¸…åŽåŒæ–¹ï¼‰ï¼Œç«å½±ï¼ˆæ¸…åŽåŒæ–¹ï¼‰ï¼Œé•­æ³¢ç­‰ç­‰ã€‚
  - æ¸¸æˆæœ¬åŽ‚å•†é™¤äº†è´´ç‰Œå‡ºå”®æ•´æœºï¼Œæœ‰äº›è¿˜ä¼šç›´æŽ¥å‡ºå”®å‡†ç³»ç»Ÿï¼Œå…¶ä¸­å¤§éƒ¨åˆ†ä»¥è“å¤©æ¨¡å…·ä¸ºä¸»ã€‚
  - å›½å¤–æœ‰ä¸å°‘å¯é€‰é›¶é…ä»¶çš„è“å¤©æ¨¡å…·å‡†ç³»ç»Ÿé”€å”®ç½‘ç«™ï¼Œè€Œå›½å†…åªæœ‰é“å¤´ï¼ˆæœªæ¥äººç±»ï¼‰å’Œç¥žèˆ¹ï¼ˆç¥žèˆŸï¼‰åœ¨å‡ºè´§ã€‚
- å¦‚æžœæƒ³è´­ä¹°èƒ½å¤Ÿåƒå°å¼ä¸€æ ·å‡çº§çš„ç¬”è®°æœ¬ç”µè„‘ï¼Œå°±é€‰å‡†ç³»ç»Ÿå¥½äº†ã€‚

- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 

- ## [åŽæœŸå‡çº§ç©ºé—´å¤§çš„ç¬”è®°æœ¬æœ‰å“ªäº›ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/314565920)
- ç¬”è®°æœ¬åªèƒ½å‡çº§ç¡¬ç›˜å’Œå†…å­˜ã€‚çº¦ç­‰äºŽæ²¡æœ‰å‡çº§ç©ºé—´ã€‚

- ä½ æœ‰æ²¡æœ‰å¬è¿‡MXMç¬”è®°æœ¬ï¼Ÿ

- ä»¥å‰çš„å¾ˆå¤šå°è£…ç§°ä¹‹ä¸ºpgaå°è£… å·²ç»ä¸åœ¨ç”Ÿäº§äº† çŽ°åœ¨çš„ç¬”è®°æœ¬é™¤äº†éƒ¨åˆ†æ˜¯å°å¼æœºä½¿ç”¨çš„lgaå°è£… å…¶ä»–çš„éƒ½æ˜¯bagå°è£…äº† ä¹Ÿå°±æ˜¯ç„Šé”¡çš„ pgaå°è£…æ˜¯æ’é’ˆçš„ æ¯”è¾ƒè€äº† å¯ä»¥è½»æ˜“æ›´æ¢CPU

- å¤–æ˜Ÿäººm51ç¬”è®°æœ¬å•Šï¼Œå°å¼æœºçš„æž„æž¶

- æ®è¯´åŽæ¥èƒ½æ¢cpuçš„ç¬”è®°æœ¬å¾ˆå°‘äº†ã€‚å°†æ¥å†ä¹°ç¬”è®°æœ¬ï¼Œç¬¬ä¸€è€ƒè™‘å¯å‡çº§æ€§

- ## [æƒ æ™®æš—å½±ç²¾çµ10slimå¯¹æ¯”ä¸Šä¸€ä»£9slimæœ‰ä»€ä¹ˆæå‡å—ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/661490891)
- æš—å½±ç²¾çµ10 Slim 16ç­‰äºŽä¾¿æºã€æ‹“å±•ã€æ€§èƒ½å“ªä¸€æ ·éƒ½æƒ³è¦ï¼Œä½†å“ªä¸€æ ·éƒ½æ²¡é¡¾ä¸Šã€‚è¯´åˆ°åº•è¿˜æ˜¯ä¸Šä»£çš„äº§å“æ€è·¯ï¼Œåœ¨2024å¹´è·Ÿä¸ä¸Šå¸‚åœºäº†ï¼Œæ¯•ç«Ÿç«žå“æœ‰åŽå‘ä¼˜åŠ¿ã€‚
  - è¦æ€§èƒ½+æ‹“å±•ï¼Œæœ‰é‡é‡å·®ä¸å¤šã€å¹²åˆ°200Wæ€§èƒ½é‡Šæ”¾ã€æ‹“å±•æ€§æ›´å¥½çš„ThinkBook 16p
  - è¦ä¾¿æº+ç»­èˆªï¼Œé…·ç¿Ultraã€1.85kgæ›´è½»è–„ã€è´¨æ„Ÿæ›´å¥½çš„ROGå¹»16 Air

- ## [å¦‚ä½•è¯„ä»·æƒ æ™®å‘å¸ƒçš„è½»è–„æ¸¸æˆæœ¬æš—å½±ç²¾çµ9 Slimï¼Œå€¼å¾—è´­ä¹°å—ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/593557269/answers/updated)
- ä¼˜ç‚¹ï¼šè½»è–„ï¼Œé¢œå€¼åœ¨çº¿ï¼Œå±å¹•é¡¶ï¼Œè¶…å¤§ç”µæ± ã€‚
- ç¼ºç‚¹ï¼šå•ç¡¬ç›˜ä½ï¼Œç¥–ä¼ å¤§ä¸‹å·´ã€‚
- è‡ªä½¿ç”¨ç‹¬æ˜¾ç›´è¿žå±è”½æ ¸æ˜¾åŽï¼Œç›´åˆ°çŽ°åœ¨æ²¡æœ‰å†æ¬¡å‡ºçŽ°è“å±é—®é¢˜ã€‚

- Slimç‰ˆåˆ™å®žçŽ°äº†çº¤è–„ä¾¿æºä¸Žæ€§èƒ½ä¹‹é—´çš„å¹³è¡¡ï¼Œæ›´é€‚åˆæ³¨é‡é¢œå€¼ä¸Žç§»åŠ¨æ€§çš„çŽ©å®¶

- ## [æœ‰å“ªäº›ç¬”è®°æœ¬æ¯”è¾ƒå®Œç¾Žåœ°æ”¯æŒubuntuï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/286150644/answers/updated)
- å¦‚æžœä¸æ‰“ç®—è·‘cudaæˆ–è€…å…¶ä»–éœ€è¦Nvidiaæ˜¾å¡çš„ç¨‹åºçš„è¯ï¼Œæˆ‘ä¸€èˆ¬æ²¡é‡åˆ°è¿‡ä»€ä¹ˆç‰¹åˆ«å¤§çš„é—®é¢˜ã€‚ä½†å¦‚æžœéœ€è¦ç”¨Nvidiaçš„æ˜¾å¡ï¼Œé‚£å°±æ˜¯é—®é¢˜ä¸æ–­ï¼Œç»å¸¸è¦çœ‹è¿æ°”äº†ã€‚
  - Ubuntuæœ¬èº«ç»å¸¸æœ‰Nvidiaæ˜¾å¡é©±åŠ¨é—®é¢˜ï¼Œä½†æ¢æˆåŸºäºŽUbuntuçš„é‚£äº›ä»¥user friendlyä¸ºæŒ‡å¯¼æ€æƒ³çš„å‘è¡Œç‰ˆæœ¬ï¼Œå¾ˆå¯èƒ½å°±ä¸éœ€è¦è‡ªå·±æŠ˜è…¾ï¼Œå®Œå…¨æ²¡é—®é¢˜äº†ã€‚è¿™é‡Œï¼Œæˆ‘å¼ºçƒˆæŽ¨èLinux Mintï¼Œåœ¨Dell XPSä¸Šä¸€æ‰«æœ€åŸºæœ¬Ubuntuçš„å„ç§æ˜¾å¡é©±åŠ¨é—®é¢˜ã€‚

- ## [ç¬”è®°æœ¬ç”µè„‘é€‚åˆå®‰è£…å“ªä¸ªLinuxï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/520319837)
- ç¬”è®°æœ¬ä¸å»ºè®®æŠ˜è…¾Linuxï¼Œè€è€å®žå®žå½“å®¢æˆ·ç«¯ç”¨å§ã€‚ç¬”è®°æœ¬æ¢äº†æ²¡é€‚é…è¿‡çš„Linuxï¼Œç”µæºç®¡ç†ï¼Œå±å¹•äº®åº¦ï¼Œæ— çº¿é©±åŠ¨éƒ½å¯èƒ½æ˜¯é—®é¢˜ã€‚ä¹°å®˜æ–¹æ”¯æŒçš„Linuxæœ¬ä»·æ ¼å¯ä¸ä½Žã€‚

- ç¬”è®°æœ¬æ¥å®‰è£…Linuxï¼Œä¼šè®©ä½ ç”¨è¿™ä¸ªç¬”è®°æœ¬çš„åˆè¡·è¿·å¤±åœ¨å„ç§ç ”ç©¶å°è¯•ä¸Šã€‚

- ## [æ±‚æŽ¨èé€‚åˆlinuxç³»ç»Ÿçš„ç¬”è®°æœ¬? - çŸ¥ä¹Ž](https://www.zhihu.com/question/1100336631)

- å°å¼æœºå»ºè®®ç”¨Linusé…çš„é‚£ä¸ªçº¿ç¨‹æ’•è£‚è€…ä¸»æœºï¼Œbç«™æœ‰é…ç½®å•ã€‚æ˜¾å¡å»ºè®®æ¢æˆrx5700xtæˆ–è€…rx6700xtã€‚å…¶ä»–çš„ç›´æŽ¥å¤åˆ¶ç²˜è´´å°±è¡Œã€‚
  - ç¬”è®°æœ¬ç”µè„‘ï¼Œiå®¶é€‰åä»£é…·ç¿ï¼ˆå«åä»£ï¼‰åŠä»¥ä¸‹çš„é…·ç¿æ ¸æ˜¾æœ¬ï¼Œaå®¶é€‰zenæˆ–ryzenæž¶æž„çš„åˆ°æœ€æ–°çš„æ ¸æ˜¾æœ¬éƒ½å¯ä»¥ã€‚åä¸€ä»£ä»¥ä¸Šï¼ˆå«åä¸€ä»£ï¼‰Intelå¤„ç†å™¨ç¡¬ä»¶æœ‰bugã€‚
  - ç‹¬æ˜¾ä¸€èˆ¬æ˜¯nå¡ï¼Œèƒ½ä¸ç”¨å°±ä¸ç”¨ï¼Œç¬”è®°æœ¬ç”µè„‘ä¸ŠLinuxç”¨nå¡æœ‰ç‚¹è‡ªæ‰¾éš¾å—ã€‚

- å¤§éƒ¨åˆ†ä¸»æµå“ç‰Œçš„éƒ½å¯ä»¥ã€‚

- æœ€æ­£ç¡®çš„éš¾é“ä¸æ˜¯éšä¾¿ä¹°ä¸€å°winæœ¬å­ï¼Œè™šæ‹Ÿæœºä¸‹é¢è·‘Linuxå—ï¼Ÿ

- å¦‚æžœä¸èƒ½å¿å—éœ€è¦æŠ˜è…¾ï¼ŒUbuntu certified laptops å¤§å¤§æ–¹æ–¹ä¹°å°±æ˜¯äº†ï¼Œä¸»è¦ä»¥Dellã€HPã€Lenovoå¾¡ä¸‰å®¶ä¸ºä¸»

- è¿™çŽ©æ„ä¸æ˜¯å–å†³äºŽä½ æ„¿ä¸æ„¿æ„æŠ˜è…¾é©±åŠ¨ä¹ˆ...
  - å¦‚æžœä¸æ„¿æ„æŠ˜è…¾å°±ä¹°ä¸ªä¸“ä¸šçš„ç§»åŠ¨å·¥ä½œç«™è¿™ç§æ¯”è¾ƒç¨³å®šï¼Œå¸¦é©±åŠ¨æ”¯æŒçš„ï¼Œ
  - å¦‚æžœæ„¿æ„æŠ˜è…¾ä¸Žå–œçˆ±ï¼Œé‚£æ€§ä»·æ¯”é«˜çš„æ¸¸æˆæœ¬éšä¾¿æ‰¾ä¸€ä¸ªå°±å¥½ï¼ŒCPUéƒ½å¯ä»¥é¡¶æ»¡åˆ°14900HX...

- ThinkPadå¤ªè´µäº†ï¼Œå¾¡ä¸‰å®¶å·¥ä½œç«™éƒ½æ²¡é—®é¢˜ï¼Œæƒ æ™®æ€§ä»·æ¯”æœ€å¥½

- èƒ½ä¸ç”¨ç¬”è®°æœ¬åˆ«ç”¨ç¬”è®°æœ¬ã€‚Linuxå¯¹ç¡¬ä»¶æ€§èƒ½æ²¡æœ‰å¤ªå¤§é™åˆ¶ï¼Œæ‰€ä»¥ï¼Œä½ çš„ç¡¬ä»¶è¶Šå¼º~ä½ å¾—åˆ°çš„å°±è¶Šå¤šã€‚
  - æ˜¾å¡ï¼Œå¦‚æžœæžAIçš„è¯ï¼Œåªé€‰NVIDIAç‹¬ç«‹æ˜¾å¡ï¼ŒçŽ°åœ¨3090äºŒæ‰‹è´§ä¹Ÿä¸è´µäº†ï¼Œåƒä¸‡åˆ«ä¿¡ä»€ä¹ˆNå¡é©±åŠ¨éš¾æžï¼Œé‚£éƒ½æ˜¯ä¸ä¼šè‹±æ–‡çš„åŽŸå§‹äººæ‰ä¼šä¿¡çš„è¯æœ¯ã€‚Linuxç”¨å…¶ä»–å¡æ‰å«ç¾éš¾ï¼Œè¦å•¥å•¥æ²¡æœ‰ï¼Œåªèƒ½æ˜¾ç¤ºï¼Œè¿˜ä¸å¦‚äº®æœºå¡ã€‚
# discuss-mac
- resources
  - [MacRumors Buyer's Guide: Know When to Buy iPhone, Mac, iPad](https://buyersguide.macrumors.com/)

- ## 

- ## 

- ## 

- ## 

- ## [Five Years of Apple Silicon: M1 to M5 Performance Comparison : r/apple _202511](https://www.reddit.com/r/apple/comments/1otq54t/five_years_of_apple_silicon_m1_to_m5_performance/)
  - [Five Years of Apple Silicon: M1 to M5 Performance Comparison - MacRumors _202511](https://www.macrumors.com/2025/11/10/apple-silicon-m1-to-m5-comparison/)
- The best decision Apple made with the Mac since 1984 was to switch from Intel CPUs and AMD GPUs to their own ARM64-based chips, after it became clear that Intel CPUs were stagnating when Appleâ€™s were getting a lot better year over year on the iPhone side.
  - Oddly enough, the second best decision was to switch from PowerPC CPUs to Intel CPUs, after it became clear that IBM wasnâ€™t interested in making PowerPC CPUs that ran faster while consuming less power.

- TLDR Twice the performance in 5 years.

- M1 Pro mbp is still going strong with 0 issues. Iâ€™ll upgraded in a few more years. They made these things too good.

- The thing is, how does the software support will go, knowing that MacOS26 is the last supported Intel chips.
  - I'd assume it'll be similar to iPhones which run ale Silicon. So about 7 years of major updates, followed by security patches.

- ## [M4 Max vs M3 Ultra for Adobe Premiere, After Effects, Resolve, Photoshop, Capture One : r/MacStudio _202511](https://www.reddit.com/r/MacStudio/comments/1ot6kkt/m4_max_vs_m3_ultra_for_adobe_premiere_after/)

- ## ðŸ†š [Apple MacBook Pro Geekbench performance compared (M1 to M5) : r/mac _202510](https://www.reddit.com/r/mac/comments/1o916qg/apple_macbook_pro_geekbench_performance_compared/)
- Apple has strong GPU and Neural Engine capabilities. What they donâ€™t have is the software stack. 
  - Nvidia built a lot of software tools to take advantage of their GPU, including helping science and engineering codes port and optimize for their CUDA libraries.
- Apple helped both TensorFlow and PyTorch ML libraries move to Metal, but Iâ€™m hoping there will be a broader effort to handle CUDA much like the Game Porting Toolkit, etc

- Depends what you meant by that.
  - Apple is working on CUDA backend for MLX, so you will be able to write programs which will be run on CUDA compatible GPUs.
  - However in other direction - running CUDA code on Apple - probably never. Well, it doesnt make much sense as CUDA is designed for enterprise solutions and Apple focus is on consumer grade hardware.

- ## [M4 Max 128 GB vs Binned M3 Ultra 96 GB Mac Studio? : r/LocalLLM _202503](https://www.reddit.com/r/LocalLLM/comments/1j8tyjr/m4_max_128_gb_vs_binned_m3_ultra_96_gb_mac_studio/)
- What do you mean â€œbinnedâ€?
  - Some of the GPU cores are not enabled. M3 Ultra has 60 core and 80 core GPU versions. The first one is 4 grand and second one costs 5.3 grand

- i think for these models, 96GB is more than enough and the GPU, NPU and RAM bandwidth are doubled on the M3 ultra vs M4 max. you would get 1.5-2X the tokens per second with the M3 ultra.

- Go with the M3 Ultra 60 core GPU 96 G 1TB variant. It is faster for LLM inference compared to M4 Max and has more memory bandwidth.
  - Note: Don't go for 80 core GPU variant. It is not value for money deal. Also go with 1TB variant. If you need more storage space, get an external SSD.

- ## [Is mac best for local llm and ML? : r/LocalLLM _202509](https://www.reddit.com/r/LocalLLM/comments/1ndhu25/is_mac_best_for_local_llm_and_ml/)
- Mac is best for energy efficiency for sure. Idle power is super low.
  - even at inference you're using less than 300W on a top of the line Mac Studio

- For casual, chat style inference it's hard to beat. However for training, high context processing and diffusion image generation Nvidia is still king and Mac will be quite slow for this.

- macs are pretty good for LLMs but as far as i know they struggle with vision nets and diffusion models 

- Bro, running models you should be good. However, training/fine-tuning (sometimes like 10% of the time works decent) other 90% you will find yourself crying watching your MAC train, slower than Dial-up internet back in the 90s.

- ## [How does M2 Ultra compare with M3 Ultra for LLM? : r/MacStudio _202508](https://www.reddit.com/r/MacStudio/comments/1mr09e2/how_does_m2_ultra_compare_with_m3_ultra_for_llm/)
- Llama 7b F16 TG
  - M1U/64 - 37.0
  - M2U/60 - 39.9
  - M3U/60 - 42.2

- ## [Mac Studio for LLMs: M4 Max (64GB, 40c GPU) vs M2 Ultra (64GB, 60c GPU) : r/LocalLLM _202506](https://www.reddit.com/r/LocalLLM/comments/1l702x2/mac_studio_for_llms_m4_max_64gb_40c_gpu_vs_m2/)
- The ultimate decision comes down to: (a) Do you want to run smaller models a little faster or (b) Do you want to be able to run larger models for less money? 
  - In my experience, the larger models are almost ALWAYS better. They just win.
  - Now, if you really do care about speed, and you plan on using LONG contexts, and you are content running smaller models, then by all means get a 3090 PC and call it a day. 
  - Just understand that the speed gaps tend to disappear at the larger models, and many of the nvidia fan boys cannot run the larger models at all due to lack of VRAM.

- M2 ultra gets destroyedy by AMD instinct Mi50 , especially if we're talking about value because we can pick up 1X 32GB GPU @ $250-300. Couple that with old mining rig motherboard or 7002-7003 EPYC CPU + cheap mobo
  - It's not easy because there's a ton of configuration needed . The MI50 is not supported by rocm anymore which means that we need to use older versions and compile it all ourselves. 

- LLMs are horribly memory bandwidth and memory size limited. Not as compute limited.
  - Forget the M4, it has MAX chip with half bandwidth.
  - The choice would be between M2/M3 Ultra at around 800GB/s. Unfortunately Apple asks for extreme premiums on memory capacity.
  - The AMD AI Max boxes go for around 2 000 with 128GB of unified memory, that alone makes them a better value, but it's slower memory at 250 GB/s
  - With AI Max 395 you spend less to run much bigger models, or regular models slower.
  - Personally I have a 7900XTX 24GB that is really competent due to the high memory bandwidth. I can run 30B models competently on my GPU with ROCm or Vulkan runtimes.

- Memory bandwidth of 3090 is also 800GB/sec right, so in terms of new machine M2/M3 Ultra is relatively similar performance with ability to use bigger model?
  - If you are serious about machine learning, not, and it's not even close. It's just LLM inference that it can work because they are very forgiving on compute, and just require huge slabs of fast memory. There are people using 12 channel EPYC processors and running LLMs on 1.5 Terabytes of memory that way.
  - Nvidia has CUDA, and there aren't words to describe how far other vendors are from providing something that works like CUDA does. I use ROCm and took a month to get acceleration running on Comfy UI. With metal my collogue gets maybe 5 % of the theoretical performance, it takes minutes to diffuse somethings that take literally 2 seconds on my 7900XTX.
- No, the RTX 3090 is 4X faster for prompt evaluation and 2X faster for token generation. Because whatever they say, compute power is important too.

- ## ðŸ†š [What models can't I run with 128gb (M4 Max) vs 256gb (M3 Ultra)? : r/LocalLLaMA _202508](https://www.reddit.com/r/LocalLLaMA/comments/1mkip7t/mac_llm_users_what_models_cant_i_run_with_128gb/)
- I got the 256GB
  - Remember that the Ultra will have twice the memory bandwidth of the M4 for more speed.
  - I hate running the very largest, because it makes it so I can't run image generation at the same time with a decent sized context.

- Technically the M3 Ultra has only about 1.5x more the mem bandwidth than M4 Max (812 vs 546 GB/s)

- I have the M3 Ultra 256 gb. The problem with really large models is that inference speed is super slow. 
  - However, you can load several smaller models concurrently. Which can be useful.

- ## [need a â€œM4 Max 128GBâ€ vs â€œM3 Ultra 96GBâ€ comparison please! : r/MacStudio _202503](https://www.reddit.com/r/MacStudio/comments/1ja5xyc/need_a_m4_max_128gb_vs_m3_ultra_96gb_comparison/)
  - M4 Max [unbinned] with 16â€‘core CPU, 40â€‘core GPU, 16â€‘core Neural Engine, 128GB unified memory.
  - M3 Ultra [binned] with with 28-core CPU, 60-core GPU, 32-core Neural Engine, 96GB unified memory.

- Just to confirm, M3 Ultra (28CPU, 60GPU, 32NE) has the same memory bandwidth as M4 Max (16CPU, 40GPU, 16NE) ?
  - Apple is confusing the heck out of people - putting â€œup to 819â€ but without providing a real figure for binned chip.
- No both M3s have the same bandwidth. From apples page â€œYou can choose between two M3 Ultra chips for this Mac Studio. Both are phenomenally powerful, with a 32-core Neural Engine. Both feature 819GB/s of memory bandwidth.â€

- the M3 Ultra single-core performance is over 20% less than the M4 Max, and a fair amount of my work is heavily dependent on single-core performance

- M4 Max does seem like the best value for money in this comparison, but I want to know if am I going to lose on Ultraâ€™s 800+Gb/s memory bandwidth which seems like an important factor when it comes to 3D rendering and video editing

- [Mac Studio (M4 Max 128GB Vs M3 Ultra 96GB-60GPU) : r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/comments/1koxr32/mac_studio_m4_max_128gb_vs_m3_ultra_96gb60gpu/)
  - M3 Ultra will perform better of course. It is two cpu running in one pc. But it also means 2x more power consumption. Personally I'd pick M4 Max even though it's a bit slower

- ## ðŸ†š [So the M3 Ultra is better than the M4 Max? Why do that? : r/MacStudio _202503](https://www.reddit.com/r/MacStudio/comments/1j45hnw/so_the_m3_ultra_is_better_than_the_m4_max_why_do/)
- the M3 Ultra is different than the prior iterations of M1 and M2 Ultra. It is not two Max chip SoCâ€™s fused together with a common I/O like the M2 Ultra, rather, its a single SoC on a megachip with the performance and experience cores of two Max chips but without the limitations in memory access across the prior I/O interface. The speed and performance improvements are substantial; 
  - You are correct that the M3 Ultra does not have the single core performance of the M4 Max, but it massively outperforms the M4 Max in multicore performance; 
  - The ability to outfit the M3 Ultra Mac Studio with 512Gbs of VRAM shared unified memory is a game changer for machine learning and large model.

- Because the M2 Ultra is better than the M3 Max, and the M1 Ultra is better than the M2 Max. Thatâ€™s how itâ€™s always been

- [why don't we have m4 ultra it's much worse than you think : r/mac](https://www.reddit.com/r/mac/comments/1ld47pn/why_dont_we_have_m4_ultra_its_much_worse_than_you/)
  - In a recent video, we see that it's already possible to make the Mac Studio with an M4 Max chip overheatâ€”even with the fans running at full speed. When both the CPU and GPU are pushed to their limits simultaneously, the system draws over 330 watts of power. Thatâ€™s already enough to overwhelm the Studioâ€™s cooling system, forcing it to throttle performance to avoid overheating.
  - if you imagine an M4 Ultraâ€”which would essentially be two M4 Max chips fused togetherâ€”youâ€™re looking at a theoretical power draw of over 670 watts. Thatâ€™s more than even a high-end GPU like the RTX 5090 consumes.
  - But itâ€™s not just about cooling. The current Mac Studioâ€™s power supply is only rated for 480 watts.
  - The Mac Studio, in its current form, simply isnâ€™t built to handle that kind of power. But there is one Mac that could handle it: the Mac Pro. 
  - m3 ultra was chosen which consumes around 450w peak

- ## [è‹¹æžœæŽ¨å‡º M4 Max / M3 Ultra èŠ¯ç‰‡ Mac Studioï¼Œå“ªäº›äº®ç‚¹å€¼å¾—å…³æ³¨ï¼Ÿ - çŸ¥ä¹Ž _202503](https://www.zhihu.com/question/14167658813)
- åœ¨ä»Šå¤©ä¹‹å‰ï¼Œæœ€é€‚åˆä¸ªäººç”¨æˆ·è·‘å¤§æ¨¡åž‹çš„æœºå™¨æ˜¯ M2 Ultra + 192G å†…å­˜çš„ Mac Studioï¼Œè€Œåœ¨ä»Šå¤©ä¹‹åŽï¼Œæˆ‘å•æ–¹é¢å®£å¸ƒ Mac Studio M3 Ultra 512G ç‰ˆæœ¬

- bç«™å¼ é»‘é»‘ï¼š[DeepSeek R1] [Q4 MLX]  19.17 token/secï¼Œé€‚åˆä¸ªäººç”¨æˆ·ï¼Œä½†æ˜¯ä¸é€‚åˆå¤§è§„æ¨¡å¹¶å‘çš„å•†ä¸šåœºæ™¯
  - 512GBç»Ÿä¸€å†…å­˜ï¼Œæœ¬åœ°è·‘Q4çš„671b R1ï¼ï¼8550åˆ€ï¼ç”šè‡³ä¸åˆ°ä¸€å¼  A100 40GB
  - å†…å­˜å¸¦å®½819GB/sï¼ï¼ˆ4090æ˜¯1008GB/sï¼Œ5090æ˜¯1792GB/sï¼Œä¹°äº†ä¸€å †å•†å•å¹ä¸Šå¤©çš„AI Max+395çš„å¸¦å®½æ˜¯256GB/sï¼‰
- ä¸è¿‡çŽ°é˜¶æ®µllmè¿˜æ˜¯ä¹°ä¸å¦‚ç§Ÿï¼Œç§Ÿä¸å¦‚ç™½å«–
  - é™¤éžæ˜¯ä¸“ä¸šç›¸å…³éœ€è¦è‡ªå·±è°ƒæ¨¡åž‹å‘paperï¼Œæˆ–è€…æ˜¯ç½‘ä¸Šæµå‡ºä¸ª671bçš„NSFWçš„modelï¼Œå¦åˆ™æœ¬åœ°éƒ¨ç½²671bæ²¡æœ‰å¤ªå¤§æ„ä¹‰ï¼ˆ70bç¼ºçš„é€šè¯†çŸ¥è¯†å¯ä»¥é€šè¿‡å…è®¸è”ç½‘æœç´¢æ¥å¼¥è¡¥ï¼‰

- å…¶å®žï¼Œæœ€åº”è¯¥å¹²è¿™ä¸ªæ´»çš„æ˜¯AMDæ‰‹é‡Œæœ‰CPUï¼Œæœ‰GPUï¼Œæœ‰ç¼“å­˜ï¼Œæœ‰é«˜é€Ÿæ€»çº¿ã€‚è€Œä¸”x86ç”Ÿæ€å¥½ã€‚AMDå¼„ä¸€ä¸ª8æ ¸å¤„ç†å™¨ï¼ŒGPUå°½å¯èƒ½å¤šçš„èŠ¯ç‰‡ï¼Œæ”¯æŒå¤šé€šé“lpddr5å¾ˆæ–¹ä¾¿ã€‚ç»“æžœï¼Œè¿˜æ˜¯è‹¹æžœå…ˆå¼„å‡ºæ¥äº†ã€‚

- AMD AI Maxï¼Œ4070çº§æ ¸æ˜¾ï¼Œ128Gç‰‡ä¸Šå†…å­˜ï¼Œä½†å†…å­˜å¸¦å®½å°±256ï¼Œè‹¹æžœæ˜¯500/800

- LLMä¸€æ¬¡æŽ¨ç†å¯ä»¥åˆ†ä¸ºprefillå’Œgenerateä¸¤ä¸ªé˜¶æ®µã€‚
  - prefillé˜¶æ®µè¯»å…¥æ‰€æœ‰tokenï¼Œç„¶åŽè®¡ç®—ä»–ä»¬çš„å†…éƒ¨è¡¨ç¤ºã€‚ä½ å¯ä»¥ç†è§£ä¸ºå†™æ–‡ç« å‰å…ˆè¯»ä¸€éä¹¦ï¼ŒæŠŠä¹¦ä¸Šçš„å­—è½¬æ¢ä¸ºè‡ªå·±ç†è§£çš„å†…å®¹ã€‚
  - generateé˜¶æ®µåˆ™æ˜¯æ ¹æ®prefillçš„è®¡ç®—ç»“æžœï¼Œç”Ÿæˆæ–°çš„tokenã€‚è¿™ä¸ªå¯ä»¥ç†è§£ä¸ºæ˜¯çœ‹å®Œä¹¦å¼€å§‹å†™ï¼Œä¸€æ¬¡å†™ä¸€ä¸ªå­—ï¼Œå†™å®Œä¸€ä¸ªå­—åŽå†å†™ä¸‹ä¸€ä¸ªã€‚
  - prefillæ˜¯è®¡ç®—å¯†é›†åž‹ä»»åŠ¡ï¼Œå› ä¸ºprefillæ—¶æ‰€æœ‰è¦è®¡ç®—çš„tokenéƒ½å·²ç»ç¡®å®šï¼Œå¯ä»¥å¹¶è¡Œåœ°åŒæ—¶è®¡ç®—æ‰€æœ‰tokenå¯¹åº”çš„å†…éƒ¨çŠ¶æ€ã€‚
  - generateæ˜¯å†…å­˜å¯†é›†åž‹ä»»åŠ¡ï¼Œå› ä¸ºgenerateæ—¶æ¯ä¸ªtokençš„è®¡ç®—éƒ½ä¾èµ–äºŽå‰ä¸€ä¸ªtokençš„è®¡ç®—ç»“æžœï¼Œæ‰€ä»¥åªèƒ½ä¸€ä¸ªä¸€ä¸ªåœ°è®¡ç®—ï¼Œè¿™æ—¶å€™å¸¦å®½å°±æˆäº†ç“¶é¢ˆ
  - prefillå½±å“çš„æ˜¯ä½ çœ‹åˆ°ç¬¬ä¸€ä¸ªè¿”å›žçš„å­—ä¹‹å‰è¦ç­‰å¤šä¹…ï¼Œgenerateå½±å“çš„æ˜¯åŽç»­tokençš„ç”Ÿæˆé€Ÿåº¦ã€‚
- å¤§å®¶éƒ½ä¼šå¿½ç•¥prefillçš„é€Ÿåº¦åªçœ‹generateçš„é€Ÿåº¦ã€‚è¿™ä¸ªåœ¨gpuä¸Šæ˜¯åˆç†çš„ï¼Œå› ä¸ºgpuçš„è®¡ç®—é€Ÿåº¦ç›¸å¯¹èƒ½å®¹çº³çš„æ¨¡åž‹å¤§å°æ˜¯è¶³å¤Ÿçš„ã€‚ä½†æ˜¯åœ¨macä¸Šï¼Œè¿™ä¸ªæƒ…å†µå°±åè¿‡æ¥äº†ï¼Œå› ä¸ºmacçš„å†…å­˜å¯ä»¥å¾ˆå¤§ï¼Œä½†æ˜¯è®¡ç®—æ€§èƒ½æ¯”è¾ƒå·®ï¼Œè¿™å°±å¯¼è‡´prefillä¼šæˆä¸ºç“¶é¢ˆã€‚

- èŠ¯ç‰‡ä¸æ˜¯M4 Ultraï¼Œè€Œæ˜¯M3 Ultraï¼Œå…¶å®žæœ¬æ¥å°±åªæœ‰M3 Ultraï¼Œè¿™åœ¨ä¸€å¹´åŠå‰å°±æœ‰æ¶ˆæ¯äº†ï¼Œå†…éƒ¨ä»£å·æ˜¯T6032/T6033
  - è‡³äºŽM4 Ultraç›®å‰æ¶ˆæ¯ä¸­æ˜¾ç¤ºæ˜¯ä¸ä¼šæœ‰çš„ï¼Œä¸æ˜¯ä¸ºäº†ç»™ Mac Pro åŽ»æ‹‰å¼€äº§å“å·®å¼‚ï¼Œè€Œæ˜¯M4 Max æ²¡æœ‰ UltraFusionè¿žæŽ¥å™¨ï¼ŒM3 Max æ˜¯æœ‰ UltraFusion çš„ï¼Œåªæ˜¯åˆ‡å‰²èŠ¯ç‰‡çš„æ—¶å€™æŠŠ UltraFusion è¿žæŽ¥å™¨åˆ‡æŽ‰äº†ï¼Œæ‰€ä»¥æ”¾åˆ°ç½‘ä¸Šçœ‹åˆ°çš„ M3 Max çš„ Die å›¾æ‰¾ä¸åˆ° UltraFusion è¿žæŽ¥å™¨ã€‚
  - M3 Ultra é›·é›³5çš„é©±åŠ¨åº”è¯¥æ˜¯é‡æ–°è®¾è®¡ï¼Œç¬¦åˆå®ƒæœ¬èº«çš„å®šä½ã€‚
- çœ‹å†…éƒ¨ä»£å· M5 Ultra ä¸º T6052ï¼Œä¹Ÿæ˜¯ä½¿ç”¨ UltraFusion è¿žæŽ¥ä¸¤å— M5 Maxã€‚
- m4maxç›¸æ¯”m3maxæ ¸å¿ƒæå‡ä¸å¤§ã€‚åšm4ultraæå‡ä¹Ÿä¸å¤§ï¼Œç ”å‘æˆæœ¬è¿˜é«˜ã€‚å¹²è„†ç›´æŽ¥m5ultraæƒŠè‰³ä¸€ç‚¹

- 
- 
- 
- 
- 

- 
- 
- 
- 

- ## [è‹¹æžœäº§å“ä¸­çš„â€œç»Ÿä¸€å†…å­˜ï¼ˆunified memoryï¼‰â€œä¸Žä»¥å¾€çš„â€å†…å­˜ï¼ˆmemoryï¼‰â€œæœ‰ä½•ä¸åŒï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/429727608)
- ç»Ÿä¸€æž¶æž„çš„å¥½å¤„ï¼Œå°±æ˜¯æŠŠä»¥å‰å†…å­˜å’Œæ˜¾å­˜ï¼ˆæ˜¾å¡çš„å†…å­˜ï¼Œgpuç”¨çš„memoryï¼‰åšäº†ç»Ÿä¸€
  - è¿™æ ·å°±å‡å°‘äº†cpuå’Œgpué€šä¿¡æ—¶å€™ï¼Œåœ¨å†…å­˜å’Œæ˜¾å­˜ä¹‹é—´æ•°æ®é€šä¿¡æ—¶å€™çš„æ‹·è´

- è¿™ä¸ªç»Ÿä¸€å†…å­˜å°±æ˜¯æŠŠå†…å­˜ã€GPUçš„æ˜¾å­˜å’Œç¥žç»ç½‘ç»œå¤„ç†å™¨çš„ç¼“å­˜æ”¾åˆ°ä¸€èµ·ï¼Œé€šè¿‡Fabricå’ŒCPU/GPU/ç¥žç»ç½‘ç»œå¤„ç†å™¨ç›¸è¿žã€‚
  - å¥½å¤„æ˜¯ç­‰äºŽåœ¨CPUä¸ŽGPUé—´åŠ äº†ä¸ªç¼“å­˜åŒºï¼Œå®ƒä»¬ä¹‹é—´çš„æ•°æ®ä¼ è¾“æ›´å®¹æ˜“ï¼›
  - åå¤„å°±æ˜¯ä¸‰ä¸ªå…¬ç”¨é‚£ä¹ˆå¤§ç»Ÿä¸€å†…å­˜ï¼ˆæ¯”å¦‚æœ‰16GBï¼‰ï¼Œç­‰äºŽç»™CPUçš„å†…å­˜å®žé™…ä¸åˆ°16GBï¼Œå…¶ä¸­æœ‰éƒ¨åˆ†ä¸å¾—ä¸åˆ†ç»™GPUå’Œç¥žç»å¤„ç†å™¨ã€‚
- æ¢ä¸ªæ€è·¯ï¼Œcpuå…¶å®žç”¨åˆ°äº†ä¸€éƒ¨åˆ†æ˜¾å­˜

- UMAè¿™ä¸œè¥¿æ—©å…«ç™¾å¹´ç”¨çƒ‚äº†ï¼Œlinuxçš„kernelé‡Œæœ‰ä¸ªdma-bufå­ç³»ç»Ÿä¸“é—¨ç”¨æ¥åšè¿™ä¸ªä¸œè¥¿
  - dma-bufå¯ä»¥ç†è§£ä¸ºä¸€ä¸ªåœ¨é©±åŠ¨é—´å…±äº«çš„å¯è¢«ä¸åŒç¡¬ä»¶å…±äº«çš„å†…å­˜ï¼Œå½“ç„¶è¿™ä¸ªå†…å­˜å±žäºŽdevice memoryï¼Œæœ‰è¯»å†™é™åˆ¶ï¼Œå’ŒCPUå®žçŽ°æœ‰å…³ï¼Œè¿™ä¸ªå­ç³»ç»Ÿè‡³å°‘é›¶å‡ å¹´å°±æœ‰äº†

- è¦è¯´ç»Ÿä¸€å†…å­˜amdèµ°å¾—æ›´å‰ï¼Œç´¢å°¼åœ¨ps4å°±ç”¨ä¸Šäº†

- [è‹¹æžœå‘å¸ƒä¼šç»Ÿä¸€å†…å­˜æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/429767639)
  - ä»¥å‰cpuæœ‰è‡ªå·±çš„å†…å­˜ï¼Œgpuä¹Ÿæœ‰è‡ªå·±çš„å†…å­˜å«æ˜¾å­˜ï¼Œè‹¹æžœç›´æŽ¥ç»Ÿä¸€èµ·æ¥äº†æ‰€ä»¥å«ç»Ÿä¸€å†…å­˜ã€‚å¥½å¤„æ˜¯é¿å…äº†å†…å­˜å’Œæ˜¾å­˜ä¹‹é—´çš„æ•°æ®æ¬è¿ï¼Œåå¤„ï¼šè´µã€‚
  - è´µä½“çŽ°åœ¨éœ€è¦æ›´å¤šçš„lpddræŽ§åˆ¶å™¨å¯¼è‡´èŠ¯ç‰‡é¢ç§¯å¤§ï¼Œè€Œä¸”lpddræœ¬èº«å°±è´µä¸€ç‚¹ï¼Œç„ŠæŽ¥ä¸€èµ·çš„lpddrå‡ ä¹Žä¸èƒ½æ›´æ¢ã€‚
  - è‡³äºŽæœ‰ä¸ªå›žç­”è¯´ä»€ä¹ˆsocçš„ï¼ŒçŽ°åœ¨æ‰€æœ‰çš„cpuéƒ½æ˜¯socï¼Œgpuä¹Ÿæ˜¯socã€‚socè·Ÿæ˜¯ä»€ä¹ˆèŠ¯ç‰‡æ²¡å…³ç³»ï¼Œåªè¦ä¸æ˜¯å•ä¸€æ¨¡å—éƒ½æ˜¯socã€‚çŽ°åœ¨çš„cpuä¹Ÿæœ‰dspï¼ˆè§†é¢‘ç¡¬ä»¶ç¼–è§£ç ï¼‰è¿™äº›æ¨¡å—æ‰€ä»¥éƒ½æ˜¯socã€‚
- UMAä¸æ˜¯ä»€ä¹ˆå‘æ˜Žï¼Œä½Žç«¯PC/æ¸¸æˆæœºä¸Šæ—©å°±æœ‰äº†ã€‚è‹¹æžœåªæ˜¯æŠŠå†…å­˜å¸¦å®½æ•´çš„æ¯”è¾ƒå¤¸å¼ ï¼ˆé€šè¿‡å°è£…ï¼‰ã€‚

- ## [å¦‚ä½•è¯„ä»·è‹¹æžœ 3 æœˆ 5 æ—¥å‘å¸ƒçš„ MacBook Air M4ï¼Œç›¸æ¯”å‰ä»£æœ‰å“ªäº›æå‡ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/14167413067)
- M4 ç›¸è¾ƒäºŽ M3 æœ‰ 18ï½ž25% çš„æå‡
- æ˜¾è‘—å½±å“ä½ çš„ç”µè„‘çš„ä½¿ç”¨å¹´é™çš„ï¼Œæ˜¯ç¡¬ç›˜å’Œå†…å­˜ï¼Œè€Œä¸æ˜¯å¤„ç†å™¨ï¼Œè¿˜æ˜¯é‚£å¥è¯ï¼šæ…¢ä¸æ…¢å’Œèƒ½ä¸èƒ½æ˜¯ä¸¤ä¸ªæ¦‚å¿µ

- å…¶å®žM4çš„å•æ ¸æå‡ä¸å¤ªé‡è¦ï¼Œå› ä¸ºM4ç›¸æ¯”M3å•æ ¸èƒ½æ•ˆæå‡å¾ˆå°ï¼ˆ3%å¤šä¸€ç‚¹ï¼‰ï¼Œå¤šå‡ºçš„é‚£äº›æ€§èƒ½éƒ½æ˜¯æ‹‰é«˜é¢‘çŽ‡æ‹¿åŠŸè€—æ¢çš„ã€‚åè€Œå¤šæ ¸æå‡æ˜¯å¾ˆé‡è¦çš„ï¼Œåƒæˆ‘å†™è®ºæ–‡ä¸€å¼€å°±æ˜¯åå‡ ä¸ªç½‘é¡µ+PDFæ–‡çŒ®+ç¼–è¯‘å™¨ï¼ŒM4å¤šå‡ºçš„ä¸¤ä¸ªå°æ ¸èƒ½æžå¤§ç¼“è§£å¤§æ ¸çš„åŽ‹åŠ›ä»Žè€Œæå‡ç»­èˆª

- M4 çš„ GPU æ€§èƒ½æ¯” M3 æå‡çº¦ 21%ï¼Œæ›´é€‚åˆå¤„ç†3Då›¾å½¢æ¸²æŸ“ç›¸å…³çš„ä»»åŠ¡
  - å¤„ç†é€Ÿåº¦æé«˜ï¼šå•æ ¸ä»»åŠ¡å¿«çº¦ 25%ï¼Œå¤šæ ¸ä»»åŠ¡å¿«çº¦ 30%

- ## ðŸ‘·ðŸ» [macbook air m4 æ•²ä»£ç æ˜¯å¦å¤Ÿç”¨ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/15035632763)
- åœ¨ä½¿ç”¨ MacBook Air M4 24 + 512 è¿‘ä¸€ä¸ªæœˆåŽï¼Œæˆ‘å¯ä»¥è¯´è¿™å·²ç»æ˜¯æˆ‘æœ€å–œæ¬¢çš„ç”µè„‘äº†ã€‚æˆ‘ç”¨ä¸€å‘¨æ—¶é—´ï¼Œåœ¨ä¸å…³æœºçš„æƒ…å†µä¸‹ç”¨ mactop å¯¹ä¸Šè¿°å·¥å†µä¸‹çš„ç³»ç»Ÿä½¿ç”¨æ•°æ®è¿›è¡Œé‡‡é›†å¹¶è¿›è¡Œç®€å•çš„ç»Ÿè®¡åˆ†æžï¼Œç»“æžœå¦‚ä¸‹ï¼š
  - æ•´ä¸ªç³»ç»Ÿè´Ÿè½½æœ€å¤§çš„æŒ‡æ ‡æ˜¯ RAM å’Œ SWAPã€‚æˆ‘çš„å†…å­˜æ˜¯ 24GBï¼Œä½†æ˜¯åœ¨å¼€å¯æ‰€æœ‰å¸¸ç”¨ç¨‹åºåŽ SWAP ä¾æ—§æ¥åˆ°äº† 8GB å·¦å³ï¼Œè¯´æ˜Žå…¶å®ž 32GB æ˜¯æœ‰å¿…è¦çš„ï¼ˆä¸è¿‡å½“æ—¶æ²¡æœ‰å›½è¡¥æ‰€ä»¥ä¹°äº† 24GBï¼‰ã€‚ä¸è¿‡å³ä½¿å¦‚æ­¤ï¼Œæ•´ä¸ªç³»ç»Ÿä¾æ—§ä¸æ»‘ï¼Œç”¨èµ·æ¥å®Œå…¨æ²¡æœ‰å¡é¡¿ã€‚
  - CPU å’Œ GPU çš„å‡å€¼ä¸è¶…è¿‡ 20%ï¼Œç•¥é«˜äºŽæˆ‘ä¸Šæ¬¡åœ¨ M4 Pro ä¸Šæµ‹è¯•çš„ç»“æžœï¼Œè¿™æ˜¯åˆç†çš„ï¼Œæ¯•ç«Ÿå·®äº† 2 - 4ä¸ªæ ¸å¿ƒï¼Œä½†æ˜¯ä¾æ—§æ²¡æœ‰æˆä¸ºæ€§èƒ½ç“¶é¢ˆã€‚95% åˆ†ä½æ•°ä¹Ÿåœ¨ 30% å·¦å³ï¼Œä¸Žä¸Šæ¬¡ç›¸å·®ä¸å¤§ã€‚è¯´æ˜Ž M4 è¿™é¢—èŠ¯ç‰‡æä¾›çš„æ€§èƒ½å…¶å®žä¾æ—§å®Œå…¨æ»¡è¶³äº†æˆ‘çš„æ—¥å¸¸éœ€æ±‚ã€‚
  - æ—¥å¸¸ä½¿ç”¨æ—¶å‡ ä¹Žæ„Ÿå—ä¸åˆ°å‘çƒ­ã€‚
- æˆ‘ç»å¸¸éœ€è¦æ‹¿ç€ç”µè„‘åŽ»ä¼šè®®å®¤å¼€ä¼šï¼Œæ¯ä¸€æ¬¡ä»Žæ¡Œä¸Šæ‹¿èµ· MacBook Pro æ—¶ï¼Œä¾§é¢çš„å‡ºé£Žå£éƒ½ä¼šç»™æˆ‘å¾ˆå¼ºçš„æ„ŸçŸ¥ï¼Œè¿™ä¸€ç‚¹ä¸Š Air çš„æ‰‹æ„Ÿå®Œèƒœã€‚

- ä¸èƒ½ç”¨windows ä¸èƒ½åšå®‰å“é€†å‘ æ·˜æ±° å•¥æ—¶å€™å›žå½’ windows å†ä¹°ï¼ŒçŽ°åœ¨ç”¨2019æ¬¾è£…çš„ win10

- å¼€äº†å†…å­˜æ³„æ¼å¤§æˆ·zoteroå’Œarcæ¸¸è§ˆå™¨ä¹‹åŽï¼Œ24gè¿å­˜å°±å¼€å§‹ä¸å¤Ÿäº†

- ä¸ªäººæµ‹è¯•mac mini m4 16gç‰ˆæœ¬ï¼Œè¿è¡Œ20wè¡Œä»£ç çš„javaé¡¹ç›®ï¼Œdockerè¿è¡Œ mongo + redis+mysqlï¼Œå¼€ä¸ƒå…«ä¸ªç½‘é¡µï¼Œå†…å­˜åŽ‹åŠ›å°±å·²ç»å¼€å§‹é»„è‰²ï¼Œå¯¹æˆ‘æ¥è¯´è¿™è¿˜æ˜¯è½»åº¦æµ‹è¯•ï¼Œæˆ‘ä¸ªäººå·¥ä½œæµå››äº”åä¸ªç½‘é¡µéƒ½å¾ˆå¸¸è§ï¼ŒåŽå°è¿˜éœ€è¦postmanï¼Œå¾®ä¿¡ï¼Œqqç­‰ï¼ŒæŒ‰æˆ‘ç”¨æ³•å¾—32gä»¥ä¸Šæ‰å¤Ÿç”¨ã€‚ã€‚

- å¦‚æžœåªæ˜¯ä¸ºäº†å¤–æŽ¥è®¾å¤‡çš„è¯ï¼Œä¸€ä¸ªå‡ ç™¾å—çš„è½¬æŽ¥å™¨å°±æžå®šäº†.

- 512GBç¡¬ç›˜å¿…å¤‡ï¼šXcodeã€Android Studioã€Dockeré•œåƒéšä¾¿ä¸€ä¸ªéƒ½èƒ½åƒ50GBï¼Œ256GBåˆ†åˆ†é’Ÿçˆ†ä»“

- çœŸè¦æ•£çƒ­ç„¦è™‘ï¼Œæ·˜å®30å—ä¹°ä¸ªç¬”è®°æœ¬æ”¯æž¶ï¼Œæ¸©åº¦è¿˜èƒ½å†é™5â„ƒ

- ## [æ˜¯é€‰M4 MacBook Airè¿˜æ˜¯M4 MacBook Pro? - çŸ¥ä¹Ž](https://www.zhihu.com/question/14423191905)
- MacBook Air M4ï¼šæœ‰2ä¸ªé›·é›³4æŽ¥å£ã€MagSafeå……ç”µæŽ¥å£å’Œä¸€ä¸ªè€³æœºæ’å­”ã€‚
- MacBook Pro M4ï¼šæœ‰3ä¸ªé›·é›³4æŽ¥å£ï¼Œè¿˜å¢žåŠ äº†HDMIæŽ¥å£å’ŒSDå¡æ§½

- Proæ­è½½M4 Pro/M4 Max èŠ¯ç‰‡ï¼Œæ€§èƒ½æ ¸å¿ƒæ›´å¤šï¼ˆå¦‚ M4 Pro 14æ ¸CPU + 20æ ¸GPUï¼ŒM4 Max 16æ ¸CPU + 40æ ¸GPUï¼‰ï¼Œå†…å­˜å¸¦å®½é«˜è¾¾ 512GB/sï¼ˆM4 Maxï¼‰ï¼Œé€‚åˆå¤šè½¨é“è§†é¢‘æ¸²æŸ“ã€å¤æ‚ç‰¹æ•ˆå–å¤šå›¾å±‚è®¾è®¡ã€‚

- Proï¼Œå±å’Œå–‡å­å·®ä¸å°‘å‘¢ ï¼Œå€¼å›žå·®ä»·ã€‚

- ## [Mac miniå¯ä»¥å°†ç¬”è®°æœ¬ç”µè„‘ä½œä¸ºæ˜¾ç¤ºå™¨å—ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/11673595878)
- å¯ä»¥ï¼Œé€‚ç”¨äºŽæ‰€æœ‰ç¬”è®°æœ¬ç”µè„‘çš„æ–¹æ³•æ˜¯ï¼Œé€šè¿‡ç½‘ç»œè¿žæŽ¥è¿œç¨‹æ¡Œé¢---ç‰¹åˆ«æ˜¯ä¸¤å°ç”µè„‘éƒ½å¤„äºŽåŒä¸€å±€åŸŸç½‘çš„æƒ…å½¢ä¸‹ï¼Œæ•ˆæžœéžå¸¸å¯ä»¥ã€‚
- å¦‚æžœç”¨è‡ªå¸¦çš„å±å¹•å…±äº«ï¼ŒMacè‡ªå·±çš„å®¢æˆ·ç«¯è¿žæŽ¥é€Ÿåº¦å°šå¯ï¼Œå…¶ä»–VNCå®¢æˆ·ç«¯å€’æ˜¯ä¸€è¨€éš¾å°½ã€‚
- å¯ä»¥ç”¨HDMIé‡‡é›†å¡ã€‚Mac miniä»Ž2010æ¬¾å¼€å§‹éƒ½æ ‡é…äº†HDMIæŽ¥å£ã€‚
  - é‡‡é›†å¡ä¸èƒ½å…±äº«é”®ç›˜é¼ æ ‡
  - æˆ–è€…KVM over USBçš„ï¼Œç„¶åŽè‡ªå·±ç”¨ä¸€å¥—é¼ æ ‡é”®ç›˜
- ç›´æŽ¥è¿žæŽ¥ä¸å¤ªçŽ°å®žï¼Œä½†æ˜¯å¯ä»¥ç”¨å±å¹•å…±äº«å·¥å…·ï¼ŒæŠŠ Mac mini æŠ•å±åˆ°ç¬”è®°æœ¬ä¸Šï¼Œå°±å¯ä»¥ç›¸å½“äºŽä½¿ç”¨ç¬”è®°æœ¬çš„é”®ç›˜å’Œè§¦æŽ§æ¿æ¥æŽ§åˆ¶Macã€‚ä½†è¦åœ¨ç¬”è®°æœ¬ä¸Šè£…æ”¯æŒ VNC åè®®çš„å®¢æˆ·ç«¯ï¼Œå†é€šè¿‡ IP åœ°å€æˆ– Apple IDæ¥ è¿žæŽ¥Macminiã€‚ä½†æ˜¯è¿™ä¸ªæ“ä½œéžå¸¸åƒç½‘ç»œç¨³å®šæ€§ï¼Œè€Œä¸”ç”»é¢å»¶è¿Ÿæœ‰ç‚¹å°é«˜ã€‚ä½ ä¸ä»‹æ„çš„è¯å°±å¯ä»¥ä¸€è¯•ï¼Œæœ€å¥½è¿˜æ˜¯ç›´æŽ¥ç»™ Mac mini é…ç‹¬ç«‹çš„æ˜¾ç¤ºå™¨ã€‚

- ç¬”è®°æœ¬ç”µè„‘æ²¡æœ‰è§†é¢‘è¾“å…¥åŠŸèƒ½ï¼Œè¦å½“æ˜¾ç¤ºå™¨ä¹Ÿä¸æ˜¯ä¸å¯ä»¥ï¼Œå¯ä»¥åŽ»ä¹°ä¸ªé‡‡é›†å¡ï¼Œå°†å°±å¯ä»¥ç”¨äº†ã€‚

- ä¸è¿‡é‡‡é›†å¡ï¼Œå¥½çš„è¿˜æ˜¯æŒºè´µçš„ï¼Œè¿˜ä¸å¦‚åŽ»ä¹°ä¸ªä¾¿æºå±å¹•ï¼Œæ–¹ä¾¿æºå¸¦ï¼Œè¿˜èƒ½ç»™ç¬”è®°æœ¬ç”µè„‘ç”¨ä¹Ÿå¯ä»¥ã€‚

- å¦‚æžœéœ€è¦æºå¸¦ï¼Œæœ‰ä¾¿æºå±å¯ä»¥é€‰æ‹©ï¼Œé…åˆMac mini M4ç”¨å¯ä»¥ä¸€çº¿é€šï¼Œè¿˜æ˜¯æ¯”è¾ƒçœå¿ƒçš„ã€‚ç‰¹åˆ«æ˜¯æœ‰äº›æœ‰ä¸€äº›æ”¯æŒè§¦æŽ§çš„ï¼Œå¯ä»¥ç»™macOSè§¦æŽ§æ“ä½œ
  - ä¾¿æºå±çš„è¯ï¼Œæˆ‘å–œæ¬¢16è‹±å¯¸çš„ï¼Œèƒ½æºå¸¦ï¼Œçœ‹ç€ä¹Ÿèˆ’æœã€‚åƒç»´è¾°æ€è¿™ä¸ªï¼Œ4Kåˆ†è¾¨çŽ‡ï¼Œæ˜¯100% DCI-P3å¹¿è‰²åŸŸï¼Œ500å°¼ç‰¹äº®åº¦ï¼Œæ—¥å¸¸å¤Ÿç”¨äº†ã€‚

- ## [Mac miniçš„æ˜¾ç¤ºå™¨æŽ¨èï¼šä¾¿æºæ˜¾ç¤ºå™¨èƒ½åšä»€ä¹ˆï¼Œå¹³æ¿èƒ½åšå±å¹•ç”¨å—ï¼Ÿ - çŸ¥ä¹Ž](https://zhuanlan.zhihu.com/p/31411990698)
- ä»€ä¹ˆå«ä¸€çº¿é€šï¼Ÿå°±æ˜¯Mac minié€šè¿‡é›·é›³4æŽ¥å£ï¼Œå’Œä¾¿æºå±è¿žæŽ¥å°±å¯ä»¥å®žçŽ°ç»™å±å¹•ä¾›ç”µå’Œä¿¡å·ã€‚ä¾¿æºå±ä¸éœ€è¦å¦å¤–æ’ç”µæºäº†ã€‚

- ä¸ºå•¥ä¸æŠŠå¹³æ¿å½“æ˜¾ç¤ºå™¨ç”¨ï¼Ÿ
  - å„ç§å¹³æ¿ç”µè„‘ä¸æ”¯æŒè§†é¢‘è¾“å…¥ï¼Œåªèƒ½é€šè¿‡è¿œç¨‹æ¡Œé¢ï¼Œæˆ–è€…æŽ¨æµæ–¹å¼å®žçŽ°ã€‚ä½†æ˜¯è¿™æ ·æ–¹æ¡ˆä¸€ä¸ªæ˜¯å»¶è¿Ÿå¾ˆä½Žï¼Œåˆ†è¾¨çŽ‡ä¹Ÿåªæ˜¯åˆ°1080Pè€Œå·²ï¼Œæ›´é«˜åˆ†è¾¨çŽ‡æŒºè´¹é’±ï¼Œæ²¡å¿…è¦ã€‚
  - åƒiPadï¼ŒçŽ°åœ¨å®‰å“å¹³æ¿ï¼Œéƒ½æ²¡æœ‰è§†é¢‘è¾“å…¥èƒ½åŠ›ã€‚è¢«å•†å®¶é™åˆ¶äº†åŠŸèƒ½ï¼Œæˆ–è€…ä¸æƒ³åšã€‚

- [MacBooké…ä»¶ä¹‹ä¾¿æºå±é€‰è´­æ”»ç•¥ - çŸ¥ä¹Ž](https://zhuanlan.zhihu.com/p/628909420)

- ## [Mac minié…å¯éšèº«å¸¦æ˜¾ç¤ºå™¨å¦‚ä½•ï¼Œæ˜¯ä¸æ˜¯æ¯”ç¬”è®°æœ¬è¿˜è‡ªç”±ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/51732960)
- ç¬”è®°æœ¬ç§»åŠ¨ç”µæºï¼ˆorå¤ªé˜³èƒ½ç”µæ± æ¿ï¼‰+è½¬æŽ¥å£+è€³æœº+ä¾¿æºå¼æ˜¾ç¤ºå™¨ã€‚
- éšèº«æ˜¾ç¤ºå™¨ï¼Œè¿˜è¦å¸¦ä¸Šéšèº«é”®ç›˜ï¼Œè¿˜æœ‰éšèº«æŽ’æ’ã€‚è¿˜æœ‰éšèº«éŸ³å“çš„äº²ã€‚

- éšèº«æºå¸¦çš„æ˜¾ç¤ºå™¨æœ‰å¾ˆå¤šé€‰æ‹©ï¼Œæˆ‘è§‰å¾—ä¸»è¦é—®é¢˜æ˜¯ç”µæºï¼Œå¦‚æžœèƒ½æžä¸€ä¸ªéšèº«æºå¸¦ç”µæ± ï¼Œæˆ‘è§‰å¾—è®© Mac mini å˜æˆç¬”è®°æœ¬å°±ä¸éš¾äº†ã€‚

- ## [å…¥é—¨macOSç³»ç»Ÿï¼Œé€‰airè¿˜æ˜¯pro? - çŸ¥ä¹Ž](https://www.zhihu.com/question/1895920692941263011)
- Proå¤šå‡ºæ¥çš„æ€§èƒ½ï¼Œæ™®é€šäººæ ¹æœ¬ç”¨ä¸ä¸Šï¼Œå°±åƒä½ ä¹°ä¸ªè·‘è½¦ä½†å¤©å¤©å µåœ¨ä¸‰çŽ¯

- airè¿˜æœ‰ä¸ªå¥½å¤„ï¼Œå¹´å¤´ä¹…äº†ä¹Ÿä¸ç”¨æ¸…ç°ï¼Œçœäº‹ã€‚

- MacBook Air M4èŠ¯ç‰‡å’ŒMac miniï¼Œä»¥åŠMacBook Proæœ‰åŒºåˆ«ï¼Œå®ƒçš„CPUæ˜¯10æ ¸å¿ƒï¼Œä½†æ˜¯GPUæ˜¯8æ ¸å¿ƒçš„ï¼Œæ¯”é‚£ä¸¤ä¸ªæ ¸å¿ƒæ•°å°‘äº†ä¸¤ä¸ªã€‚åœ¨å›¾å½¢ç§˜ç±çš„å› å…¬ï¼Œæ¯”å¦‚ä¸€äº›æ¸¸æˆï¼Œä¼šæœ‰ä¸€äº›å½±å“ã€‚

- ## [Macbook Air M4 24+512è¿˜æ˜¯ Macbook Pro M4 Pro 24+512? - çŸ¥ä¹Ž](https://www.zhihu.com/question/1893050996537668535)
- æœ‰æ¡ä»¶è¿˜æ˜¯å°½é‡é€‰proï¼Œproçš„æŽ¥å£å’Œå±å¹•æ›´é€‚åˆç”Ÿäº§åŠ›ï¼Œ
  - å®ƒçš„mini ledå±åœ¨å†™ä»£ç æ—¶ï¼Œ120Hz Promotionå¸¦æ¥çš„è·Ÿæ‰‹æ„Ÿæ˜¯ç”¨äº†å°±å›žä¸åŽ»çš„ã€‚
  - è€Œä¸”proé»˜è®¤æ”¯æŒåŒæ—¶å¤–æŽ¥2å°6Kæ˜¾ç¤ºå™¨ï¼Œairéœ€å¼€ç›–æ‰èƒ½å¤–æŽ¥åŒå±ï¼Œproå¯¹äºŽå¤šçª—å£å·¥ä½œæ›´çµæ´»ã€‚
  - åƒä½ å¦‚æžœç»å¸¸åŒæ—¶è¿›è¡Œå¤šä»»åŠ¡ï¼Œæ¯”å¦‚åŽå°è·‘Stata+å¼€PyCharm+Chromeå¤šæ ‡ç­¾ï¼Œéœ€è¦å¤–æŽ¥å¤šå±æˆ–é«˜é€ŸæŽ¥å£ï¼Œé‚£å¿…é¡»æ˜¯pro

- Air å’Œ pro æˆ‘è§‰å¾—ä½“éªŒä¸Šçš„æœ€å¤§å·®å¼‚æ˜¯å±å¹•è§‚æ„Ÿï¼Œå¦‚æžœä½ éœ€è¦é«˜äº®åº¦ï¼Œé«˜å¯¹æ¯”åº¦ï¼Œé«˜åˆ·æ–°çŽ‡ï¼Œé‚£æ— ç–‘åªæœ‰ pro æ»¡è¶³ï¼Œå¦‚æžœå¯¹è¿™äº›æ²¡è¦æ±‚ï¼Œé‚£å°±å›¾ Air çš„è½»è–„æ–¹ä¾¿æºå¸¦å§ï¼›

- ä½œä¸ºç»´ä¿®äººå‘˜æ¥è¯´ï¼ŒPROçš„æ•…éšœçŽ‡æ¯”AIRé«˜å¾ˆå¤šï¼Œ10å°åæŽ‰çš„æœºå™¨7æˆæ˜¯PROï¼ŒAIRæ•…éšœçŽ‡éžå¸¸ä½Žï¼Œè‹¹æžœåŽ†ä»£çš„AIRéƒ½æ˜¯è¿™æ ·çš„ï¼Œè‹¹æžœçš„AIRç”¨ä¸ªå‡ å¹´ï¼Œé¡¶å¤šç”µæ± æ‰›ä¸ä½äº†æ¢ä¸ªç”µæ± å°±å¥½äº†ï¼ŒPROå°±ä¸ä¸€æ ·ï¼Œä¸»æ¿æ•…éšœçŽ‡å¯¹æ¯”AIRé«˜å¤ªå¤šäº†

- ## ðŸ†šï¸ [MacBook Air ä¸Ž MacBook Pro å·®åˆ«å¤šå¤§ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/20385806)
- MacBook Pro ä¸Ž MacBook Airå·®åˆ«æœ‰å¤šå¤§ï¼Œè¦å¤§å¯ä»¥å¾ˆå¤§ï¼Œè¦å°ä¹Ÿå°±ä¸ªé£Žæ‰‡çš„å·®è·ã€‚

- Airæ²¡æœ‰é…é£Žæ‰‡ï¼Œå¤§åž‹è½¯ä»¶åªèƒ½è½»åº¦ä½¿ç”¨ã€‚å¤–æŽ¥æ˜¾ç¤ºå™¨è¶…è¿‡ä¸€å®šæ—¶é—´å‘çƒ­å¤„ç†å™¨å°±ä¼šé™é¢‘ã€‚
  - Proæœ‰é£Žæ‰‡ï¼Œå¤§åž‹è½¯ä»¶è€—ç”µè¾ƒå¤§ã€‚ä½†Proçš„æ€§èƒ½é™¤Mac proå’Œstudioå¤–æœ€å¼ºï¼

- åŒé…ç½®çš„M1 èŠ¯ç‰‡ MacBook Air å’Œ M1 èŠ¯ç‰‡ MacBook Proï¼Œå·®è·å°±åœ¨äºŽMacBook Proæœ‰é£Žæ‰‡ï¼ŒMacBook Airæ²¡æœ‰é£Žæ‰‡ï¼Œå¯¼è‡´MacBook Proåœ¨æŒç»­é«˜æ€§èƒ½å·¥ä½œä¸‹è¡¨çŽ°æ›´ä¼˜å¼‚ã€‚

- [çŽ°åœ¨é€‚åˆå…¥æ‰‹Macbookå—ï¼ŸProå’ŒAiræ€Žä¹ˆé€‰ï¼Ÿå†²M3è¿˜æ˜¯ç­‰M4ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/655713407)
- macbook æˆ‘åªæŽ¨è pro: air å¹¶ä¸è½»ï¼Œä¸æ˜¯å« air å°±è½»ï¼Œair è¿˜æœ‰å¾ˆå¤šé—®é¢˜ï¼Œæ•£çƒ­å·®ï¼Œå±å¹•å·®ï¼Œè€Œä¸”æ²¡æ³•æŽ¥å¤šä¸ªæ˜¾ç¤ºå™¨ï¼Œåªèƒ½åŒæ—¶ç‚¹äº®ä¸¤ä¸ªå±å¹•ï¼Œæ„æ€å°±æ˜¯ä½ æŽ¥äº†ä¸¤ä¸ªå±å¹•çš„æƒ…å†µï¼Œair æœ¬ä½“çš„å±å¹•å°±æ²¡æ˜¾ç¤ºäº†ï¼Œæˆ‘çš„ macbook pro ä¸Šé¢æŽ¥äº† 3 ä¸ªå±å¹•ï¼Œæœ¬ä½“å±å¹•ä¹Ÿæ­£å¸¸ä½¿ç”¨ 

- Airæ— é£Žæ‰‡è®¾è®¡ï¼šé€‚åˆçŸ­æ—¶é—´é«˜è´Ÿè½½ä»»åŠ¡ï¼ˆå¦‚è½»åº¦è§†é¢‘å‰ªè¾‘ã€ç¼–ç¨‹ç¼–è¯‘ï¼‰ï¼Œä½†æŒç»­é«˜è´Ÿè½½ï¼ˆå¦‚é•¿æ—¶é—´æ¸²æŸ“ã€3Då»ºæ¨¡ï¼‰å¯èƒ½å¯¼è‡´é™é¢‘ï¼Œæ€§èƒ½ä¸‹é™ã€‚

- Proé…å¤‡ä¸»åŠ¨æ•£çƒ­é£Žæ‰‡ï¼šå¯ç»´æŒé•¿æ—¶é—´é«˜æ€§èƒ½è¾“å‡ºï¼Œæ›´é€‚åˆä¸“ä¸šçº§å·¥ä½œæµï¼ˆå¦‚4K/8Kè§†é¢‘å‰ªè¾‘ã€å¤æ‚å»ºæ¨¡ï¼‰ã€‚

- æˆ‘å†™ä»£ç ä»¥å‰æ˜¯iOSå¼€å‘ä¸ºä¸»ï¼ŒçŽ°åœ¨æ˜¯å°ç¨‹åºå¼€å‘ã€‚ä¹‹å‰ç”¨çš„æ˜¯MacBook Proï¼ŒçŽ°åœ¨ç”¨çš„æ˜¯Airï¼Œä»¥åŽåº”è¯¥éƒ½ä¼šç”¨Airäº†ã€‚æ—¢ç„¶é€‰äº†ç¬”è®°æœ¬ï¼Œå°±æ˜¯ä¸ºäº†è½»ä¾¿åŽ»çš„ã€‚ æˆ‘çŽ°åœ¨ç”¨çš„æ˜¯16G+1Tã€‚ çœŸæ­£è€ƒéªŒæ€§èƒ½çš„å¯èƒ½å°±æ˜¯è§†é¢‘å‰ªè¾‘ç±»çš„äº†ï¼Œå†™ä»£ç Proä¸ŽAiréƒ½èƒ½å¯¹ä»˜çš„ã€‚

- proç‰ˆå¤šäº†ä¸€ä¸ªHDMIæŽ¥å£ï¼Œå¦‚æžœä½ éœ€è¦å¤–æŽ¥æ˜¾ç¤ºå™¨æˆ–è€…æŠ•å½±ä»ªä¹‹ç±»çš„ä¸œè¥¿ï¼Œè¿™ä¸ªæŽ¥å£ä¼šæ–¹ä¾¿å¾ˆå¤šï¼Œå¦‚æžœä¸éœ€è¦çš„è¯ï¼Œé‚£è¿˜æ˜¯å»ºè®®çœä¸‹ä¸€åƒå—ã€‚
# discuss-pc-vendor
- ## 

- ## 

- ## 

- ## [å¦‚ä½•è¯„ä»·é«˜é€šå‘å¸ƒçš„æ–°ä¸€ä»£æ——èˆ°å¤„ç†å™¨éªé¾™8 Elite/è‡³å°Šç‰ˆï¼Œæ˜¯ä»Šå¹´æœ€å¼ºSOCå—ï¼Ÿ - çŸ¥ä¹Ž _202410](https://www.zhihu.com/question/1651714161)
- è‡ª2015å¹´11æœˆ11æ—¥é«˜é€šå‘å¸ƒäº†æ­è½½è‡ªç ” [Kryo CPU] çš„éªé¾™820ä»¥åŽï¼Œé«˜é€šå°±æ”¾å¼ƒäº†è‡ªç ”CPUï¼ŒéšåŽçš„å¤„ç†å™¨CPUéƒ½æ˜¯åŸºäºŽ [ARMå…¬ç‰ˆæž¶æž„] é­”æ”¹ï¼Œè¿™ä¸€æ¬¡åœ¨éªé¾™8 Eliteèº«ä¸Šï¼Œè‡ªç ”CPUæž¶æž„ç»ˆäºŽå›žå½’
  - éªé¾™å¤„ç†å™¨è¿™ä¹ˆå¤šå¹´ä»¥æ¥ç»åŽ†äº†æ•°æ¬¡æ”¹åï¼Œä»Žæœ€å¼€å§‹çš„MSMxxxxåˆ°éªé¾™xxxå†åˆ°éªé¾™x Gen xï¼Œä»Šå¤©åˆå‡ºæ¥ä¸ªæ–°åå­—
  - å·¥è‰ºåˆ¶ç¨‹ä¸Šäº†å°ç§¯ç”µ3nmï¼Œå’Œä¹‹å‰å‘å¸ƒçš„å¤©çŽ‘9400ä»¥åŠè‹¹æžœA18/A18 Proç›¸åŒã€‚

- 2023å¹´10æœˆ24æ—¥ï¼Œé«˜é€šå‘å¸ƒäº†NUVIAçš„ç¬¬ä¸€ä¸ªäº§å“â€”â€”éªé¾™ X Eliteï¼Œè¿™æ˜¯ä¸€æ¬¾ç”¨äºŽç¬”è®°æœ¬çš„å¤„ç†å™¨ï¼Œå®ƒå°±æ­è½½äº†Oryon CPUæž¶æž„
  - è¿™ä¸€æ¬¡Oryonæž¶æž„ç”¨åœ¨äº†æ‰‹æœºå¤„ç†å™¨ä¸Šï¼Œå¹¶ä¸”é«˜é€šå®£ç§°éªé¾™8 Eliteæ­è½½çš„æ˜¯ç¬¬2ä»£Oryonæž¶æž„

- ç›®å‰é¦–å‘æœºåž‹å·²ç»ç¡®è®¤æ˜¯å°ç±³15ç³»åˆ—

- CPUéƒ¨åˆ†ï¼Œå–æ¶ˆäº†ä¸‰ç¼“ï¼Œæ¢ä¸Šäº†å¤§äºŒç¼“ï¼Œå’Œè‹¹æžœä¸€æ ·çš„æ€è·¯ï¼Œå»¶è¿Ÿä¼šå¥½çœ‹å¾ˆå¤šã€‚
  - 8eliteåœ¨10ç“¦åŠŸè€—ï¼Œå°±èƒ½è¾¾åˆ°9400 18ç“¦åŠŸè€—ä¸‹çš„æˆç»©ï¼Œæ­¤æ—¶åŒæ€§èƒ½ä¸‹45%åŠŸè€—ä¼˜åŠ¿ã€‚åŒåŠŸè€—10wæƒ…å†µä¸‹ï¼Œæœ‰11%çš„æ€§èƒ½å·®è·ã€‚

- ## [é«˜é€šéªé¾™ X Elite å¾ˆåŽ‰å®³å—ï¼Ÿ - çŸ¥ä¹Ž _202402](https://www.zhihu.com/question/644273100)
- è¦æ€§èƒ½æ²¡æ€§èƒ½, è¦ç”Ÿæ€æ²¡ç”Ÿæ€, è¦æ€§ä»·æ¯”æ²¡æ€§ä»·æ¯”, è¦ç»­èˆªæ²¡ç»­èˆª, å”¯ä¸€èƒ½å¹çš„é©¬ä¸Šä¹Ÿè¦è¢«iå’Œaåè¶…äº†

- è½¬è¯‘æ‰§è¡Œ [x86 ç¨‹åº] çš„æŠ˜æŸè¿˜æ˜¯æœ‰ç‚¹å¤§ï¼Œè¿™å¯¼è‡´æ•´ä½“çš„æ€§èƒ½å’Œ13ä»£é…·ç¿åŸºæœ¬æŒå¹³ï¼Œ30Wä»¥å†…ï¼Œæ®‹è¡€ç‰ˆå¯¹åº”x86çš„è·‘åˆ†è¿˜ä½Žä¸€äº›
- è½¬è¯‘è¿è¡ŒX86/X64è½¯ä»¶ï¼Œä¸è€ƒè™‘ä¸å…¼å®¹çš„é‚£éƒ¨åˆ†ï¼Œæ€§èƒ½ä¼šè¢«AMD/IntelåŽŸç”Ÿè¿è¡ŒåŠæ‰“ã€‚

- æ²¡æœ‰ä½“ä¼šåˆ°è½¬è¯‘å’ŒåŽŸç”Ÿçš„åŒºåˆ«ï¼Œéƒ½å¾ˆé¡ºç•…
- äº‹å®žä¸Šæ‰€è°“çš„å…¼å®¹æ€§é—®é¢˜èµ·ç æœ‰ä¸€åŠä»¥ä¸Šæ˜¯ä¼ªå‘½é¢˜â€”â€”å› ä¸ºç»å¤§å¤šæ•°ä¼ ç»Ÿx86åº”ç”¨éƒ½ä¸æ˜¯æ€§èƒ½å¯†é›†åž‹åº”ç”¨ã€‚æˆ‘è‡ªå·±ç”¨çœŸæœºå®žæµ‹ï¼Œx64è½¬è¯‘ç‰ˆå¾®ä¿¡ï¼Œsteamå’Œå°é»„æ²¹ï¼Œå®Œå…¨æ„Ÿå—ä¸åˆ°ä»»ä½•å¡é¡¿ï¼Œç»­èˆªçœ‹èµ·æ¥æ²¡æœ‰æ˜Žæ˜¾å¼‚å¸¸â€”â€”æœ€é‡è¦çš„æ˜¯è·Ÿè¿è¡Œæ—¶è·ŸåŽŸç”Ÿåº”ç”¨ä¸€æ ·å®Œå…¨æ²¡æœ‰å‘çƒ­

- åœ¨åŒæ ·çš„æ¨¡å…·ä¸‹ï¼Œé«˜é€šX Elite åœ¨NBCä¸­çš„ç»­èˆªä¹Ÿæ²¡è·‘è¿‡Lunar Lake

- å’Œè‹¹æžœçš„Apple Silicon Mç³»åˆ—èŠ¯ç‰‡ç›¸æ¯”ï¼Œé‚£å°±æ˜¯èƒ½æ•ˆå’Œæ€§èƒ½éƒ½èµ¢ä¸äº†ï¼Œä½†æ˜¯ä»·æ ¼å¯ä»¥æ›´ä¾¿å®œã€‚

- å¯¹äºŽä¸€äº›å°ä¼—éœ€æ±‚çš„ç”¨æˆ·ï¼Œæ¯”å¦‚å·¥ä¸šç”¨çš„è½¯ä»¶ï¼ŒARMçš„ç”Ÿæ€ç›®å‰åº”è¯¥æ˜¯ä¸å¤ªé€‚åˆçš„ã€‚é‡åº¦æ¸¸æˆç”¨æˆ·ä¹Ÿæ˜¯å¦‚æ­¤ã€‚

- 
- 
- 
- 

# discuss-pc-mini/diy
- tips
  - ä¸æŽ¨èä¹°æ•´æœºå·¥ä½œç«™ï¼Œè´­ä¹°å•ç‹¬çš„ç®—åŠ›å¡å³å¯

- ## 

- ## 

- ## [What Mini PC is best for gaming? : r/MiniPCs _202511](https://www.reddit.com/r/MiniPCs/comments/1os3dc7/what_mini_pc_is_best_for_gaming/)
- The 780m will NOT do most games med-high settings 1080p 50-60fps, it will run older games fine and emulators fine but mid high in 2020 and newer games come on

- I just received my GMKtec Evo-X1 which I paid 800 before tax. Havenâ€™t done extensive testing yet but itâ€™s performing much better than my Z1E Ally.

- Budget wise you'll be far better off getting a used desktop rig. Older gen desktop GPUs will beat the pants off integrated GPU for less money You could try a mini with an egpu

- ## [å¦‚ä½•è¯„ä»·intelæ”¾å¼ƒNUCäº§å“çº¿ï¼Ÿ - çŸ¥ä¹Ž _202307](https://www.zhihu.com/question/611600066)
- è™½ç„¶NUCæ˜¯Next Unit of Computingçš„ç®€ç§°ï¼Œå¯ä»¥ç†è§£ä¸ºâ€œä¸‹ä¸€ä»£å‡†ç³»ç»Ÿâ€ã€‚
  - å³é€šå¸¸æä¾›ä¸€ä¸ªè¶³å¤Ÿè¿·ä½ çš„ä¸»æ¿+CPUï¼Œè€Œå†…å­˜å’Œå­˜å‚¨éƒ¨åˆ†ä½ å¯ä»¥DIYï¼ŒåŒ…å«äº†ä¸»æ¿å’ŒCPUçš„å¹³å°æˆ‘ä»¬ä¸€èˆ¬å°±å«â€œå‡†ç³»ç»Ÿâ€ï¼Œä¸è¿‡å‡†ç³»ç»Ÿå¹¶ä¸å®Œå…¨ä¸€å®šæ˜¯ä¸»æ¿+CPUçš„ç»‘å®šï¼›æ¯”å¦‚åŽæœŸå¦–æ¿åŽæ“Žåšçš„ç³»åˆ—å°±æ˜¯å¯ä»¥è‡ªå·±é€‰æ‹©CPUï¼Œä¸”æ”¯æŒæ¡Œé¢çº§CPUï¼Œåªæ˜¯CPUæœ‰ä¸€å®šçš„åŠŸè€—é™åˆ¶ç­‰ã€‚
- NUCæœ¬èº«æ˜¯ä»‹äºŽåŠžå…¬ç”µè„‘å’Œä¸€ä½“å¼ç”µè„‘ä¹‹é—´çš„äº§ç‰©
  - NUCå°±æ„Ÿè§‰æ˜¯ä¸€ä½“å¼ç”µè„‘æŠŠæ˜¾ç¤ºå™¨å’Œä¸»æœºéƒ¨åˆ†åˆå‰¥ç¦»å‡ºæ¥ï¼Œåªä¸è¿‡æŠŠä¸»æœºåšå¾—è¶³å¤Ÿå°
  - æ‰€ä»¥ä¸€å¼€å§‹NUCçš„è®¾è®¡å°±æ”¯æŒæŠŠNUC æŒ‚åœ¨æ˜¾ç¤ºå™¨åŽé¢ï¼Œåªéœ€è¦ä¸€ä¸ªæ‰©å±•é“çš®å°±è¡Œäº†ã€‚

- NUCæˆ‘ä¹Ÿä¹°äº†, æ€§èƒ½å¾ˆæ™®é€š. çœ‹ä¸­çš„å°±æ˜¯ä¸€ä¸ªå°å·§å’Œç¨³å®š. å¤§å®¶å¯ä»¥çœ‹ä¸‹ç½‘ä¸ŠåŒæ ·çš„å°ç”µè„‘çš„å¯¹æ¯”, èƒ½æ”¯æŒ7*24Hå½“ä¸ªäººæœåŠ¡å™¨çš„è¿è¡Œçš„, ä¹Ÿå°±Intelçš„äº†.(Dellæƒ æ™®çš„é‚£äº›æœºå™¨ä¹Ÿè¡Œ, ä½†æ˜¯å‘çƒ­ä½Žçš„æ€§èƒ½è¿˜æ˜¯æ¯”intelå·®ä¸€ç‚¹)

- NUCå¤§éƒ¨åˆ†äº§å“çº¿ miniPCï¼ˆé™¤å¼€ç‹¬æ˜¾éƒ¨åˆ†ï¼‰åœ¨äº§å“å®šä¹‰ä¸Šéƒ½æ˜¯å¾ˆå¥½çš„äº§å“ï¼šæ€§èƒ½å¤Ÿç”¨/æ‰©å±•æ€§å¤Ÿç”¨/ä½“ç§¯å°/å¯é æ€§ä¹Ÿä¸é”™/æ•´ä½“æŒæœ‰æˆæœ¬ä½Ž
  - ä½†å¸‚åœºè¥é”€çš„ç”¨æˆ·æ•™è‚²å­˜åœ¨é—®é¢˜ï¼Œå¤§éƒ¨åˆ†ç”¨æˆ·ç”šè‡³éƒ½ä¸äº†è§£è¿™æ¡äº§å“çº¿å­˜åœ¨ï¼Œå³ä½¿çŸ¥é“ï¼Œå¯¹å…¶æ€§èƒ½å’ŒæŒæœ‰æˆæœ¬ä¹Ÿæ²¡æ­£ç¡®è®¤çŸ¥ï¼Œæƒ³å½“ç„¶çš„è®¤ä¸ºå°æœºå™¨æ€§èƒ½å·®/ä»·æ ¼è´µã€‚

- ä½œä¸ºè§£å†³æ–¹æ¡ˆçš„åˆ¶å®šè€…ï¼Œåˆä¸èƒ½å®Œå…¨éœ¸å å¸‚åœºï¼Œéœ€è¦ç»™åˆä½œä¼™ä¼´ä»¬åˆ†ä¸€æ¯ç¾¹ï¼Œæ‰€ä»¥ï¼Œè‹±ç‰¹å°”çš„NUCæº¢ä»·éžå¸¸é«˜ï¼Œå¦‚æžœä¸æ˜¯åƒæˆ‘ä¸€æ ·å…¥äº†é­”ï¼Œå°±æ˜¯æƒ³è¦é‚£ä¸ªLOGOï¼Œåªæ˜¯éœ€è¦ä¸€å°å°å·§çš„è¿·ä½ ä¸»æœºçš„åŒ–ï¼Œå…¶å®žæœ‰éžå¸¸å¤šçš„å“ç‰Œå’Œäº§å“å¯ä»¥é€‰

- ## [Will apple make a macbook pro with an ultra chip? : r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/comments/1o8ax0f/will_apple_make_a_macbook_pro_with_an_ultra_chip/)
  - Just imagine 1 tb of ram on a m5 or m6 ultra MacBook Pro? The price will be absurd and the battery will be short? Maybe they will restrict the ram, since it will use more power? 
- It's well known for people that work with computing hardware that RAM requires a lot of power and consumption grows as RAM increases. 
  - The issue is that data in RAM has a short life and has to be refreshed regularly or it gets corrupted/disappears. That's why laptops are always RAM constrained and desktops are not. 
  - There's more to it about scale and speed that requires workstation class machines to get to have extremely large RAM.

- ## [20å¯¸è¡ŒæŽç®±å°ºå¯¸é•¿å®½é«˜ï¼ˆ20å¯¸æ‹‰æ†ç®±åˆ°åº•åˆ°åº•æœ‰å¤šå¤§ï¼‰](https://www.zhihu.com/tardis/zm/art/320648263?source_id=1003)
- ä¸ç®¡æ˜¯è¡ŒæŽç®±è¿˜æ˜¯ç”µè§†ï¼Œç»Ÿä¸€ç”¨çš„éƒ½æ˜¯è¿™ä¸ªæ–œå¯¹è§’å°ºå¯¸æµ‹é‡æ–¹æ³•ã€‚
  - 1å¯¸=2.54cm
  - 20å¯¸=50.8cm
- 20è‹±å¯¸å¹¶æ²¡æœ‰ä¸€ä¸ªå›ºå®šçš„é•¿å®½é«˜ï¼Œä½†æ˜¯æˆ‘ä»¬å¯ä»¥ç»™ä¸€ä¸ªç›¸å¯¹æ ‡å‡†çš„æ‹‰æ†ç®±å°ºå¯¸ä½œä¸ºå‚ç…§ã€‚
  - 20inch: 50 x 34 x 19 cm, 32.3L
  - 22inch: 55 x 42 x 23 cm, 53.1L(å¯ç”¨çº¦47L)
  - 28inch: 70 x 47 x 27 cm

- ## [AMD EPYC 9654çš„ä¸»æ¿ä¸ºä»€ä¹ˆè¿™ä¹ˆè´µï¼Ÿå•è·¯9654èƒ½æ‰“7763åŒè·¯å—ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/598929770)
- å¤šé¡¹æµ‹è¯•é‡Œå•è·¯ 96æ ¸ 9654 éƒ½ä¼˜äºŽ åŒè·¯ 128æ ¸ 7003ï¼ˆ7763/7773xï¼‰ã€‚
  - æž¶æž„åˆ¶ç¨‹å‡çº§ã€é¢‘çŽ‡ï¼ˆå¤§å¹…ï¼‰æå‡ï¼ˆå…¨æ ¸æ»¡è½½æå‡0.5GHz+ï¼‰ã€12é€šé“DDR5 4800ã€å•è·¯æœ¬å°±æ›´ä½Žçš„å¤šçš„CCDé—´é€šè®¯å»¶è¿Ÿç­‰ï¼Œéƒ½æ˜¯ä¸å°çš„ä¼˜åŠ¿
- çŽ°åœ¨9004ä¸»æ¿ä¹Ÿæ²¡é‚£ä¹ˆè´µäº†ï¼Œ**å•è·¯æ¿å­5kä»·ä½å°±èƒ½æ‹¿ä¸‹**ï¼Œæ²¡æ¯”åŒè·¯7003è´µå¤šå°‘ï¼Œddr5 regä»·æ ¼ä¹Ÿåœ¨ä¸‹é™ï¼Œæ•´å¥—è¿˜æ˜¯æ¯”è¾ƒè¶…å€¼çš„ã€‚

- 5kçœŸçš„ä¸ä¼šèµ”æœ¬ä¹ˆï¼Ÿæ¯ä¸ªå†…å­˜é€šé“æ˜¯ä¸æ˜¯72è·Ÿä¿¡å·çº¿ï¼Œ12é€šé“æ˜¯864ï¼Œé™¤æ­¤ä»¥å¤–è¿˜æœ‰é‚£ä¹ˆäº›PCI-Eï¼Œè¿™äº›è¿˜è¦å’Œç”µæºçº¿åœ°çº¿æ··åœ¨ä¸€èµ·ï¼Œæ„Ÿè§‰å¾ˆä¸å®¹æ˜“äº†ã€‚å½“ç„¶äº†ï¼Œè¦è¯´æ¯æ ¹ä¿¡å·çº¿é¢‘çŽ‡å…¶å®žä¸ç®—é«˜ï¼Œè·Ÿnvlinkä¹‹ç±»çš„æ²¡å¾—æ¯”

- ## [éœ‡æƒŠï¼åŽå—é‡‘ç‰Œå¯¹æ ‡è¶…å¾®H12SSLå¹²äº†ä¸€ä¸ªEPYCå•è·¯ä¸»æ¿H12D-8D - çŸ¥ä¹Ž](https://www.zhihu.com/zvideo/1883448198976218443)
  - è¿™æ¬¾H12D-8Dæ˜¯ç›´æŽ¥å¯¹æ ‡H12SSLï¼Œæ”¯æŒAMD EPYC 7002/7003 ï¼ŒRomeå’ŒMilan
  - 8ä¸ª DDR4 å†…å­˜æ’æ§½
  - 4ä¸ª PCIe 3.0/4.0 x16 æ’æ§½

- ## ðŸ› [ä¸ºä»€ä¹ˆåŽå—ã€ç²¾ç²¤è¿™ç§å¯¨åŽ‚ä¸åšEPYCä¸»æ¿ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/4214916755)
- EPYCè¿˜çœŸæ˜¯æµå‡ºæ¥çš„å¤šï¼Œä½†æ˜¯èƒ½ç”¨çš„å´ä¸å¤š
  - çœ‹zen3åŒæ¬¾epycä¸»æ¿çš„æž¶æž„å›¾ã€‚æ˜¯ä¸æ˜¯å¾ˆç®€å•ï¼Œè¿žä¸ªæ¡¥ç‰‡éƒ½ä¸ç”¨ã€‚
  - ä¸ºä»€ä¹ˆå»‰ä»·çš„EPYCæ¯”è¾ƒå°‘å‘¢ï¼Ÿ
  - å› ä¸º EPYC åœ¨OEMåŽ‚å•†é‚£å¸®æœ‰ä¸ª PBSç»‘å®šæ”¿ç­–ï¼ŒOEMå•†å¯ä»¥è®¾å®šå”¯ä¸€ç§˜é’¥ç»‘å®šï¼Œä¹Ÿå°±æ˜¯é¦–æ¬¡ä½¿ç”¨å¯ä»¥æŠŠCPUå’Œä¸»æ¿ç»‘å®šï¼Œå½“CPUæ›´æ¢ä¸»æ¿æ—¶ï¼Œè§¦å‘PBSç­–ç•¥æ‹’ç»å¯åŠ¨ã€‚

- æ¿Uç»‘å®šè¿™ä¸ªç­–ç•¥ï¼Œåˆä¸ä»…ä»…æ˜¯epycæœ‰ï¼ŒCoreå’ŒXeonéƒ¨åˆ†OEMåŽ‚çš„è´§ä¹Ÿæœ‰ã€‚æŸä¸€çº¿å¤§ç‰Œçš„Coreå•†ç”¨æ•´æœºæˆ‘å°±é‡åˆ°è¿‡

- tbä¸Šèƒ½æ‰¾åˆ°çš„å¤§éƒ¨åˆ†éƒ½æ˜¯æ— é”ï¼Œé»„é±¼ä¸Šå°±ä¸çŸ¥é“äº†
- é—²é±¼ä¸Šæœ‰å¾ˆå¤šæœ‰é”çš„ï¼Œä¸è¿‡å¦‚æžœæ˜¯åŒè·¯ä¸»æ¿çš„è¯åªæ£€æµ‹ç¬¬ä¸€ä¸ªCPUæœ‰æ²¡æœ‰é”ï¼Œç¬¬äºŒä¸ªCPUå³ä½¿æœ‰é”ä¹Ÿä¸å½±å“ä½¿ç”¨
- å› ä¸ºepyc bootåªç”¨cpu0å§
  - cpu1çš„io dieåœ¨å¯åŠ¨é“¾é‡Œé¢ä¸è´Ÿè´£å®‰å…¨æ ¡éªŒ

- æ€§èƒ½å¤Ÿç”¨ï¼Œè¿˜æ²¡åˆ°å¤§è§„æ¨¡æ·˜æ±°æœŸï¼Œå·²ç»æµå‡ºæ¥çš„éƒ¨åˆ†å¾ˆå¤šåˆè¢«aiç‚¼ä¸¹å¸ˆç»™æ”¶èµ°ï¼Œå®ƒçš„PCIeé€šé“æ¯”åŒæœŸIntel Xeonå¤šã€‚
- epycé“ºå¼€æ¥æ‰å‡ å¹´å•Šï¼Œäº‘æœåŠ¡å™¨èƒ½ç§Ÿåˆ°epycçš„uä¹Ÿæ˜¯è¿™ä¸¤å¹´çš„äº‹
- AMDç¬¬ä¸€ä»£ç¬¬eypcå’Œç¬¬äºŒä»£eypcéƒ½æ˜¯è¯•æ°´ï¼Œå¼€å§‹å–èµ·æ¥éƒ½æ˜¯ç¬¬ä¸‰ä»£äº†ï¼ŒçŽ°åœ¨ä¸Šæ¸¸æ·˜æ±°æ²¡é‚£ä¹ˆå¿«ï¼Œæœªæ¥å¤§æ¦‚çŽ‡è¿˜ç®—ä¹°æ•´æœºå˜›ï¼Œå…¶äºŒçŽ°åœ¨ä½ è¦æž64æ ¸çš„æ–¹æ¡ˆï¼Œamdçš„å¯ä»¥DDR4ï¼Œ6kå·¦å³æžå®šå¤§å†…å­˜æ–¹æ¡ˆï¼Œintelè¦å¤§å†…å­˜åªèƒ½ç”¨esç‰ˆçš„ä¸Šddr4ï¼Œå¦‚æžœä¸Šddr5ä»·æ ¼å°±é£žå¤©äº†ã€‚

- åˆšåˆšæŸ¥äº†ä¸€ä¸‹ï¼ŒåŽå—é‡‘ç‰Œå‡º3647ä¸»æ¿äº†ã€‚
  - ä»·æ ¼ä¸ä¾¿å®œï¼Œå¯¹åº”çš„æž¶æž„ä¸è¿‡æ˜¯skylakeè€Œå·²ã€‚
- å†æ¬¡æ›´æ–°ï¼Œæ”¯æŒEPYCçš„ä¸»æ¿æ¥äº†ã€‚
  - åŽå—é‡‘ç‰Œ H12D å•è·¯epycä¸»æ¿ å¯ä»¥ç”¨æ¥æ»¡è¡€deepseekçš„è£…æœºä¸»æ¿ pcie4.0ä¸»æ¿

- æˆæœ¬é«˜ï¼Œè®¾è®¡éš¾åº¦é«˜ï¼Œé‡å°ï¼Œè¿˜æ˜¯åŽ»ä¼ºå€™åˆæ²¡å•¥é’±åˆäº‹å¤šçš„åžƒåœ¾ä½¬ï¼Œä½•è‹¦å‘¢ï¼Ÿ
  - è¶…å¾®x13 å•è·¯æ¿çœ‹èµ·æ¥å¾ˆä¸åªæœ‰8ç›¸ä¾›ç”µåŸºæœ¬æ²¡æ•£çƒ­æ˜¯ä¸æ˜¯ï¼Œç”¨ä¸‹æ¥å®ƒå¯ä»¥æŒç»­ç¨³å®š385wè¾“å‡º mosæ¸©åº¦ä¹Ÿå°±80ã€‚ä¸æ˜¯æ¶ˆè´¹çº§é‚£äº›æ•´äº†åå‡ ç›¸ä¸Šè¶…é‡æ•£çƒ­è£…ç”²200wè¿˜å¥”ä¸ƒå…«åçš„åžƒåœ¾ä¾›ç”µmosèƒ½æ¯”çš„ã€‚

- å¥½åƒï¼Œæ®è¯´Ryzen Proå’ŒTr Proä¹Ÿå¼€å§‹ä¸Šé”äº†ï¼Ÿè¿™ç±»Uä¹Ÿæ˜¯ä¸“ä¾›OEMä¸é›¶å”®çš„
- è¿™å¯¹äºŽåžƒåœ¾ä½¬+Aç‚®è€Œè¨€æ˜¯ä¸ªå™©è€—ã€‚Ryzen APUä»Ž8000Gå¼€å§‹ï¼Œæ ¸æ˜¾çš„ç¼–ç è§£ç èƒ½åŠ›å·²ç»æ¯”è¾ƒå¥½äº†ï¼ŒåŠ ä¸Šå®ƒä¼˜ç§€çš„åŠŸè€—å’Œæ€§èƒ½ï¼Œä»¥åŠProç‰ˆæ”¯æŒECCå†…å­˜ï¼Œæœªæ¥å¾ˆæœ‰æ½œåŠ›æˆä¸ºç§å­NAS DIY/è½¯è·¯ç”±ç­‰å®¶åº­æœåŠ¡å™¨çš„ç¥žUã€‚ä½†å¸¦é”å¯å°±ã€‚ã€‚ã€‚

- ä¸»è¦åŽŸå› æ˜¯CPUä¸å¤Ÿä¾¿å®œï¼Œå®žé™…ä¸Šä¹Ÿåšäº†å‡ æ¬¾ï¼Œä½†æ²¡å¤šå°‘äººåŽ»ä¹°ã€‚
  - E5è£…æœºå¸‚åœºç¹è£ï¼Œå‰ææ˜¯æ€§èƒ½å¤Ÿç”¨+ç›¸å¯¹å»‰ä»·ï¼Œä»Žæ ¸å¿ƒå¤šé¢‘çŽ‡åä½Žçš„æœåŠ¡å™¨ç”¨ï¼Œåˆ°æ ¸å¿ƒå°‘é¢‘çŽ‡é«˜çš„å•è·¯å·¥ä½œç«™ç‰ˆæœ¬éƒ½æœ‰æä¾›ï¼Œè¿˜æœ‰åˆ©ç”¨v3ç³»åˆ—E5çš„bugï¼Œå¼ºåˆ¶å…¨æ ¸ç¿é¢‘è·‘çš„é¸¡è¡€è¡¥ä¸ï¼Œå±žäºŽå¤šå¼€æŒ‚æœºã€å•æœºçŽ©æ¸¸æˆï¼Œéƒ½èƒ½ä¸Šã€‚
  - EYPCéœ„é¾™æ˜¯ [é”é¾™] åŒä»£ï¼Œè¦æ¯”E5æ™šä¸Šå¥½å‡ å¹´ï¼Œæ€§èƒ½è‡ªç„¶æ˜¯æ›´å¥½ï¼Œä¹Ÿå› ä¸ºå¦‚æ­¤ï¼Œå¤§è§„æ¨¡ä»Ž [IDC] ä¸‹æž¶çš„æ—¶é—´è¿˜æ—©ï¼Œè´§æºä¸å¤šï¼Œä¾æ—§è¾¾ä¸åˆ°â€œåžƒåœ¾ä»·æ ¼â€ã€‚æœ¬æ¥ä¸€ä»£çš„7601é…åˆå›½é‘«å¹³å°ä¾¿å®œè¿‡ä¸€æ®µæ—¶é—´ï¼Œä½†å› ä¸ºQUä¹‹ç±»çš„CPUçŸ¿åˆæ¶¨å›žåŽ»ï¼ŒåŽæ¥AIç«çƒ­ï¼ŒEPYCçš„æ ¸å¿ƒå’ŒPCIeé€šé“å·¨å¹…ä¼˜åŠ¿ï¼Œåˆè®©äºŒæ‰‹å¸‚åœºä»·æ ¼éš¾ä»¥éª¤é™ã€‚
  - æœ€ç»ˆç»“æžœå°±æ˜¯ï¼Œå› ä¸ºCPUä¸å¤Ÿä¾¿å®œï¼Œä¸‹æž¶æ•°é‡å°‘ï¼Œå°½ç®¡EYPCæ˜¯ä¸éœ€è¦å—åŒ—æ¡¥èŠ¯ç‰‡ç»„ï¼Œè€Œæ˜¯åŸºäºŽPCIe HUBåšæ‰©å±•å³å¯ï¼Œä½†å¯¨æ¿ä»¬æ²¡åŠ¨åŠ›å’Œèƒ½åŠ›åŽ»åšä¸»æ¿ã€‚
  - æŠ„æ¿çš„è¯ï¼Œå¤§åŽ‚ä¸»æ¿å¤šå±‚PCBï¼Œæˆæœ¬é«˜åˆ°è®©å¯¨åŽ‚æŠ„ä¸åŠ¨ã€‚å®žé™…ä¸ŠåŽå—å·²ç»å‡ºäº†çš„EYPCå’ŒC621ä¸»æ¿ï¼Œå®žé™…é›¶å”®éƒ½æ˜¯ä¸¤åƒå—ä¸€ç‰‡ï¼Œæ¯”è¶…å¾®ã€æ³°å®‰ä¾¿å®œæœ‰é™ï¼Œ éš¾ä»¥åšåˆ°E5å¯¨æ¿é‚£èˆ¬çƒ­å–ã€‚

- ## ðŸ†šðŸ’¡ AMD Threadripper PRO 7985WX and Threadripper 7980X  have the same cores/threads/chiplets-ccd-numbers
- [AMD Ryzenâ„¢ Threadripperâ„¢ 7980X Drivers](https://www.amd.com/en/support/downloads/drivers.html/processors/ryzen-threadripper/ryzen-threadripper-7000-series/amd-ryzen-threadripper-7980x.html?utm_source=chatgpt.com)
  - Memory Channels: 4
  - System Memory Specification: DDR5 Up to 5200 MT/s
  - ECC Support: Yes (Default Enabled)

- [AMD Ryzenâ„¢ Threadripperâ„¢ PRO 7985WX Drivers](https://www.amd.com/en/support/downloads/drivers.html/processors/ryzen-threadripper-pro/amd-ryzen-threadripper-pro-7000-wx-series/amd-ryzen-threadripper-pro-7985wx.html)
  - Memory Channels: 8
  - System Memory Specification: DDR5 Up to 5200 MT/s
  - ECC Support: Yes (Default Enabled)

- [AMD EPYCâ„¢ 9354](https://www.amd.com/en/products/processors/server/epyc/4th-generation-9004-and-8004-series/amd-epyc-9354.html)
  - Memory Channels: 12
  - System Memory Specification: DDR5 Up to 4800 MT/s
  - Per Socket Mem BW: 460.8 GB/s

- [åŒæ ·16æ ¸32çº¿ç¨‹64Mç¼“å­˜ï¼ŒEPYC 7282ä¸ºä»€ä¹ˆæ¯”5950Xè´µå¾ˆå¤šï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/513604769)
  - åŽ»çœ‹çœ‹ç›®å‰æµ·é²œå¸‚åœºçš„ä»·æ ¼ï¼Œ7282ä»·æ ¼260çš„æ ·å­ï¼Œ5950Xä»·æ ¼è¿˜åœ¨1800å·¦å³
  - ä¸è¿‡é…å¥—çš„æ¿å­ä»·æ ¼å°±ä¸€ä¸ªå¤©ä¸€ä¸ªåœ°äº†ï¼ŒEPYCäºŒä»£æ¿å­1000èµ·ï¼Œèƒ½è·‘æ»¡5950Xçš„ B450é«˜é…æ¿å­300èµ·ï¼Œæ•´æœºè¿˜æ˜¯5950X ç¨è´µç‚¹å„¿
  - 7282å…¨æ ¸é¢‘çŽ‡3.2Gï¼Œ5950Xæ•£çƒ­å¥½çš„è¯å¯ä»¥å•æ ¸4.85G, å¤šæ ¸4.4G
  - å¯¹æ¸¸æˆæ€§èƒ½æœ‰è¦æ±‚çš„äººï¼Œè¿œæ¯”å¯¹128ä¸ªPCIEé€šé“æœ‰è¦æ±‚çš„äººå¤šï¼Œæ‰“æ¸¸æˆçš„ç»™ä¸ª PCIE4.0 16X + 4X NVME å°±å¤Ÿäº†

- ## ðŸ¤” [Thoughts on older/used threadripper for deep learning machine build : r/threadripper _202410](https://www.reddit.com/r/threadripper/comments/1g3meqp/thoughts_on_olderused_threadripper_for_deep/)
- whatâ€™s the difference between epyc and threadripper? It seems perfect for me and itâ€™s a lot cheaper than a threadripper. Whatâ€™s the catch?
  - Threadripper was designed for workstation users. Threadripper CPUs generally have faster cores with higher boost clocks, as they are designed to be used interactively in real-time.
  - Epyc is designed for servers. Slower cores, less boost, perhaps more outright(å…¨éƒ¨çš„, å½»åº•çš„) compute per watt, but not designed to maximize responsiveness for real-time user interaction.

- just saw Epyc doesnâ€™t support windows. 
  - Epyc runs on Windows 10/11 Pro for Workstations
  - At work we use Windows VMs running on Epyc processors in Azure, and the underlying host would be Windows Server, not Linux.
  - I read somewhere that you can use the Workstation version for that
  - I've seen that option when installing from the Windows installation USB image
  - Windows 11 Pro for Workstations

- Another option is an EPYC system, which will have lower CPU performance than TR Pro, but the same memory capacity and PCIe lane count.

- ## [Where to look for cheap PCIE gen 4+ threadripper cpus at a low price on the EU : r/threadripper _202505](https://www.reddit.com/r/threadripper/comments/1kbvmfs/where_to_look_for_cheap_pcie_gen_4_threadripper/)
- I switched from tr consumer to tr pro to epyc. Originally mostly VMs and some cpu heavy work. Then mostly VMs with some AI. Now all AI. Just running a 7313p (previously 3960x and 3970x boxes, then 3975wx and 5965wx). Epyc is lower power, supports u2/sas, tons of cheap ecc ram. Worth a look. Bought a few TR combos from tugm, good seller who has both platforms.

- ## [Testing Ryzen 8700G LLama3.1 : r/LocalLLaMA _202407](https://www.reddit.com/r/LocalLLaMA/comments/1efhqol/testing_ryzen_8700g_llama31/)
- I think for a lot of gaming tasks, memory bandwidth isn't necessarily the limiter, and they're trying to max out what they can do in a 'normal' desktop. Threadripper has quad and octa channel ram, so putting one of these in that could make for a very potent LLM system as they can address something like 2TB and the 7995wx can hit like 700GB/S of ram bandwidth. I'm sure that'd make for an interesting memory controller setup on there...
  - I don't have a 7995wx but I do have a 7980x and I was disappointed in the LLM speed. That 700GB/S figure is very misleading in the marketing its the CCD to Controller Speed not the RAM. Real bandwidth is closer to 300 on 7995wx and 150-180ish on mine. I guess if you could find a 7200 RDIMM ECC module for less than a house it might do better but I paid over 1400 for 256 GB of 6000, I wouldn't want to think of what a 7200 would cost if I could even get it to run at that.

- ## [Why is EPYC faster but cheaper than Threadripper? : r/buildapc _202404](https://www.reddit.com/r/buildapc/comments/1buf060/why_is_epyc_faster_but_cheaper_than_threadripper/)

- Threadripper PRO 5955WX is a 64-core Zen 3 CPU (2020 architecture). EPYC 9654 is a 96-core Zen 4 CPU (2022 architecture). That's why the EPYC is faster.
  - Under normal circumstances, the 5995WX should be much cheaper. In my area, the 5995WX is available for ~1500 USD. And EPYC 9654 normally costs many times more than $4K, so confirm that it's legit before buying.
  - There are Zen 4 Threadripper PROs available as well. The 7995WX is faster than the EPYC 9654 thanks to higher clock speeds and higher power limits.

- First of all, Threadripper and EPYC are based upon the scalability of Ryzen CPUs and Dies. 
  - But while Ryzen CPUs offer the highest single-core performance and are suitable for desktop use, the use of a Threadripper demands very special hardware: special Mainboard, RAM, CPU cooling solution and a much higher PSU requirement. Also, Threadripper CPUs are selected Dies that offer higher clock speeds under lower voltages. To get a max. of 96 cores to work with a TDP of 350W while a 16 core 7950X asks for 170W, should show the difference in Die quality. Also, Threadripper work great in Windows and other desktop OS and even in games they work - although less optimal, as any Ryzen 7 and upwards will be faster due to higher single-core clock speeds. Scientific laboratories, professional workers (CAD, architecture, engineering, ...) love this kind of power in the machines.
  - EPYC CPUs however are designed to work very efficiently, very stable and offer basically unmatched performance in data centers. They really shouldn't be used in a desktop environment as boards are usually way less beautiful (most important point), designed to be mounted in a rack, way more expensive and not optimized to run any desktop stuff without a virtualization environment. The single core boost is 1, 4GHz slower than that of a Threadripper Pro. Also, support is business orientated. Meaning: No special support contract, no or basically no support. An adequate cooling solution is also a problem.
  - The probably best way to spend money if you have it is a Threadripper Pro 7975WX. 4GHz base clock, 5, 3GHz turbo boost and with 64 cores more than enough for basically everything you throw at it.

- The Threadripper should spank(ç”¨æ‰‹æŽŒæˆ–æ‰å¹³ç‰©æŽ´) the EPYC in workloads that don't utilize a lot of cores.
  - If your workloads can utilize all the cores (make sure they can!) the EPYC is significantly better. It does use a lot more power but that doesn't sound like a concern for you.
  - Also, that 9654 is suspiciously cheap. Like waaaaaaay too cheap. That's why the TR looks like crap in comparison.
  - You really shouldn't be looking at canned benchmarks in a situation like this. You need to find benchmarks that represent the workload(s) you'll be doing.

- ## ðŸ§© [æ—…è¡Œçš„å¥½æ­å­æ‹‰æ†èƒŒåŒ…ï¼Œtaæ¥äº†ï¼ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/6810462000000000230145b2?xsec_token=AB_QqkK7_ZF3_KbwyW1ZB1W-e9_xlRmGRCX97e_tYARKI=&xsec_source=pc_search&source=unknown)
  - æ‰©å®¹ä¹¦åŒ…æ³°æ ¼æ–¯æ‹‰æ†ç®±

- æ—¥å¸¸é€šå‹¤35Lï¼Œå‡ºå·®ä¸€é”®æ‰©å®¹åˆ°40Lï¼Œä¸ç”¨æ‰˜è¿ï¼
  - æ‹‰é“¾å…¨å¯ä¸Šé”ï¼Œé˜²ç›—è®¾è®¡å¤ªé€‚åˆæœºåœºç”¨äº†ï¼

- ## [å¹³æ›¿è¡ŒæŽç®±çš„å•†åŠ¡åŒè‚©åŒ…ï¼Œ40Lï¼è¿˜èƒ½æ‰©å®¹ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/6835bf120000000021002156?xsec_token=ABatORMjMwyzFmPxDjEJEf-p8c6FH-fG8_XdNtue8G_L0=&xsec_source=pc_search&source=unknown)
  - å®¹é‡è¶…å¤§ï¼šä¸»ä»“+æ‰©å®¹å±‚40Lå®¹é‡ï¼Œ5-7å¤©è¡£ç‰©+ç”µè„‘+æ´—æ¼±åŒ…å…¨å¡žä¸‹ï¼Œä¾§é¢è¿˜èƒ½æ’è¡ŒæŽç®±æ†ï¼Œèµ¶è½¦è¶…æ–¹ä¾¿
  - è´´å¿ƒåˆ†åŒºï¼šç”µè„‘éš”å±‚å¸¦ç¼“å†²+ç‹¬ç«‹æ–‡ç»„ä»“+æš—æ ¼é˜²ç›—ï¼Œè¿žå……ç”µå®éƒ½æœ‰ä¸“å±žä½å’Œå¤–æŽ¥å£

- [æ±‚ä¸€ä¸ª40lå·¦å³çš„åŒè‚©åŒ…æŽ¨è æœ‰èƒŒè´Ÿç³»ç»Ÿçš„ å”¯ä¸€é™„åŠ è¦æ±‚ å¥½çœ‹ï¼ï¼ï¼ï¼ æ±‚æ±‚ #èƒŒåŒ…å®¢ #æˆ·å¤–å¾’æ­¥ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/6842cbd0000000002100057b?xsec_token=ABT9L2VXltMP-GUaPSRafreWyko5UR63i8ehZlDenL0as=&xsec_source=pc_search&source=unknown)
  - ç¥žå†œradix47ï¼ˆç™½è‰²ï¼‰ã€æ ¼é‡Œé«˜åˆ©ç¥ç€44ï¼ˆçº¢è‰²ï¼‰ã€å§‹ç¥–é¸Ÿaerios35ï¼ˆé»‘è‰²ã€ç´«è‰²ï¼‰

- [ä¸€ä¸ªäººæ—…è¡Œç³»åˆ—ä¹‹å¯ç™»æœºåŒè‚©åŒ… - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/65e1833800000000040027ab?xsec_token=ABIG1oshPpa6-_2S9Eiadw0dwjUN6w5GF6LRXEljnCLc0=&xsec_source=pc_search&source=unknown)
  - ä¸€èˆ¬æ¥è¯´å›½å†…èˆªç©ºæ˜¯115åŽŸåˆ™ï¼Œæ—¢55åŽ˜ç±³Ã—40åŽ˜ç±³Ã—20åŽ˜ç±³ï¼Œé‡é‡ä¸€èˆ¬ä¸º7KGï¼Œï¼ˆå…·ä½“è¿˜æ˜¯è¦çœ‹èˆªå¸è§„å®šï¼‰ã€‚
  - æœ‰äº›ä¹Ÿåˆ†äº«è¿‡45ï¼Œ48ï¼Œ50lç™»æœºçš„ï¼Œå®žé™…ä¸Šæˆ‘ä¹Ÿçœ‹åˆ°è¿‡ï¼Œä½†æ˜¯ï¼ä½†æ˜¯ï¼ä½†æ˜¯ï¼ä¹Ÿæœ‰äººè¢«æ‹¦ä¸‹çš„ï¼æ‰€ä»¥èˆªç©ºå…¬å¸ä¸åŒï¼Œåœ°æ–¹ä¸åŒï¼Œå¯èƒ½å¯¼è‡´ä¸ä¸€æ ·çš„ç»“æžœã€‚

- Peak Design backpack 45l ï¼Œ2.09kg
  - ä¼˜ç¼ºç‚¹ï¼š30læ¨¡å¼ä¸‹å¯ç™»æœºï¼Œæ‹‰é“¾å¼çš„å¯æ‰©å®¹45læ¨¡å¼ï¼ˆå‡ ä¹Žæ²¡è¶…ï¼‰å¤§å®¹é‡ï¼Œå¤šç”¨é€”å¯æ­é…å†…èƒ†ï¼ˆè‡ªè¡Œè´­ä¹°ï¼‰ï¼Œä»–æ˜¯æœ€å¥½çš„æ—…è¡ŒåŒè‚©ç›¸æœºåŒ…ï¼Œå¯èƒ½æ²¡æœ‰ä¹‹ä¸€ã€‚

- æœ€å¤§å®¹é‡çš„åŒ…Osprey Farpoint 40Lå’ŒOsprey Porter 46L
  - ç˜¦é•¿çš„åŒ…ä¸åˆé€‚ï¼Œèƒ½æ”¾è¿›åŽ»ä½†æ˜¯å®¹é‡ä¼šæ¯”è¾ƒå°‘ã€‚

- è¿ªå¡ä¾¬299çš„50lä¹Ÿå¯ä»¥ä¸Š

- 
- 
- 
- 
- 

- ## [å®¶ç”¨çº§ä¸»æ¿èƒ½ä¸èƒ½æ’åŒæ˜¾å¡ï¼Ÿ - çŸ¥ä¹Ž _](https://www.zhihu.com/question/595962358)
- è¿™æ®µæ—¶é—´æ­£å¥½åœ¨ç ”ç©¶è¿™ä¸ªï¼Œä¹Ÿæ˜¯æƒ³æ‰¾ä¸ªåŒæ˜¾å¡çš„æ–¹æ¡ˆã€‚å¾¡ä¸‰å®¶çš„ä¸»æ¿çœ‹äº†ä¸ªéï¼Œä¸‰å®¶intel 7ç³»ä¸»æ¿é‡Œæ”¯æŒåŒæ˜¾å¡çš„æœ€ä¾¿å®œçš„ä¸»æ¿æ˜¯ ï¿¼ï¿¼[åŽç¡•ProArt Z790-CREATOR] ï¼Œ4200å…ƒï¼Œæ”¯æŒ [PCIe 5.0]  16x/0 å’Œ 8x/8x ä¸¤ç§æ¨¡å¼ã€‚å…¶ä»–æ”¯æŒåŒæ˜¾å¡çš„ä¸»æ¿éƒ½è¦5000ä»¥ä¸Šäº†ã€‚
  - å…¶ä»–å“ç‰Œçš„ä¸»æ¿ä¹Ÿçœ‹äº†äº›ï¼ŒåŽæ“Žå¤ªæžçœ‹ä»‹ç»ä¹Ÿèƒ½æ”¯æŒåŒæ˜¾å¡ï¼Œä½†æ²¡çœ‹åˆ°å“ªé‡Œæœ‰å–ï¼Œä¼°è®¡ä¹Ÿä¸ä¾¿å®œçš„ã€‚
- ç¡®å®žå¦‚æ­¤ã€‚æƒ³åŒæ˜¾å¡ä¸»æ¿ä¸èƒ½å·®äº†ï¼Œæœ€å¥½å¾—æ˜¯åŒPCIe5.0 16Xçš„ï¼Œè¦ä¸ç„¶ç¬¬äºŒä¸ªæ˜¾å¡é€Ÿåº¦ç›´æŽ¥æ…¢ä¸€æˆªï¼Œä½†ä»·ä½ç›´æŽ¥5000äº†ã€‚

- ä½ è¿™ä¸ªéœ€æ±‚åº”è¯¥åŽ»ä¹°X570å¸¦pcie bifurcationçš„ä¸»æ¿ï¼Œå› ä¸ºz690ã€z790å’Œamdæ–°çš„x670ä¸Šäº†pcie5.0ï¼Œ5.0çš„æ‹†åˆ†èŠ¯ç‰‡éžå¸¸æ˜‚è´µï¼Œåªæœ‰æ——èˆ°æ‰ä¼šç”¨ï¼Œ4.0çš„æ‹†åˆ†èŠ¯ç‰‡ç›¸å¯¹ä¾¿å®œã€‚ä¹°ä¸ªrog strix x570eå°±è¡Œäº†

- ## ðŸŒ° [CoolerMaster Qube 500 with dual GPUs : r/mffpc _202507](https://www.reddit.com/r/mffpc/comments/1m3x31m/coolermaster_qube_500_with_dual_gpus/)
  - CPU: Ryzen 5 9600X 
  - GPU1: RTX 5070 12Gb 
  - GPU2: RTX 5060 16Gb 
  - Mboard: ASRock B650M 
  - RAM: Crucial 32Gb DDR5 6400 CL32 
  - SSD: Lexar NM1090 Pro 2Tb 
  - Cooler: Thermalright Peerless Assassin 120 é£Žå†·
  - PSU: Lian Li Edge 1200W Gold
  - case: QUBE 500 Flatpack Black & White Edition | Cooler Master, 33.5L
  - Will be updating it to a Core Ultra 9 285K, Z890 mobo and 96Gb RAM next week, but already doing productive work and having fun with it.

- Did you mount the PSU to the front panel of the case?
  - Yep, tâ€™s the standard PSU bracket, in the top position, giving more room underneath for cables and gpu. It sits right up close to front panel, yes. Very nice case, super easy to build in.

- [Dual GPU set up was surprisingly easy : r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/comments/1m3xgjo/dual_gpu_set_up_was_surprisingly_easy/)
- How's your temperatures with that thing during use?
  - Excellent so far with this biggish case and the decent size air cooler for the CPU, and plenty of room to add more fans if needed.

- is there any reason you're going for an Intel core ultra? 
  - For LLMs, Intel can have a bit of an edge with DDR5 bandwidth.
  - Ryzen memory bandwidth on AM5 is bottlenecked by the infinity fabric, which means you donâ€™t get the full speed of dual channel DDR5. Intel doesnâ€™t have this bottleneck, so youâ€™d get the full bandwidth.
  - Of course this is only relevant if youâ€™re wanting to load models larger than your VRAM. In my case I got 96GB of DDR5-6000 for occasionally loading massive models (eg Mistral Large 123B), but I donâ€™t get the full 96GB/s theoretical bandwidth, itâ€™s closer to 60GB/s due to the infinity fabric bottleneck.

- [Updated: Dual GPUs in a Qube 500 : r/mffpc _202508](https://www.reddit.com/r/mffpc/comments/1mmebz9/updated_dual_gpus_in_a_qube_500/)
  - CPU: Core Ultra 9 285K, 
  - MBD: Gigabyte Z890 Aero G ATX, 
  - RAM: 256Gb (4x64) Crucial DDR5 5600MHz CL46 ( with four memory sticks itâ€™s stabilised at 5200MHz), 
  - GPU1: RTX 5070ti 16Gb, 
  - GPU2: RTX 5060ti 16Gb, both GPUs run at x8 smoothly
  - ssd * 3
  - PSU: Lian Li Edge 1200W 80+ Gold, 
  - Case: CoolerMaster Qube 500 (33 litres).
  - Getting 125+ TPS with GPT-OSS 20b, so pretty happy.

- I just bought the Qube 500 and plan on putting my rig into it. I have similar specs to yours, including a Lian Li Edge PSU (mine is 1000W). Iâ€™m worried about its size and fit in the case, especially with my 5070ti Gigabyte Gaming OC gpu. Did you run into a lot of issues from the size of the PSU? Did you have to mod anything to make it all work?
  - Yes it fits and works, no mods required, but thereâ€™s two options. There a series of rungs for the placement of the psu. 1. The top rung is harder to do, you have to push and shove the clips and the cables from the front panel a bit to get it in, but then as the psu is higher in the case, thereâ€™s better clearance of all the psu cables above the gpu. 2. Or, the second from the top rung, which is easier to fit in, but as the psu is lower then the power cables may be a bit cramped by the gpu.
  - I started with 2, then changed to 1, and recommend you start the same way. Depending on the length of your gpu, option 2 may be just fine.

- ## [ä¸ºä»€ä¹ˆå…‰å¨è¿™ä¸ªç‰Œå­çš„å†…å­˜è¿™ä¹ˆä¾¿å®œ? - çŸ¥ä¹Ž](https://www.zhihu.com/question/310230307/answers/updated)
- ä¾¿å®œçš„åŽŸå› ä¹Ÿä¸å¤–ä¹ŽäºŽç‰Œå­æ–°ï¼Œå“æŽ§ç•¥ä¸å¦‚å·¨å¤´ã€‚
  - ä½†æ˜¯å†…å­˜ç»ˆèº«è´¨ä¿å•Šï¼Œä½ æ€•å•¥ã€‚æˆ‘ç”šè‡³é‡åˆ°è¿‡åœäº§çš„åž‹å·ä»–ä»¬è¿˜ç»™åŽŸä»·é€€æ¬¾çš„ï¼Œè¿˜è¦ä»€ä¹ˆè‡ªè¡Œè½¦ã€‚

- æœ‰ç¨³å®šæ€§éœ€æ±‚çš„ç”¨æˆ·å¯ä»¥ä¹°ECCç”¨ä¸ä¸Šæ™®é€šå†…å­˜

- æˆ‘å®¶çš„ï¼Œå…¨å¤©24å°æ—¶å¼€æœºï¼Œä¸€ç›´ç”¨çš„éƒ½æ˜¯å…‰å¨å†…å­˜ï¼Œä»Žæ¥æ²¡å‡ºè¿‡é—®é¢˜ï¼Œ
  - å…‰å¨å†…å­˜åœ¨äº¬ä¸œçš„é”€é‡è¶…è¿‡20ä¸‡æ¡ï¼Œé”€é‡ä»…æ¬¡äºŽå¸‚åœºç¬¬ä¸€å“ç‰Œé‡‘å£«é¡¿ï¼Œ
  - å†åŠ ä¸Šè´¨ä¿æ˜¯â€œç»ˆèº«è´¨ä¿â€åªæ¢ä¸ä¿®ï¼Œæ ¹æœ¬ä¸ç”¨æ‹…å¿ƒã€‚

- å˜‰åˆåŠ²å¨æ——ä¸‹åªæœ‰é˜¿æ–¯åŠ ç‰¹å’Œå…‰å¨

- å†…å­˜å¤©ä¸‹ä¸‰åˆ†ï¼Œç¾Žå…‰å‰¯åŽ‚å‡ºå“

- ## [Who builds PCs that can handle 70B local LLMs? : r/LocalLLaMA _202502](https://www.reddit.com/r/LocalLLaMA/comments/1io811j/who_builds_pcs_that_can_handle_70b_local_llms/)
- Ryzen Threadripper CPU with 4x 3090 (with used parts it was close to $3, 000)

- For setup #2, how do you run 4x 3090 and a Threadripper cpu with a single 1600w psu? Don't the 3090's power spike from what I hear?
  - Yes that's accurate, I have one 1600 watts PSU to power it all.
  - If you see my setup guide, I also power limit 3090s to 270 watts using nvidia-smi. 270 watts per 3090 is that sweet spot that I found. I walk through it in the video and it is linked in the video, but here it is for easy reference:

- ## ðŸ†š [Is the difference between CL28 and CL30 6000MHz RAM noticable? : r/buildapc _202506x](https://www.reddit.com/r/buildapc/comments/1lo5iu2/is_the_difference_between_cl28_and_cl30_6000mhz/)
  - And is the difference worth an additional 20 euros?

- Nope, definitely not worth that amount. Just stick with 6000mhz CL30.

- You get a couple more FPS at most, not worth the 20 euros. Spend that money on a game with the current Steam summer sales instead.

- It depends on the game engine design too. Sometimes it does and sometimes not so much. As that video mentions, itâ€™s much less relevant on x3d CPUs. Extra cpu cache hides latency issues with ram for some workloads.
  - If you donâ€™t run x3d parts or do an Intel build, ram latency matters a lot more

- Not really but will be slightly faster in a few games. 6000/30 is sweet spot according to AMD too. Cheap and a nobrainer for most people.
- 6400/28 or even 26 might give you a few percent however 6000/30 and 28 is pretty much the same.
- If used with a X3D CPU the memory is even less important. Don't overpay on memory!

- [6400mhz cl30 or 6000mhz cl28 for 9800x3d? (gaming) : r/overclocking](https://www.reddit.com/r/overclocking/comments/1gxzstd/6400mhz_cl30_or_6000mhz_cl28_for_9800x3d_gaming/)
  - DDR5-6400 CL30 > DDR5-6000 CL28, but its more likely your chip will run the 6000CL28 or 30, than 6400CL30 1:1. You are the mercy of the silicon lotery, its better to bet to lose.
  - I run that 6400 kit at 6200 cl26, zero stability issues.. just depends on how much you wana fiddle. It ran 6400 cl30 expo no problem. Also run 1:1 with infinity fabric at 2067 and 1.6V. Also this kit is Hynix A-die.

- ## [è´µçš„æœºç®±å’Œä¾¿å®œçš„æœºç®±ï¼Œåœ¨ä½¿ç”¨ä½“éªŒä¸Šåˆ°åº•æœ‰å¤šå¤§åŒºåˆ«ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/589948503)
- çœŸæ­£å¥½ç”¨çš„æœºç®±ï¼Œå¾€å¾€ä¸ç®—éžå¸¸è´µï¼Œå…¶å®žæ˜¯â€œ[Silver Bullet]â€çº§åˆ«çš„è®¾è®¡ï¼Œå‡å¦‚é¢˜ä¸»éœ€è¦ä¸ªéžå¸¸èƒ½â€œè£…â€çš„æœºç®±ï¼Œé‚£ä¹ˆæ— è„‘æŽ¨èè¿½é£Žè€…PK620ï¼Œä»…ä»…699çš„[E-AT]æœºç®±ï¼Œè¶…çº§èƒ½è£…ï¼Œæ¯”ä»€ä¹ˆ1499çš„é…·å†·H500Mï¼Œä¸¤åƒå¤šå—çš„é…·å†·C700Méƒ½èƒ½è£…ã€‚
- è´µçš„æœºç®±å’Œä¾¿å®œçš„æœºç®±å¾€å¾€åœ¨åŠŸèƒ½æ–¹é¢åŒºåˆ«ä¸å¤§ï¼Œè®¾è®¡è¿™ä¸ªä¸œè¥¿ï¼Œä¸æ˜¯ç®€å•ç”¨é’±å°±èƒ½ä¹°åˆ°çš„ã€‚åœ¨æœºç®±ä¸ŠèŠ±æ›´å¤šé’±ä¹°åˆ°çš„ä¸€èˆ¬æ˜¯é—ªäº®çš„é’¢åŒ–çŽ»ç’ƒä¾§é€ï¼Œé˜³æžæ°§åŒ–å½©è‰²é“åˆé‡‘å¤–å£³ï¼ŒRGBç¯æ¿ç­‰ç­‰å¹¶ä¸æ˜¯æœºç®±å†…æ¶µçš„ä¸»è¦æˆåˆ†ã€‚ç‚«å½©é€äº®çš„æµ·æ™¯æˆ¿ï¼Œé›ªæ™¯æˆ¿æœºç®±ã€‚ä½†æ˜¯è¿™ä¸ä»£è¡¨ä½¿ç”¨ä½“éªŒä¼˜ç§€ã€‚

- ä¸€èˆ¬æ¥è¯´200å·¦å³åŠä»¥å†…çš„æœºç®±æ’‘æ­»äº†å°±æ˜¯ä¸ªæ ·å­è´§ã€‚ä¸»è¦ä½œç”¨æ˜¯æŠŠé›¶ä»¶ç»„åˆæˆä¸€ä¸ªç®±å­æ–¹ä¾¿ä½ æ¬èµ°ã€‚
  - ç”¨æ–™å®žåœ¨å¤ªå·®ã€‚é“çš®è–„ï¼Œå¡‘æ–™åŸºæœ¬ä¸Šéƒ½æ˜¯äºŒæ¬¡æ–™ï¼Œè„†çš„ä¸€æ‰¹è€Œä¸”æžæ˜“è€åŒ–ï¼ŒæŽ¥å£è´¨é‡å·®ï¼Œè¿™äº›å¤§å®¶å¯èƒ½éƒ½åœ¨è¯´ã€‚ä¸é‡å¤ã€‚
  - åŸºç¡€ç»“æž„è®¾è®¡ä¸åˆç†ã€‚æ¯”å¦‚[æ˜¾å¡] è£…å¥½åŽï¼Œ[HDMI] ä¼šæŠŠæŽ¥å£æŒ¡ä¸€åŠï¼›èƒŒæ¿ç©ºé—´ç‹­å°èµ°ä¸äº†å¤§çº¿ï¼›å‰é¢æ¿çº¿è·³çº¿é•¿ä¸å¤Ÿåªèƒ½æ–œæ‹‰é£žçº¿ï¼ˆå¾€å¾€è¿˜ä¸æ˜¯å…¨é»‘çº¿ï¼‰ï¼›ç­‰ç­‰ç±»ä¼¼çš„æƒ…å†µã€‚å¤ªå¸¸è§äº†ã€‚
  - å…¬å·®å¤§ã€‚è¿™ä¸ªè£…æœºçš„äººæ‰èƒ½ä½“ä¼šåˆ°â€¦â€¦å¦‚æžœä½ çŽ©æ¨¡åž‹çš„è¯å°±ä¼šçŸ¥é“ä¸€ä¸ªä¸œè¥¿å«åšâ€œç»„åˆåº¦â€ï¼Œ200å·¦å³çš„æœºç®±åŸºæœ¬éƒ½æœ‰è¿™ä¸ªæ¯›ç—…ã€‚ä»Žå†…åˆ°å¤–çš„é‚£ç§ã€‚ä½ ä¼šå‘çŽ°ä¸»æ¿ä¸Šèžºä¸çš„æ—¶å€™èžºä¸å­”ä½éƒ½å¯¹ä¸ä¸Šï¼Œéœ€è¦ç¨å¾®ç”¨ä¸€ç‚¹ç‚¹åŠ›æ‰èƒ½æŠŠèžºä¸é’»è¿›åŽ»ã€‚
- å¦‚æžœä½ é¢„ç®—å†é«˜ä¸€ç‚¹ï¼Œèƒ½æåˆ°500å·¦å³ï¼Œä¸€èˆ¬èƒ½åœ¨ä¸Šé¢1-3ä¸­æ”¹å–„æˆ–è€…è§£å†³ä¸€éƒ¨åˆ†
  - ä½¿ç”¨èµ·æ¥è¯´å®žè¯ï¼Œç»å¤§å¤šæ•°äººå››äº”ç™¾çš„æœºç®±å°±å¯ä»¥äº†ã€‚åˆ°è¿™ä¸ªä»·ä½ï¼Œåšå·¥ç”¨æ–™â€”â€”å°¤å…¶æ˜¯æŽ¥å£å’Œå¼€å…³çš„è´¨é‡åŸºæœ¬å°±é è°±äº†ã€‚
- æ›´é«˜ä»·æ ¼çš„æœºç®±æ›´å¤šçš„æ˜¯ç»™ä½ æ›´å¥½çš„å¤–å½¢å’ŒåŠŸèƒ½ï¼Œåœ¨â€œæ»¡è¶³ä½¿ç”¨éœ€æ±‚â€æ–¹é¢æ²¡æœ‰ä»€ä¹ˆæ›´å¤§çš„ä¼˜åŠ¿ã€‚
  - é™éŸ³å…¨å¡”
  - æœ‰è¯´æ³•æ˜¯é™éŸ³ç®±æ¯”ä¾§é€ç®±çš„ç”µç£å±è”½èƒ½åŠ›è¦å¥½ä¸€äº›ã€‚ä½†å®žé™…ä¸Šä½¿ç”¨èµ·æ¥æ²¡æœ‰æ”¶é›†åˆ°ä»€ä¹ˆè‚‰çœ¼å¯è§çš„å·®å¼‚ã€‚

- ä¸€èˆ¬æ¥è¯´200å·¦å³åŠä»¥å†…çš„æœºç®±æ’‘æ­»äº†å°±æ˜¯ä¸ªæ ·å­è´§ã€‚è¿™å¥è¯æ”¾åœ¨ä»¥å‰æˆ‘é«˜ä½Žç»™ä½ ä¸¾ä¾‹åé©³ä¸€ä¸‹ï¼ŒçŽ°åœ¨åé©³ä¸äº†
  - è‡ªä»Žå¼€å§‹æµè¡Œä¾§é€ä¹‹åŽåŸºæœ¬å°±å…¨æ˜¯ä¸€å¤©æ¯”ä¸€å¤©çƒ‚ï¼Œæ‰€ä»¥æˆ‘æ‰æ”¾å¿ƒè¯´è¿™è¯çš„

- å¤§çš„å®‰è£…çš„æ—¶å€™å¾ˆæ–¹ä¾¿ï¼Œå°æœºç®±è¦æ˜¯æœºå™¨è¦ç»´ä¿®æ•…éšœäº†ä½ ä¼šæƒ³ç ¸äº†å®ƒ
  - æ‰€ä»¥ä¸æ˜¯ç‰¹æ®Šéœ€æ±‚æˆ‘éƒ½æŽ¨èä¹°å…¨å¡”æœºç®±ï¼Œæˆ–è€…ä¸Šé¢æˆ–è€…å‰é¢èƒ½æ‹†å¼€çš„ä¸­å¡”

- ## [è¿Žå¹¿å’Œä¹”æ€ä¼¯çš„æœºç®±ä¸ºä»€ä¹ˆéƒ½é‚£ä¹ˆè´µï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/59837988)
- ä¹”æ€ä¼¯å°±æ˜¯ä»¥ä½Žä»·æ ¼è®©ç¾¤ä¼—äº«å—åˆ°åšå·¥å‡‘åˆè¿˜è¡Œçš„å…¨é“æœºç®±è€Œå‡ºåçš„

- ä¹”æ€ä¼¯æ˜¯æˆ‘å¾…é€‰æœºç®±é‡Œå”¯ä¸€ä¸€ä¸ªç”¨SGCCæ¿æå’Œ5mmçŽ»ç’ƒçš„ã€‚å…¶å®ƒå†è‰¯å¿ƒä¸€ç‚¹çš„å°±æ˜¯SECCå’Œ4mmçŽ»ç’ƒï¼Œè¿˜æœ‰å°±æ˜¯SPCCã€‚ä½†æ˜¯ä¹”æ€ä¼¯è®¾è®¡çš„è§‰å¾—å¤ªå·®åŠ²ï¼Œä¸è®ºæ˜¯é£Žå†·è¿˜æ˜¯æ°´å†·æ•£çƒ­è®©äººå¿ƒé‡Œæ²¡åº•ã€‚è¿Žå¹¿303ç¡®å®žæ¼‚äº®ï¼Œä½†æ˜¯åæ§½ç‚¹æœ‰äºŒï¼š1ã€çŽ»ç’ƒ0.3ï¼Œ2ã€ä¸Šç½®ç”µæºã€‚ä»¥ä¸Šåªæ˜¯ä¸ªäººè§‚ç‚¹ï¼Œä¸å–œå‹¿å–·ï¼

- spccå°±æ˜¯å†·è½§é’¢ï¼Œseccæ˜¯ç”µé•€é”Œé’¢æ¿ï¼Œsgccæ˜¯çƒ­è§£é”Œé’¢æ¿ï¼›
  - seccå’Œsgccæ¯”spccå¥½ï¼Œä½†seccå’Œsgccå„æœ‰ä¼˜åŠ¿ï¼Œsgccè€è…èš€æ›´å¼ºï¼Œä½†seccä¿æŒäº†å†·æ¿çš„åŠ›å­¦ç‰¹æ€§ï¼Œåœ¨è–„æ¿çš„æƒ…å†µä¸‹å¼ºåº¦æœ‰ä¼˜åŠ¿

- ## ðŸ“¦ [æœºæ¢°å¤§å¸ˆC34 Proæœºç®±å¥½ç”¨å—ï¼Ÿç¼ºç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ - çŸ¥ä¹Ž](https://zhuanlan.zhihu.com/p/642308682)
- æœºç®±ä½¿ç”¨äº†æ¨¡å—åŒ–è®¾è®¡ï¼Œæ— è®ºæ˜¯ä¸Šç½®ç”µæºè¿˜æ˜¯ä¸‹ç½®ç”µæºï¼Œç›´æ’æ˜¾å¡è¿˜æ˜¯ç«–è£…æ˜¾å¡ï¼Œæˆ‘ä»¬åªéœ€è°ƒèŠ‚ç›¸åº”çš„æ¨¡å—å³å¯ï¼Œå¯¹ç¡¬ä»¶çš„åŒ…å®¹æ€§æžé«˜ã€‚
  - æ¯”å¦‚å°¾éƒ¨çš„7ä¸ªPCIeæ§½ä½è®¾è®¡ï¼Œä¸­é—´çš„ç¬¬2ä¸Ž3æŒ¡æ¿æ˜¯å¯ä»¥æ‹†å¸çš„ï¼Œç„¶åŽé€šè¿‡ç§»åŠ¨æ¥å®žçŽ°ATX/MATXä¸»æ¿è§„æ ¼çš„è½¬æ¢ã€‚

- åœ¨è®¾è®¡ç»†èŠ‚ä¸Šï¼Œæœºç®±æœ€å¤§å¯æ”¯æŒ420mmæ˜¾å¡ï¼Œè®©æˆ‘åŽç»­åœ¨å‡çº§æ—¶ä¹Ÿæœ‰äº†ä¸€å®šçš„é€‰æ‹©ã€‚å¹¶ä¸”è‡ªå¸¦æ˜¾å¡æ”¯æ’‘æž¶è®¾è®¡ï¼Œä¸å¿…æ‹…å¿ƒæ˜¾å¡å¤ªé•¿ä¼šäº§ç”Ÿå˜å½¢ã€‚ä¸è¿‡æ˜¾å¡é•¿åº¦è¶…è¿‡336mmçš„è¯ï¼Œç”µæºå°±ä¸èƒ½ä¸‹ç½®å®‰è£…ã€‚

- ä½œä¸ºä¸€æ¬¾é€‚åˆæ‘†æ”¾åœ¨æ¡Œé¢çš„æœºç®±ï¼Œå…¶I/Oé¢æ¿æ”¾åœ¨äº†å³ä¸‹è§’å¤„ã€‚ä»Žä¸Šè‡³ä¸‹ä¾æ¬¡ä¸ºä¸¤ä¸ªUSB3.0 TypeAå£ã€Type-Cæ’å£ã€3.5mmè€³éº¦äºŒåˆä¸€å­”ã€ç”µæºå¼€å…³ï¼ˆå†…ç½®ç™½è‰²LEDï¼‰ã€‚

- æœºæ¢°å¤§å¸ˆC34 Proé¢„ç•™æœ‰2ä¸ª3.5/2.5å¯¸ç¡¬ç›˜æ”¯æž¶ä»¥åŠåŽç½®2ä¸ª2.5å¯¸å›ºç›˜ä½ï¼Œè¾¾æˆå…±è®¡4ä¸ªç¡¬ç›˜ä½çš„æ”¯æŒï¼Œæ»¡è¶³ä¸åŒç”¨æˆ·çš„éœ€æ±‚ã€‚è€ƒè™‘åˆ°æˆ‘çŽ°åœ¨å¤šæ˜¯ä½¿ç”¨M.2 SSDå›ºæ€ç¡¬ç›˜ï¼Œæœºç®±é€šå¸¸ä¹Ÿå°±åªä¼šç”¨åˆ°åŽç½®çš„2.5å¯¸ç¡¬ç›˜ä½è€Œå·²ã€‚

- æœºç®±åº•éƒ¨é¢„ç•™äº†ä¸¤ä¸ªæ•£çƒ­é£Žæ‰‡å®‰è£…ä½ï¼Œå¯ä»¥è¿›ä¸€æ­¥åŠ é€Ÿæœºç®±å†…éƒ¨çš„çƒ­é‡æŽ’å‡ºã€‚

- æœºç®±èƒŒé¢æ‹¥æœ‰18mmç†çº¿ç©ºé—´ï¼Œå¹¶ä¸”é…å¤‡äº†ç©¿çº¿å­”ï¼Œçº¿æèµ°å‘ä¸ç”¨è¿‡äºŽæ‹˜è°¨ï¼Œåˆ©äºŽç†çº¿ã€‚

- C34 Proæ˜¯æˆ‘è§è¿‡é…ä»¶æ–¹é¢æœ€èµ°å¿ƒçš„æœºç®±ã€‚ç¬¬ä¸€æ¬¡è§èžºä¸é’‰è‡ªå¸¦é…ä»¶ç›’ï¼Œè¿˜é™„èµ äº†ç£å¸èžºä¸åˆ€ã€ATX/MATXåˆ‡æ¢ç»„ä»¶ä»¥åŠé˜²å°˜ç½‘ã€‚è‡³äºŽä¾¿æºææ‰‹æˆ‘å¹¶æ²¡æœ‰å®‰è£…åˆ°æœºç®±ä¸Šï¼Œå› ä¸ºè£…å…¥ç”µæºå’Œæ˜¾å¡åŽçš„æ•´ä½“é‡é‡å¤ªå¤§ï¼Œå•æ‰‹ææ‹¿ä¸åŠ¨ã€‚

- [æ–¹ç³–æœºæ¢°å¤§å¸ˆ C34 Pro AIRç‰ˆæœºç®±å‚æ•° -ZOLä¸­å…³æ‘åœ¨çº¿](https://detail.zol.com.cn/2114/2113024/param.shtml)
  - 429Ã—205Ã—349mm, 30.7L
  - å°å¼æœºç®±ï¼ˆä¸­å¡”ï¼‰ï¼Œå¸éŸ³é™å™ªæœºç®±ï¼ŒçŽ»ç’ƒä¾§é€æœºç®±
  - é€‚ç”¨ä¸»æ¿	E-ATXï¼ˆåŠ å¼ºåž‹ï¼‰ï¼ŒATXï¼ˆæ ‡å‡†åž‹ï¼‰ï¼ŒM-ATXï¼ˆç´§å‡‘åž‹ï¼‰
  - æ˜¾å¡é™é•¿	420mm
  - CPUæ•£çƒ­å™¨é™é«˜	165mm
  - USBæŽ¥å£	2Ã—USB3.0æŽ¥å£ï¼Œ1Ã—USB3.1 Type-CæŽ¥å£çº 
  - è‡³å¤šæ”¯æŒï¼š8Ã—120mmé£Žæ‰‡ä½
  - æ”¯æŒï¼š360/280mmæ°´å†·æŽ’
  - æˆ‘çš„atxçš„æ¿å­åŠ 170é•¿çš„å¤§ç”µæºåŠ 7900xtxè¶…ç™½é‡‘çš„æ˜¾å¡éƒ½å¡žè¿›åŽ»äº†ï¼Œè€Œä¸”ç”¨ç”µæºè‡ªå¸¦çš„çº¿ä¸å¸¦å®šåˆ¶çº¿ä¹Ÿå¯ä»¥å¡žä¸‹ã€‚æ•´ä¸ªæœºç®±å¤§éƒ¨åˆ†åœ°æ–¹éƒ½å¯ä»¥å¸æŽ‰èžºä¸æ‹†ä¸‹æ¥ï¼Œå¤§å¤§é™ä½Žäº†è£…æœºéš¾åº¦ã€‚å°±æ˜¯é˜²å°˜ç½‘çš„å­”å¤ªå¤§äº†ï¼Œæ„Ÿè§‰æŒ¡ä¸ä½ç°å°˜é¢ã€‚
  - å†…éƒ¨ä¸€ä¸ªå¤§åŒå¡”å®Œå…¨æ²¡é—®é¢˜
  - æœºç®±æ¯”è¾ƒç´§å‡‘ï¼Œå°±æ˜¯å†·æŽ’æ°´ç®¡åªæœ‰èµ°å³è¾¹ï¼Œå»ºè®®å·¦è¾¹å¼€å­”ç¨å¾®å®½ä¸€ç‚¹ï¼Œå…¶ä»–è¿˜æ˜¯å¾ˆå®Œç¾Ž
  - ä»€ä¹ˆæ˜¯ä¸‡èƒ½æœºç®±ï¼Œè¿™å°±æ˜¯ä¸‡èƒ½æœºç®±ï¼Œæœºç®±æ°¸è¿œçš„ç¥žï¼Œå„ç§ç»„è£…å¡å¡ä¸€å¼„å¾ˆé…·ç‚«å¾ˆæ–¹ä¾¿ä¾¿æ·ï¼ŒATXä¹Ÿèƒ½å¾ˆå°å·§ï¼ŒæŽ¨èè´­ä¹°ï¼Œç‰©è¶…æ‰€å€¼ï¼Œæ•£çƒ­ä¹Ÿå¾ˆå¥½
  - 34proé•¿ä¸€ç‚¹æ¯”34å¥½è£…å¤šäº†ï¼Œè¿˜èƒ½èµ°ä¸‹èƒŒçº¿ä½ æ•¢ä¿¡ï¼Ÿ
  - å¯è£…ä¸‹ ATXä¸»æ¿ + 360æ°´å†· + è¶…é•¿æ˜¾å¡çš„æ–¹æ¡ˆæŒºå®žç”¨ã€‚
  - è¿™æ˜¯æˆ‘ç›®å‰çœ‹åˆ°çš„ï¼Œèƒ½è£…ä¸‹atxä¸»æ¿å’Œ4080æ˜¾å¡çš„æœ€å°æœºç®±
  - è¿™æ¬¾æœºç®±å·²ç»çœ‹äº†å¥½ä¹…ï¼Œå› ä¸ºè´µï¼Œæ²¡èˆå¾—ä¹°ï¼Œä¹°äº†D40ã€‚æ— å¥ˆD40åªæ”¯æŒ240æ°´å†·ï¼Œå¤¹äº†æ±‰å ¡ä¹ŸåŽ‹ä¸ä½13900fã€‚è¿˜æ˜¯é€‰äº†è¿™æ¬¾ï¼Œå†æŠ˜è…¾ä¸€é
  - é€‚é…vertex+4090å…¬ç‰ˆ+360æ°´è¿™ç§ç»„åˆ

- ðŸ¤” [C34Proè£…æœºå…¼å®¹æ€§å®Œç¾Žï¼ŒCS2ç»ˆäºŽè·‘æ»¡360å†³èµ›åœˆTK2å’ŒC34Proï¼Œæƒ³åˆ°æ”¾æ¡Œä¸‹å¤§éƒ¨åˆ†æ—¶é—´çœ‹ä¸åˆ°ï¼Œå¯¹å…‰æ±¡æŸ“ä¹Ÿä¸æ„Ÿå†’ï¼Œé€‰äº†æ›´å†·å³»ç¡¬æœ—çš„æœºæ¢°å¤§å¸ˆï¼Œæœºç®±å…¼å®¹æ€§å¹çˆ†ï¼Œå°ºå¯¸åœ¨ATXæœºç®±ä¸­ç»å¯¹ç®—æžé™åŽ‹ç¼©hz - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/684bae9a000000002300fe85?xsec_token=ABDPZc4kz4GSpMhS22KwCsX8BjChgpSLV5ZsDCfogMlOE=&xsec_source=pc_search&source=web_search_result_notes)
  - å†³èµ›åœˆTK2å’ŒC34Proï¼Œæƒ³åˆ°æ”¾æ¡Œä¸‹å¤§éƒ¨åˆ†æ—¶é—´çœ‹ä¸åˆ°ï¼Œå¯¹å…‰æ±¡æŸ“ä¹Ÿä¸æ„Ÿå†’ï¼Œé€‰äº†æ›´å†·å³»ç¡¬æœ—çš„æœºæ¢°å¤§å¸ˆï¼Œæœºç®±å…¼å®¹æ€§å¹çˆ†ï¼Œå°ºå¯¸åœ¨ATXæœºç®±ä¸­ç»å¯¹ç®—æžé™åŽ‹ç¼©
  - ä¸»æ¿ï¼šB850æˆ˜æ–§å¯¼å¼¹å¤§æ¿ï¼Œé»‘è‰²æœºç”²é£Žé…é­”çˆªç»¿LOGOç‚¹ç¼€æ°åˆ°å¥½å¤„ï¼Œé‡åˆ°æœ‰çº¿ç½‘è¿žä¸ä¸Šçš„é€šç—…
  - æ˜¾å¡ï¼šçž„å‡†5070tiï¼Œ7.3Kä¹°åˆ°ADOCä¹Ÿç®—å¥½ä»·å°±å½“ç¼˜åˆ†
  - CPUï¼š9800X3Då¯¹CSã€åƒé¸¡ã€é­”å…½ä¸‰æ –çŽ©å®¶è‡´å‘½å¸å¼•ï¼Œå åˆ¸åŽæ¿Uå¥—4.6Kå…¥æ‰‹
  - å›ºæ€ï¼šä¸‰æ˜Ÿ990Pro 5090Då¯Œå“¥è£…æœºå¿…é€‰é—­çœ¼å…¥
  - ç”µæºï¼šAMP GH850Wé¢œå€¼æ­è°ƒï¼Œä»·æ ¼åˆé€‚ï¼ŒèŸ’çº¹çº¿å’Œè‡ªå¸¦çº¿æ¢³è„±é¢–è€Œå‡º
  - é£Žæ‰‡ï¼šè”åŠ›çŒ«å¤´é¹°è¶…é¢„ç®—ï¼Œé¾™é³žå…‰æ•ˆæ¸…çˆ½ï¼Œåœ†è§’çŸ©å½¢æœ‰è¾¨è¯†åº¦ï¼Œä»·æ ¼é€‚ä¸­ï¼Œä¸¤ç‚¹ä¸è¶³ï¼šâ‘ å…‰æ•ˆä¸å¤Ÿå‡åŒ€ï¼ˆLEDå°‘æˆ–åŒ€å…‰æ¿ä¸å¤ŸåŽšï¼‰â‘¡å™ªéŸ³å¤§å¸¦è€³æœºéƒ½å¬å¾—åˆ°ï¼Œä¸è¿‡æˆ‘èƒ½å¿å—
  - æ°´å†·ï¼š5.31é’›é’½é¦–å‘æ–°å“LG600ï¼Œ3.95è‹±å¯¸å¤§å±å‡ºå½©ï¼Œå·®ç‚¹è£…ä¸ä¸‹ï¼ŒC34Proåˆæ˜¯åˆšå¥½å…¼å®¹ï¼Œå±å¹•è·Ÿä¸Šæ–¹é£Žæ‰‡å°±1~2mmé—´éš™

- ## ðŸ› [Smallest possible ATX case that can fit a full size GPU : r/buildapc _202406](https://www.reddit.com/r/buildapc/comments/1djnxe3/smallest_possible_atx_case_that_can_fit_a_full/)
  - I currently have a mini itx setup with an i5 10400, and an rx 6700xt. Itâ€™s feeling like itâ€™s time for an upgrade and microcenterâ€™s CPU, MOBO, RAM combos are too good to pass up. ($370 for a Ryzen 7 7700x and 32gb of ram) Especially compared to the $700+ I would have to spend on those parts, an itx mobo and a capable SFX PSU.
- A case like the GameMax Meshbox Pro is probably the smallest youâ€™re going to get without needing an SFX power supply, at about 33.5L in volume. Can still fit GPUâ€™s up to 335mm in length, and is a very reasonable $62.

- ## [Looking for a Compact, Silent Server Case : r/homelab _202504](https://www.reddit.com/r/homelab/comments/1k6nbse/looking_for_a_compact_silent_server_case/)
  - Motherboard: ATX (specifically the Supermicro H13SSL, which I plan to use)
  - Support for 8 or more HDDs

- The N5 might check all the boxesâ€”except for noise. It lacks any sound-dampening material.
  - 50L
- I'd use a Jonsbo n5 and dynamat the hell out of it if I found it too noisy. 

- ## [Looking for a compact case for my H11SSL-i - Hardware Hub / Build a PC - Level1Techs Forums _202311](https://forum.level1techs.com/t/looking-for-a-compact-case-for-my-h11ssl-i/203506)
  - I just received my H11SSL-i Supermicro motherboard with an Epyc CPU that has 16 cores and 256 GB of RAM. However, I am yet to find a suitable case for it. I am looking for a compact case that has at least 3 to 4 bays for 3.5-inch hard drives and another 3 to 4 bays for 2.5-inch drives. 
- Fractal Design Node 804 has really cornered this market, available for ~$140

- H11SSL-i is ATX, so no, it wonâ€™t fit in mATX cases.

- I canâ€™t give advice about a case that fits your requirements, but for a reference, Iâ€™m currently using Fractal Define 7 Compact for my H11SSL-i + 7551P. The case only has 2x 3.5" drive bay with a cage underneath the bottom cover and 2x 2.5" drive behind the motherboard. I think if you donâ€™t use the bottom PCIe slot, you may be able to fit two more 2.5" above the PSU. A standard Fractal Define 7 should fit, but itâ€™s not compact 

- ## ðŸ“Œ [æ±‚ä¸€æ¬¾atxç´§å‡‘åž‹æœºç®±? - çŸ¥ä¹Ž](https://www.zhihu.com/question/328153905)
- æœ€è¿‘æˆ‘è£…äº†ä¸€å°AMDå¹³å°çš„æ¸¸æˆPCï¼Œä¸ºäº†æ›´å¥½çš„æ‰©å±•æ€§æˆ‘é€‰æ‹©äº†ATXå¤§æ¿ï¼Œä½†æˆ‘åˆè¿½æ±‚å°å·§æœºèº«å’Œæ‰©å±•æ€§ï¼Œæ‰€ä»¥è¿˜æ˜¯æœ‰ç‚¹éš¾åŠžçš„ï¼Œåœ¨æœºç®±çš„é€‰æ‹©æ–¹é¢æˆ‘ä¹Ÿæ˜¯ç ”ç©¶äº†è®¸ä¹…ï¼Œæœ€ç»ˆç»“åˆå®žé™…ã€é€‰æ‹©äº†è®¾è®¡éžå¸¸ç‹¬åˆ°çš„ç´§å‡‘æœºç®±ï¼šæœºæ¢°å¤§å¸ˆC34 Proã€‚
  - è¿™ä¸ªæœºç®±æ”¯æŒATX/EATXæ¿å­ï¼Œä½†å°ºå¯¸åªæœ‰429x205x349mmï¼Œæ¯”å¸¸è§„çš„ATXæœºç®±å°äº†å¾ˆå¤šï¼Œä½†æ¨¡å—åŒ–çš„ç‹¬ç‰¹è®¾è®¡è®©å®ƒå…·å¤‡äº†éžå¸¸æ£’çš„æ‰©å±•æ€§å’Œå¯ç»´æŠ¤æ€§
  - CPUï¼šAMD RYZEN 7 9700X
  - ä¸»æ¿ï¼šè“å®çŸ³NiTRO+æ°®åŠ¨B850A WIFI
  - å†…å­˜ï¼šä½°ç»´DW100 DDR5 6800C32
  - æ˜¾å¡ï¼šå…¬ç‰ˆRTX 4080
  - ç¡¬ç›˜ï¼šç³»ç»Ÿç›˜Â·è¥¿éƒ¨æ•°æ®SN750 500GBï¼›æ¸¸æˆç›˜Â·è‡´æ€TiPro9000 4TB
  - æœºç®±ï¼šæœºæ¢°å¤§å¸ˆC34 Pro, 429*205*349mm, 30.6L
  - CPUæ•£çƒ­å™¨ï¼šè¿½é£Žè€…Polarä¼¯ä¹T6
  - ç”µæºï¼šå®‰è€ç¾Žç™½é‡‘ç«žè PK1000W
  - æœºæ¢°å¤§å¸ˆC34 Proè¿™ä¸ªæœºç®±æ­£é¢é‡‘å±žè´¨æ„Ÿå°½æ˜¾ï¼Œçœ‹èµ·æ¥æžä¸ºä¼˜é›…

- [æœ‰æ²¡æœ‰ä»€ä¹ˆä½“ç§¯æ¯”è¾ƒå°çš„ATXæœºç®±æŽ¨è. å°å¼æœºï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/51668457/answers/updated)

- ## [åŒ RTX 5060 Ti ç™½è‰²å®¶åº­å·¥ä½œç«™ ä¹”æ€ä¼¯ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/687ab0d4000000002203d812?xsec_token=ABsbkh11yQDdy4hEUo0ho9xZjLdOVOCgvh31n3gg0Yyw8=&xsec_source=pc_search&source=web_explore_feed)
  - ä¸»æ¿ï¼šåŽç¡• Z690 Formula
  - æœºç®±ï¼šä¹”æ€ä¼¯ D41 MESH
  - CPUï¼ši7-14700
  - æ˜¾å¡1ï¼šå¾®æ˜Ÿ RTX 5060 ti 16GB TRIO
  - æ˜¾å¡1ï¼šæŠ€å˜‰ RTX 5060 Ti 16G
  - å†…å­˜ï¼š64GB DDR5 6400 CL32
  - ç¡¬ç›˜ï¼šKioxia KXG80ZN84T09 4TB
  - ç”µæºï¼šæµ·ç›—èˆ¹ RM750e ATX 3.1
  - AIOï¼šé…·å‡› FX360 PRO
  - é£Žæ‰‡ï¼š8 x Arctic BioniX P120

- ## ðŸŒ° [5k2k 144Hz Dual GPU LSFG Setup : r/losslessscaling _202504](https://www.reddit.com/r/losslessscaling/comments/1k837cb/5k2k_144hz_dual_gpu_lsfg_setup/)
  - Just here to share my completed dual GPU build, managed to get stable 144fps in MH Wilds with LSFG 3.0 Fixed x3 with 80 flow scale, HDR enabled. And my goodness the gameplay looks incredible smooth.
  - CPU: AMD Ryzen 7 5800X3D 
  - GPU for Rendering: ASRock RX 9070 XT Steel Legend 
  - GPU for LSFG: VASTARMOR RX 7650 GRE (I bought it from China Taobao) 
  - GPU Undervolt settings: 9070 XT -80mV, -10% PL, 2700MHz Memory 7650 GRE -60mV, -6% PL
  - RAM: 4 x 16GB DDR4 3200MHz CL16
  - power: FSP Hydro Ti PRO 1000W
  - case: Jonsbo D41 Mesh Screen (White)
  - Fun fact: The total cost of getting these 2 GPU is still lower than any rtx5080 I can find in my region ffs.
  - My top GPU takes like 2.9 slot (only left about 2mm clearance between GPU), bottom GPU takes 2.4 slot, if I removed the bottom fans it can easily fit a full size 3 slot card, but the air flow will be worse obviously.
  - I should have mentioned my case fans arrangements too: 1 x front intake, 2 x bottom intake, 1 x top (front) intake, 1 x rear exhaust, 2 x top (rear) exhaust

- Nice looking build but that top GPU will be starving for fresh air. I tried the same with my build and ended up getting another case so I could move the bottom card into a vertical mount on a riser.

- I'm interested about temps after ~1 hour or longer game session
  - So far my top GPU hotspot temp can be kept below 83C range, VRAM temp around 95C worst case, from I have seen 9070XT memory temp is hot across all AIB partner, I will just live with it..
  - So far my top GPU hotspot temp can be kept below 83C range, VRAM temp around 95C worst case, from I have seen 9070XT memory temp is hot across all AIB partner, I will just live with it..

- ## [ä¹”æ€ä¼¯æŽ¨å‡ºæ¾æžœ D41 ATX ç³»åˆ—æœºç®±ï¼Œè¯¥äº§å“éƒ½æœ‰å“ªäº›äº®ç‚¹è®¾è®¡ï¼Ÿ - çŸ¥ä¹Ž _202212](https://www.zhihu.com/question/572085484)
- ä¹”æ€ä¼¯ä¸ºCR3000é£Žå†·æ•£çƒ­å™¨æ ‡æˆäº†260ç“¦çš„çƒ­è§£èƒ½åŠ›
  - CR3000é£Žå†·æ•£çƒ­å™¨ä¸ºéžå¸¸ä¼ ç»Ÿçš„åŒå¡”ç»“æž„ï¼Œæ•´ä½“å°ºå¯¸ä¸º120x132x160mmï¼Œåœ¨é€‰é…æœºç®±æ—¶è¯·æ³¨æ„æ•£çƒ­å™¨å…¼å®¹é«˜åº¦ï¼ŒåƒD41è¿™ç§å°±èƒ½å®Œç¾Žè£…å…¥ã€‚ 

- https://www.zhihu.com/question/477140818/answer/3215457076
  - è¿™ä¸å°±æ˜¯æˆ‘çš„ä¹”æ€ä¼¯D41å˜›ï¼æˆ‘ä¹Ÿåœ¨è€ƒè™‘é£Žé“é—®é¢˜ã€‚ç›®å‰æœ€åˆç†çš„å®‰ç½®æ–¹å¼å°±æ˜¯ï¼š1. åº•éƒ¨é£Žæ‰‡å¸æ°”å…¼ç»™æ˜¾å¡ä¾›é£Žï¼›2. ç”µæºé£Žæ‰‡æœå‰ï¼Œå¾€ä¸Šå¹é£Žï¼›3. å‰ç½®å°é£Žæ‰‡é‡Œå¹æ°”ï¼Œå…¼å¹æ˜¾å¡ï¼›4. CPUåŠåŽç½®é£Žæ‰‡å¾€åŽå¹ã€‚
  - å¦ä¸€ç§ä¸åˆç†çš„æ–¹å¼å°±æ˜¯ï¼Œæ•´ä½“ä»ŽåŽå¾€å‰å¹ï¼Œè°ƒè½¬ç”µæºé£Žæ‰‡ä»Žæœºç®±å†…éƒ¨å¸æ°”ï¼Œå‰ç½®é£Žæ‰‡ä»Žå†…éƒ¨å¸æ°”ã€‚

- ## [ä¹”æ€ä¼¯å‘å¸ƒæ¾æžœ D31 ç´§å‡‘åž‹ M-ATX æœºç®±ï¼Œæ”¯æŒåˆ° 360 æ°´å†·æŽ’, æ•£çƒ­æ€§èƒ½æ€Žä¹ˆæ ·ï¼Ÿ - çŸ¥ä¹Ž _202210](https://www.zhihu.com/question/562398994)
- æœºç®±å‰¯å±æ˜¯ä¸€ä¸ªäº®ç‚¹ï¼Œç´§å‡‘åž‹æœºèº«èƒ½æ”¾ä¸‹360ä¸€ä½“æ°´å†·ï¼Œæƒ³æ³•ä¸é”™ã€‚ä½†æ˜¯ç›®æµ‹ä¼šæœ‰äº›é—®é¢˜ï¼Œæ¯”å¦‚æˆ‘è´­ä¹°å°±æ˜¯ä¹”æ€ä¼¯TF360ä¸€ä½“æ°´å†·æ•£çƒ­å™¨ï¼Œæ°´æ³µåœ¨æ°´ç®¡ä¸Šï¼Œè·ç¦»å†·æŽ’è¿›å‡ºæ°´å£ä¸åˆ°10åŽ˜ç±³ï¼ˆå¯èƒ½ä¸å‡†ï¼‰ä½ç½®ä¸Šã€‚è‹¥ä½¿ç”¨D31çš„è¯ï¼Œç”µæºå¯èƒ½æ— æ³•å®‰è£…åœ¨LV1æˆ–è€…LV2çš„ä½ç½®

- [ä¹”æ€ä¼¯æ¾æžœD31æœºç®±ç®€ä»‹ã€‚å«D31æœºç®±æŽ¨èçš„è£…æœºé…ç½®æ–¹æ¡ˆ - çŸ¥ä¹Ž](https://zhuanlan.zhihu.com/p/583985999)
- ä¹”æ€ä¼¯æ¾æžœD31çš„æ€»ä½“ç»“æž„å’ŒD30ç›¸ä¼¼ã€‚æ”¯æŒM-ATXä¸»æ¿ï¼Œç”µæºå‰ç½®ï¼Œé¡¶éƒ¨å®‰è£…æ°´å†·ã€‚åŒºåˆ«åœ¨äºŽD31æ›´å¤§ï¼Œé¡¶éƒ¨å’Œåº•éƒ¨å¯ä»¥å®‰è£…360æ°´å†·ï¼ŒTYPE-CæŽ¥å£ä¹Ÿæ”¹æˆäº†çœŸæ­£çš„ï¼ˆD30æ˜¯å’ŒUSBå¹¶çº¿çš„ï¼‰ã€‚
- ç›®å‰ç±»ä¼¼ç»“æž„ï¼Œæ”¯æŒé¡¶éƒ¨å®‰è£…360æ°´å†·çš„æœºç®±è¿˜æœ‰åŽç¡•çš„å†°ç«‹æ–¹AP201ã€‚

- ä¹”æ€ä¼¯æ¾æžœD31ä»…æœ‰ä¸€ä¸ªæœºæ¢°ç¡¬ç›˜ä½ç½®ï¼Œå¹¶ä¸”è¿™ä¸ªä½ç½®æ˜¯åº•éƒ¨çš„ä¸€ä¸ªé£Žæ‰‡ä½ï¼Œé£Žæ‰‡å’Œç¡¬ç›˜åªèƒ½äºŒé€‰ä¸€å®‰è£…ã€‚
  - æœ‰2ä¸ª2.5å¯¸SATAå›ºæ€ç¡¬ç›˜ä½ã€‚

- ## ðŸ“ŒðŸ’¡ [æœ‰å“ªäº›å·¨å¥½çœ‹çš„æœºç®±ï¼Ÿ æœºæ¢°å¤§å¸ˆ - çŸ¥ä¹Ž](https://www.zhihu.com/question/347824157/answer/1841037981)
- æœºæ¢°å¤§å¸ˆCç³»åˆ—å…¨é‡‘å±žæœºç®±äº†è§£ä¸€ä¸‹
- ç›®å‰æœºæ¢°å¤§å¸ˆCç³»åˆ—æœ‰C24ã€C26ã€C28ã€C34ä¸€å…±å››æ¬¾æœºç®±ï¼Œè¿™å››æ¬¾æœºç®±ç”±å°åˆ°å¤§ï¼Œæ¶µç›–äº†ä»ŽITXè¶…å°ä½“ç§¯åˆ°æœ€é«˜ATXåŒæ°´å†·çš„æ€§èƒ½æ”¯æŒã€‚
  - ä¸åŒçš„å°ºå¯¸ï¼Œç»Ÿä¸€çš„è®¾è®¡æ€è·¯ã€‚å…¨ç³»åˆ—é‡‡ç”¨å®¶æ—å¼è®¾è®¡ï¼Œé™¤äº†å…¼å®¹ç¡¬ä»¶çš„ä¸åŒå’Œå¤šå˜çš„ç”¨æ³•å¤–ï¼Œæ¡†æž¶æè´¨ã€è®¾è®¡æ€è·¯å‡ä¿æŒé«˜åº¦çš„ä¸€è‡´ã€‚
  - å…¨ç³»åˆ—å‡é‡‡ç”¨å¯æ‹†å¸å¤–å£³ä¸Žä¸»ä½“æ¡†æž¶åˆ†ç¦»å¼è®¾è®¡
  - å› å¤–å£³çš„å¯æ›´æ¢æ›¿ä»£æ€§ï¼Œæ‰€ä»¥å»¶ä¼¸å‡ºäº†æ›´å¤šçš„çš„è‰²å½©æ–¹æ¡ˆ
  - ä¸ºäº†å¢žåŠ ä¾¿æºæ€§å’Œæ›´å¥½æ›´æ–¹ä¾¿çš„ç§»åŠ¨æœºç®±ï¼Œåœ¨æœºç®±çš„é¡¶éƒ¨å‡è®¾ç½®äº†ä¸€ä¸ªé“åˆé‡‘çš„å¯æ‹†å¸å¼ææ‰‹
  - é€‚åº”å„ç±»ç”µæºçš„ä¸åŒæœå‘ï¼Œç”µæºä½ç½®å‡è®¾è®¡äº†ä¸åŒå¤§å°çš„å¯å˜è§’åº¦ç”µæºæ”¯æž¶
  - æœºç®±é™¤äº†æ ‡é…çš„é‡‘å±žå‰é¢æ¿å’ŒçŽ»ç’ƒä¾§é€å¤–ï¼Œè¿˜å¯ä»¥é€‰æ‹©æ›´æ¢ä¸ºå¸¦æ•£çƒ­å¼€å­”çš„é“ä¾§æ¿å’Œæ–œå¼€å­”çš„AIRå‰é¢æ¿
- C24å°æ–¹ç³– 9.9L
  - C24ä¸ä»…æ˜¯æ•´ä¸ªCç³»åˆ—ä¸­å°ºå¯¸æœ€å°çš„ä¸€æ¬¾ï¼Œä¹Ÿæ˜¯ä¾¿æºæ€§æœ€å¥½çš„ã€‚å®žæµ‹å¤§ä¸€ç‚¹çš„çš„éžåˆ†ä»“å¼åŒè‚©åŒ…éƒ½å¯ä»¥æ”¾çš„ä¸‹ã€‚
  - 249 x 249 x 155 mm, 9.6L
  - æ”¯æŒ130mmçš„å¡”å¼æ•£çƒ­ï¼Œè¿˜åŒ…æ‹¬æ˜¾å¡ç›´æ’ã€SFXç”µæºæ”¯æŒå’Œå¤šç¡¬ç›˜å¤šé£Žæ‰‡ä½çš„æ”¯æŒã€‚ä¸ä»…èƒ½ä¿è¯å‚¨å­˜ç©ºé—´ï¼Œè¿˜èƒ½æœ€å¤§é™åº¦çš„æž„å»ºæœ‰æ•ˆæ•£çƒ­é£Žé“
- C26å£°æ³¢ 13.3L
  - æ”¯æŒM-ATXä¸»æ¿ï¼Œè¿˜å¢žåŠ äº†æ˜¾å¡é€‰æ‹©ä¸Šçš„å®½å®¹åº¦ã€‚
  - å¹¶ä¸”åœ¨æ­é…æ°´å†·ç¡¬ç›˜æ‹“å±•æ”¯æž¶æ—¶ï¼Œä½¿ç”¨ITXä¸»æ¿å¯ä»¥å®‰è£…æ›´å¤šçš„ç¡¬ç›˜ï¼›è¿˜å¯ä»¥å®‰è£…240æ°´å†·ï¼Œå®žçŽ°æ›´å¼ºæ•£çƒ­ã€‚
  - C26 Plus 15.1L
- C28 è„‰å†²/å°è§†ç•Œ 17.9L
  - 243 x 284 x 185 mm, 12.7L
  - C28æ˜¯Cç³»åˆ—é‡Œå¯æ‰‹æçš„M-ATXæœºç®±ä¸­ä½“ç§¯æœ€å¤§çš„ä¸€æ¬¾ï¼Œä½†å³ä¾¿è¿™æ ·ï¼Œåœ¨å’Œå¸‚é¢ä¸Šå…¶ä»–å“ç‰Œçš„éƒ¨åˆ†ITXæœºç®±æˆ–è€…æ˜¯ç´§å‡‘åž‹çš„M-ATXæœºç®±æ¯”ï¼ŒC28çš„ä½“ç§¯ä¹Ÿæ˜¯å°çš„å¤š
  - å¯ä»¥åœ¨é¡¶éƒ¨å’Œåº•éƒ¨æ”¯æŒå®‰è£…240æ°´å†·ï¼Œå³ä½¿ä½¿ç”¨é£Žå†·æ•£çƒ­ï¼ŒC28æœ€é«˜ä¹Ÿå¯æ”¯æŒåˆ°162MMçš„å¡”å¼é£Žå†·æ•£çƒ­ï¼Œä¸æ¯«ä¸å¦¥åæ•£çƒ­çš„è§„æ ¼
  - 335mmçš„æ˜¾å¡é•¿åº¦å’Œé«˜å¡”æ•£çƒ­çš„æ”¯æŒï¼Œä¿è¯äº†æ——èˆ°çº§æ€§èƒ½çš„ç¨³å®šé‡Šæ”¾
- C34è§†ç•Œ 22.8L
  - 342 x 342 x 185 mm, 21.6L
  - C34æ˜¯æ•´ä¸ªCç³»åˆ—ä¸­æœ€å¤§çš„å­˜åœ¨ï¼Œä¹Ÿæ˜¯å”¯ä¸€ä¸€ä¸ªæ ‡é…æ²¡æœ‰å¸¦ææ‰‹çš„åž‹å·ï¼Œå› ä¸ºä»–ç›¸è¾ƒä¸Žå¦å¤–ä¸‰æ¬¾æœºç®±ï¼Œè£…æ»¡åŽä¼šæ¯”è¾ƒé‡

-  ðŸŒ¹ [C34 Pro](http://www.m-master.cn/pd.jsp?id=22)
  - 429mm x205mm x349mm, 30.6L; äº§å“å°ºå¯¸ 429*205*403mm, 35.4L
    - ðŸŽ’ ç‰¹å¤§å·çš„åŒè‚©åŒ…çš„é«˜åº¦å¯ä»¥æ»¡è¶³450mm, åº•éƒ¨é•¿å®½éš¾ä»¥æ»¡è¶³ 205x403
  - æ˜¾å¡æ”¯æŒ 420mmä»¥å†…
  - ä¸»æ¿æ”¯æŒ ATX/EATX/MATX/ITX
  - æ•£çƒ­æ”¯æŒ 165mmé£Žå†·/360æ°´å†·/280æ°´å†·
  - ç”µæºæ”¯æŒ ATX(200mmé•¿ä»¥å†…ï¼‰
  - 2.5å¯¸ç¡¬ç›˜ä½ è‡³å¤š4ä¸ª
  - 3.5å¯¸ç¡¬ç›˜ä½ è‡³å¤š2ä¸ª
  - æ”¯æŒITXã€MATXã€ATXå’ŒEATXä¸»æ¿ï¼Œæ°´å†·ä¹Ÿèƒ½å®‰è£…360å°ºå¯¸ï¼Œé£Žå†·æœ€å¤§165mmå¡”å¼ã€‚
  - å¤–å£³ä¸º2mmé“åˆé‡‘ï¼Œå†…å£³æ˜¯1mmé’¢æ¿ï¼Œå…¨èº«ä½¿ç”¨ç™½è‰²å–·æ¼†
  - å‡€é‡ï¼š6.2KG / æ¯›é‡ï¼š7.4KG, ðŸ› æ¯”æ™®é€šæœºç®±é‡å¾ˆå¤š

- https://www.zhihu.com/question/391355479/answer/2789629897
- æ­¤å¤–C26æ˜¯åªæ”¯æŒSFXç”µæºï¼ŒC26PLUSå’ŒC28ä¸ºäº†å®‰è£…é•¿æ˜¾å¡æˆ–è€…æ°´å†·ç­‰ç­‰æƒ…å†µï¼Œä¹Ÿåªèƒ½å®‰è£…SFXç”µæºï¼Œæ‰€ä»¥åœ¨ç”µæºæ–¹é¢ä¼šå¢žåŠ ä¸€äº›æˆæœ¬ã€‚
- å¦å¤–æœºç®±å®‰è£…æ–¹é¢ï¼Œè¿™äº›æœºç®±éƒ½ä¸ç®—éžå¸¸å¥½å®‰è£…ï¼ŒåŸºæœ¬éƒ½å¾—æ‹†å¸æ‰€ä»¥çš„æ¿ææ‰èƒ½è¿›è¡Œå®‰è£…ï¼Œæ‰€ä»¥æœ‰èžºä¸å¤§å¸ˆè¿™ä¹ˆä¸€ä¸ªç§°å·ã€‚æ­¤å¤–è¿˜æ²¡æœ‰èƒŒçº¿ç©ºé—´ï¼Œæ‰€ä»¥æœ€å¥½æ˜¯åšå®šåˆ¶çº¿ï¼Œæ‰èƒ½å¾—åˆ°ä¸€ä¸ªæ¯”è¾ƒå®Œç¾Žçš„è£…æœºæ•ˆæžœã€‚
- è¿™å‡ æ¬¾å¯ä»¥èƒŒåŽç†çº¿å—
  - è¿™å‡ æ¬¾éƒ½ä¸å¯ä»¥

- [ç”¨ç»ç‰ˆæœºç®±æ‰“é€ æžè‡´ç”Ÿäº§åŠ›â€”â€”9950X+192Gå¤§å†…å­˜ - çŸ¥ä¹Ž](https://zhuanlan.zhihu.com/p/1943668215206122278)
  - ã€ä¸»æ¿ã€‘å¾®æ˜Ÿ B850M MORTAR WIFI è¿«å‡»ç‚® ï¼ˆ1499ï¿¥ï¼‰
  - ã€CPUã€‘AMD R9 9950X å…¨æ–°ç›’è£… ï¼ˆ3999ï¿¥ï¼‰
  - ã€å†…å­˜ã€‘æµ·ç›—èˆ¹ (196G) 48G*4 6000MHz C30 ï¼ˆ5398ï¿¥ï¼‰
  - ã€æ˜¾å¡ã€‘å¾®æ˜Ÿ ä¸‡å›¾å¸ˆ 4070 Super 2X ï¼ˆ5499ï¿¥ï¼‰
  - ã€æœºç®±ã€‘æœºæ¢°å¤§å¸ˆ C26PLUS ï¼ˆåœäº§ï¼‰
  - ã€æ•£çƒ­ã€‘çŒ«å¤´é¹° C14S + çŒ«å¤´é¹° NF-A14 PWM ï¼ˆ579+180ï¿¥ï¼‰

- ## ðŸ“ŒðŸ’¡ [2025å¹´5æœˆæ›´æ–°ï¼Œç”µè„‘æœºç®±æŽ¨èã€‚æŽ¨èä¸€æ³¢é«˜é¢œå€¼çš„æœºç®±ã€‚åŒ…å«ITX, M-ATX, ATX, E-ATXæœºç®± - çŸ¥ä¹Ž](https://zhuanlan.zhihu.com/p/210537601)
  - [2025å¹´5æœˆæ›´æ–°ï¼Œç”µè„‘æœºç®±æŽ¨èã€‚æŽ¨èä¸€æ³¢é«˜é¢œå€¼çš„æœºç®±ã€‚åŒ…å«ITX, M-ATX, ATX, E-ATXæœºç®±](https://www.zhihu.com/tardis/zm/art/210537601)

- èƒŒåŒ…çš„å¯é€‰å°ºå¯¸
  - 50L: 3.6 x 1.8 x 5.4
  - 60L: 3.8 x 2.0 x 5.6
  - 65L: 3.8 x 2.2 x 5.8   ==> 48.5L
  - 80L: 4.0 x 2.2 x 6.5   ==> 57.2L
  - 85L: 4.2 x 2.4 x 6.6   ==> 66.5L
  - æœ—æ–åŒè‚©åŒ…ç”·èƒŒåŒ… / ä¸‰æ –è™Ž / è¢‹é¼ æ—…è¡ŒèƒŒåŒ…
    - 85L: 4.2 x 2.4 x 6.6 
  - å®ˆæŠ¤è€…70Lå˜85å‡
    - 70L: 4.8 x 2.7 x 6.8  , æ¬¾å¼è¿åŠ¨ âœ…
    - å¤šå¤„æŒ‚è½½ç³»ç»Ÿ
  - é‡‘åˆ©æ¥ï¼ˆGoldlionï¼‰é•¿é€”æ—…è¡Œæ‰“å·¥å¤§å®¹é‡
    - 85L: 4.3 x 2.4 x 6.7 , ä¸Šæ–¹å¾ˆçª„
  - é»‘è‰²85å‡1920# /é˜²æ»‘èƒ¸æ‰£/å‡è´Ÿè…°å¸¦
    - 85L: 4.3 x 2.6 x 6.9 ==> 77.1L ,  å¤ªé«˜äº†
    - 70L: 4.1 x 2.3 x 6.0 ==> 56.6L
    - 55L: 3.8 x 2.0 x 5.5 ==> 41.8L
  - é…·å¥‡è¢‹é¼ å¤§å·80Lè¶…å¤§å®¹é‡ç™»å±±åŒ…åŒè‚©åŒ…
    - 80L: 4.3 x 2.6 x 6.7 ==> 74.9L
    - 80L: 4.1 x 2.3 x 6.7
    - 80L: 4.0 x 3.0 x 6.6
  - 85å‡è¶…å¤§å®¹é‡åŠ 
    - 85L: 4.2 x 3.5 x 6.2

- tips-cases
  - æ‰¾æœºç®±æ—¶åœ¨çŸ¥ä¹Žæˆ–è®ºå›æ‰¾æ•ˆçŽ‡ä½Žï¼Œå¯ç›´æŽ¥åœ¨äº¬ä¸œåº—é“ºæ‰¾ï¼Œä¼˜ç§€çš„å•†å®¶ä¼šæŠŠå„ç³»åˆ—çš„æœºç®±å°ºå¯¸éƒ½åœ¨å•†å“è¯¦æƒ…é¡µå¹¶æŽ’åˆ—å‡ºï¼Œå¯¹æ¯”çœ‹å°ºå¯¸/åŠŸèƒ½/ä»·æ ¼æ•ˆçŽ‡æ›´é«˜
  - å¯»æ‰¾äº§å“æ—¶ï¼Œç›´æŽ¥æŒ‰é”€é‡æŽ’åºï¼Œç„¶åŽæ ¹æ®çƒ­é—¨äº§å“çš„è¯„è®ºå†…å®¹æœç´¢ç«žå“æ›´å¿«

- [Choose A Case - PCPartPicker](https://pcpartpicker.com/products/case/)

- Cooler Master Elite 361  25.1L
- Jonsbo D40  	31.6 L
- Jonsbo U4 Plus  	31.7 L
- Jonsbo D41 MESH  	35.4 L
- KOLINK Observatory MX Mesh ARGB  30.8L
- KOLINK Inspire K4  33.4L
- GameMax MeshBox Pro  33.5L
- Silverstone RM42-502  35.4L

- Cooler Master 
- Cooler Master 400L
  - 411 x 218 x 410mm, 36.7L
  - ä¸»æ¿: itx/matx
- Cooler Master Qube 500 / Q500L
  - 380 x 231 x 381mm, 33.4L
- Cooler Master MasterBox 600L V2 æ™ºçž³600 ðŸ¤” /éžmeshç‰ˆ
  - 400 x 204 x 455mm, 37.15L, ä»…æ¯”d41é«˜1.5cm
- Cooler Master QUBE 500 Flatpack  38.9L
- Cooler Master Elite 371  38.7L
- Cooler Master CMP 320  38.6L
- Cooler Master Elite 330/334/500  38.2L
- Cooler Master MasterBox MB600L V2  37.7L
- DIYPC Solo-T1  38.9L
- Deepcool MACUBE 110  38.8L
- Deepcool CC360 ARGB  38.7L
- Deepcool CH370  38.3L
- Zalman P10 NAMU  38.6L
- Zalman Z1 Iceberg  38.5L
- Zalman S3/S2/Z3  38.4L
- Thermaltake V3   38.5L
- Silverstone Lucid 04  38.2L
- Lian Li PC-V650  38.2L
- Lian Li PC-C32B  37.4L
- Lian Li PC-V359W  36.6L
- Jonsbo UMX4/U5/VR4  38.0L
- Phanteks Eclipse P300  36L
- Fractal Design Core 2300/2500  37.8L
- Fractal Design Meshify C Mini  36.6L
- Fractal Design Pop Mini Air  36.5L
- Fractal Design Focus G Mini  36.4L
- Fractal Design Define Mini C /Tg  35.7L

- è¿·ä½ å°é’¢ç‚®ITXæœºç®±æŽ¨è

- é…·å†·è‡³å°Šé­”æ–¹ NR200/NR200P
  - ç®±ä½“é•¿å®½é«˜ï¼ˆmmï¼‰376 x 185 x 292mm, 20.3L
  - æ”¯æŒITXå’ŒDTXè§„æ ¼çš„ä¸»æ¿
  - åªèƒ½ç”¨SFXç”µæºã€‚ATXç”µæºéœ€è¦è‡ªå·±DIYæ”¯æž¶ï¼Œè€Œä¸”ä¼šé™åˆ¶æ˜¾å¡é•¿åº¦
  - é…·å†·æœ€è¿‘æŽ¨å‡ºäº†NR200P MAXç‰ˆæœ¬ã€‚é¡¶éƒ¨é¢„è£…äº†280æ°´å†·ã€‚è‡ªå¸¦850Wç”µæºï¼Œæ˜¾å¡åªèƒ½ç«–è£…ã€‚è®¾è®¡ä¸é”™ã€‚

- åˆ†å½¢å·¥è‰ºTorrent Nano
  - æ”¯æŒ310mmçš„æ˜¾å¡
  - æ”¯æŒ20CMé•¿çš„ATXç”µæº
  - è¿™æ¬¾å±žäºŽä½“åž‹åå¤§çš„ITXæœºç®±ï¼Œæ•£çƒ­è®¾è®¡ä¼˜ç§€ï¼Œä»·æ ¼ç¨è´µã€‚è¿™æ¬¾æœºç®±æ¯”è¾ƒé€‚åˆåšé£Žå†·æ•£çƒ­æ–¹æ¡ˆã€‚

- ä¹”æ€ä¼¯ï¼ˆJONSBOï¼‰A4 Ver1.1ç‰ˆæœ¬
  - 340MM (æ·±) x 169MM (å®½) x 273MM (é«˜)
  - ä½¿ç”¨SFXæˆ–AFX-Lç”µæº

- M-ATXæœºç®±æŽ¨è

- æ–¹ç³–æœºæ¢°å¤§å¸ˆ C+Max
  - 392*185*284mm, 20.5L
  - æ”¯æŒM-ATXå’ŒITXä¸»æ¿ã€‚
  - ç”µæºå¯ä»¥ç”¨SFXæˆ–14cmé•¿çš„ATXç”µæºã€‚
  - æ”¯æŒ240æ°´å†·æˆ–162mmé«˜çš„é£Žå†·
  - ä»·æ ¼å°è´µï¼Œåœ¨800å…ƒé™„è¿‘

- [ä¹”æ€ä¼¯ Z20](https://www.jonsbo.com/products/Z20--.html)
  - 370*186*295mm, 20.3L
  - æ˜¾å¡æ”¯æŒé•¿åº¦ï¼šâ‰¤363mm
  - æ”¯æŒ240æ°´å†·ï¼Œæˆ–æœ€é«˜160mmçš„é£Žå†·
  - 1ä¸ªæœºæ¢°ç¡¬ç›˜ä½

- ä¹”æ€ä¼¯C6 MAX
  - 202 x 349 x 295mm, 20.8L
  - æ˜¾å¡: â‰¤  300mm-335mm

- å…ˆé©¬ï¼ˆSAMAï¼‰è¶£é€ I'm Mini
  - 391ï¼ˆé•¿ï¼‰*185ï¼ˆå®½ï¼‰*303ï¼ˆé«˜ï¼‰mm, 21.9L
  - æ˜¾å¡é™é•¿ï¼šâ‰¤33cm
  - æ”¯æŒM-ATXå’ŒITXä¸»æ¿

- è”åŠ› A3
  - 443 x 194 x 396 mm, 34L
  - æœ€é«˜æ”¯æŒ165mmçš„é£Žå†·ã€‚æ”¯æŒ360æ°´å†·
  - æœ€é•¿æ”¯æŒ415mmçš„æ˜¾å¡ã€‚åº•éƒ¨æ”¯æŒå®‰è£…ä¸€ä¸ªæœºæ¢°ç¡¬ç›˜

- åŽç¡•AP201 å†°ç«‹æ–¹
  - 205mm*350mm*460mm, 33L
  - æ˜¾å¡ï¼ˆè¿žä¾›ç”µå¤´æ€»é•¿åº¦ï¼‰é™é•¿â‰¤32cm
  - ç¡¬ç›˜ä½3ä¸ª
  - æ”¯æŒçš„ä¸»æ¿ï¼šM-ATXï¼ŒITX, ðŸ› ä¸æ”¯æŒATX
  - æ”¯æŒçš„æ˜¯M-ATXä¸»æ¿ï¼Œæ€»ä½“å¸ƒå±€å’Œä¹”æ€ä¼¯D30ç±»ä¼¼ï¼Œä½†æ˜¯åŽç¡•AP201é‡‡ç”¨çš„æ˜¯å…¨æ‰“å­”é¢æ¿ï¼Œä¸”é¡¶éƒ¨æ”¯æŒ360æ°´å†·ï¼Œæ•£çƒ­éžå¸¸çš„ä¸é”™ï¼Œæ”¯æŒTYPE-C USB 3.2 GEN2ï¼ˆä¹”æ€ä¼¯D30çš„type-Cæ˜¯å’ŒUSBå¹¶åœ¨ä¸€èµ·çš„ï¼‰ã€‚

- ä¹”æ€ä¼¯ D31 mesh ðŸŒ¹
  - äº§å“å°ºå¯¸ï¼š205 (å®½) *347.5 (é«˜) *440mm (æ·±)ï¼ˆ31.3Lï¼‰ 
    - 205mmï¼ˆå®½ï¼‰*363mmï¼ˆé«˜ï¼‰*452mmï¼ˆæ·±ï¼‰ï¼ˆæœºç®±æ€»å°ºå¯¸ï¼‰
  - æ˜¾å¡é•¿åº¦ï¼š330-400mm
  - ä¸»æ¿æ”¯æŒï¼šITX / DTX / M-ATX, ðŸ› ä¸æ”¯æŒatx
  - æœºæ¢°ç¡¬ç›˜ä½ï¼š2.5ã€žSSD*2 + 3.5ã€žHDD*1
  - PCIæ‰©å±•æ§½ï¼š4
  - ç”µæºç±»åž‹ï¼šATX

- ä¹”æ€ä¼¯ D32 STD MESH
  - 384mm * 207mm* 302mmï¼Œ 24L
  - å…¼å®¹ä¸»æ¿ï¼šMINI-ITX / MICRO-ATXæ ‡å‡†åž‹ / MICRO-ATXèƒŒæ’åž‹

- ä¹”æ€ä¼¯ D32 PRO MESH
  - 384mm * 207mm* 302mmï¼Œ 24L
  - å…¼å®¹ä¸»æ¿ï¼šMINI-ITX / MICRO-ATXæ ‡å‡†åž‹ / MICRO-ATXèƒŒæ’åž‹(æœºç®±éœ€åˆ‡æ¢è‡³Bæ¨¡å¼)

- ä¹”æ€ä¼¯ D40 /æ— meshå¯¼è‡´æ•£çƒ­å·®
  - 204mm (W) *401mm (D) *386mm (H), 31.51L
  - ç¡¬ç›˜ä½ï¼š2.5ã€ž*3+3.5ã€ž*1 or 2.5ã€ž*4
  - æ˜¾å¡æ”¯æŒé•¿åº¦ï¼š293-374mm
  - ä¸»æ¿æ”¯æŒï¼šATX/M-ATX
  - å‰ç½®æŽ¥å£ï¼šUSB3.2 Gen 1 Type-C*1(5Gbps)     USB3.2 Gen 1 Type-A*1(5Gbps)     å¤åˆå¼éŸ³é¢‘æŽ¥å£*1
  - PCIæ‰©å±•æ§½ï¼š7
  - ç”µæºï¼šATX PSIIâ‰¤140-200mm

- ä¹”æ€ä¼¯ D41 mesh ðŸŒ¹ /~~æ”¾ä¸è¿›èƒŒåŒ…~~
  - 205mm (å®½) *392mm (é«˜) *440mm (æ·±)ï¼ˆå®¹ç§¯ï¼š35.4Lï¼‰
    - æ€»å°ºå¯¸  205mm*407mm*452mm, 37.7L
  - æ˜¾å¡æ”¯æŒé•¿åº¦: 330-400mm
  - ä¸»æ¿æ”¯æŒï¼šATX / M-ATX
  - ç”µæºï¼šATXç”µæº
  - CPUæ•£çƒ­å™¨ï¼š168mm
  - æ°´å†·æ”¯æŒï¼šé¡¶éƒ¨ï¼š240/280/360*1        åŽéƒ¨ï¼š120*1      åº•éƒ¨ï¼š240/360*1
  - ç¡¬ç›˜ä½ï¼š2.5ã€žSSD*3 + 3.5ã€žHDD*2
  - å‰ç½®æŽ¥å£ï¼šUSB3.2 Gen 2 Type-C*1         USB3.0*1/Audio & Mic*1
  - å‡€é‡ï¼š6.6KG        å¤–ç®±+æœºç®±ï¼š7.6KG

- ä¹”æ€ä¼¯ U4 Pro
  - 205mm(W) * 395mm(D) * 426mm(H)ï¼ˆå«è„šåž«ï¼‰, 34.5L
  - æ˜¾å¡æ”¯æŒé•¿åº¦ï¼šâ‰¤280-330mm
  - ä¸»æ¿æ”¯æŒç±»åž‹ï¼šITX / M-ATX / ATX
  - ç”µæºæ”¯æŒï¼šATXâ‰¤170-190mm

- ATXï¼ˆä¸­å¡”ï¼‰æœºç®±æŽ¨è
  - ATXï¼ˆä¸­å¡”ï¼‰æœºç®±æ˜¯ç›®å‰å¤§éƒ¨åˆ†ç”¨æˆ·çš„é€‰æ‹©ï¼Œè¿™ç±»çš„æœºç®±å°ºå¯¸åå¤§ï¼ŒåŸºæœ¬éƒ½æ”¯æŒATXï¼ŒM-ATXï¼ŒITXç‰ˆåž‹ï¼Œéƒ¨åˆ†æ”¯æŒåŒ…æ‹¬E-ATXåœ¨å†…çš„æ‰€æœ‰ç‰ˆåž‹ã€‚
  - ä¼˜ç‚¹åœ¨äºŽæ•£çƒ­å¥½ï¼ŒATXæœºç®±åŸºæœ¬éƒ½æ”¯æŒ240åŠ360æ°´å†·ï¼Œå¯¹å¤§åž‹åŒå¡”é£Žå†·æ•£çƒ­çš„æ”¯æŒä¹Ÿæ›´å¥½ã€‚æ‰©å±•ä½å¤šï¼Œæ–¹ä¾¿å®‰è£…æ›´å¤šçš„ç¡¬ç›˜ç­‰è®¾å¤‡ã€‚

- å…ˆé©¬ï¼ˆSAMAï¼‰æœ±é›€se ðŸŒ¹ /å‰æ¿ç½‘å­”æ•£çƒ­
  - 3.96*2.15*4.82mm, 41.03L
  - ä¸»æ¿å…¼å®¹: ATX/MATX/ITX
  - hdd*2, ssd*1
  - æ˜¾å¡é™é•¿ 345mm
  - æ•£çƒ­é™é«˜ 163cm
  - æ°´å†·æ”¯æŒ 360/280/240
  - æ”¯æŒæ˜¾å¡ç«–è£…
  - æœºç®±é‡é‡ <5kg
  - [æœ±é›€se - å…ˆé©¬å®˜ç½‘](http://www.sama.cn/archives/9452)
  - [ã€å…ˆé©¬ æœ±é›€SEï¼ˆé»‘ï¼‰ã€‘å…ˆé©¬ï¼ˆSAMAï¼‰æœ±é›€SEé»‘è‰² å°å¼ç”µè„‘ä¸»æœºç®± å‰æ¿æ•£çƒ­ç½‘å­”/æ”¯æŒATXä¸»æ¿/360æ°´å†·/ç«–è£…æ˜¾å¡/åŒé¢é˜²å°˜/Type-Cé¢„ç•™å­”ã€è¡Œæƒ… æŠ¥ä»· ä»·æ ¼ è¯„æµ‹ã€‘-äº¬ä¸œ](https://item.jd.com/100135456146.html)

- å…ˆé©¬ï¼ˆSAMAï¼‰æœ±é›€air 
  - 4.08Ã—2.33Ã—4.62mm, 43.9L

- å…ˆé©¬ï¼ˆSAMAï¼‰é»‘æ´ž7pro ðŸŒ¹
  - 4.05Ã—2.15Ã—4.82mm, 41.97L
  - æ˜¾å¡é™é•¿ 345mm
  - [ã€å…ˆé©¬ é»‘æ´ž7 PROï¼ˆé»‘ï¼‰ã€‘å…ˆé©¬ï¼ˆSAMAï¼‰é»‘æ´ž7proä¸­å¡”å¼å¸éŸ³é™å™ªç”µè„‘ä¸»æœºç®±é»‘è‰² æ ‡é…2æŠŠé™å™ªé£Žæ‰‡/é«˜åˆ†å­æ ‘è„‚æ£‰/æ”¯æŒATXä¸»æ¿/ç«–è£…æ˜¾å¡ã€è¡Œæƒ… æŠ¥ä»· ä»·æ ¼ è¯„æµ‹ã€‘-äº¬ä¸œ](https://item.jd.com/100075167747.html)
  - å…ˆé©¬ï¼ˆSAMAï¼‰å°é»‘æ´žpro  /MATX
    - 4.17Ã—2.15Ã—4.25mm, 38.1L
  - å…ˆé©¬ï¼ˆSAMAï¼‰é»‘æ´ž7 
    - 3.9Ã—2Ã—4.46mm, 34.8L

- å…ˆé©¬ï¼ˆSAMAï¼‰å¹³å¤´å“¥M2 Pro
  - 4Ã—2.1Ã—4.45, 37.38L
  - æ˜¾å¡é™é•¿ 325mm
  - ATX/MATX/ITX
  - é’¢åŒ–çŽ»ç’ƒä¾§é€

- é…·å†·è‡³å°Š 600L v2 ðŸŒ¹ /æ— mesh
  - 400x204x455.3mm, 37L
    - åŒ…æ‹¬çªå‡ºç‰©	405.5x204x455.3mm, 37.6L
  - ä¸»æ¿å…¼å®¹æ€§	Mini-ITX, Micro-ATX, ATX
  - æ˜¾å¡	 350mm (w/o front fans & radiator)
  - ç”µæº	160mm
  - CPU æ•£çƒ­å™¨	161mm

- é…·å†·è‡³å°Š Q500L /æ¯”D41å°
  - 386 x 230 x 381mm, 33.8L
  - ä¸»æ¿å…¼å®¹	Micro-ATX, Mini-ITX, ATX
  - æ˜¾å¡é™é•¿	360mm
  - CPUæ•£çƒ­å™¨é™é«˜	160mm
  - ç¡¬ç›˜ä½	1*HDD+2*SSD
  - ç”µæºæ”¯æŒ	é¡¶éƒ¨å‰æ”¯æž¶, ATX PS2
  - å‡€é‡	3.83kg

- é…·å†·è‡³å°Š é…·æ–¹500
  - 380 x 231 x381mmï¼Œ 33.4L; 
    - åŒ…å«å‡¸èµ· 406 x 231 x 415mm, 38.9L
  - ä¸»æ¿å…¼å®¹æ€§	ATX / Micro ATX / ITX / E-ATXæœ€å¤§ 280mm
  - CPU æ•£çƒ­å™¨	164mm~172mm (ç§»é™¤ä¾§é¢æ°´å†·æ”¯æž¶)
  - ç”µæº	ä¸ŽGPUæ— å¹²æ¶‰ ï¼š173mm, æœ€å¤§å°ºå¯¸ï¼š216mm(ä¸è®¡ç†çº¿ç©ºé—´) 
    - åº•éƒ¨å®‰è£…æ—¶ï¼š332mm (ä¸è®¡ç†çº¿ç©ºé—´)
  - æ˜¾å¡ 365mm

- é…·å†·è‡³å°Š MB400L
  - 411 x 218 x 410mm, 36.74L
  - MATX

- åˆ†å½¢ North /æ”¯æŒå…¨meshä¸”æ— çŽ»ç’ƒ
  - 4.33*2.15*4.5, 41.9L; 
    - æ•´æœºå°ºå¯¸ 4.47*2.15*4.69, 45.07L

- é•¿åŸŽï¼ˆGreat Wallï¼‰å•†é€¸R40/R41
  - 4.09Ã—2.03Ã—4.4, 36.5L
- é•¿åŸŽï¼ˆGreat Wallï¼‰å•†é€¸R50
  - 4.25Ã—2.03Ã—4.65, 

- é•¿åŸŽï¼ˆGreat Wallï¼‰æœ¬è‰²K13 v6
  - 3.94Ã—2Ã—4.56, 35.9L
- é•¿åŸŽï¼ˆGreat Wallï¼‰æœ¬è‰²K13
  - 3.96Ã—2Ã—4.51, 35.7L
  - æ˜¾å¡é™é•¿ 340mm

- çˆ±å›½è€…ï¼ˆaigoï¼‰A15
  - 3.7*1.9*4.38, 30.8L

- çˆ±å›½è€… yogo t21
  - 4.08Ã—2.3Ã—4.6, 43.1L

- é‘«è°·æ— å°½1 /å•é¢çŽ»ç’ƒä¾§é€/æœ‰ç‚¹å°
  - 3.6x2.3x4.35, 36L; 
    - æ•´æœºå°ºå¯¸ 3.95Ã—2.3Ã—4.55, 41L

- é‘«è°·æ— ç•Œ1 /2é¢çŽ»ç’ƒæµ·æ™¯æˆ¿/æ— mesh
  - 4.2x2.1x4.65, 41L; 
    - æ•´æœºå°ºå¯¸ 4.38x2.1x4.85, 44L

- èˆªå˜‰ GX750A 
  - 4.3x2.18x4.35, 40.7L; 
    - äº§å“å°ºå¯¸ 4.65x2.18x4.61, 46L
  - ä¾§è¾¹ç½‘å­”æ•£çƒ­

- æ¸¸æˆå¸å›½ï¼ˆGAMEMAXï¼‰å†°é­”æ–¹mesh
  - 401 x 204 x 386mm, 31.57L

- ## [2024å¹´æœ€æ–°ATXå°æœºç®±æŽ¨è - çŸ¥ä¹Ž _202401](https://zhuanlan.zhihu.com/p/680148767)
- æ—¢æƒ³è¦ä¸»æœºå¤Ÿå°ï¼Œåˆæƒ³è¦ATXä¸»æ¿çš„æ‹“å±•æ€§æ˜¯å¾ˆéš¾è¾¾æˆçš„ï¼ŒäºŽæ˜¯å¾ˆå¤šäººé€€è€Œæ±‚å…¶æ¬¡é€‰æ‹©MATXä¸»æ¿å’ŒMATXæœºç®±ã€‚ä½†ATXå°æœºç®±ä¾ç„¶æ˜¯å¾ˆå¤šäººçš„æ‰§ç€æ‰€åœ¨ã€‚ä½œè€…å¯¹å¸‚é¢ä¸Šç›®å‰åœ¨å”®çš„ATXæœºç®±è¿›è¡Œäº†ç²—ç•¥çš„æ¢³ç†ï¼Œå‘çŽ°ç›®å‰è¾ƒå°çš„ATXæœºç®±ä¸»è¦æœ‰ä»¥ä¸‹è¿™äº›

- ç¼”èª“ç§‘æŠ€L59p ä½“ç§¯13.2 L å”®ä»·ï¼š499
  - å°ºå¯¸æ•°æ®ï¼š400x90x368

- Ssupd Meshroom S ä½“ç§¯ï¼š14.93 L
  - å°ºå¯¸æ•°æ®ï¼š247x167x362

- å‚»ç“œè¶…äººK99air ä½“ç§¯ï¼š21.48 L å”®ä»·ï¼š129
  - å°ºå¯¸æ•°æ®ï¼š348x186x328

- æœºæ¢°å¤§å¸ˆC34 ä½“ç§¯ï¼š21.65 å”®ä»·ï¼š799
  - å°ºå¯¸æ•°æ®ï¼š342X85X342

- ä¹”æ€ä¼¯RM2 ä½“ç§¯ï¼š22.34 L å”®ä»·ï¼š299
  - å°ºå¯¸æ•°æ®ï¼š209x302x354

- é“å°å®p100 ä½“ç§¯ï¼š24.9 L å”®ä»·ï¼š179
  - å°ºå¯¸æ•°æ®ï¼š375x185x359

- å·§ç¾Ž äº‘é›€plus ä½“ç§¯ï¼š25.03L å”®ä»·ï¼š217
  - å°ºå¯¸æ•°æ®ï¼š394x165x385

- SKTC Q5 ä½“ç§¯ï¼š27.97 L å”®ä»·ï¼š299
  - å°ºå¯¸æ•°æ®ï¼š370x210x360

- [2023å¹´ATXå°æœºç®±æŽ¨è](https://www.zhihu.com/tardis/zm/art/632965955?source_id=1003)
- å‚»ç“œè¶…äººK99 é’æ˜¥ç‰ˆï¼Œä½“ç§¯çº¦ä¸º19Lï¼Œå”®ä»·ï¼š159
  - å°ºå¯¸ 375x158x325mm

- æœºæ¢°å¤§å¸ˆC34è§†ç•Œ ä½“ç§¯21.6L å”®ä»·ï¼š729
  - å°ºå¯¸ï¼š342x342x185mm

- æœºæ¢°å¤§å¸ˆc34 pro ä½“ç§¯30.6L å”®ä»·899
  - å°ºå¯¸ï¼š205x349x429

- ä¹”æ–¯ä¼¯rm2 ä½“ç§¯çº¦ä¸º21.5L å”®ä»·ï¼š245
  - å°ºå¯¸ï¼š209x302x354mm

- ä¹”æ€ä¼¯ u4 ä½“ç§¯çº¦ä¸º30L å”®ä»·299, å·²åœäº§
  - å°ºå¯¸ï¼š205MM (W) * 340MM (D) * 428MM (H), 29.8L 
  - [ä¹”æ€ä¼¯JONSBO](https://www.jonsbo.com/products/qiaosiboU4baiban.html)

- ä¹”æ€ä¼¯ u4pro ä½“ç§¯34.5L å”®ä»·299
  - å°ºå¯¸ï¼š205x395x426

- ä¹”æ€ä¼¯D41 ä½“ç§¯35.4L å”®ä»·249
  - å°ºå¯¸ï¼š205x392x440

- é­”ç¥žm90pro ä½“ç§¯çº¦ä¸º20L å”®ä»·199
  - å°ºå¯¸ï¼š157x325x395mm

- ## [24å¹´å¸‚å”®å¾®å°åž‹atxæœºç®±é€ŸæŸ¥è¡¨å¤§å…¨ï¼Œæœ€å°ä¹Ÿæ˜¯æœ€å¤§ - çŸ¥ä¹Ž](https://zhuanlan.zhihu.com/p/715494773)
- å°æ˜¯ä½“ç§¯å°ï¼Œå¤§æ˜¯èƒ½å¤Ÿå®¹çº³ATXä¸»æ¿å’ŒATXç”µæº

- æ–¹ç³–æœºæ¢°å¤§å¸ˆ c34ä½“ç§¯22.6Lï¼Œc34proä½“ç§¯30.6L
  - ç‰¹ç‚¹æ˜¯ä»–æœ‰6ç§ç”µæºæ‘†æ”¾æ–¹å¼ï¼Œæ ¹æ®ä¸ªäººéœ€æ±‚è¿›è¡Œæ‘†æ”¾

- é…·å†·è‡³å°Šç‰¹è­¦365
  - 25.6L
  - é…·å†·è‡³å°ŠQ500L
  - 27.9L

- ä¹”æ€ä¼¯C5, åœäº§åž‹å·
  - 218MM (W) * 360MM (D) * 439MM (H), 34.5L
- ä¹”æ€ä¼¯ï¼ˆJONSBOï¼‰U4 Pro
  - 34.5L

- å…ˆé©¬ï¼ˆSAMAï¼‰é»‘æ´ž7
- é•¿åŸŽï¼ˆGreat Wallï¼‰æœ¬è‰²K13

- ## ðŸ¤” [Can you use an ATX server board with a consumer tower case and power supply? : r/HomeServer _202006](https://www.reddit.com/r/HomeServer/comments/gy4i70/can_you_use_an_atx_server_board_with_a_consumer/)
- If it is true ATX, then yes. ATX is ATX. For a board to claim to be ATX, it needs to fit in the standard ATX size with standard ATX standoff locations and a standard ATX motherboard and CPU connector.
  - Looking at these, they all say they are ATX formfactor and have either 20 or 24-pin mainboard power and 4 or 8 pin CPU power connectors. So yes they will work.
  - For cooling, generally the board itself doesn't need any special cooling requirements, but the motherboard may list a minimum airflow rate in the manual. Remember not all servers are rack servers.

- I think/know you can wire up and get a supermicro mobo running with a consumer psu. Many supermicro are e-atx. They do have matx boards however. It says atx so its atx. You may need a fan controller for a supermicro hacking box. Looks like it would fit. Power wont be an issue.

- The first thing I would look out for is the form factor. Some boards are larger than ATX size, e-atx is sort of a nebulous non-standard, sometimes the server boards have screws laid out in a different location than a typical computer case 
  - The second thing is power, especially if the motherboard is dual CPU, it may have one or two 8-pin EPS connectors, which can be hard to find on a consumer power supply

- [Epyc, supermicro motherboard and ram, cheap on ebay... What else to consider? Or refurbed z840 dual xeon : r/homelab _202401](https://www.reddit.com/r/homelab/comments/1989fsp/epyc_supermicro_motherboard_and_ram_cheap_on_ebay/)
  - Im not sure if the supermicro h11ssl needs some special case/ mounts? Do I need a special PSU? I'll need a heatsink fan etc for the CPU. I'll be able to reuse my graphics card, I think it's a GTX 1080.

- Supermicro H11SSL-i should be standard ATX. There is a link on the page to the motherboard manual. It will specify PSU requirements.

- supermicro h11ssl is a standard atx board. any atx chassis shall allow you mount it without issue. PSU is also standard. The board requires standard ATX power and a 8-pin CPU power.

- The H11SSL is a standard ATX board, I've got mine in a Phanteks Enthoo Pro case with no issues as far as mount holes lining up, running off a Thermaltake 1050w PSU. The 1080 will be fine on that board as well, it's new enough to support UEFI firmware, I've run a 2060S, P100, and 4080 on mine with zero issues.

- Running a 7302P here, you'd want an H12SSL for PCIe4.0 as far as I'm aware, seeing as my 4080 is still on a 3.0 link with the H11SSL.

- ## [Supermicro + 4x 3090 build: Idle Power Consumption, Case, Cooling, PCIe 4.0 riser, Noise : r/LocalLLaMA _202410](https://www.reddit.com/r/LocalLLaMA/comments/1g54h9l/supermicro_4x_3090_build_idle_power_consumption/)
  - Supermicro H12SSL-i motherboard (5x PCIe 4.0 x16)
  - AMD EPYC 7282 CPU (128 PCIe lanes)
  - 256GB (8x32GB) 2133P DDR4 ECC RAM
  - Noctua NH-U14S TR4-SP3 CPU Cooler
  - 4x RTX 3090 GPUs SilverStone HELA Series HELA 2050R Platinum 2050W ATX 3.0 Power Supply
  - 4x PCIe Riser Cables 2TB NVMe M.2 SSD
  - Case: I'm still unsure about the case - how to pack all these components while ensuring good airflow and cooling? What would you recommend to ensure proper cooling? It seems to me that there are no perfectly fitting enclosures available. It looks like I might have to build the case myself, or what do you think?

- I have a build with dual 3090s, and Iâ€™ve encountered an issue with the H12SSL-i motherboard. The Noctua fans donâ€™t spin fast enough at low RPMs, which causes the motherboard to constantly ramp them up to 100%, then stop, then ramp them up again. Iâ€™ve tried various IPMI configurations available online, but nothing seems to work, even with settings like this:
  - Not with the H12SSL, but I have a few X11DPIs and I had your same issue initially. I can check the IPMI command I'm using tomorrow if you want, it solved it for me. Basically, you need to change the minimum rpm setting as a percentage, IIRC.

- Quad setups are physically tricky. Reconsider open frames, they give you significantly more flexibility with positioning of GPUs and risers. Airflow is fine the cards have their own coolers and at most need an intake or two aimed at them depending on how you position.

- ## ðŸŒ° [New server build : r/homelab _202509](https://www.reddit.com/r/homelab/comments/1lve852/new_server_build/)
  - CPU: AMD Epyc 7443P
  - Motherboard: Supermicro H12SSL-i
  - Memory: 8x SK Hynix 32GB 3200MT/s ECC (265GB)
  - SAS HBA: Broadcom 9400-16i
  - NVME HBA: Supermicro AOC-SLG4-4E4T
  - NIC: Mellanox ConnectX-4 dual 25G
  - NVME Backplane: Silverstone RAC-BP-304N
  - CPU Cooler: ARCTIC Freezer 4U-M
  - PSU: Corsair RM850x
  - Case Silverstone RM43-320-RS: 442  x 175 x 660 mm, 51L

- [Academic/Cryo-EM Build: EPYC 7402 with Supermicro H12 : r/Amd](https://www.reddit.com/r/Amd/comments/ij0h5k/academiccryoem_build_epyc_7402_with_supermicro_h12/)
  - CPU	EPYC 7402
  - Motherboard	H12SSL-CT
  - Case: be quiet! Dark Base Pro 900 Rev. 2 ATX Full Tower Case, 52L

- [Finally got around to building my home server! (AMD EPYC Proxmox Build) : r/homelab](https://www.reddit.com/r/homelab/comments/10egnxx/finally_got_around_to_building_my_home_server_amd/)
  - I was hoping to get the Meshify 2 (or Meshify 2 XL) but I couldn't find a single one in stock in Europe so I settled for the Define R6 (543 x 233 x 465 mm, 58L).

- ## [[FS][USA-NY] EPYC 7232 ROME CPU + H12SSL-NT PCIe 4 Motherboard + 4U 24 Bay server case + Add ons : r/homelabsales _202501](https://www.reddit.com/r/homelabsales/comments/1idbdvk/fsusany_epyc_7232_rome_cpu_h12sslnt_pcie_4/)
  - ATX 850 Bronze PSU: 850W 80+ Gold
  - Epyc Rome 7232 8 core processer 
  - Supermicro H12SSL-NT
  - 88GB RAM DDR4 2133
  - OWC Quad NVME 3.5HDD adaptor
  - LSI 9300-16i HBA
  - Jeyi PCIe 4x16 Quad NVME Bifurcation adaptor 
  - Generic Brand PCIe 3x8 QUAD NVME adaptor
  - 40G Mellanox QSFP NIC
  - NO CPU cooler provided
  - PRICE $1150 + Shipping based on location
  - Moved to a sliger case with an EPYC Siena build, so looking to off load his server
  - RM43-324-RS: 4U 24-bay 2.5"/3.5" HDD , 442mm (W) x 175mm (H) x 660mm (D), 51.1L

- ## [[W] Supermicro H12SSL / Epyc / DDR4 3200Mhz : r/homelabsales _202308](https://www.reddit.com/r/homelabsales/comments/163s183/w_supermicro_h12ssl_epyc_ddr4_3200mhz/)
- Yeah, that board has 2x M.2 and 1x Slimline x8. So that's pretty decent, because that 1 slimline port can handle 2 U.2 drives or even 2 M.2 with an adapter. (Or you can get a cable that goes to 8x SATA or 2x Mini SAS, for a backplane) I like those connectors a lot, but the cables aren't cheap.

- I have 128GB ram, 7343 CPU
  LSI 9300 HBA 10w
  a GTX 1660 Super that idles at 13-15w
  2x U.2 that are a bit power hungry, but fast. 10-20w each
  2x M.2 at about 9w each
  and 20 WD HC530 HDD's.

- Take a look at the Gigabyte MZ32-AR0. Just got one with a 7502. It's a very nice board with a ton of features

- Hey mind sharing what cooler have you been using? Trying to find something quiet but it seems Noctua''s are the only option? Wondering if the BeQuiet DarkPro for TR4 would fit this board
  - I love Noctua and have several of them, but for EPYC and TR it seems the ARCTIC Freezer 4U for AMD TR4 is the way to go. It's very quiet and should be able to handle 300 Watts.
  - I think one reason I ended up going with it was because the Noctuas didn't fit into my 4U case.

- ## ["The Talking Cube" 4x3090 local AI server : r/LocalLLaMA _202402](https://www.reddit.com/r/LocalLLaMA/comments/1aux2es/the_talking_cube_4x3090_local_ai_server/)
  - Supermicro H12SSL-i AMD EPYC 7262 256GB RAM 4xEVGA RTX 3090 FTW3 ULTRA Completely DIY / custom mounting solution for the 3 gpus on top

- ## [Cooling a server motherboard in a desktop case. : r/homelab _202403](https://www.reddit.com/r/homelab/comments/1bgpzno/cooling_a_server_motherboard_in_a_desktop_case/)
  - I have a Supermicro H12SSL-i  with an Epyc 7762 that has 64 cores. It's installed in the Fractal Define XL 7 case and is an all purpose server.
  - Fractal Design Define 7 XL: 604 x 240 x 566 mm, 82L ðŸ“¦
  - It runs well in a typical workload, but if I run the cpu full throttle, it will crash, likely due to the lack of ventilation blowing over the VRMs and such when there's such a huge spike in watts.
  - Anyway, do any of you DIYers know what could be done? The quieter, the better. It's full (19) of 3.5 inch drives so ventilation is a bit tricky.

- server boards need air flow, the more the better. I would make sure all of the fans are pushing/moving the air one way, i.e. in from the front and out the back, make sure that the cpu heatsink fans are not fighting this needed air flow, and I would max out on fans and sizes, like the Fractal will take the 140mm fans, I would go with the Noctua NF-A14 Industrial PPC-3000, yeah they will be louder than the slower 1500rpm fans but they move twice the air.

- I ended up downgrading the CPU to a lower tdp - AMD EPYC 7302P.

- ## ðŸ§© [What other supermicro boards are as good or better than: SUPERMICRO MBD-H12SSL-I-O ATX Server Motherboard AMD : r/homelab _202412](https://www.reddit.com/r/homelab/comments/1h59xtp/what_other_supermicro_boards_are_as_good_or/)
  - Using Epyc processors. Is there a better board? In this generation?

- Standard ones: H12dsi: dual processor, more PCIe and more ram slots
- Nonstandard:
  - H12ssw-ntr: 12 Ram slots on a single socket board
  - H12dsu: for u(ultra) server. Dual sockets with 24 Ram slots. 4 GPU power connectors.

- ## [Amd Epyc Genoa : r/LocalLLaMA _202406](https://www.reddit.com/r/LocalLLaMA/comments/1d5u33o/amd_epyc_genoa/)
  - Iâ€™m contemplating between buying a mac studio m2 192gb(or maybe waiting for the m4) or an amd epyc with about 750gb Ram.
- I have such a system with Epyc 9374F and 12 x 32GB of RAM. I'm quite pleased with its stability and performance, but remember that its 460.8 GB/s memory bandwidth is a theoretical value. On Aida64 I had around 375 GB/s. It's possible that Genoa CPUs with 12 CCDs (mine has 8 CCDs) will perform a bit better. Avoid CPUs with 4 CCDs, they have limited memory bandwidth. If you want estimated Q8 LLM generation performance simply divide the memory bandwidth value by the number of model parameters. So for Epyc Genoa and 400b model it will be around 1 t/s.

- Do you know if getting two sockets will double the speed?
  - I have no experience with dual-socket Epyc Genoa systems, but I remember talking to u/MadSpartus who ran llama.cpp on a dual Epyc Genoa system and it performed worse than my single-socket machine. You can ask him if he found any settings that improved the performance.
- I managed to just barely beat the single socket genoa with a dual socket by using numa tuning. Not worth it unfortunately. Only using llama.cpp though.

- Im running 9374F with 12x64gb dimms.
  - Deepseek R1 0528 with 671b runs on ollama at 7-8 tokens/s.
  - Deepseek R1 0528 8b qwen3, runs on ollama at ~45 tokens/s

- ## [My ugly beast - 64 core AMD EPYC 7763 w/ 160GB 8-channel DDR4 RAM, 3x3090 (72GB VRAM) & 6TB NVME storage : r/LocalLLaMA _202411](https://www.reddit.com/r/LocalLLaMA/comments/1gy7xp5/my_ugly_beast_64_core_amd_epyc_7763_w_160gb/)
  - All used parts, all in just under $4000 (technically about $3300 but I already had a 3090 prior to building this).
  - The EPYC 7763 is an engineering sample I found for $600, board is an open box supermicro h12ssl-i w/ 128 PCIE lanes. 
  - The 2 3090s I just waited patiently for deals and never paid over $650. $100 Used 1600W EVGA power supply on a dedicated 20A 120V branch circuit. DDR4 RAM is crazy cheap used, though I didn't go for the fastest. No thermal or power issues, I didn't even need to power limit the cards. 
- llm
  - 15.6 tokens/sec on qwen 72b (Q4_K_M w/ 32k context) 
  - 27.5 tokens/sec on qwen 32b (Q6_K w/ 32k context)

- ## [ATX LGA 2011 single cpu motherboard with 8 DDR3 slots supporting 256GB RAM? : r/buildapc _202309](https://www.reddit.com/r/buildapc/comments/1682clw/atx_lga_2011_single_cpu_motherboard_with_8_ddr3/)
  - I am looking for an affordable ATX LGA 2011 motherboard with 8 DDR3 slots that will safely fit into normal ATX case (e.g., Chieftec ba-01) and support 1 CPU, ideally Xeon v2 or maybe v3 if needed
  - Chieftec ba-01: 540mm x 205mm x 650mm

- I found the following ATX motherboards with 8 DDR3 slots that could work, although not all of them will support 256GB RAM, depending mostly on their latest BIOS updates. On top of that, given that most of them are consumer boards, they usually do not support ECC memories.
  - MSI X79A-GD45 Plus
  - MSI Big Bang-XPower II
  - Gigabyte GA-X79-UP4
  - Gigabyte GA-X79S-UP5-WIFI (does not support registered ecc, only unbuffered)
  - ASUS X79-Deluxe
  - ASUS P9X79, P9X79-E WS
  - ASRock X79 Extreme6, X79 Extreme9
  - Supermicro X9SRi-F
  - Supermicro X9SRA
- Due to the potential ECC issues, I eventually went with Supermicro X9SRi-F, which works really well for my purposes (256 GB RAM with no problem) and later got my hands on Supermicro X9DRI-F, which I haven't tested properly, but should work fine too.
  - In the meantime, I experienced a short episode with Jingsha X99, that is in some ways more modern (m2 ports, for example) and worked semi-well, but in comparison to Supermicro, I found the lack of support and fiddling with drivers rather discouraging.
- Same, the problem was with AliExpress x79 cheap dual socket mbrd, problem was with USB 3.0 ports(which in my case was very important).so I was searching something to change

- ## [DDR5-compatible motherboards with 8 RAM slots? : r/buildapc _202312](https://www.reddit.com/r/buildapc/comments/18lmms0/ddr5compatible_motherboards_with_8_ram_slots/)
- you'll need hedt or server hardware.

- Get a threadripper 7000 motherboard. Itâ€™s a really expensive platform, but I doubt cost is your primary concern here.
  - Recent epyc and xeon platforms are also options, but Threadripper would be my recommendation.

- ## [Show me your AI rig! : r/LocalLLaMA _202409](https://www.reddit.com/r/LocalLLaMA/comments/1fqwler/show_me_your_ai_rig/)
- With enough memory bandwidth and a recent CPU you can run very large models like Llama 405B in main memory and get 4 tp/s or so. You can roughly calculate it by dividing model size by memory bandwidth. Make sure you get fast RDIMMs, ideally 3200 otherwise your TPS will suffer. Without enough RAM you'll be running smaller, usually inferior models.

- I bought a used Epyc 7282, but your 7F52 looks a bit nicer! 
  - Definitely try to populate all 8 slots of RAM, this board/CPU supports 8 channels, so you can really up your memory bandwidth doing that. I am going to run 8x 32GB PC 3200 RDIMMS. 
  - If you are running DDR4 3200, you get 25.6 GB/s of memory bandwidth per channel, so if you are only single channel or dual channel now, going to 8 could take you from 25 or 50 GB/s to 205 GB/s!

- You should fill all 8 slots with a Ram module of the same size, so your total Ram would be either 128 or 256 GB. Your Cpu has a maximal memory bandwidth of 200 GB/s.

- ## [Epyc Turin (9355P) + 256 GB / 5600 mhz - Some CPU Inference Numbers : r/LocalLLaMA _202502](https://www.reddit.com/r/LocalLLaMA/comments/1ihpzn2/epyc_turin_9355p_256_gb_5600_mhz_some_cpu/)
  - I decided that three RTX 3090s janked together with brackets and risers just wasnâ€™t enough; I wanted a cleaner setup and a fourth 3090.
  - My requirements were: at least four double-spaced PCIe x16 slots, ample high-speed storage interfaces, and ideally, high memory bandwidth to enable some level of CPU offloading without tanking inference speed. Intelâ€™s new Xeon lineup didnâ€™t appeal to me, the P/E core setup seems more geared towards datacenters, and the pricing was brutal. Initially, I considered Epyc Genoa, but with the launch of Turin and its Zen 5 cores plus higher DDR5 speeds, I decided to go straight for it.
  - Due to the size of the SP5 socket and its 12 memory channels, boards with full 12-channel support sacrifice PCIe slots. The only board that meets my PCIe requirements, the ASRock GENOAD8X-2T/TCM, has just 8 DIMM slots, meaning we have to say goodbye to four whole memory channels.
  - Getting it up and running was an adventure. At the time, ASRock hadnâ€™t released any Turin-compatible BIOS ROMs, despite claiming that an update to 10.03 was required
  - CPU: Epyc Turin 9355P - 32 Cores (8 CCD), 256 MB cache, 3.55 GHz Boosting 4.4 GHz - $3000 USD from cafe.electronics on Ebay (now ~$3300 USD).
  - RAM: 256 GB Corsair WS (CMA256GX5M8B5600C40) @ 5600 MHz - $1499 CAD (now ~$2400 - WTF!)
  - Asrock GENOAD8X-2T/TCM Motherboard - ~$1500 CAD but going up in price

- Please add the likwid-bench memory bandwidth test results, as PassMark is known for its tendency to overstate the value in its memory threaded test. 
  - Theoretical max for 8-channel 5600 RAM is 358.4 GB/s and it shows 431 GB/s. This may be misleading.

- ## ðŸ§®ðŸ’¡ [Comparing Threadripper 7000 memory bandwidth for all models : r/threadripper _202402](https://www.reddit.com/r/threadripper/comments/1azmkvg/comparing_threadripper_7000_memory_bandwidth_for/)
  - 7945WX and 7955WX (2 CCDs, 8 memory channels) have the lowest Memory Threaded test results (~102 GB/s). 
  - Next, we have 7960X and 7970X (4 CCDs, 4 memory channels), and we can observe a moderate increase in test results (167 GB/s, 179 GB/s). 
  - The results for 7965WX and 7975WX (4 CCDs, 8 memory channels) again are a little higher (236 GB/s, 246 GB/s) compared to the non-PRO models, It's definitely not a 2x bandwidth increase compared to the corresponding non-PRO models. 
  - Only when we compare the models with 8 CCDs: 7980X and 7985X, there is around 90% increase in the test result (240 GB/s vs 453 GB/s). Finally, 7995WX (12 CCDs) has the best performance in this test.
  - ðŸ¤” The overall conclusion is that the lower-end models with 2-4 CCDs have limited memory bandwidth. We had the same situation in previous Threadripper generations. If you need a lot of bandwidth, you probably should use EPYC.

- we need to make a distinction between
  - the bandwidth between memory modules and the memory controller, 
  - the bandwidth between the memory controller and CCDs (where CPU cores are).
- These bandwidths are two independent things and they both affect the total available memory bandwidth in the system. Overall theoretical available memory bandwidth is the lower value from the two.
- First, we have the bandwidth between memory modules and the memory controller. 
  - I calculated the total available bandwidth for various numbers of memory modules (for 4x, 8x, and 12x configurations) and memory speeds (4800 MT/s is the default for EPYC Genoa, 5200 MT/s is the default for Threadripper 7000, 7200 MT/s is commercially available overclocked memory for TRX50 and WRX90).
  - This is how much bandwidth is theoretically available. It's nice that we can use overclocked memory in Threadripper since 8 7200 MT/s sticks will give us the same bandwidth as 12 4800 MT/s sticks in Epyc.
- The second bandwidth is the bandwidth of the GMI3 links between the memory controller and CCDs. 
  - Let's calculate how much bandwidth we have depending on the number of CCDs in the CPU. I assumed an FCLK of 1.8 GHz, so a single GMI3 link has 57.6 GB/s read bandwidth.
- Each CCD is connected with I/O die containing the memory controller with a GMI3 link, and this link has limited bandwidth. All CPU cores within a single CCD use this GMI3 link for memory access. So the more CCDs in CPU, the higher is the number of GMI3 links to the I/O die

- ðŸ“Œ To get the best memory bandwidth, (theoretically) you should:
  - Increase FCLK for 8-channel configurations with 2 or 4 CCDs (7945WX, 7955WX, 7965WX, 7975WX), 
  - Use overclocked memory in all remaining Threadripper models, 
  - For Epyc, purchase a motherboard with 12 memory slots and an Epyc 9004 processor with at least 8 CCDs. Fill all memory slots.

- Another site (userbenchmark) mostly verifies what fairydreaming posted, shows a bit more improvement from 3000 to 7000, but lacks information on highly overclocked builds
  - Results are thin for the 7000 series (no 7945WX results) but the improvement from 3000 to 7000 appears more significant than using PassMark. Single-core more than doubled and multi-core up about 80%.

- Can you repeat this excercise for epyc processors?
  - I checked a few performance EPYC 9004 models that could be used in workstation builds: 
    - 9174F (16c) achieved 402 GB/s with 8 RAM modules, 
    - 9274F (32c) around 588 GB/s with 12 RAM modules, 
    - 9474F (64c) achieved 449 GB/s with unknown number of RAM modules.
- Thank you so much. Okay. So the 16 core epyc has 8 ccdâ€¦ so the number of ccd is the memory bandwidth bottleneck. â€”- ryzen 7950x3d has memory threaded score of 54 MBytes/s. So the threadripper 7960x is the sweet spot for cost/clock speed/cores/167 MB bandwidth with around 3x mem bandwidth at a little over 2x cost of 8950x3d

- I can tell you the results of the threaded memory test that I found the PassMark database:
  - AMD EPYC 7F52 (16c Rome): ~145 GB/s (with 8 DDR4 RAM modules)
  - AMD EPYC 74F3 (24c Milan): ~217 GB/s (unknown number of DDR4 RAM modules)
  - AMD EPYC 9174F (16c Genoa) ~402 GB/s (with 8 DDR5 RAM modules)
  - AMD EPYC 9274F (32c Genoa) ~588 GB/s (with 12 DDR5 RAM modules)
  - All models have 8 CCDs.

- I checked a few performance EPYC 9004 models that could be used in workstation builds: 
  - 9174F (16c) achieved 402 GB/s with 8 RAM modules, 
  - 9274F (32c) around 588 GB/s with 12 RAM modules, 
  - 9474F (64c) achieved 449 GB/s with unknown number of RAM modules.

- Really wish I had seen this BEFORE I picked up my 7955WX. It's insane to me that this isn't more openly communicated somehow. Now I'm debating what my next path is. Switch to Epyc for additional bandwidth, or wait for a deal on Ebay to get a 7985WX or 7995WX.
  - I feel your pain. I purchased all components already and now IM LOST AS SHIT. Hoping vcolor will let me exchange the 256 6400 ram.

- 
- 
- 
- 
- 
- 
- 
- 

- ## ðŸ¤” [EPYC/Threadripper CCD Memory Bandwidth Scaling : r/LocalLLaMA _202509](https://www.reddit.com/r/LocalLLaMA/comments/1nesi8g/epycthreadripper_ccd_memory_bandwidth_scaling/)
  - There's been a lot of discussion around how EPYC and Threadripper memory bandwidth can be limited by the CCD quantity of the CPU used. What I haven't seen discussed is how that scales with the quantity of populated memory slots. 
  - Would populating 2 dimms on an 8 channel or 12 channel capable system only give you 1/4 or 1/6th of the GMILink-Limited bandwidth (25 GB/s or 17GB/s) or would it be closer to the bandwidth of dual channel 6400MT memory (also ~100GB/s) that consumer platforms like AM5 can achieve.

- Theoretical total memory bandwidth is straightforward. For example, AMD EPYC 9XXX with 12 memory channels is 614 GB/s with 6400 MT/s DIMM
  - (64 (DQ pins per DIMM) * 6.4Gbps speed per DQ pin * 12 channels ) / 8 = 614 GB/s
  - If there are 3 channels in each NUMA quad, that's 153.6GB/s already, well over 100GB/s BW available to CCD over GMI. CCD can access all 12 channels, but not all at once, so there is the memory wall.

- Ccd numbers is easy to tell. The desktop gaming cpu maxes out a dual channel ram system and this cpu has just 1 ccd. Which means you need atleast 1 ccd per 2 channels. So for a 12 channel epyc motherboard you need a cpu with atleast 6 ccds, although higher ccd options are preferable if you can afford them.

- Iâ€™m curious to ask, have you considered Intel Xeon? I myself am in the process of comparing Xeon 6 and EPYC 9005, and I hear conflicting reports on both. EPYC has more memory channels and higher bandwidth, whereas Intel has AMX instructions. So on the face of it, assuming that prompt processing happens on VRAM, EPYC appears to be the choice. However, I still hear from some people that Xeon is more widely deployed in inference infra due to inherent advantages in its architecture and less issues with NUMA, particularly in dual-socket configurations. Iâ€™d be interested to hear what youâ€™ve come up with in regard to this during your own search.
  - I've been eyeing Xeon W7-3565X or AMD Epyc 9355P (same price tag), equivalent 32 core TR is just too expensive. From what I could tell Intel AMX does seem promising and further research suggest has much better memory BW/latency due to monolithic die for MCC CPU CKU (like 32 core).

- [AI: Memory Bandwidth comparison for selected DDR4 CPUâ€™s _202410](https://phoenixgamedevelopment.com/blog/ai-memory-bandwidth-comparision-for-selected-ddr4-cpus/)
- I have purchased a Threadripper PRO 3955WX CPU for the purposes of building an LLM inference machine.
  - However, I have since discovered that there is a serious issue with using some Threadripper and Epyc CPUâ€™s (Including the 3955wx) for this purpose.
- The issue is that these CPUâ€™s use 2 CCDâ€™s (Core Chiplet Dies), which substantially reduces the memory bandwidth.

- The fundamental issue is that in order to reach the maximum bandwidth of 8-Channel RAM (About 200 GB/s) it is necessary to have not just 8 Channels supported, but 8 CCDâ€™s as well.
- Only extremely expensive CPUâ€™s have 8 CCDâ€™s.
  - The cheaper CPUâ€™s have only 2, which effectively limits their ram bandwidth to quad channel speeds (Around 80-100 GB/s) or slightly more.

- At my price point, it seems that 4 CCDs with 8 Channels is basically the best that can be achieved. This means that the actual read/write speeds in the real world are in the region of 150 GB/s read 100 Gb/s Write.
  - It seems, based on my research, that there is no inherent difference between Threadripper/Pro and Epyc CPUs that have the same number of CCDs.

- ## ðŸ‘€ [Filling up 12 memory channels on EPYC server with 6x dual-channel kits : r/homelab _202501](https://www.reddit.com/r/homelab/comments/1i0oait/filling_up_12_memory_channels_on_epyc_server_with/)
  - Anyone foresee any issues filling up the 12 channels on a 32-core 9384x EPYC cpu build with 6 kits of identical consumer grade non-ecc memory such as these?
- You can use normal desktop memory with Epyc but why spend all of that money on a Epyc cpu just to stick it with cheap non-ecc memory? It's like putting a RTX4090 with an i3 cpu. I'm also fairly certain that 12 DIMs would limit you to 2933MT/s or maybe 3200MT/s, I can't remember off the top of my head, but there is a limit.
  - Only RDIMMs and LRDIMMs work in any SP5 CPU. You absolutely cannot use UDIMMs or CUDIMMs and if you think you can, please link to a motherboard specs that shows it supported.
  - 1DPC is 4800MT for Genoa and is a 12 channel CPU, motherboards with 1 CPU and 24 DIMMs are 2DPC
  - ðŸ§ 9384x is an 8 CCD CPU and will gain no performance benefit from having more than 8 DIMMs installed, although you can for more RAM
  - EDIT: e.g. motherboard showing 12DIMMs/1DPC at 4800 and only RDIMMs supported https://www.supermicro.com/en/products/motherboard/h13ssl-n
- Thanks. Good to know about lanes being tied to ccds.

- ## [AMD Epyc 4004 line - General Discussion - TrueNAS Community Forums _202405](https://forums.truenas.com/t/amd-epyc-4004-line/5183)
  - AMD recently released an Epyc CPU which fits into the AM5 socket. It does have the light weight iGPU and supports ECC memory, as well as lower power than some of the newer Epycs, (which seem to make great house heaters!).
  - When I brought up a thread in the old forum for ideal, low end CPU, one thing was I thought was required, were about 40 PCIe lanes. The AM5 socket only supports 28 lanes, 4 of which appear dedicated to the companion chip. For a lower end desktop, which is what the AM5 is designed for, 24 PCIe lanes for the user is fine.

- I agree about wanting 40 PCIe lanes. Especially when you may want to add a couple of 16x or 8x NVMe bifurcation cards, and maybe an 8x dGPU for transcoding or image analysis.

- Existing boards use the B650(E) chipset. Supermicro, AsRock Rack and Gigabyte have added â€œEPYC 4004â€ to the specifications of thier existing server Ryzen boards. SATA and USB ports would then depend on the chipset (typically 6 SATA with B650, and I donâ€™t see much use for the X chipset here); USB4 would require an additional Maple Ridge or ASM4242 controller.

- ## [Do Epyc Processors Have Integrated Graphics? : r/AMDHelp](https://www.reddit.com/r/AMDHelp/comments/cgztk3/do_epyc_processors_have_integrated_graphics/)
- Epyc processors do not have integrated GPU's, even vGPU, or however you call them.

- I got EPYC 4124 have Integrated GPU but didn't get any after that, is that true?

- [AMD Epyc Rome Server CPUs - iGPU inside, support for hypervisors like ESX? : r/Amd](https://www.reddit.com/r/Amd/comments/ctcgf8/amd_epyc_rome_server_cpus_igpu_inside_support_for/)
- > all blue servers i saw got somewhere a iGPU in the CPU or on the Motherboard
  - IIRC all server motherboards have a small GPU chip, no server CPU has an iGPU, but I might be wrong. (Epyc doesn't have iGPU, motherboards do).

- [Why does this Amd Epyc motherboard (SuperMicro H11SSL-i) have a VGA out, if the cpu has no onboard graphics? It would also need a GPU card too right? : r/homelab](https://www.reddit.com/r/homelab/comments/u17mnu/why_does_this_amd_epyc_motherboard_supermicro/)
  - Many server boards have onboard graphics. Just a small 2D chip.

- ## ðŸŒ° [Upgraded self-hosted AI server - Epyc, Supermicro, RTX3090x3, 256GB : r/LocalLLaMA _202405](https://www.reddit.com/r/LocalLLaMA/comments/1d3dh4c/upgraded_selfhosted_ai_server_epyc_supermicro/)
  - moving from AM4 to Epyc. CPU/mb/GPU/RAM/frame purchased on Ebay. 
  - CPU - AMD Epyc 7F52 CPU
  - Motherboard - Supermicro H12SSL-i
  - RAM - 8x32GB DDR4 ECC Reg 3200 Mhz, DDR5 is only supported on Epyc 8000/9000 series, the Epyc 7001/7002/7003 lines only support DDR4.
  - 3 x RTX3090 Founders Edition, all on PCIE 4.0 x16 risers
  - Veddha 6GPU miner open frame: Veddha V3C 6-GPU Mining Case Aluminum Stackable
  - Proxmox RAID Z1 (mirrored) on 2 x Kingston 256GB SSD
  - Samsung 1TB m.2 NVME for VMs
  - Samsung 4TB SSD for models & data
  - Intel X540 T2 2 x RJ45 10GBe nic
  - Corsair HX1500i, 34.6 x 23.8 x 13.2 cm, 10.8L
  - Ollama running command-r-plus:latest eval rate 12 t/s, llama3:70b Q4_0 17 t/s, llama3:70b-instruct-q6_K 13.06 t/s

- ## [Whatâ€™s the deal with all the cheap EPYC mobo +cpu + ram bundles selling from China? : r/homelab _202210](https://www.reddit.com/r/homelab/comments/yemiap/whats_the_deal_with_all_the_cheap_epyc_mobo_cpu/)
  - There are hundreds of these kinds of offers on eBay and elsewhere - at ridiculously low seeming prices Eg: AMD EPYC 7551P CPU 32 Cores + Supermicro H11SSL-i Motherboard +8x 8GB 2133P RAM
  - Are these a scam?
- More likely they're decommissioned hardware from data centre.
  - This has been asked multiple times. The answer is they're old and being decommissioned. 1st gen stuff has been available for cheap for a couple years, while second gen is starting to get cheap. It's not like people are shocked when they see a 1950x for less than a quarter of the original MSRP.

- ## [AMD EPYC 9004 series 1U chassis : r/homelab _202311](https://www.reddit.com/r/homelab/comments/17nopmx/amd_epyc_9004_series_1u_chassis/)
  - EPYC 4th AMD EPYCâ„¢ 9354P
  - Motherboard Supermicro H13SSL-NT
  - 256 GB RAM + M2 storage.
  - [The new EPCY 9004 CPU's look like a great option for a low(ish) power build. : r/homelab](https://www.reddit.com/r/homelab/comments/181e2u2/the_new_epcy_9004_cpus_look_like_a_great_option/)

- The board is listed as ATX so any case thats takes that size motherboard is on the table except for one thing - trying to find a suitable case.

- ## [Xeon 6230 or Epyc 8124P or 9124 for Homelab? - Hardware Hub / Build a PC - Level1Techs Forums _202502](https://forum.level1techs.com/t/xeon-6230-or-epyc-8124p-or-9124-for-homelab/225592)
  - Iâ€™m looking to build a server for my homelab (HV + NAS). I donâ€™t see many comparisons or benchmarks for the 8004â€™s and lower end 9004â€™s. 
  - Epyc 8004 motherboards are still pretty limited. For various IO reasons, I donâ€™t really love the current 8004 options (ie: ME03-CE0 & SIENAD8-2L2T), making me lean toward the 9124.
  - Used DDR4 ECC is so cheap that I can max out all six memory channels (6x64GB) right away. Which would be great for TrueNAS and my VMâ€™s. With the Epycâ€™s, I would start with 2x64GB and wait for DDR5 ECC prices to drop, meaning more cost later. And who knows how long until they actually drop.

- ASUS S14NA-U12 is another 8004 motherboard option. Iâ€™ve no experience with any Epyc motherboard, but this looks nice and is a bit cheaper in EU

- I have a 8024P AMD EPYC running in my home lab on a Gigabyte ME03-CE0 motherboard with 6 16GB ECC DDR5 RDIMMs and storage.
  - Itâ€™s a bit weak (wish I had found a 8124P or even a 8324P if it was somewhat affordable), but gets the job done.

- ## [Asrock vs Supermicro - AMD Epyc Genoa : r/truenas _202406](https://www.reddit.com/r/truenas/comments/1dekxey/asrock_vs_supermicro_amd_epyc_genoa/)
  - I am looking to buy a new motherboard for my server (TrueNAS Scale) and am considering the following models: ASRock GENOAD8UD-2T/X550, Supermicro H13SSL-NT
  - My previous experiences with Supermicro motherboards have been very unpleasant. The IPMI port didnâ€™t work, the PCIe card I installed for the network didnâ€™t appear in BIOS, and a RAID card (purchased from a trusted company) had the same issue.

- I use the Supermicro H13SSL-NT with windows at this point, in a desktop case and everything is working fine. I have the epyc 9124. And windows desktop doesn't support the 10gbe broadcom adapter.  

- ## [What are the cheapest Intel/AMD CPUs supporting Quad-channel RAM in 2023? - Quora](https://www.quora.com/What-are-the-cheapest-Intel-AMD-CPUs-supporting-Quad-channel-RAM-in-2023)
- xeon w3 2423 the latest its like 400$ but has 4 channel memory

- There are a few different candidates, depending on whether you include old or second-hand components, and how you define â€œquad-channelâ€.
- Technically the Xeon E5 2620 is the cheapest CPU you can buy in 2023 with quad-channel support.
  - Itâ€™s a very weak 6-core server CPU from 2012, and you can buy one second-hand from Aliexpress for about $2 or Â£1.50
  - It supports quad-channel DDR3, both registered and unbuffered, but because it only supports DDR3, itâ€™s not a good option
- Most modern laptop CPUs support quad-channel LPDDR RAM, because LPDDR channels are half as wide as DDR channels (32 bits vs 64 bits), so you can fit twice as many channels on a given CPU, though each channel has half as much bandwidth. 

- If you want a current-gen CPU with support for at least 4 full memory channels (at least 256-bit memory bus, at least 8 DDR5 sub-channels), the cheapest option is a 6-core Intel Xeon W3-2423 (4 channels) or 8-core AMD EPYC 8024P (6 channels) which both cost about $400 or Â£400.

- ## [Ryzen DDR5 Quad channel resources - Hardware Hub - Level1Techs Forums _202412](https://forum.level1techs.com/t/ryzen-ddr5-quad-channel-resources/221787)
- Check your motherboardâ€™s QVL list for compatible memory kits.
  - Itâ€™s not the number of sticks, itâ€™s the number of memory ranks. So you can typically do 4 single rank sticks or 2 dual rank sticks at EXPO speeds. 
  - The problem is consumer memory rarely specifies the number of ranks as they may swap suppliers based on whatâ€™s cheap/available.

- ## [Does a CPU with 2 memory channels support using 4 sticks of RAM? : r/buildapc](https://www.reddit.com/r/buildapc/comments/13d83mt/does_a_cpu_with_2_memory_channels_support_using_4/)
- It CAN use up to four sticks, yes. It's still dual channel, it's just double-populated dual-channel (true quad-channel RAM CPUs do exist, but it's highly unlikely you have one).
  - Finally, if it's a situation of DDR4, RAM is so goddamn cheap right now that if you want to go from 16GB (2x8GB) to 32GB (2x16GB), you can usually just sell your old kit on like ebay, and even after the fees, it's within a few dollars of the same net cost as if you bought another 2x8GB kit.

- ## ðŸ†šðŸ‘€ [Framework strix halo vs Epyc 9115 -- is Epyc better value? : r/LocalLLaMA _202503](https://www.reddit.com/r/LocalLLaMA/comments/1jo50iz/framework_strix_halo_vs_epyc_9115_is_epyc_better/)
  - I've put in a reservation for the Framework desktop motherboard, which is about $1800 with 128GiB ram, 256 GiB/sec bandwidth. 
- However, I was going through some server configurations, and found this:
  - Epyc 9115 -- 16-core, 12-channel memory, $799
  - Supermicro Motherboard w/ 12 DIMM slots -- $639
  - DDR5 6400 16GiB x 12 -- $1400
  - That would give me (12 channel x 64 bit wide per channel * 6400) 614.4 GiB/sec bandwidth, about 2.5x the Strix Halo motherboard configuration. Cost would be about 1k more, but getting 50% more memory too.
  - Now this would be doing CPU only inference, which I understand is mostly memory bandwidth bound anyway. Prompt processing would suffer, but I can also throw in a smaller sized GPU to use for prompt processing.

- That Epyc has just two CCD. Even if it uses 2 GMI3 links per CCD, it would be limited to 240 GB/s.
  - AMD has this fraud of advertising bandwidth between RAM and memory controller, even when it's severly bottlenecked by bandwidth between CPU and controller.
  - In order to obtain the advertised 9005 bandwidth you need to use the 12 or 16 CCD SKUs.

- 9115 costs less than 1k, not 10k. But it has just 2 CCD and probably its actual performance is much lower than expected. A way better choice would be the 9175F, which goes for 4k.
  - Or I would consider 9274F, if the price has reduced after 9275F launch.

- I was just going to reply 9175F is $2650 on Newegg and 16CCD. I might go for that instead. Thanks for the reply! Any RAM recommendations? And amount?
  - 9175F supports 12 channel memory, so you should look for a single-CPU 12-channel mobo. Theoretically, it should be able to benefit of memory up to 7200 MT/s, but without benchmarks is hard to say.

- The cheapest Epyc Turin that will give you more bandwidth would the 9225 at 2, 500 usd. (4 ccd)

- I regularly find the previous EPYC 9554 64-core CPU with 8x CCDs (measured at 390GB/sec on STREAM) listed for $2500-2900. This is the most value for money configuration I believe and it offers more computation FLOPs for prompt processing (~5 TFLOPS in AVX2 is my estimate).

- The reason to choose Epyc is for the PCIe lanes or amount of memory, i.e. you are planning to load up GPUs in it or want to run something that requires a lot of memory.
  - ðŸ¤” If you only want the lanes you can go cheaper with an SP3, something like 7532 which is the cheapest 8 CCD second gen you can buy, an ATX motherboard gets you 7 total PCIe slots, and in something like the H12SSL 5 of which are 16x - you could put in 5 x16 GPUs and still have lanes to spare. Placing them will be tricky because two would have to be single width but you can use cables.
  - If amount of memory matters and you can live with lower speed then SP3 wins again, because you can easily get 512Gb RAM+ for less than the cost of pretty much anything in DDR5 - DDR5 RDIMMs are eye wateringly expensive. Depending on what you're doing you may get similar or better memory bandwidth out of a 7532 compared to the low CCD count SP5.

- If you want to get a versatile CPU for other tasks as well, the previous gen AMD Epyc 9554 is better value imo (regularly under $2900) with 64 cores (~5 TFLOPS) and measured at 390GB/sec on STREAM. It achieves this with DDR5 4800 which is cheaper as well.

- Just get 5 7900 XTX. Strix Halo sucks big time in those machine where the motherboard does not support ECC. I hope some Strix Halo provider will finally create a ECC memory supported device
  - The HP Z2 G1a has ECC

- Early leaks point to Medusa Halo using a 384 bit bus, posdibly even LPDDR6.

- The 9015 was tested at 240GB/s on STREAM. I doubt that the 9115 will be much higher than that so you should temper your expectations

- ## ðŸ§®ðŸ’¡ [Is DDR4 3200 MHz Any Good for Local LLMs, or It's Just Too Slow Compared to GDDR6X/7 VRAM and DDR5 RAM? : r/LocalLLaMA _202509](https://www.reddit.com/r/LocalLLaMA/comments/1ndg19v/is_ddr4_3200_mhz_any_good_for_local_llms_or_its/)
- For those wondering DRAM memory bandwidth can usually be calculated using following formula:
  - MT/s x 8bytes x memory channels / 1024 
  - So 3200MT/s x 8bytes x 2 channels / 1024 = 50GB/s

- Well, not only is DDR4 considered slow, it's more a question of how many memory channels you have got. 
  - Chances are that it's not going to be very many, it but really depends on the hardware you have. 
  - The rule is that each transaction is 64 bits or 8 bytes wide, so 3200 MT/s where T is for transactions means 3.2 GT/s can be performed by the hardware, and 3.2 GT/s * 8 B/T gives you 25.6 GB/s per channel. 
  - DDR5 is not hugely faster in this scale, e.g. you might have 6400 MT/s DDR5, which also has 64-bit transactions and thus double the data rate. 
  - Multiple memory channels is how you take these raw results in 50 GB/s order to the 200+ GB/s data transfer rates where inference starts to become practical. 4 are probably required, 8 or 12 is better.

- A common mistake is that something like am5 has only 2 memory channels but 4 slots for ram. This means that even with 4 sticks you only get 2 stick bandwidth (probably at an even lower speed). Make sure you check what your cpu is capable of.

- It isn't going to be as fast as pure vram obviously, but if you're using moe models it works better than you'd think. Having 256GB of ram with a large moe will do good, even with just 24GB of vram. You also can partially offload a dense model but still have super fast input prompt processing. 
  - My desktop computer for example is 96GB of system ram and 24GB of vram. I can run a 70B or a 100B model, process 200, 000 tokens of input within a couple minutes, and wait for slower tk/s but much shorter output.
  - I also use llms on my laptop that only has 2 channel 64GB ddr4 at 3200mhz. No gpu. I'm getting 2.5 tokens/sec with GLM 4.5 air @ 3Q right now. Not fast by any means but not impractical. I just let it do it's thing for a couple minutes and come back for the answer.

- I've was here not long ago as I upgraded to 128 GB of ddr4 3200 ram. The Qwen3 235B Q2 (Need 96GB ram) runs at 3.7 tk/s and with the Qwen3 235B Q4 (128GB ram) I get 2.2 tk/s. So yes very slow.

- VRAM > [LPDDR5X > DDR5 > DDR4] > Disk

- [What is the theoretical data rate limit of a DDR5 DIMM slot? : r/hardware _202106](https://www.reddit.com/r/hardware/comments/nxvsk7/what_is_the_theoretical_data_rate_limit_of_a_ddr5/)
- ram is overclockable. But first theres something you need to understand about ram speed: the MHZ speed you see listed on ram is not the actual clockspeed , the real clock is half but since modern ram is DDR (Double Data Rate), everyone advertises the 'effective clockspeed ' , which is actually the transfer rate as measured in MT/s (Mega transfers per second).
- Now each dimm slot is a 64 bit wide bus so to get the theoretical data rate, you simply take the transfer rate times the bus width , so for example with 1 dimm of '3200 mhz ram' aka 3200 MT/s ram, thats 3200 * 64 = 204, 800 Mbps or 25, 600 MBps.

- ## [Which motherboards support quad channel memory : r/buildapc](https://www.reddit.com/r/buildapc/comments/sw22cg/which_motherboards_support_quad_channel_memory/)
- Note that it's not enough for the board to support it. The CPU has to as well. Most consumer ones do not.
  - Boards that support quad channel only support CPUs that also support quad channel. 

- ## [ä¸»æµçš„ ITX ä¸»æ¿æœ‰å“ªäº›ï¼Œé‚£ä¸€ä¸ªç‰Œå­æˆ–è€…åž‹å·æ¯”è¾ƒå¥½? - çŸ¥ä¹Ž](https://www.zhihu.com/question/350786479)
  - å¾®æ˜ŸæŠ€å˜‰åŽç¡•åŽæ“Žè¿™å››å®¶
- åŽæ“Žæ˜¯æ‰€æœ‰å“ç‰Œé‡Œä»·ä½æœ€ä½Žçš„ï¼Œå¹³å‡ä½Ž100å…ƒå·¦å³ï¼Œè¿™ä¸ªè¦è¯´ä¸æ˜¯ä¼˜åŠ¿ï¼Œé‚£ç»å¯¹æ˜¯èƒ¡è¯´ã€‚
  - ä¾›ç”µä¸Šæ¯”å¾®æ˜Ÿå°‘äº†ä¸€ç›¸ï¼Œä½†è€ƒè™‘åˆ°itxä¸éœ€è¦è€ƒè™‘è¶…é¢‘éœ€æ±‚ï¼Œä¸Šä¸ª3700Xç”šè‡³æ›´é«˜ä¹Ÿæ¯«æ— åŽ‹åŠ›ï¼Œå› æ­¤æ²¡æœ‰å¿…è¦è€ƒè™‘è¿™ä¸€ç‚¹ã€‚
  - è¯¥æœ‰çš„å…¨éƒ½æœ‰ï¼Œä¸è¯¥æœ‰çš„ï¼Œå¯èƒ½å®ƒä¹Ÿæœ‰ï¼Œæ¯”å¦‚å…‰çº¤éŸ³é¢‘
- åŽæ“ŽB450Iæœ€å¥½ï¼Ÿï¼Ÿçœ‹å¾—æˆ‘ä¸€å¤´é—®å·ï¼Œä¾›ç”µæ¯”ä¸ä¸Šå¾®æ˜Ÿï¼Œæ— çº¿æ¯”ä¸ä¸ŠæŠ€å˜‰ï¼Œä¿¡ä»°æ¯”ä¸ä¸ŠROGï¼Œè¿˜æ²¡ç¯ï¼Œå°±ä¸€å¹¶è”â€œ3+2â€ï¼Œä¹Ÿå°±å¿½æ‚ å¿½æ‚ å°ç™½å§

- å¾®æ˜Ÿçš„B450iå–çš„æ¯”åŽæ“ŽB450iå¤šå¾—å¤šå•Šï¼Œä¸çŸ¥é“å•¥åŽŸå› ï¼Œéš¾é“åªæ˜¯ä¸ºäº†å†…å­˜è¶…é¢‘ï¼Ÿ
  - åŽæ“ŽæŒ–çŸ¿æ¿å‡ºçš„å¾ˆå¤šï¼Œæ¶ˆè´¹å¸‚åœºè¿™å‡ å¹´å¾ˆç–²è½¯ï¼Œéƒ½æ‰“ç®—è¿›å†›å•†ç”¨äº§å“äº†ã€‚æˆ‘è¯´çš„æ˜¯é˜²æŽ‰åŽ‹ï¼Œä¸è¿‡3ä»£AUè¶…é¢‘æ€§èƒ½å¾ˆä¸€èˆ¬ï¼Œç¡®å®žæ²¡å¿…è¦ï¼Œæ‰€ä»¥è¯´ä¸è€ƒè™‘pcie4.0ï¼ŒX570éƒ½æ²¡å•¥æ„æ€ã€‚
- åŽæ“Žæ²¡å‡ºè¿‡å¤šå°‘æŒ–çŸ¿ç‰ˆã€‚ä»–æ¯”åˆ«äººå¯ä»¥ä¾¿å®œä¹Ÿèµšé’±çš„åŽŸå› æ˜¯å·¥åŽ‚åœ¨è¶Šå—ï¼Œè€Œä¸”ä¸éœ€è¦è¥é”€ã€‚ITXç‹¬å­¤æ±‚è´¥ã€‚ä½ è¯´çš„é˜²æŽ‰ç”µæˆ‘åˆšæ‰æ²¡çœ‹åˆ°ï¼Œé‚£ä¸ªæ˜¯å¤„ç†å™¨éƒ¨åˆ†çš„é˜²æŽ‰åŽ‹å§ï¼Ÿ

- itx é¦–æŽ¨å¦–æ¿ åŽå‹¤Â·Â·Â·Â·Â· ä»·æ ¼ä¾¿å®œ åŽç¡•å…„å¼Ÿå“ç‰Œ

- ## [FormD T1 - sub-10L 64-core Epyc with 7x Gen4 NVMe : r/sffpc _202506](https://www.reddit.com/r/sffpc/comments/1l48tsm/formd_t1_sub10l_64core_epyc_with_7x_gen4_nvme/)
  - FormD T1 Sandwich V2.1 (silver, CNC): 13.5 x 22 x 33.5cm, 10L
  - AsRock Rack ROMED4ID-2T deep-ITX motherboard
  - AMD Epyc Milan 7Y83 64 cores 128 threads (OEM of 7763)
  - NVIDIA Quadro RTX A4000 16GB
  - Samsung 2S2Rx4 DDR4 ECC RDIMM 256GB (4x64GB)
  - Samsung PM9A1 2TB (OEM 980 Pro, heatsink)
  - 6x Gen4 M.2 NVMe on 3x carrier cards/heatsinks connected via SlimSAS (PCIe Gen4 8x per card)
  - Custom GPU-side fan bracket (Xianyu)
  - Corsair SF850

- ## ðŸŒ° [An Epyc FormD T1 : r/sffpc _202504](https://www.reddit.com/r/sffpc/comments/1k1grum/an_epyc_formd_t1/)
  - Asrock Rack ROMED4ID-2T
  - Epyc 7532
  - 4 x 64GB 3200MHz RDIMMs
  - Corsair H100i Elite Capellix with slim Noctua A12x15s
  - Runs Proxmox with a bunch of VMs
  - Despite having no GPU, this leaves a lot of room for more U.2 drives

- Be careful with U.2s, you usually need some decent airflow to keep them cool. I would use the gpu hole to push or pull some more airflow.

- ## ðŸŒ°ðŸ–¥ï¸ [Built a Powerful and Silent AMD EPYC Home Server with My Kids (for a Fraction of the Price!) : r/homelab _202412](https://www.reddit.com/r/homelab/comments/1hmnnwg/built_a_powerful_and_silent_amd_epyc_home_server/)
  - we built a beast of a home server powered by an AMD EPYC 7C13 (3rd gen).
  - CPU - AMD EPYC Milan 7C13 64C/128T 2.2GHz SP3 (100-000000335 7763 7713)	
  - Motherboard - Supermicro H12SSL-NT SP3 AMD EPYC DDR4 ECC	
  - RAM - Samsung 64GB DDR4 LRDIMM ECC x8 (512GB Total), DDR4 RAM: Delivers 130GB/sec bandwidth.
  - Case - Fractal Design North Tempered Glass ATX Mid-Tower Computer Case - White/Oak: 433 x 215 x 450 mm, 41L; ä»Žå›¾ç‰‡çœ‹ï¼Œæœºç®±æœ‰ç‚¹å¤§
  - CPU Cooler - Noctua NH-U14S TR4-SP3 (Premium-Grade)	
  - PSU - 850W SFX (ATX 3.0, PCIE 5.0 Ready, 80 Plus Gold)	
  - SSD - Samsung 990 Pro 1TB (7450 MB/s Read)	

- Regarding the CPU, I see some active listings on eBay â€“ try searching for "AMD EPYC Milan 7B13" (or 7C13) for the same price range. Just a heads-up, though â€“ there are engineering sample (ES) listings on eBay. Keep in mind that confidential computing (AMD SEV-SNP) wonâ€™t work on those CPUs, and there might be other feature limitations or performance issues that Iâ€™m not fully aware of.

- I've worked as a pc technician for a few years and built & repaired many machines over the years. In my experience, I would turn the cooler 90Â° that the airflow matches the direction of the intake fans in the front. If you ever want to add a gpu, then this layout works great. Depending on the temps, you might want an exhaust fan in the back or top

- ## [Mini ITX EPYC 64 core 128 thread SFF Build : r/homelab _202311](https://www.reddit.com/r/homelab/comments/182i7k3/mini_itx_epyc_64_core_128_thread_sff_build/)
  - Case Cooler Master Nr200: 360 x 185 x 274mm, 18.25L
  - ASRock Rack ROMED4ID-2T Deep Mini ITX motherboard.
  - Noctua NH-U12S TR4-SP3 cooler. çŒ«å¤´é¹° é£Žæ‰‡
  - AMD EPYC ROME SP3 ZEN2 7662 64-Core 128 thread
  - 256gb DDR4 RAM.
  - 4tb NVME Drive.
  - Running ESXI vSphere 8 with VCenter Server 8.
  - Ruining like a champ temps in the 40-50c range, headless server with IPMI OOB management and remote console.
  - Putting these similar spec parts in a cart on Newegg says $5101.52.
- Iâ€™m guessing the cpu / mb / memory probably cost around $1000 on the used market. I just built a similar system second hand.. hard to beat the value!

- They make Mini ITX EPIC boards? That is wild.
  - Theyâ€™re not true ITX. They are Deep ITX (wider than ITX, closer to mATX, but the same height as ITX).

- ðŸ†š what's the difference between RDIMM and LRDIMM?
  - [UDIMM, RDIMM, and LRDIMM | Exxact Blog](https://www.exxactcorp.com/blog/HPC/differences-between-dual-in-line-memory-modules-rdimm-vs-lrdimm)
  - A DIMM (Dual In-line Memory Module) is the physical memory stick that houses DRAM (Dynamic Random-Access Memory) chips. These chips serve as RAM, the volatile memory pool CPUs use to quickly access data during tasks.
  - UDIMM (Unbuffered DIMM): Standard in desktops and laptops. Affordable, simple, and designed for everyday tasks like browsing, content consumption, and productivity.
  - RDIMM & LRDIMM: Specialized modules designed for servers and enterprise workloads, offering higher capacity and stability. These will be the focus of this guide.
  - Registered DIMMs (RDIMMs) are designed for greater stability and scalability than standard UDIMMs. They include a register buffer that improves signal integrity and reduces the electrical load on the memory controller. 
  - Load-Reduced DIMMs (LRDIMMs) push performance further by using advanced buffering to minimize electrical load and maximize capacity. They are built for systems that demand extreme memory density and efficiency.

- For the price of this even 2nd hand (~$1500 for 7662, $300 mobo) -- you could build three separate i9-12900k/ryzen-7900x systems which combined would be about 2.5x-3x the total compute of this
  - This motherboard doesn't even get you the PCIe lanes.
  - 3x the compute but also a lot more power and maintenance. There's a reason hyperscalers use Epycs for x86.

- How's the noise?
  - I put in 4 noctua fans, and it's silent. Along with the 2 cooler master fans that came with the case and its dead silent. Although I need to put more VMS and put it to the test.

- ## [[PC] AMD EPYC Milan (7763) 64c/128t Build : r/homelabsales _202501](https://www.reddit.com/r/homelabsales/comments/1ht1fdu/pc_amd_epyc_milan_7763_64c128t_build/)
  - Got an email yesterday saying electricity rates in my area are increasing. My wife gave me the look after looking at the power bill for this month (and looking over previous months...) so I'm looking into downsizing my homelab.
  - AMD EPYC 7J13 (Oracle rebrand of the 7763 with slightly higher clocks) 64 core / 128 thread CPU
  - ASRock Rack ROMED8-2T motherboard (with Intel NICs)
  - 512GB (8x64GB) DDR4 3200 Registered ECC RAM (MICRON MTA36ASF8G72PZ)
  - ARCTIC Freezer 4U heatsink
  - ICY DOCK ToughArmor MB720MK-B 4x NVMe enclosure w/ OCuLink PCIe splitter card
  - ASUS Hyper M2 PCIe 4.0 card with 2x Optane P1600X 118GB + 2x Samsung 970 EVO 1TB
  - Intel X710-DA2 10G card
  - Intel Arc A380
  - Corsair HX1000i 1000W power supply
  - Prices seem to be all over the place for the CPU and motherboard, but the RAM prices seem to be stable. I was thinking in the ballpark of $3000 for everything?

- My energy rates went up too. My solution was to buy 8 more solar panels.

- ["Sleepy Chungus"... AMD EPYC 7763 w/ 64x cores, 128 threads @ 2.450GHz in a GEEEK A30 V2 && 128GB of Quad Channel, Dual Rank, 3200MT ECC REG RAM (linux sffpc, btw) : r/sffpc _202209](https://www.reddit.com/r/sffpc/comments/x6phtn/sleepy_chungus_amd_epyc_7763_w_64x_cores_128/)
- I'm not sure if it is called sffpc with that psu and chonky cooler.

- ## [Need expert recommendations for a scalable, portable midrange AI hardware setup (2025) : r/LocalLLaMA _202510](https://www.reddit.com/r/LocalLLaMA/comments/1o3p83a/need_expert_recommendations_for_a_scalable/)
  - My goal is to start with a solid midrange setup that is truly expandable â€” meaning I want to be able to add more GPUs, RAM, and storage later on without major hassle
  - CPU: AMD Threadripper PRO or EPYC 7004 series for high core count and ECC support
  - GPU: NVIDIA RTX 4090 or RTX 6000 Ada for strong AI performance and CUDA compatibility
  - RAM: Minimum 128GB DDR5 ECC with at least 8 slots for future upgrades
  - Storage: NVMe SSDs (1TB system drive + multiple TBs for data with RAID options)
  - Mainboard: Supports multiple PCIe 5.0 x16 slots for GPU expansion, robust VRM for stable power delivery
  - Chassis: Portable midtower or flight case with good airflow and room for multiple GPUs
  - Power supply: 1200W or higher modular platinum rated PSU, with capacity for future GPU additions

- CPU & Motherboard: Maybe Epyc 9B14/9V84, or anything higher than 9354 if these "cloud" varients are not available, and pair it with a supermicro H13SSL-N(not sure whether MZ33-AR0 works). I think EMR Xeons (Xeon 6530 or "cloud" ones like 8555C) can be a cheaper replacement of Epyc, with fewer bandwidth, but it has AMX support.
  - RAM: Maybe 12x48=576GB DDR5 4800(for Zen4) or 8x 48GB=384GB DDR5 5600(for EMR)
  - Chassis: Maybe phanteks enthoo pro 2(or any ATX/E-ATX case with >=8 PCIe slots) or second hand server chassis.
  - Power supply: >=1600W platinum, depending on GPU
- why should the pc case have over 8 PCIE slots?
  - 4 x dual slot GPUs lead to 8, you can go standard ATX case with 7 slots if you only need dual GPUs.
  - For most single-socket modern server processors (Rome or later Epyc, Sapphire Rapids or later Xeon), 4 GPUs are a sweet spot. As the 80-128 PCIe lanes provided by server processor can adequately support 4 GPUs.

- If its for inference only i wouldnt put a lot of value on ECC, id prioritise ram speed . If youre going with threadripper pro it needs to be one of the top models to utilise the ram bandwith, if you cant afford those youll get more bang for your buck with a regular threadripper 

- For potable, Go to Mac Ultra M3 512 or await DGX Spark x2 EA

- I've been building systems for other people, sort of a "just-in-case" inference in a rugged case with 64-128gb vram, preloaded with models and data (wikipedia, army trauma medic guides, etc), and literally solar powered. Some customers have particular power budgets, so I'm not necessarily aiming for highest tok/s but lowest power per token/s or lowest idle power. It's not exactly in big demand, but I can speak more about it if there's interest..

- ## ðŸŒ° [AMD EPYC mini-ITX build : r/sffpc _202207](https://www.reddit.com/r/sffpc/comments/w81afy/amd_epyc_miniitx_build/)
  - Case: Streacom DA2 V2, 340 x 286 x 180mm, 17.5L
  - Motherboard: Asrock ROMED4ID-2T
  - CPU: AMD EPYC 7443P, 24 Core, 48 Thread
  - RAM: 4x 64GB DDR4 PC4-25600 3200MHz LRDIMM ECC
  - PSU: Corsair SF Series SF600 SFX 600W
  - Boot SSD: Micron 3400 512GB NVMe M.2
  - Storage SSD: Samsung PM1723b 15.36TB NVMe U.2
  - CPU Cooler: Noctua NH-D9 DX-3647 w/ NM-AFB7b bracket for SP3
  - Exhaust Fan: Noctua NF-A9
  - Side Intake Fan: Noctua NF-F12
  - M.2 Cooler: Sabrent SB-HTSK
  - U.2 Cable: HighPoint Slim SAS SFF-8654 to 2x SFF-8639
  - TPM: Asrock TPM2-SLI
- About $5650 USD new, plus the cost of the bracket which I couldn't find. OP mentioned they bought the SSD slightly used, so probably closer to $5500

- With that PSU where it is, is it even possible to fit a GPU in there?
  - It's all been measured, 2x 40Gbps QSFP+ card is coming later

- Those are some absolutely eye watering specs (24 cores, 256gb, and a 15.36 TB ssd, I'm so jealous lmao). Truly a cut above. It's so cool to see enterprise hardware crammed into a boutique SFF.

- Only ASRock would make a mini ITX SP3 motherboard
  - Asrock rack is a true miracle, at least when I did my epyc server build, it was the only company that was selling mobos for epyc that wasn't stupidly overpriced, or required you to at least buy a barebones server (looking at you supermicro).

- Does epyc have igpu?
  - No, but the motherboard has a basic onboard GPU

- [AMD EPYC mini-ITX home hypervisor : r/homelab _202207](https://www.reddit.com/r/homelab/comments/w81bxe/amd_epyc_miniitx_home_hypervisor/)
- Some of the best features of Epyc are wasted in this configuration though. PCIE lanes, 8 channel memory etc..

- What is the power requirement for that?
  - The verdict @ 240V AC (I'm in the UK): 60-70W idle and 235W maxed out

- [å¦‚ä½•åœ¨æœ¬åœ°éƒ¨ç½²DeepSeek-R1æ¨¡åž‹ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/10630134422/answer/89240187608)
- å›½å¤–è¿™ä¸ªåšä¸»Matthew Carrigan æä¾›äº†åœ¨æœ¬åœ°è¿è¡Œ Deepseek-R1 çš„å®Œæ•´ç¡¬ä»¶å’Œè½¯ä»¶é…ç½®ï¼Œæˆæœ¬å·®ä¸å¤šæ˜¯6000ç¾Žå…ƒï¼Œtokençš„outputå¤§æ¦‚åœ¨6-8ä¸ªæ¯ç§’ã€‚
- æ³¨æ„ï¼šè¿™æ˜¯çº¯CPUç‰ˆæœ¬ï¼ŒGPUç‰ˆæœ¬å¾—10ä¸‡ç¾Žå…ƒ+ï¼Œæ‰€ä»¥ä¹Ÿå¯ä»¥ç†è§£ä¸ºç©·é¬¼å¥—é¤ã€‚
  - ä¸»æ¿ï¼šæŠ€å˜‰MZ73-LM0/LM1ï¼ˆåŒè·¯EPYCæ’æ§½ï¼Œè§£é”24é€šé“DDR5å¸¦å®½ï¼‰
  - å¤„ç†å™¨ï¼šåŒè·¯AMD EPYC 9004/9005ç³»åˆ—ï¼ˆæŽ¨è9115/9015ï¼Œæ€§ä»·æ¯”ä¹‹é€‰ï¼‰
  - å†…å­˜ï¼š24Ã—32GB DDR5-RDIMMï¼ˆæ€»é‡768GBï¼Œå¿…é¡»å æ»¡24é€šé“ï¼
  - å‚è€ƒåž‹å·ï¼švColor/Neumaxï¼‰
  - æœºç®±ï¼šEnthoo Pro 2 Serverç‰ˆ(æ”¯æŒæœåŠ¡å™¨ä¸»æ¿å®‰è£…çš„æ¶ˆè´¹çº§æ–¹æ¡ˆ), 240 x 580 x 560 mm, 77L
  - ç”µæºï¼šå®žæµ‹åŠŸè€—<400Wï¼Œä½†éœ€åŒCPUä¾›ç”µã€‚æµ·ç›—èˆ¹HX1000iä¸ºç¨³å¦¥é€‰æ‹©ï¼ˆå…¼å®¹åž‹å·å¯å¹³æ›¿ï¼‰
  - æ•£çƒ­ï¼šSP5æ’æ§½éœ€ç‰¹æ®Šæ•£çƒ­å™¨ï¼ˆEbay/Aliexpressä¸“ä¾›åž‹å·å®žæµ‹å¯ç”¨ï¼‰ï¼Œé™éŸ³æ”¹é€ æ–¹æ¡ˆè§Newegg
  - å­˜å‚¨ï¼š1TB+ NVMe SSDï¼ˆ700GBæ¨¡åž‹åŠ è½½è€ƒéªŒæŒç»­è¯»å†™ï¼ŒPCIe4.0ä¸ºä½³ï¼‰
  - BIOSè®¾ç½®ï¼šNUMAç»„æ•°é‡è®¾ä¸º0 â†’ å†…å­˜å…¨äº¤é”™è®¿é—® â†’ åžåæ€§èƒ½ç¿»å€

- ## [Is quad channel simply 4 sticks of ram together? | guru3D Forums _201203](https://forums.guru3d.com/threads/is-quad-channel-simply-4-sticks-of-ram-together.360222/)
- No, dual channel and quad channel are different.
  - To put this very simply, think of it like a road, dual channel gives you 2 lanes and quad channel gives you 4 lanes. This enables twice the traffic (data) to be sent because you've doubled the number of lanes (channels) the traffic can use to get where it's going.
  - For memory to work in dual channel you need a pair (or 2 pairs) of memory sticks and for quad channel you need 4 memory sticks (or 8 if there will be any motherboards that support 8 sticks?)

- but as you know lga775 and 1155 for eg have 4 dimm slots so if you put in 4 sticks of ram why is that still dual and not quad channel?
  - That's because it's what's supported by the chipset. X79 will be able to run quad channel, just like my x58 chipset supports tri channel and your x48 chipset only supports dual channel.
  - Just because you have 4 dimm slots doesn't mean you can run quad channel.

- quad is not just 4 sticks.

- ## [Memory Channels: Single, Dual, Triple, and Quad Channel Memory](https://storedbits.com/types-of-memory-channels/)
- Memory channels matter mainly for bandwidth and not directly the speed. It also doesnâ€™t double your RAM size â€” but it can double the bandwidth, meaning more data can travel at once. That helps especially in tasks like gaming, video editing, or multitasking.

- What is a Memory Channel?
  - The CPU connects to the memory through a pathway. It is a dedicated data path between the CPU (or memory controller) and RAM modules (DIMMs). On the physical level, it is composed of copper traces (wires) etched into the motherboard, connecting the CPU socket (specifically, the memory controller) to the RAM slots (DIMMs).

- ## [ä¸ºä»€ä¹ˆAMDéœ„é¾™EPYCæœ€å¤šåªæ”¯æŒåŒè·¯è¿è¡Œï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/7936434502)
- å¤„ç†å™¨ä¹‹é—´æ˜¯éœ€è¦é«˜é€Ÿä¿¡å·äº’è”çš„ï¼Œæ¯ä¸ªéƒ½è¦å’Œå…¶ä»–æ‰€æœ‰å¤„ç†å™¨æœ‰ç›´æŽ¥è”ç³»çº¿ï¼ˆå¦åˆ™å°±å‡†å¤‡å¥½å»¶è¿Ÿçˆ†è¡¨å§ï¼‰ã€‚åŒè·¯åªè¦ä¸€æ ¹è”ç³»çº¿ã€‚å››è·¯éœ€è¦6æ ¹ã€‚å…«è·¯éœ€è¦ã€‚ã€‚ã€‚ã€‚æ¯ä¸ªuå’Œå…¶ä»–7ä¸ªä¸€æ ¹ï¼Œ8*7æ ¹ï¼Œç”±äºŽAåˆ°Bå’ŒBåˆ°Aé‡å¤è®¡ç®—äº†ï¼Œé™¤ä»¥2ï¼Œå¾—åˆ°28æ ¹ã€‚è¿™äº›è¿žæŽ¥çº¿éƒ½æ˜¯å’Œå†…å­˜å¸ƒçº¿ä¸€ä¸ªéš¾åº¦çš„é«˜é€Ÿä¿¡å·çº¿ï¼Œè€Œä¸”ç”±äºŽCPUæ’åº§çš„ç‰©ç†å°ºå¯¸å·¨å¤§ï¼Œè¿™äº›ä¿¡å·çº¿è¿˜ä¸å¾—ä¸å˜å¾—æžé•¿ï¼Œå¹¶ä¸”8è·¯å¸ƒçº¿å‡ ä¹Žæ— å¯é¿å…åœ°è¦ä¸Žå†…å­˜å¸ƒçº¿å‘ç”Ÿå†²çªï¼Œä»¥è‡³äºŽæ ¹æœ¬æ²¡åŠžæ³•æŽ§åˆ¶ä¸»æ¿çš„æˆæœ¬ã€‚ 

- å› ä¸ºOEMåŽ‚å®¶éƒ½åé¦ˆ 4è·¯ï¼Œå…«è·¯ç³»ç»Ÿï¼Œå…¨çƒä¸€å¹´å–ä¸å‡º100å¥—ã€‚

- éœ„é¾™å•ç‰‡å¤„ç†å™¨å°±æ˜¯åäºŒé€šé“äºŒåå››æ¡å†…å­˜ï¼Œä¿©å¤„ç†å™¨å°±æ˜¯å››åå…«æ¡
  - å•ä¸ªå¤„ç†å™¨å°±æ˜¯128æ¡pcieé€šé“ï¼Œä¸¤ä¸ªå°±æ˜¯256æ¡ï¼Œå“ªæ€•å…¨å¡žéƒ½èƒ½å¡ž32ä¸ªï¼Œå¦‚æžœåšæˆå¸¸è§„pciex16æŽ¥å£èƒ½å¡ž16æ ¹ï¼Œä¸€èˆ¬æ˜¯ä¸ä¼šé…ç½®è¿™ä¹ˆå¤šx16
  - å†å¤šâ€¦â€¦ä¸»æ¿å¡žä¸ä¸‹å•Šï¼Œéœ„é¾™çš„è®¾è®¡æœ¬æ¥å°±æ˜¯å•å¤„ç†å™¨å¡žæµ·é‡æ ¸å¿ƒå’Œæµ·é‡æ‰©å±•ï¼Œå¤šccdè®¾è®¡å®ƒå•ä¸ªå¤„ç†å™¨å°±ç±»ä¼¼å¤šè·¯å¤„ç†å™¨äº†

- ## ðŸ’¡ [Local LLM Build with CPU and DDR5: Thoughts on how to build a Cost Effective Server : r/LocalLLaMA _202505](https://www.reddit.com/r/LocalLLaMA/comments/1kjvo1t/local_llm_build_with_cpu_and_ddr5_thoughts_on_how/)
  - DDR5 RAM: 576GB (4800MHz, 6 lanes) - Total Cost: $3, 500(230.4 gb of bandwidth)
  - CPU: AMD Epyc 8534p (64-core) - Cost: $2, 000 USD
  - 8xx Gen EPYC CPUs: Chosen for low TDP (thermal design power), resulting in minimal monthly electricity costs.
  - ASUS S14NA-U12 (imported from Germany) Features include 2x 25GB NICs for future-proof networking.
  - qwen3:32b-fp16: 1.14 tokens/s
  - qwen3:235b-a22b-q8_0: 2.70 tokens/s
  - deepseek-r1:671b_1.58bit: 3.26 tokens/s

- Older EPYC models (e.g., 9124) offer a balance between PCIe lane support and affordability.

- The GPU could be used to run attention layers and host kv cache. llama.cpp's -ot 'ffn=CPU' (or -ot 'exps=CPU' for MoE) is worth a try.

- While the hexa-channel DDR5 4800MHz configuration provides similar bandwidth to Epyc Milan's 8x 3200MHz DDR4 (204.8GB/s), Zen4 (c) might offers faster prefill performance due to AVX512 support.
  - You might want to offload MoE tensors using: `--override-tensor 'blk\.\d?\d\.ffn_.*_exps.weight=CPU'`

- Additionally, frameworks like ktransformers or ik-llamacpp are optimized for CPU-GPU hybrid inference.

- In China, there are OEM server processor options that offer comparable pricing to entry-level models while delivering significantly better prefill performance than 16-core alternatives. Notable affordable options include:
  - - **Intel**: Xeon 8455C (48C SPR 8xDDR5 4800MHz ~Â¥6, 000), 8481C (56C SPR ~Â¥7, 500), 8581C (60C EMR 8xDDR5 5600MHz ~Â¥9, 000)
 - **AMD**: Epyc 7B13 (64C Zen3 8xDDR4 3200MHz ~Â¥3, 800), Epyc 9v74 (80C Zen4 12xDDR5 4800MHz ~Â¥8, 500)
  - Beyond OEM models, the Epyc 9375F (32C Zen5 12x6000MHz) offers exceptional single-core performance and memory bandwidth, making it better for some tasks. 
- When comparing Intel and AMD platforms:
  - Intel's advantage lies in AMX instructions for prefill acceleration
  - AMD offers 12-channel DDR5 bandwidth and more PCIe lanes for multi-GPU setups

- ## ðŸ†šðŸ“Œ [Memory Bandwidth Comparisons - Planning Ahead : r/LocalLLaMA _202402](https://www.reddit.com/r/LocalLLaMA/comments/1amepgy/memory_bandwidth_comparisons_planning_ahead/)
- Epyc actually has 12 channels of ram. The latest 9004 series has 460.8 GB/s. Threadripper is the one that comes with quad and octa channel variants.
  - Note: The upcoming Epycs(zen 5) are supposed to have even more bandwidth due to the new out-of-the-box ram speed being 6000mhz instead of the current 4800mhz
- 6000 MT/s would be nice, giving 4090-like memory bandwidth over 24 channels in a 2P system, but with a minimum of 384GB instead of a maximum of 24GB. That's assuming all else is equal/negligible, which isn't quite the case.
- Yeah, an ideal environment for sparse MoE like Mixtral

- Lpddr5x at 120gb/s I have a core ultra 7 155h with lpddr5 at 100gb/s. You can ask me for some tests if you want

- Is there any reason that regular consumer motherboards can't support quad or 8 channel RAM? I feel like if we can have 8 channels DDR6, we'd be at around 600 to 800GB/s, which is very similar to gpu vram speeds. Maybe this is what we should ask AMD to do instead of GPU's with 46gb or 96gb RAM for consumers at reasonable prices.
  - It would normalize everyone potentially having great bandwidth for local inference, wouldn't require a GPU at all, and would basically explode the number of devices that could locally inference at reasonable speed. This would open the flood gates for local llm's - open or closed source, because now everyone and their grandma would be able to use it effectively.
  - And unlike GPU's, you'd never be limited by how many GB's of RAM you want to install, and therefore not be dependent on NVIDIA (or whomever) to hopefully one day release a card with more VRAM. The power would go back to consumer. And the bandwidth would double again for DDR7 and so on.
  - I just don't know if putting quad or 8 channels on a motherboard is somehow difficult and can only done at high price to the consumer, which is why only pro-sumer or server level mobos do it.
- They could, but the main limiting factor is the memory controllers are on the CPU. Intel, AMD, and the others use number of channels as a market segmentation method. But ultimately it boils down to memory channels equal $$.

- The bandwidth numbers for the Apple M1/2/3 SoC are just the raw totals from the memory, but depending one which cluster is using it (P-cores, E-cores, GPU) they have their own limitations. Here is the explanation for the M1 series
  - On the M1 Max with 400GB/s the CPU can get maximum 204GB/s when using the P cores only or 243GB/s when using both the P and E cores.

- ## âš¡ï¸ðŸ“ŠðŸ“Œ [æœ‰äººå¯ä»¥åšä¸€ä¸ªepycæœåŠ¡å™¨CPUçš„å¤©æ¢¯æ¦œå—ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/596966739)
- cpu, cinebench-r23, pricing
  - AMD Ryzen 9 7900x, 3.0w, 2469
  - AMD Ryzen 5 7500F, 1.4w, 938
  - AMD EPYC 7742/7B12, 5w, 6k
  - AMD EPYC 7552, 4.4w, 6k
  - AMD EPYC 7702, 4.9w, 7k
  - AMD EPYC 7b13/7c13/7v13/7763/7j13, 6.1w, 5850
  - AMD EPYC 9V74, 10.5w, 1.2w 
  - AMD EPYC 9654 ES, 11w, 1w 

- [AMD Server Processor Specifications](https://www.amd.com/en/products/specifications/server-processor.html)

- [Ryzen Threadripper - AMD - WikiChip](https://en.wikichip.org/wiki/amd/ryzen_threadripper)
  - ðŸŽ¯ zen2(2019):
    - [Template:AMD Epyc 7002 series - Wikipedia](https://en.wikipedia.org/wiki/Template:AMD_Epyc_7002_series)
  - ðŸŽ¯ zen3(202103): uni epyc 7313p/7443p/7543p/7713p; 
    - multi epyc 7313/7343/7443/7543/7713/7763
    - EPYC 7003 "Milan"
    - 8 channels per socket, up to 16 DIMMs, max. 4 TiB
    - Up to PC4-25600L (DDR4-3200)
    - [Zen 3 - Wikipedia](https://en.wikipedia.org/wiki/Zen_3)
    - [Template:AMD Epyc 7003 series - Wikipedia](https://en.wikipedia.org/wiki/Template:AMD_Epyc_7003_series)
  - ðŸŽ¯ zen4(202211): uni epyc 9354P/9554p/9654p; 
    - multi epyc 9124/9174F/9224/9254/9454/9634/9654
    - lp/edge: 8324p/8324pn/8434p/8534p
    - EPYC 9004 "Genoa": 12 channels per socket, two 40-bit (32 data, 8 ECC)
    - DDR5 subchannels per channel
    - Up to 24 DIMMs, max. 6 TiB
    - Ryzen 7000 "Raphael"
    - 9124: 16-core (32-threads), 4 Ã— CCD, I/OD, Base Clock3.0GHz, DDR5-4800, p-200w
    - 9224: 24-core (48-threads), 4 Ã— CCD, I/OD, Base Clock2.5GHz, DDR5-4800, p-200w
    - 9254: 24-core (48-threads), 4 Ã— CCD, I/OD, Base Clock2.9GHz, DDR5-4800, p-220w
    - EPYC 4004: 16 AMD â€Zen 4â€ cores, 32 threads, an L3 cache of 128MB, DDR5 memory support, and 28 PCIeÂ® 5 lanes
      - Max DDR5 Freq (MHz) (1DPC): 5200
      - EPYC 4004 is just a rebrand of the Ryzen 7000 series, designed to make it clearer about ECC support mainly.
    - [Zen 4 - Wikipedia](https://en.wikipedia.org/wiki/Zen_4)
    - [Template:AMD Epyc 9004 Genoa - Wikipedia](https://en.wikipedia.org/wiki/Template:AMD_Epyc_9004_Genoa)
  - ðŸŽ¯ zen5(202411): uni epyc 9015p/9125p/9355p/9755p
    - multi epyc 9005/9015/9115/9125/9175F/9335/9665/9755F
    - The series offers core counts ranging from 8 cores to 192 cores, 
    - with support for up to 12 channels of DDR5-6000 memory (up to 6 TiB per socket) and 128 PCIe 5.0 lanes
    - [Template:AMD Epyc 9005 series - Wikipedia](https://en.wikipedia.org/wiki/Template:AMD_Epyc_9005_series)
    - [Template:AMD EPYC 9000 Series - Wikipedia](https://en.wikipedia.org/wiki/Template:AMD_EPYC_9000_Series)

- [å¦‚ä½•è¯„ä»·AMD EPYC 7B13, 7K83, 7T83, 7763? - çŸ¥ä¹Ž](https://www.zhihu.com/question/542414897)
  - è¿™äº›éƒ½æ˜¯7763çš„é©¬ç”²ï¼Œå¦å¤–è¿˜æœ‰7J13ï¼Œ7V13ç­‰ç­‰ã€‚ã€‚ã€‚ã€‚å¯èƒ½é¢‘çŽ‡è®¾ç½®ä¸Šç•¥æœ‰ä¸åŒï¼ŒTDPä¹Ÿéƒ½æ˜¯280Wï¼ŒåŸºæœ¬ä¸Šæ»¡è½½æ€§èƒ½æ˜¯å·®ä¸å¤šçš„ã€‚
  - å„ç§äº‘çš„å®šåˆ¶ç‰ˆï¼Œäº‘åŽ‚å•†æœ‰åŠŸè€—ï¼Œæ€§èƒ½çš„éœ€æ±‚ï¼Œamdå°±å¸®ä»–ä»¬å®šåˆ¶

- æ€§èƒ½çœŸå¼ºï¼Œè¯´èµ·æ¥7r13æœ€è¿‘å¥½åƒé™ä»·äº†ï¼Œæ„Ÿè§‰å¥½åƒæ¯”7c13è¿˜å¼ºç‚¹ã€‚

- EPYCæœåŠ¡å™¨åŸºæœ¬ä¸Šä¸éœ€è¦è°ƒä¼˜ï¼Œ7003è¿˜æœ‰NPSè®¾ç½®ï¼Œ9004å¼€å§‹å°±æ²¡æœ‰äº†ï¼Œå†…å­˜é¢‘çŽ‡åªéœ€è¦è‡ªåŠ¨ï¼Œè‡ªå·±è°ƒé«˜å¿…è“å±ã€‚

- epycå¾ˆå¤šéƒ½æ˜¯ç”¨æ¥è·‘cfdçš„ï¼Œç”¨è¿™ç§è·‘åˆ†è½¯ä»¶å¾—å‡ºçš„ç»“è®ºå®Œå…¨æ˜¯é”™çš„ã€‚éƒ½æ˜¯ç”¨openfoamåšbenchmarkå¯¹æ¯”ï¼Œåˆ«è¯´7950xäº†ï¼Œæˆ‘çš„9950xå’Œæˆ‘çš„epycå·¥ä½œç«™æ¯”èµ·æ¥ï¼Œéƒ½è¢«ç§’åˆ°æ¸£éƒ½ä¸å‰©

- epycç³»åˆ—çš„CPUï¼Œæ ¹æœ¬ä¸éœ€è¦åšå¤©æ¢¯å›¾ï¼Œæ€§ä»·æ¯”æœ€é«˜çš„åº”è¯¥å°±æ˜¯7ï¼Ÿ83ï¼ˆ7T83ã€7W83ç­‰ï¼‰ã€‚1wå‡ºå¤´å°±èƒ½æ‹¿ä¸‹æ¿+64æ ¸Uã€‚

- [EPYCæˆ–çº¿ç¨‹æ’•è£‚è€…æˆ–XEONæœ‰æ²¡æœ‰å•æ ¸æ€§èƒ½å¼ºåˆå»‰ä»·çš„U? - çŸ¥ä¹Ž](https://www.zhihu.com/question/1947237447466464324)
  - ç›®å‰æ˜¯çœ‹äº†q30h/q2t7å’Œms03è¿˜æœ‰256g då†…å­˜ï¼Œé¢„ç®—åˆšå¥½å¡çš„å¾ˆæ­»ï¼Œä¸çŸ¥é“æœ‰æ²¡æœ‰å•¥æ›´ä¼˜çš„é€‰æ‹©

- ## [I want a compact case. But the question is the motherboard Mini ITX there is 2 channels of RAM. 16+16 and 8+8+8+8 what is the difference in performance? : r/buildapc _202508](https://www.reddit.com/r/buildapc/comments/1msjal1/i_want_a_compact_case_but_the_question_is_the/)
- They're both dual channel. The four module configuration has two DIMMs per channel (2DPC). That config puts more stress on the memory controller, usually leading to slower speeds or reduced stability.

- ## [DDR5 2 vs 4 sticks, different speeds, same bandwidth? Confused : r/overclocking _202502](https://www.reddit.com/r/overclocking/comments/1ih0rfe/ddr5_2_vs_4_sticks_different_speeds_same/)
- 4 sticks will still run in dual channel. So 4x sticks @3600 will always be much slower than 2x sticks @6000
  - There are thousand of posts like this one Every week.
  - Just return 2x sticks or all 4x and just get 2x48 6000-6400MTs if you need high capacity & speed

- 2 sticks is the same bandwidth as 4 because each channel shares 2 lanes. Youâ€™re only getting half the bandwidth on each stick with 4. Not really all that much to it.

- ## [do you think i could run the new Qwen3-235B-A22B-Instruct-2507 quantised with 128gb ram + 24gb vram? : r/LocalLLM _202507](https://www.reddit.com/r/LocalLLM/comments/1m5wgcg/do_you_think_i_could_run_the_new/)
  - i am thinking about upgarding my pc from 96gb ram to 128gb ram. do you think i could run the new Qwen3-235B-A22B-Instruct-2507 quantised with 128gb ram + 24gb vram? it would be cool to run such a good model locally

- The old qwen3 235b model ran, at UD-Q4_K_XL, on my system with a R9 7950x and 96gb ram and a 4090 with 24 gb vram. ~5 t/s once it was warmed up. Processing speed was about the same though (X_X).
  - That's the best I got, so far. I tried a few different off-loading strategies, but just offloading to cpu for most of it and MMAPing the file was what did the best on my system with its constraints.

- You should be able to run the Q4 with that. How fast will it be will depend on what speed RAM you have.

- Someone ran qwen235b at iq4 on 2 sticks of 64gb ddr5 5600 with 3.5-4 tokens/s on cpu only (7950X).

- two amd mi50 & 128 gb ddr5 could gen 7 t/s With Qwen235b-Q4

- ## [How large models can I run with 128GB RAM? : r/LocalLLaMA _202405](https://www.reddit.com/r/LocalLLaMA/comments/1cjtzft/how_large_models_can_i_run_with_128gb_ram/)
  - I currently have 16GB VRAM and 32GB RAM. I would be fine upgrading to 128GB RAM.
  - I can run 8B/13B-models without issues. Can I run larger models if I upgrade to 128GB? I would want to avoid buying more RAM unless it has any effect.

- I get 1.9 tokens/sec generation speed on wizardlm2 8x22b q5_k_m 128gb quad channel ddr 4 2133. No offloading to gpu.

- Adding more RAM will just allow you to run larger models ...on the CPU, which will be incredibly slow.

- ## [Mini-PC Dilemma: 96GB vs 128GB. How Much RAM is it worth buying? : r/LocalLLaMA _202509](https://www.reddit.com/r/LocalLLaMA/comments/1nmlluu/minipc_dilemma_96gb_vs_128gb_how_much_ram_is_it/)
  - I'm planning to pick up one of the new mini-PCs powered by the AMD Ryzen AI Max+ 395 CPU, specifically the Bosgame M5. The 96GB RAM model looks more cost-effective, but I'm weighing whether it's worth spending ~15% more for the 128GB version.

- Get the 128 GB one. It's soldered RAM so not upgradable.
- Under Linux, you can use all the RAM with the GPU at full speed (215 GB/s).
  - That means qwen 235B A22B at Q3_K_XL at 15 tokens per second at 54 Watts.
- The ability to run up to 120 GB MoE models is likely to be increasingly useful as more are released.
  - It's also possible to run other models in Comfy UI but slow and unstable. This may improve when AMD makes rocm less uncompetitive with cuda.

- I have a pc with 192GB and I would use 256 if I would have purchase 4x64 instead. I run huge model (like DeepSeek-V3.1-UD-TQ1_0.gguf) on a 3090 + 172gb pc ram (ddr5) and I can get 'decent' around 3T/s, which I find acceptable since I can configure many parameters.
  - If you use GGUF versions of a model, you don't need 'pc' ram to be dedicated as a gpu, since the model can put part of the model on the pc ram by itself.

- ## ðŸ†š [Any downside to having 128GB of RAM on two 64GB sticks? : r/buildapc _202510](https://www.reddit.com/r/buildapc/comments/1nyso1u/any_downside_to_having_128gb_of_ram_on_two_64gb/)
  - should I split it into four 32GB sitcks or get two 64GB sticks? Is there a difference to performance? 
  - The specific product I am looking at is: Corsair Vengeance 128 GB (2 x 64 GB) DDR5-6400 CL42 Memory
  - I could get 4 32GB sticks instead. But I read that DDDR5 RAM doesn't play well on AM5 if all 4 sticks are utilized.(AM5 is the latest CPU socket from AMD for their Ryzen 7000, 8000, and 9000 series desktop processors, replacing the long-lived AM4 socket)

- You likely won't be able to run four sticks at 6400MHz, but there's a higher chance you will with two. It depends on your CPUs memory controller. I have 4x32GB 6000 CL30 and I regret not getting 2x64GB. You live and you learn, I guess.

- Much better performance-wise on two sticks than four for DDR5. Downside is lighter wallet lol

- You can buy a motherboard with 4 slots and only populate two of them. Dual slots ATX mobo are very rare
  - I have built and bought parts for at least a dozen pcs and i am pretty sure i have never seen a motherboard with 2 slots in my life
- Itâ€™s much more common in ITX boards though.
  - Only itx and ultra cheapo boards have 2 slots.
- All mini-ITX form factor board, a good chunk of the lowest end budget boards (ie stuff like A620 boards generally intended for low power office machines, that kind of thing), and a tiny few extremely high end OC boards (two slots to use larger traces and maximize stability at extreme OCs). You can just set the number of slots to 2 on PCPartPicker to see.

- If only people listened to Apple, and just accept whatever memory came on the device when they bought it
  - Shit, big Repair got to him in the middle of his sentence

- Maybe look into 2x48GB: 6000MT/s CL30 isn't extortionately priced.
  - 2x48 is your best bet. You won't have any performance penalties with that setup. 2x48 is no harder on the memory controller than 2x32.
  - I wouldn't take the performance hit of 128GB of RAM, when 96GB works so well. Unless you really need it, that is. I use my PC as a workstation for processing drone imagery into orthomosaic maps and 64GB is enough for mapping up to 150 acres. OpenDroneMap is pretty damn RAM hungry.
  - If you really need 128GB, you should still stick to 2 DIMMs. 2x64 is going to be much easier to get working and perform better than 4x32.

- 2 sticks have better performance than 4 sticks.

- As others are saying, dual channel is going to be significantly more stable (as opposed to 4x32).
  - If youâ€™re just tinkering and have the funds, there are boards that support 196GB. Or you could jump up into professional stuff and go for 256GB.
  - All of this is assuming DDR5.

- There's not any specific significant downside, but some motherboards may not support a RAM with 64 GB per stick without a BIOS update.
  - those 64 GB sticks are slower than 32 GB sticks (6000 CL30 > 6400 CL42), as small as it might be.
  - If your PC is AM5, 6400 is highly not likely to boot with 1:1 setting. There's also going to be longer RAM training initially but that's just one time thing.
  - 99% of AM5 CPUs support 6000 at 1:1 speed, but any higher than that, the chance lowers noticeably, and 6400 1:1 is a crap shoot. It doesn't help it's a high-capacity 64 GB, dual rank stick, which puts even more stress on to the memory controller.
  - It's just the way AM5 CPU memory controllers roll. There's a G. Skill 128 GB set (2x 64GB) that is EXPO certified, at 6000 CL32, 34, or 36 that you can get instead. I have the CL34 one, then tightened RAM timings to get it down to 32-40-40-76.

- Most consumer motherboards are going to be duel channel RAM, which means there's only 2 lanes between the RAM and CPU. Duel channel motherboards with 4 RAM slots will have 2 slots share a lane, so in most cases you will get more performance out of 2 sticks then 4, as long as you follow the instruction in the manual and use the slots it tells you to put the RAM in (Often A2 and B2, but can be board specific).
  - Worth keeping in mind a lot of CPU/motherboards don't seem to like running large amounts of RAM at higher speeds, so while it might be rated for 6400MHz you might have to run it at 6000, so if there's a cheaper 6000MHz kit, especially one with a lower latency (CL42 part of the product you listed) I'd probably go for that. Having a quick look it seems common for CL40+ on 128GB kits though.
  - If you must have 128GB, look at something like the G. Skill Flare X5 128 GB (2 x 64 GB) DDR5-6000 CL32 Memory for lower latency, though depending on where you are lower latency kits might not be available. I can see a few CL32 128GB kits available on US pc part picker, but the lowest it shows in stock for the UK is CL34, still be an improvement over CL42.

- for some reason, 2x48gb 6400 CL32, is relatively easy to find
  - but once you go for 2x64gb, it's hard to find good timings.

- it's possible to get even 256GB of DDR5 to run on AM5, so 128GB should be no problem.. not at the same speeds you'll get with the "generic gaming choice of 32GB", ofc, but still.

- if you want 6400MHz, shoot for CL32
  - I believe that is the correct spread change for DDR5 above 6000MHz CL30

- I got 4 sticks CL30 Corsair Vengeance 4 x 32, could not get >5200Mhz stable with MSI Mag 870E + 9950x3D. Though running benchmarks, I ended up staying with this config instead of 2x48 @ 6000. There was negligible difference in any of my workloads, for work or for play, but I did benefit from the at the time, very drastic price difference, and the additional ram is useful in my use-cases.

- Why stop at 128gb when you can now do 256gb 6000MT? See Level1Techs video from 2 weeks ago.

- ## [æ±‚æŽ¨èmATXéžä¾§é€æ•£çƒ­å¥½çš„æœºç®± - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/688e90bf00000000250132d4?xsec_token=ABB5_uSFZrF4Fb2p-cIYUQAnzEybe1BZQKTuCoX9z-RXw=&xsec_source=pc_search&source=unknown)
- çœ‹æ ‡é¢˜ç¬¬ä¸€ååº”å°±æ˜¯è¿½é£Žè€…xtm3äº†ï¼Œæ°´å†·å¯ä»¥é€‰åŽç¡•çš„é‚£ä¸ªï¼Œé£Žå†·å¯¹é£Žé“è¦æ±‚é«˜åªæœ‰è¿½é£Žè€…åˆé€‚äº†ã€‚
  - å¦‚æžœä½ çš„é…ä»¶éƒ½æ˜¯æ— å…‰çš„ï¼Œä¹Ÿæ— æ‰€è°“éžä¾§é€äº†

- é…·å†·è‡³å°Š MASTERBOX NR200 ðŸ“Œ
  - [æœºç®±_äº§å“_é…·å†·è‡³å°Š - NR200](https://www.coolermaster.com.cn/product_detail/335.html)
  - 185x292x376mm, 20.3L 
  - æ”¯æŒæ˜¾å¡å°ºå¯¸ 330x156x60mm

- [ASUS Prime AP201 MicroATX Caseï½œæ©Ÿæ®¼ï½œASUS é¦™æ¸¯](https://www.asus.com/hk/motherboards-components/cases/prime/asus-prime-ap201-microatx-case/)
  - 33 å…¬å‡çš„æ™‚å°š MicroATX
  - å¯å®¹ç´ 360 mm æ°´å†·æ•£ç†±å™¨ã€é•·é” 338 mm é¡¯ç¤ºå¡åŠæ¨™æº– ATX é›»æºä¾›æ‡‰å™¨

- ## [æœ‰æ²¡æœ‰å•æ¡64Gæˆ–è€…æ›´é«˜çš„å†…å­˜æ¡ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/518047029)
- æ™®é€šçš„DDR4å†…å­˜å•æ¡32Gåˆ°é¡¶ï¼Œè¦æœåŠ¡å™¨ç”¨çš„RECCå†…å­˜æœ‰å•æ¡256G, 512Gçš„ï¼Œå½“ç„¶ï¼Œä»·æ ¼ç¾Žä¸½ï¼Œä¸”éœ€è¦ä¸»æ¿æ”¯æŒ
- æ™®é€šæ¡ä¹Ÿæœ‰64g
  - ddr4 æœ‰ï¼Œddr5ä¸ç¡®å®šå› ä¸ºè¿˜æ²¡è§åˆ°

- ## [ä¸ºä»€ä¹ˆå¸‚é¢ä¸Šæ²¡æœ‰å•æ¡64Gçš„é«˜é¢‘DDR5ï¼ˆ8000MHzä»¥ä¸Šï¼‰ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/1932456730404587491)
- ä½ å†…å­˜é¢‘çŽ‡ä¸ŠåŽ»äº†ï¼Œä¸»æ¿å’ŒCPUè·Ÿä¸ä¸Šï¼Œç™½æ­
- 4æœˆä»½ï¼ŒèŠå¥‡å°±å‘å¸ƒäº†ä¸€æ¬¾DDR5-8000 128GBå†…å­˜å¥—è£…ï¼Œä¹Ÿå°±æ˜¯DDR5-8000 128GBï¼ˆ64GB x2ï¼‰ï¼Œæ—¶åºä¸ºCL44-58-58-127ï¼Œä¸è¿‡è¿™æ¬¾å†…å­˜æ¡æš‚æ—¶è¿˜æ²¡æœ‰ä¸Šå¸‚ï¼Œå±žäºŽç¬¬ä¸€æ¬¾64Gçš„DDR5-8000é¢‘çŽ‡å†…å­˜ã€‚
  - 4æœˆä»½ï¼ŒèŠå¥‡å°±å‘å¸ƒäº†ä¸€æ¬¾DDR5-8000 128GBå†…å­˜å¥—è£…ï¼Œä¹Ÿå°±æ˜¯DDR5-8000 128GBï¼ˆ64GB x2ï¼‰ï¼Œæ—¶åºä¸ºCL44-58-58-127ï¼Œä¸è¿‡è¿™æ¬¾å†…å­˜æ¡æš‚æ—¶è¿˜æ²¡æœ‰ä¸Šå¸‚ï¼Œå±žäºŽç¬¬ä¸€æ¬¾64Gçš„DDR5-8000é¢‘çŽ‡å†…å­˜ã€‚
  - çŽ°åœ¨DIYè£…æœºçš„ä¸»æµä¾ç„¶æ˜¯32Gï¼ˆ16x2ï¼‰DDR5 6000MT/såŠä»¥ä¸Šé¢‘çŽ‡å’Œ48Gï¼ˆ24x2ï¼‰DDR5 6000MT/sçš„å†…å­˜æ¡ï¼Œå³ä½¿ä½ åœ¨æŸäº›ç”Ÿäº§åŠ›ä¸Šé¢éœ€è¦ï¼Œä¹Ÿ64Gï¼ˆ32Gx2ï¼‰DDR5å°±å¾ˆè¶³å¤Ÿäº†ã€‚
  - æ­£å¸¸ä½ è¦æ˜¯AMDçš„è¯ï¼Œä¸Šå¥—6000MT/sçš„DDR5å°±å¯ä»¥ï¼Œè€Œè‹±ç‰¹å°”å¤„ç†å™¨çš„è¯ï¼Œå®žé™…ä¸Šå¥—6800MT/sçš„DDR5å°±å¯ä»¥ï¼Œæ‰€ä»¥ä¸ç”¨çº ç»“å¤ªå¤šã€‚

- äº‹å®žä¸Šå‘¢ï¼ŒGSK4æœˆä»½å°±å‘è¡¨äº†8000MHzçš„128GBå¥—è£…å’Œ64GBçš„DDR5-9000MHzç‰¹æŒ‘å¥—è£…ï¼Œç„¶è€Œå…·ä½“çš„ä¾›è´§å‘¢ï¼Ÿè¿˜æ˜¯é‚£äº›æ¸ é“æ‰æœ‰ï¼Œå®˜æ–¹ä¸ä¼šéšä¾¿ç»™ä»·æ ¼ï¼Œå¥½æ–¹ä¾¿ä»–ä»¬æ¼«å¤©è¦ä»·
  - 8000MHzè¶…é«˜å®¹é‡æ¯”6400sçš„è´µä¸€å€æˆ–è€…ä¸¤å€éƒ½æ˜¯æ¸ é“å•†ä»¬éšä¾¿å–Šã€‚
  - ä½ è¦æžè¿™ç§ä¸œè¥¿ï¼Œå…¶ä»–éƒ¨åˆ†å¯ä»¥å…ˆæ»¡ä¸Šï¼Œç„¶åŽåç­‰ä¸Šè´§ï¼Œæ¯•ç«ŸèŠå¥‡çš„æµ‹è¯•å¹³å°ç”¨çš„å°±æ˜¯ï¼š
  - å¤„ç†å™¨ï¼šIntel-265K/AMD 9950X3D
  - ä¸»æ¿ï¼šåŽç¡•çŽ©å®¶å›½åº¦MAXIMUS Z890 APEX
  - æ˜¾å¡ï¼šNV XPG RTX5090-24G

- ## [æ„Ÿè§‰åŽæ“Žçš„ä¸œè¥¿åšå·¥ç”¨æ–™éƒ½å¾ˆæ‰Žå®žå‘€ï¼Œä¸ºä»€ä¹ˆéƒ½è¯´æ˜¯äºŒçº¿ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/354822608)
- åŽæ“Žæ˜¯çŽ°åœ¨å…¬è®¤çš„å››å¤§å®¶ï¼Œæ‰€æœ‰çš„è·Ÿä¸»æ¿ç›¸å…³çš„è®¤è¯ï¼Œä¸€å®šæ˜¯ä¼šé€šè¿‡åŽæ“Žçš„è®¤è¯çš„ã€‚
  - åœ¨ç¡¬ä»¶æ”¯æŒä¸Šä¹Ÿä¸€ç›´ä¿ç•™è‡ªå·±çš„ç‰¹è‰²ï¼ŒæŽ¥å£å’Œè®¾è®¡ä¸Šä¸€ç›´éƒ½ç®—æ˜¯æ¯”è¾ƒå…¨ä¸”ç›¸å½“å‹å¥½çš„ã€‚
  - ä»–æœ€è¾‰ç…Œçš„æ—¶å€™åº”è¯¥æ˜¯2011å¹´ï¼Œå½“å¹´çš„é”€é‡å†²ç ´äº†1000ä¸‡ç‰‡ï¼Œè¾¾åˆ°å…¨çƒç¬¬ä¸‰ã€‚
  - å‰å‡ å¹´è·ŸåŽç¡•åˆ†æ‰‹å¯¼è‡´çš„é˜µç—›æ¯”è¾ƒä¸¥é‡ï¼Œä¸è¿‡è‡ªèº«äº§ä¸šè½¬åž‹å‡çº§å¾ˆå¿«ï¼Œæ¸ é“ä¸Šä¸å¤ªå¾…è§åŽæ“Žï¼Œä¸»è¦åŽŸå› æ˜¯ä¸èµšé’±ï¼Œæ²¡æœ‰è¡¥è´´åŠ›åº¦ï¼ˆæ·±æœ‰ä½“ä¼šï¼Œæ²¡æœ‰ä¼šè®®æ²¡æœ‰é’±â€¦â€¦ï¼‰
  - çŽ°åœ¨åŽæ“Žåœ¨å›½å†…çš„ä»½é¢åªæœ‰2.8%ï¼Œå±žå®žå¯æ€œï¼ŒåŸºæœ¬çœ‹ä¸åˆ°äº†ï¼Œè€Œä¸”åŽæ“Žä¸æŽ¥å—ä¸ªäººé€ä¿ï¼Œä¸»æ¿æ€§ä»·æ¯”æžä½³ï¼Œä½†é™¤éžæ˜¯äº¬ä¸œè‡ªè¥ï¼Œå¦åˆ™è‡ªå·±ä¹°ï¼Œå”®åŽå±žå®žéº»çƒ¦ã€‚
  - ä»£ç†å•†æ˜¯ä¸ç»™äºˆä»£ä¿çš„ï¼ˆæ¯”å¦‚å¤§ä»™ï¼Œä¸æ˜¯è‡ªå·±å‡ºçš„åŽæ“Žä¸»æ¿åäº†ï¼Œæ˜¯çœŸçš„ä¼šæ‹’ç»ä»£ä¿ï¼‰
  - ä¸è¿‡æ€»é”€é‡ä¾æ—§å¯è§‚ï¼Œå…¨çƒä¸»æ¿å‡ºè´§é‡åœ¨2018å¹´çš„æ—¶å€™æ˜¯400ä¸‡ç‰‡å·¦å³ï¼Œ2019å¹´å¥½åƒæœ‰æŽ¥è¿‘600ä¸‡çš„å‡ºè´§é‡ï¼ˆæ•°æ®å­˜ç–‘ï¼Œå› ä¸ºæ‰¾ä¸åˆ°ä¹‹å‰çœ‹åˆ°çš„æ•°æ®äº†ï¼‰ï¼Œç›¸å½“å¯è§‚ï¼Œé€†å¸‚å¢žé•¿é‚£ç§ã€‚
  - ä¿æŒå‡ºè´§ä¸è·Œçš„åªæœ‰å¾®æ˜Ÿå’ŒåŽæ“Žä¸¤ä¸ªå“ç‰Œã€‚
  - åŽæ“Žæ˜¯è¿„ä»Šä¸ºæ­¢ï¼Œæœ€å‹å¥½çš„å°æ¹¾ç³»å“ç‰Œå•†ä¹‹ä¸€ï¼Œä¸­æ–‡ç½‘ç«™è®¿é—®å’Œèµ„æ–™æœç´¢éƒ½æ˜¯æœ€å‹å¥½çš„ï¼Œè¯´å‡ºæ¥ä¸€èˆ¬äººéƒ½å¯èƒ½ä¸å¤ªç›¸ä¿¡ã€‚ã€‚

- åŽæ“Žæ”¯æŒä¸ªäººé€ä¿ï¼Œåªéœ€å‡ºæ¥å›žè¿è´¹

- æˆ‘ä¸ªäººæ„Ÿè§‰å…¶å®žå°±æ˜¯å”®åŽçŽ‡ï¼Œå”®åŽæ•ˆçŽ‡å¤ªæ‰¯æ·¡äº†ç‚¹ã€‚1æ‰€æœ‰ä¸»æ¿å”®åŽå¾—é€šè¿‡çœä»£èµ„æ ¼çš„æ‰‹å¯„åˆ°æ·±åœ³ï¼Œå†è¿”å›žæ¥ï¼Œå’Œå¾®æ˜Ÿæœ‰çš„ä¸€æ‹¼ã€‚
  - ä»ŽçŸ¿æ¿å°±å¯çœ‹å‡ºå”®åŽçŽ‡å¤ªé«˜ï¼Œå‰å‡ å¹´çŸ¿æ½®ä¹Ÿå°±å‡ Kçš„çŸ¿æ¿å”®åŽçŽ‡ç¡¬æ˜¯èƒ½å¤§å‡ ç™¾ç‰‡ï¼ŒæžœçœŸä¸€åˆ†é’±ä¸€åˆ†è´§ã€‚è‡³ä»Šä»“åº“é‡Œè¿˜10ç‰‡çŸ¿æ¿æ‡’å¾—å”®åŽä¹Ÿæ²¡äººè¦ï¼Œç­‰è¿‡ä¿ä¿®äº†å–åžƒåœ¾ã€‚

- [å¦‚ä½•è¯„ä»·åŽæ“Žä¸»æ¿ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/27738363/answers/updated)

- ## [Mini server for virtualization with 128 GB ECC RAM, many CPU cores : r/selfhosted _202412](https://www.reddit.com/r/selfhosted/comments/1hbfay9/mini_server_for_virtualization_with_128_gb_ecc/)
- DDR5 is inherently ECC. You do not need explicit ECC, though the on-die ECC only protects the DRAM cells, not the link between the CPU and the RAM chips. So, run the bus slower (say, if you have LPDDR5X 7500, run it at 6400, if you have DDR5 5600, run it at 5200), and you will be fine.
  - with on-die ECC, you do not get early warning on ECC events, and you do not get unrecovered 2-bit ECC reports, so it's safer than no ECC, but not as safe as true ECC. You should not do ZFS RAM caching, for instance, with this setup. But most home server applications should be fine, though.
  - As for capacity, you can get 96GB easily. 128GB would be hard until vendors start making 64GB sticks. So far, the largest consumer grade sticks are 48GB. My setup is MS-A1+7950X+2x48GB+2x2TB+1x118GB Optane. It's been rock solid far.

- Minisforum MS01 ticks all the boxes except RAM. It can go up to 96GB, has 3 m.2 slots, a spare pcie slot, dual 10gbe SFP, dual 2.5gbe with one offering IPMI.

- I have been eyeing the Asrock B650M PG Riptide mATX board.
  - Supports AMD Ryzenâ„¢ 9000, 8000 and 7000 Series Processors
  - Supports 256GB DDR5 ECC/non-ECC, un-buffered memory up to 7200+(OC)
  - 2.5G Ethernet
  - 2 x 16x PCIe slots (One of which may only support x4)
  - 2 x M.2 Gen 4 slots
- AsRock DeskMeet seems similar. The motherboard doesnâ€™t seem to support bifurcation to make use of PCIe slot for 4 NVMe, and there is no IPMI. Otherwise OKish, albeit 8 liters
  - I think you have to compromise if you want a small formfactor / non-server board. Have been struggling with the same compromises. But at least this have 2.5G Lan.
  - Bifurcation would have been nice.
  - I don't think it is going to be easy to find a small/non-server board with IPMI.

- ## [Mini ITX AM5 mobo that supports 2x64GB RAM sticks? : r/sffpc _202507](https://www.reddit.com/r/sffpc/comments/1m8wexd/mini_itx_am5_mobo_that_supports_2x64gb_ram_sticks/)
- check the SFF masterlist > mITX boards tab. Lots of boards support 128GB
  - https://docs.google.com/spreadsheets/d/1AddRvGWJ_f4B6UC7_IftDiVudVc8CJ8sxLUqlxVsCz4/edit?gid=523597416#gid=523597416
  - I would still double check the motherboard's website just to be sure. As this is still a community maintained page so info isn't guaranteed to be 100% accurate.

- The Asus B650E-I has a maximum capacity of 64GB per RAM slot, with 128GB total
  - Cheaper models like the MSI 650I Edge and the AsRock B650I Lightning only have a maximum capacity of 48GB per slot

- Gigabyte X870I AORUS PRO ICE supports 128GB. Saw it on Microcenter's website and doublechecked on the Gigabyte site
- If you really want to be sure you have enough RAM capacity, you can always go for an ITX X870 board, but that's a prety big upcost for pretty much no benefits in terms of features (outside of maybe more USB ports in the rear I/O)

- ## [DDR5 128GB on ITX possible nowadays? Experience? : r/sffpc _202506](https://www.reddit.com/r/sffpc/comments/1lgu72h/ddr5_128gb_on_itx_possible_nowadays_experience/)
  - I couldn't find new information on anyone trying out 64GB DDR5 Sticks in their ITX build.
  - Would two sticks work to yield 128GB DDR5?
  - Kingston FURY Beast schwarz DIMM 64GB, DDR5-5600, CL40-40-40
  - there is also a Crucial 64GB stick and an even faster Kingston 64GB stick.
  - âœ… Update: Received my 2x Kingston 64GB RAM sticks and after a 1min initial boot, setting the right EXPO profile in the BIOS, it works perfectly without any issues. To whoever reads this in the future, good luck on your build!

- If you want small with 128GB of fast RAM, then something built with the AMD AI Max 395 might be of interest? Framework are going to sell an ITX motherboard (and SFF PC) with the same chip, but it isn't available yet
  - Yes I am aware of its existence and the advantages soldered RAM has to reduce latency and improve memory bandwidth, but I already got a rig and am happy with the general performance of my 7900. 
  - I was considering upgrading form my measly 2*16GB and my most recent info is that optimum uses 2*48GB sticks, hence 96GB, but I couldn't find further info on 2*64GB.

- Even though only 96 GB of RAM is listed there, it is possible to use 128 GB. I've seen it in YouTube videos, but only with mini PCs, and the guy used SO DIMMs.

- Just did this on my homelab server. The board claims to only support 64GB but I put this 128GB kit in and all is well. (Passed prime95, etc tests. All 128GB is usable.)

- I think the biggest problem is there hasn't actually been 64GB sticks out for very long and with the price not many people have actually tried it. I would just go with a motherboard that states it supports 128GB and make sure you buy the ram from a retailer with a good return policy.

- ## [å…­è”æ™ºèƒ½æŽ¨å‡º AMD "Strix Halo" Thin Mini ITX ä¸»æ¿ï¼Œæ¿è½½å†…å­˜è®¾è®¡ - ITä¹‹å®¶ _202507](https://www.ithome.com/0/869/805.htm)
- AMD çš„é”é¾™ AI Max 300 "Strix Halo" å¹³å° ODM ä¼™ä¼´å…­è”æ™ºèƒ½æŽ¨å‡ºäº†ä¸€æ¬¾æ¿è½½è¯¥ç³»åˆ—å¤„ç†å™¨å’Œ DRAM å†…å­˜é¢—ç²’çš„ Thin Mini ITX ä¸»æ¿ STHT1ã€‚
- è¿™ä¸€ä¸»æ¿ç›®å‰å·²è¢«å…­è”æ™ºèƒ½çš„ 2L è¿·ä½ ä¸»æœºã€8L ç´§å‡‘åž‹å°å¼æœºã€ä¸€ä½“æœºè§£å†³æ–¹æ¡ˆé‡‡ç”¨ï¼Œè€Œå…¶å…¼å®¹å¤–å½¢è§„æ ¼ä½¿ä¹‹å­˜åœ¨ç›´æŽ¥å®‰è£…äºŽæ ‡å‡†å°å¼æœºæœºç®±çš„å¯èƒ½ã€‚
- è¯¥ä¸»æ¿åŒ…å« 8 ä¸ª LPDDR5x ç„Šç›˜ï¼Œæ”¯æŒè‡³é«˜ 128GB å†…å­˜å®¹é‡ï¼›é…å¤‡ 2 ä¸ª M.2 2280 PCIe 4.0Ã—4 ç›˜ä½ï¼›æä¾› 1 ä¸ª M.2 2230 æ— çº¿ç½‘å¡ä½ã€‚

- ## [Is a mini-itx first homelab a good idea? : r/homelab _202207](https://www.reddit.com/r/homelab/comments/w6dzji/is_a_miniitx_first_homelab_a_good_idea/)
- At the time I was fine with just one PCIe and 2 memory slots but now the lack of expansion is a pain.
  - Was also limited in the number of drives that could be connected and has a distinct lack of fan headers (not sure if newer boards would have any more - there's really no space).

- Unless you absolutely need the smallest footprint, Mini-ITX is always a bad choice, regardless of application. 
  - There's always a hardware tax, you generally lose out on features (e.g. you get fewer PCIe slots, DIMM slots, M.2 slots), you (almost) always have worse cooling, and the actual build or modifying process is more painful (literally and figuratively).
  - I'd advise going for microATX instead, which allows you to put together a relatively compact build, but should give you more value for money and more freedom than Mini-ITX.

- ## [Are there any ITX motherboards that can handle 128GB RAM? : r/buildapc _202307](https://www.reddit.com/r/buildapc/comments/15cazh5/are_there_any_itx_motherboards_that_can_handle/)
- Are there ones that you, right now, as an average consumer or even business can buy? No.
  - There are custom ITX server boards that have 4 DIMM slots, but they're for fairly old and slow server CPUs using DDR3, and have no PCIe slots.
  - DDR5 can technically support up to 512GB on a single DIMM, so an Intel 13th gen or Ryzen 7000 ITX motherboard could theoretically support up to 1TB of RAM! But the largest consumer DIMM is 48GB, so the most you can get on an ITX motherboard right now is 96GB. 

- If you need 128GB right now, you have to get an mATX motherboard. There is no other option.
- That said, the SSUPD Meshroom S can take an mATX motherboard, even a full sized ATX motherboard, and isn't much bigger than the Terra.

- ## [Can you guys recommend me a motherboard which can support 128gb ram? : r/buildapc _202412](https://www.reddit.com/r/buildapc/comments/1hbspr8/can_you_guys_recommend_me_a_motherboard_which_can/)
  - I'm looking for a motherboard which can support a lot of ram for programming. Preferably it should be mATX. I've heard that ITX boards aren't really great for that soft of thing. edit : CPU is Ryzen 9 7950x.
- ASUS rog-strix-b650e-f has 128 GB configurations on their Memory QVL for Ryzen 9 7950x. According to them it'll run at 5200.
  - I'm considering such a configuration now. I've not yet found an ASROCK Motherboard with any 128GB configurations on their QVL.

- All of the mid tier boards with 4 memory slots will support minimum 128GB.
  - First choice you have to make is which cpu you want, after that you can look for mobo recommendations.

- Since you're 7950X (though I'd strongly recommend getting a 7900X or 9700X as they're far better value - www.bestvaluecpu.com exists, filter for AM5), just get one with decent VRMs. This probably means going ATX as high end boards are usually this size.
  - I would not recommend putting a 7900X in a ITX build, it'll get spicy in there!
  - 64gb is enough even for most video editing, 128gb is "I do programming for my job and my job paid for this PC" kind of levels.

- [128GB of RAM in a tiny box? : r/buildmeapc](https://www.reddit.com/r/buildmeapc/comments/17lxgsj/128gb_of_ram_in_a_tiny_box/)
- The smallest motherboard with 4 dimms would be a micro ATX. Mini ITX only have 2 slots, that's why you can't find options for 128 GB.
  - I thought maybe DDR5 had been out long enough to be able to find a 2x64GB kit, but looks like maybe not. But, Crucial does have a 2x48GB DDR5 kit, and 96GB would be alright.

- I'd suggest the following that gets you 128GB of DDR5 RAM, a 14-core 13600K, compact 17.9L case, with very good CPU cooling capacity that will allow the CPU to run under heavy multi-core load without thermal throttling.
  - CPU: the 13600K provides a good number of cores for a lot of VM's, 
  - Motherboard: mATX motherboard with wifi and bluetooth, plus 4 RAM slots.
  - Memory: 128GB of RAM (four sticks of 32GB).
  - Storage: Good sped 2TB PCie 4 NVME.
  - Video Card: It wasn't clear if you need a separate GPU or not. Added in a decent GPU for not too much money - though if you can just use integrated graphics, you could upgrade to a 13700 for more cores.
  - Power Supply: SFX unit for space savings in the compact case.
  - Case: The Mechanic Master C28, despite being mATX, is smaller than several mITX cases 

- [Please advise on a mATX build with 128GB RAM : r/buildapc _202307](https://www.reddit.com/r/buildapc/comments/15e1r2j/please_advise_on_a_matx_build_with_128gb_ram/)
  - So far my only criteria is: - AMD 7950X, 128GB RAM, RTX4090. Likely the CPU would be under a lot most stress than the GPU for most of my use cases, 
- Asus Prime AP201 MicroATX Mini Tower Case	
  - Motherboard	MSI MAG B650M MORTAR WIFI Micro ATX AM5 Motherboard
  - Memory	G. Skill Trident Z5 Neo 64 GB (2 x 32 GB) DDR5-6000 CL30 Memory x2

- 4x DDR5 configurations barelly run with 4800MT/s and even that might need some DDR5 kit swaps till you have 4 working DIMMs.
  - Getting DDR5 6000MT/s CL30 is ridiculous.

- [Is it possible to have 128GB RAM with SFFPC? : r/sffpc _202210](https://www.reddit.com/r/sffpc/comments/yd2z0b/is_it_possible_to_have_128gb_ram_with_sffpc/)
- Matx board, 25L matax case and 4x32gb dimms?
  - Silverstone Alta g1m or asus ap201 are ones I want since they support a 360 AIO

- Should i maybe get c26 or c28 cases? It looks like even c26 can fit an ATX board so with that it should solve these issues?
  - You will not be able to properly cool the components you are aiming for in a case like the C26, which by the way will not be able to fit a 4090. C28 maybe, but I wouldn't want to travel with a case that has a TG panel. And you need all the airflow you can get.
  - The new Asus Prime AP201 looks promising. I would not advise to go smaller than that.

- [Smallest possible m-atx + 7950x + 4090.... advice appreciated! : r/sffpc _202301](https://www.reddit.com/r/sffpc/comments/107jq5o/smallest_possible_matx_7950x_4090_advice/)
- I just received C26plus, bought B660 mATX MB and 12600K, pending to get a 4090 and PSU. Will get back to you if the case is good fit for 4090 FE
  - Nope, side panel cannot close even with native 16pin cable

- AP201 is the current matx meta imho but the d31 is nice

- ## [Should I Choose a Motherboard with 128GB or 256GB RAM Max? : r/buildapc _202410](https://www.reddit.com/r/buildapc/comments/1fvoskv/should_i_choose_a_motherboard_with_128gb_or_256gb/)
  - is there a significant performance difference if I opt for the 128GB option?

- No. Chance is that you won't even reach the 128GB mark long before you make another full upgrade certain years down the road. 

- ## [64Gå†…å­˜+çº¯CPUè£¸è·‘gpt-oss:120b - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/68a6ee02000000001c03f964?xsec_token=ABIl2xpN-BcJcn0jmdi2k1RkNoJcXZiMAtj5QFwnpIark=&xsec_source=pc_search&source=unknown)
  - 64Gå†…å­˜+çº¯CPUè£¸è·‘gpt-oss:120bï¼Œä¸€ç§’é’Ÿå‡ ä¸ªå­—å„¿å¾€å¤–è¹¦
- æ…¢ä¸»è¦æ˜¯å› ä¸ºç”¨çš„DDR4ï¼Œå†…å­˜å¸¦å®½å¤ªä½Ž

- æ¢AMDï¼Œ7840Hï¼‹96Gå†…å­˜ï¼Œçº¯CPUè·‘30Bï¼Œ30t/s, Q4ï¼Œæˆ‘éœ€è¦é•¿ä¸Šä¸‹æ–‡ï¼ŒQ4æ‹‰æ»¡256kè¦79Gå†…å­˜ã€‚é‡åŒ–å†å¾€ä¸Šå°±åŠ è½½ä¸ä¸Šäº†
  - 7840Hæ²¡æœ‰npu

- ç»„ä¸€ä¸ªä¸€åƒå¤šå—çš„æ´‹åžƒåœ¾ï¼Œ256gddr3å†…å­˜è·‘ï¼Œæ•ˆæžœçœ‹ç€è¿˜è¡Œï¼Œbç«™åˆ«äººæœ‰ç±»ä¼¼è§†é¢‘

- ## [å¤šä¹ˆç—›çš„é¢†æ‚Ÿï¼Œä¸Šç™¾å°ITXç”µè„‘æ€»ç»“å‡ºçš„ç»éªŒ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/64d4825a000000000c034f36?xsec_token=ABRh3ACWg_DKSLuH2VaseP_A7Mn7MpO5RifkuaugGycJM=&xsec_source=pc_search&source=unknown)
- ç¬¬ä¸€ç§æœºç®±ç±»åž‹ï¼šITXä¸»æ¿+å°1Uç”µæºï¼ˆä¸ªäººéžå¸¸ä¸æŽ¨èï¼‰
  - ä¼˜ç‚¹ï¼šä½“ç§¯å¯ä»¥åšåˆ°å¾ˆå°ï¼Œå¾ˆè–„ã€‚
  - å‘ç‚¹ï¼šå°1Uç”µæºå™ªéŸ³å¤§ä¸”æ˜¯ä½ å—ä¸äº†çš„é‚£ç§ã€CPUæ•£çƒ­å™¨éš¾ä»¥é€‰æ‹©ã€éœ€è¦æ˜¾å¡å»¶é•¿çº¿ã€éœ€è¦åŠé«˜æ˜¾å¡ã€‚
  - å»ºè®®ï¼šéžå¿…è¦ï¼Œç›´æŽ¥ä¸è¦é€‰æ‹©

- ç¬¬äºŒç§æœºç®±ç±»åž‹ï¼šITXä¸»æ¿+SFXç”µæºï¼ˆæ¯”è¾ƒæŽ¨èï¼Œä½†ä¹Ÿä¸æ˜¯æ²¡æœ‰é—®é¢˜ã€‚ï¼‰
  - ä¼˜ç‚¹ï¼šå¯é€‰æ‹©çš„ç”µæºæ¯”è¾ƒå¤šã€ç»“æž„åˆç†ã€å¾ˆå¤šå“ç‰Œçš„ç”µæºä¹Ÿå¯ä»¥åšåˆ°æ²¡ä»€ä¹ˆå™ªéŸ³ã€‚
  - å‘ç‚¹ï¼šå‡çš„SFXç”µæºæ¯”è¾ƒå¤šä¸”è™šæ ‡ã€æœ‰äº›ä¹Ÿéœ€è¦æ˜¾å¡å»¶é•¿çº¿
  - å»ºè®®ï¼šä¼˜å…ˆé€‰æ‹©ç±»ä¼¼æœºæ¢°å¤§å¸ˆC24è¿™ç§æ˜¾å¡ç›´æ’å½¢å¼çš„ã€‚SFXç”µæºå°½é‡é€‰æ‹©é•¿åŸŽã€TTè¿™äº›å“ç‰Œã€‚

- ç¬¬ä¸‰ç§æœºç®±ç±»åž‹ï¼šå°å°ºå¯¸MATXä¸»æ¿+SFXç”µæºï¼ˆæ¯”è¾ƒæŽ¨èï¼Œä¸»è¦è¿™ç±»æœºç®±è¾ƒå°‘ï¼Œå¥½çœ‹çš„ä¸å¤šï¼‰
  - ä¼˜ç‚¹ï¼šä¸»æ¿é€‰æ‹©ç©ºé—´å¤§ï¼Œæœ‰å¾ˆå¤šä¾¿å®œçš„ä¸»æ¿ï¼Œå¯æ‰©å±•ç©ºé—´å¤§ï¼Œè£…äº†æ˜¾å¡è¿˜èƒ½è£…ç½‘å¡ï¼Œè´¹ç”¨å°‘ã€‚
  - å‘ç‚¹ï¼šæ²¡å•¥å‘ç‚¹ï¼Œå°±æ˜¯å¯é€‰æ‹©çš„æœºç®±æœ‰ç‚¹å°‘ã€‚
  - å»ºè®®ï¼šå°±é€‰è‰¾ç½—æ‹‰SS31/30ã€ç¬¨ç‰›U45ç­‰ï¼Œå¦‚æœ‰å…¶ä»–å»ºè®®è¯„è®ºåŒºç•™è¨€å¸®åŠ©å¤§å®¶ã€‚

- ç¬¬å››ç§æœºç®±ç±»åž‹ï¼šITXä¸»æ¿+MATXç”µæºï¼ˆéžå¸¸æŽ¨èï¼Œä½†è¿™ç±»æœºç®±æ›´å°‘äº†ï¼‰
  - ä¼˜ç‚¹ï¼šç”µæºå¯é€‰æ‹©æ€§å¾ˆå¤šï¼Œç©ºé—´å¯Œè£•ï¼Œæ˜¾å¡å¯ç›´æ’ä¸»æ¿ç­‰ã€‚
  - å‘ç‚¹ï¼šåŒæ ·æ²¡å•¥å‘ç‚¹ï¼Œä¹Ÿæ˜¯å¯é€‰æ‹©çš„æœºç®±æœ‰ç‚¹å°‘ã€‚
  - å»ºè®®ï¼šç›®å‰æˆ‘è§è¿‡çš„æœºç®±æœ‰é—ªé³žG200ï¼ŒåŒæ ·å»ºè®®æœ‰å¥½å¿ƒäººè¯„è®ºåŒºç•™è¨€å¸®åŠ©ä¸€ä¸‹å¤§å®¶ã€‚

- è£…äº†å¥½å¤šç§itxï¼Œå°1ué‚£ç§é€‚åˆåŠŸè€—æ¯”è¾ƒä½Žçš„ï¼Œè€Œä¸”å¤§å¤šæ•°å°1uç”µæºæœºç®±éƒ½è¦ä¹°æ˜¾å¡å»¶é•¿çº¿ï¼Œè€Œä¸”å¥½çš„é™éŸ³ç”µæºå¾ˆè´µï¼Œå»ºè®®è¿˜æ˜¯è£…é‚£ç§sfxç”µæºçš„ï¼Œçœäº‹ï¼Œä¹Ÿæ¯”è¾ƒä¾¿å®œï¼ŒåŽæœŸæ‰©å±•æ€§ä¹Ÿæ¯”è¾ƒå¤§ï¼Œæ˜¾å¡é€‰æ‹©ä¹Ÿæ›´å¤šæ ·ä¸€äº›ï¼Œå‰é¢æåˆ°çš„é‚£ç§ä¸€èˆ¬éƒ½æ˜¯çŸ­å¡ï¼Œä»·æ ¼åˆä¸ŠåŽ»äº†

- ## [u7 265kç”¨ä»€ä¹ˆé£Žå†·èƒ½åŽ‹ä½ pa140å¯ä»¥å—ï¼Ÿè¿˜æ˜¯p60tï¼Œæˆ–è€…fc140ï¼Ÿ  ](https://www.xiaohongshu.com/explore/68d1b0a30000000013007154?xsec_token=AB9X5HvN7d3sRdmBFeEqk4N5mZwaaHkl_t8SjBmCKQI7c=&xsec_source=pc_feed)
  - å¼€å§‹çœ‹åˆ°æœ‰äººè¯´pa120å°±å¯ä»¥ï¼Œç„¶åŽ140å·®ä¸äº†å¤šé’±æ€§èƒ½æ¯”è¾ƒå¥½ï¼Œä½†æ˜¯åŽ»é—®å®¢æœï¼Œå®¢æœè¯´ä¸è¡Œï¼Œè¯´fc140å¯ä»¥ã€‚ç„¶åŽä¹Ÿçœ‹åˆ°æŽ¨èp60tv3çš„ï¼Œä½†ä¹Ÿæœ‰è¯´é˜¿è¨è¾›éƒ½åŽ‹ä¸ä¸‹265kçš„ã€‚
- é»˜é¢‘æ»¡è½½åŠŸè€—ä¹Ÿä¸ä½Žå•Šï¼Œå®˜æ ‡250wï¼Œæˆ‘çš„æ»¡è½½è·‘é»˜é¢‘260wï¼Œæœ€å¥½çš„é£Žå†·ä¹Ÿä¸å»ºè®®åŽ»åŽ‹240wä»¥ä¸Šçš„uã€‚é™¤éžä½ ä¹°265kå°±ä¸ºäº†åˆ·åˆ·è§†é¢‘ï¼Œè€Œä¸”å¯¹æ¸¸æˆå¸§æ•°æ²¡è¦æ±‚ï¼Œæ²¡ç”Ÿäº§åŠ›éœ€æ±‚ã€‚

- æ­£å¸¸ç”¨éšä¾¿ä¸€ä¸ªè®¾è®¡æ²¡ç¡¬ä¼¤çš„åŒå¡”éƒ½èƒ½åŽ‹ï¼Œç”šè‡³éžç”Ÿäº§åœºæ™¯å•å¡”éƒ½è¡Œï¼Œå› ä¸ºultraç³»åˆ—çš„ä¼˜åŠ¿å°±æ˜¯è¶…é«˜èƒ½è€—æ¯”ï¼Œä½ŽåŠŸè€—ä¹Ÿèƒ½å‘æŒ¥ç»å¤§éƒ¨åˆ†æ€§èƒ½ï¼Œ
  - ä½†ä½ è¦ä»¥é•¿æœŸæ»¡è½½å’Œå–œæ¬¢çƒ¤é¸¡çœ‹æ¸©åº¦ä¸ºè¦æ±‚ï¼Œè¿™uæ»¡è½½250wé£Žå†·å¹²ä¸åŠ¨åªèƒ½æ°´ï¼Œæˆ‘ä¼šé€‰æ‹©pa120è¿™ç§ä¸­å°å°ºå¯¸åŒå¡”æˆ–è€…åŽšå•å¡”ï¼Œç›¸å¯¹å¥½è£…çœäº‹å„¿ï¼Œfc140è¿™ç§å¤§é©¼å­é™¤äº†å®‰è£…å’Œæ›´æ–°ç¡…è„‚æ—¶å¸¦æ¥ç—›è‹¦å¸¦ä¸æ¥ä»€ä¹ˆ
- è¿™ä½è§£é‡Šçš„å¾ˆå¥½äº†ã€‚æ»¡è½½é£Žå†·ä¸å¤Ÿï¼Œä½†å¤§å¤šæ•°æƒ…å†µä¸‹åŒå¡”é£Žå†·éšä¾¿é€‰
- é™ä¸ªåŽ‹å§ï¼ŒæŸå¤±ä¸€ç‚¹ç‚¹æ¢ä¸ªå¥½åŠŸè€—ç”¨
- ä¸è¶…é¢‘é™åŽ‹ç”¨é£Žå†·å°±æ²¡é—®é¢˜ï¼Œå¦‚æžœè¦è¶…é¢‘é‚£åŠŸè€—å°±å†²ç€300wåŽ»äº†ï¼Œå¿…é¡»æ°´å†·
- ä½ è¦æ˜¯åšè§†é¢‘è§£ç å•¥çš„è¿˜æ˜¯æ°´å†·å§ï¼Œæ’‘çš„æ—¶é—´é•¿äº›ï¼Œä¸ç„¶é™é¢‘äº†
- å¯ä»¥é™åˆ¶å•Šã€‚ä½ çŽ©itxè¿½æ±‚å®Œç¾Žé‡Šæ”¾æ€§èƒ½å—ï¼Ÿ

- æˆ‘è¿™pa120æ¢æ‰‡p12eå¯¹æˆ‘è¿™ä¸ªç”¨äºŽç¼–è¯‘çš„å·¥å†µæ˜¯å¤Ÿçš„ï¼Œp60tæ²¡å¯¹æ¯”è¿‡

- 265è·Ÿ147æ¯”å°±æ˜¯ï¼Œæ€§èƒ½ä¸€æ ·ï¼Œä¸ç¼©ç¼¸ï¼ŒåŠŸè€—è¿˜ä½Žï¼Œ6çƒ­ç®¡åŒå¡”é£Žå†·å°±è¡Œã€‚147ä¸€èˆ¬éƒ½æ˜¯360æ°´å†·

- pa140ï¼Œæ¢ä¿©12cmçš„é£ŽåŽ‹æ‰‡ï¼Œè®°å¾—é¢å¤–ä¹°ä¸ª12cmé£Žæ‰‡çš„æ‰£å…·

- å¦‚æžœä½ ä¼šè®¾ç½®cpuï¼Œ265kï¼Œ190ç“¦å·¦å³ï¼Œå°±å¯ä»¥å‘æŒ¥å‡º97%çš„æ€§èƒ½ï¼Œä¹Ÿå°±æ˜¯è¯´ä½ ç”¨b60tä¹Ÿè¡Œï¼Œç”šè‡³å¤§éœœå¡”

- ## ðŸ¤” [itxä¸»æœºCPUé€‰å“ªä¸ªï¼ˆAMDè¿˜æ˜¯intelï¼‰ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/444107051/answers/updated)
- 11ä»£æ˜¯ç‰™è†å€’å¸ï¼Œæ²¡å¿…è¦ã€‚AMDå¸¦Gçš„ä¹Ÿåœ¨æ¶¨ï¼Œè½»åº¦ä½¿ç”¨3400Gå®Œå…¨è¶³å¤Ÿï¼Œè¿˜å¯ä»¥å…¼é¡¾ç‚¹æ¸¸æˆï¼Œä¸è¿‡è¿˜æ˜¯çœ‹é¢„ç®—å§ï¼Œè‚¯å®šæ˜¯é¢„ç®—å†…å †æ ¸å¿ƒã€‚
  - itxä¸»æœºéº»çƒ¦åœ¨æ•£çƒ­å™¨å’Œæœºç®±çš„é€‰æ‹©ä¸Šï¼Œä½“ç§¯åŽ‹ç¼©åˆ°æžè‡´è¿˜è¦æ•£çƒ­å¼ºï¼Œä¸ç„¶å®¹æ˜“ç§¯çƒ­ã€‚å½“ç„¶å¦‚æžœä¸åœ¨ä¹Žä½“ç§¯çš„è¯å¦è¯´

- åœ¨ITXçŽ¯å¢ƒä¸­ï¼Œè¿˜æ˜¯intelæœ‰ç‚¹ä¼˜åŠ¿ 
  - å› ä¸ºITXä¼˜ç‚¹å’Œç¼ºç‚¹ä¸€æ ·æ˜Žæ˜¾ æ‰€ä»¥é€‰æ‹©intelçš„å¹³å°ï¼ŒåŠžå…¬å°½é‡é€‰æ‹©ä½ŽåŠŸè€—çš„, æ¡Œé¢atx/matxçš„diyå¹³å°ï¼Œé€‰æ‹©amd ryzen

- [10lä»¥ä¸‹ITXå¯ä»¥æ”¯æŒæœ€é«˜ä»€ä¹ˆcpuï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/7439796831)

- 10Låˆšå¥½èƒ½è£…åŒå¡”ï¼ŒåŒå¡”é£Žå†·æ•£çƒ­å™¨æ‰€èƒ½æ”¯æŒæœ€é«˜CPUæ˜¯ EPYC 9004ç³»åˆ—å’ŒR9 9950Xç³»åˆ—ã€‚

- çŽ°åœ¨æœ‰çš„10Lçš„æœºç®±å¯ä»¥è£…135mmçš„æ•£çƒ­å™¨ã€‚135mmåŒå¡”çš„è§£çƒ­èƒ½åŠ›åœ¨200Wå‡ºå¤´ã€‚
  - å¦‚æžœä»¥ç”Ÿäº§åŠ›éœ€æ±‚ä¸ºä¸»ï¼Œé‚£ä¹ˆå¯ä»¥ä¸Šæ–°çš„ultra7 265kï¼Œæ–°çš„ultraç³»åˆ—è™½ç„¶æ¸¸æˆæ€§èƒ½å¼€å€’è½¦ï¼Œä½†æ˜¯èƒ½è€—æ¯”æ¯”ä¸Šä¸€ä»£æœ‰å¤§å¹…åº¦çš„æå‡ï¼Œæ¯”è¾ƒç¬¦åˆä½ çš„æƒ…å†µï¼Œä½†æ˜¯æ€§ä»·æ¯”ä¸é«˜ï¼ŒæŒ‰éœ€é€‰æ‹©ã€‚
  - å¦‚æžœä»¥æ‰“æ¸¸æˆä¸ºä¸»ï¼Œé‚£ä¹ˆamd X3Dç³»åˆ—çš„CPUå¯ä»¥éšä¾¿ç”¨ã€‚å› ä¸ºå·¥è‰ºé—®é¢˜ï¼Œé™¤äº†æœ€æ–°å‡ºçš„9000ç³»åˆ—x3då…¶ä»–çš„éƒ½æ˜¯é™åˆ¶åŠŸçŽ‡çš„ã€‚åŠŸçŽ‡æ¯”éžx3dåž‹å·çš„CPUè¦ä½Žã€‚
  - å…¶ä»–çš„amdç³»åˆ—çš„å¤„ç†å™¨ã€‚åŸºæœ¬å¯ä»¥éšä¾¿ä¸Šï¼Œå³ä½¿æ˜¯è§£é”äº†åŠŸè€—çš„9950xä¹Ÿåªæœ‰230Wã€‚

- 10Lä»¥ä¸‹çš„æœºç®±ä¸Šä¸äº†ä¸‰æ§½çš„æ ‡å‡†æ˜¾å¡ã€‚åªèƒ½æ ¸æ˜¾æˆ–è€…æœ‰äº›å¯ä»¥ç”¨ä¸“é—¨çš„itxçŸ­å¡ã€‚å¦‚æžœæ˜¯ç”¨é£Žå†·ï¼ŒåŸºæœ¬å°±ä¸è¦è€ƒè™‘intelå¸¦kçš„åž‹å·å’Œamdçš„é«˜ç«¯åž‹å·äº†ã€‚å¯èƒ½æœ‰ç”¨120æ°´å†·çš„ï¼Œä¸Šä¸ªi5å¸¦kçš„å°±æœ€å¤šäº†ã€‚
  - 10Lå·¦å³èƒ½ä¸Š240æ°´å†·çš„æœºç®±æˆ‘ä»¥å‰è¿˜çœŸç ”ç©¶è¿‡ï¼Œè¿™ç§çš„åŸºæœ¬æœ€é«˜èƒ½è·‘ä¸¤ç™¾ç“¦å‡ºå¤´ï¼Œä¸Ši7å¸¦kçš„åž‹å·ç¨å¾®é™ä¸€ç‚¹ç”µåŽ‹åŸºæœ¬èƒ½å‘æŒ¥å‡ºæ¥ï¼Œé¡¶çº§çš„i9å¸¦kè·‘ä¸æ»¡ï¼Œä½†ä¹Ÿä¸æ˜¯å½»åº•ä¸èƒ½ç”¨ã€‚

- é»˜è®¤ç”¨çš„è¯å…¶å®žç›®å‰ [Ultra200Sç³»åˆ—] æˆ–è€… AMD 9000ç³»åˆ— éƒ½å¯¹æ•£çƒ­è¦æ±‚è¾ƒä½Žäº†ï¼Œè€ƒè™‘10å‡ä»¥å†…çš„æ——èˆ°å¤„ç†å™¨ä¹Ÿéƒ½é—®é¢˜ä¸å¤§ï¼ŒåŸºæœ¬ä¸ä¼šæœ‰i9æ€§èƒ½æŸå¤±åŽåªæœ‰i7ç”šè‡³i5æ€§èƒ½çš„é—®é¢˜ã€‚
  - æ‰€ä»¥ä¸è®ºé’ˆå¯¹æ¸¸æˆæˆ–è€…ç”Ÿäº§åŠ›ä¸»æœºï¼Œé…ç½®ä¸Šå¤„ç†å™¨éƒ½å¯ä»¥æ”¾å¿ƒçš„é€‰æ‹©9950Xæˆ–è€…9800X3Dæˆ–è€…æ˜¯U9 285Kéƒ½æ˜¯OKçš„ã€‚

- [U7 265Kå’Œ9700Xåˆ°åº•ä¹ˆé€‰ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/68a883b8000000001c03c2ab?xsec_token=AB2GCeMJb66g6AJnAmLcHLOqUT9Bzg3qO1V9MsHhNoFL4=&xsec_source=pc_search&source=web_search_result_notes)
  - é¦–å…ˆ9700xæœ‰ç§¯çƒ­é—®é¢˜åˆæˆ–è€…è¯´è¿™ä¸ªUå¤ªæŒ‘æ•£çƒ­å™¨ä¹Ÿå¾ˆéš¾åŽ‹æ¸©åº¦ æˆ‘é£Žå†·åŒå¡”æ•£çƒ­å™¨ä¹å·žé£Žç¥žAK620é»˜è®¤é¢‘çŽ‡å¾…æœºæ¸©åº¦57åº¦ éšä¾¿å¼€ä¸ªè½¯ä»¶60æ¥åº¦ æ‰“3Aæ¸¸æˆç”šè‡³70å¤šåº¦ æ•£çƒ­å™¨å’Œæœºç®±é£Žæ‰‡å¿½åµå¿½é™ ä¸¥é‡å½±å“æˆ‘æ­£å¸¸ä½“éªŒ
  - å…¶æ¬¡æˆ‘çš„æœºç®±æ˜¯Z20 æ˜¾å¡5070Adoc è¿™ä¹ˆå°çš„æœºç®± æˆ‘ç¨å¾®çŽ©ä¸€ä¸‹3Aæ¸¸æˆè¿™ä¿©è´§ç»™æˆ‘æœºç®±æžçš„è·Ÿä¸ªç‚‰å­ä¼¼çš„ 
  - åŽŸå…ˆ14600KFæ±Ÿè¥¿å¤å¤©ä¸å¼€ç©ºè°ƒæ¸¸æˆæ¸©åº¦58åº¦ä¸åˆ°ã€æ˜¾å¡æœ€é«˜65åº¦ã€æ¢äº†9700Xæ¸¸æˆæ¸©åº¦æžåº¦ä¸ç¨³å®šå¹³å‡73åº¦ å¶å°”æŠ½æä¸€ä¸‹æ¸©åº¦èƒ½å¹²åˆ°80åº¦ æ˜¾å¡ä¹Ÿæ›´çƒ­äº†
- çƒ¤é¸¡40åˆ†é’Ÿéƒ½æ²¡ä½ æ‰“æ¸¸æˆçƒ­
  - æˆ‘å„ç§è¯•è¿‡äº† é—®äº†å•†å®¶ä»Šå¹´æ‰¹æ¬¡çš„9700Xç”µåŽ‹é»˜è®¤ç»™çš„é«˜ ä½†æ˜¯æˆ‘ä¸å¼€PBOç„¶åŽè´ŸåŽ‹30æ¸©åº¦è¿˜æ˜¯å¾ˆé«˜ æˆ‘è§è¿‡æœ€ä½Žæ¸©åº¦53åº¦å·®ä¸å¤š
- ä½ è¿™æ¸©åº¦åº”è¯¥å¼€pboè€Œä¸”è¿˜æ²¡é™åŽ‹å§ï¼Œ9700xé»˜è®¤88wæ¸©åº¦ä¸é«˜å•Šï¼Œ9700xä¸å¼€pboï¼Œç”¨ä¸ªç™¾å…ƒçš„é£Žå†·éšä¾¿åŽ‹å•Šï¼Œæ‰“æ¸¸æˆå™ªéŸ³æ›´å¤šæ¥è‡ªæ˜¾å¡å§

- ä¸»è¦265kæ²¡æ³•å‡çº§äº† am5èµ·ç èƒ½ç”¨åˆ°2027å¹´ ä½†æ˜¯Intelæ˜Žå¤©åˆè¦æ¢æŽ¥å£ å¤ªé€†å¤©äº†

- ä¿©éƒ½ä¸æ˜¯ä¸€ä¸ªç­‰çº§çš„ï¼Œ97xèƒ½é…å‡ ç™¾å—å…¥é—¨çš„b650ï¼Œ265kæ­é…çš„zæ¿æœ€å·®çš„ä¹ŸæŽ¥è¿‘1kï¼Œç¨å¾®å¥½ç‚¹çš„bæ¿ä¹Ÿè¿™ä¸ªä»·ï¼Œæ€»æ‹¿è´§ä»·æ¯”97xé«˜ä¸€ä¸ªæ•°é‡çº§äº†ï¼Œæœ¬æ¥å°±ä¸è¯¥æ‹¿æ¥æ¯”ï¼Œ265çœŸæ­£çš„å¼ºåŠ¿æ¥æºäºŽèƒ½è·Ÿæ›´è´µçš„79x99xæŽ°æ‰‹è…•

- ç”Ÿäº§åŠ›265 æ¸¸æˆ97xï¼Œè¿˜æœ‰70åº¦å¯¹äºŽcpuæ¥è¯´è¿˜å¤ªä½Žäº†ï¼Œ85åº¦éƒ½å¾ˆæ­£å¸¸ï¼Œä½ è¿™å®žå±žæ¸©åº¦çžŽç„¦è™‘

- ## [ä¸ºä»€ä¹ˆITXæž¶æž„çš„çŸ­æ˜¾å¡å¤§éƒ¨åˆ†éƒ½æ˜¯Nvidiaçš„ï¼Œè€ŒAMDçš„é«˜ç«¯ITXæ˜¾å¡åˆ™ä¸€å¡éš¾æ±‚ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/318806879)
- ITX çŸ­å¡å°±æ˜¯ä¸€ä¸ªç»†åˆ†å¸‚åœº, äº‹å®žä¸Šé™¤äº†æˆ‘å›½æœ‰ä¸€å † K39, é±¼æ½®S3 è¿™æ ·çš„æœºç®±, å…¶ä»–å›½å®¶åŸºæœ¬éƒ½æ‰¾ä¸åˆ°ç±»ä¼¼çš„æœºç®±.
  - ç›®å‰ N å¡é˜µè¥é‡Œçš„çŸ­å¡ä¸»è¦ä»¥ [æŠ€å˜‰] ä¸ºä»£è¡¨, åŒ…å« 1060/1070/1080, 2060/2070 å’Œ 1660. æ‰€ä»¥é™¤äº† 1080Ti/2080 è¿™äº›é¡¶çº§æ——èˆ°è´§, åŸºæœ¬ä¸Šç”œå“å¡éƒ½æœ‰äº†.

- æœ€æ ¹æœ¬çš„åŽŸå› åœ¨æˆ‘çœ‹æ¥æ˜¯æºè‡ªäºŽnå¡å¯¹ç¬”è®°æœ¬å¸‚åœºçš„é‡è§†ã€‚ç¬”è®°æœ¬å—åˆ¶äºŽç”µæºé€‚é…å™¨ï¼Œæ‹¢å…±å°±200wå·¦å³çš„ä¾›ç”µèƒ½åŠ›ï¼ŒCPUå’ŒGPUï¼ˆæ˜¾å¡æ ¸å¿ƒï¼‰éƒ½è¦åƒç”µçš„æƒ…å†µä¸‹ï¼Œä¸¤ä½å¤§å“¥éƒ½å¾—æŽ§åˆ¶ä½è‡ªå·±çš„åŠŸè€—ã€‚
  - ä¸€èˆ¬å°±åˆ†ç»™æ˜¾å¡90-140wï¼Œç»™cpu 60-90wï¼Œå¤šäº†è¦ä¹ˆç”µæºæ‰›ä¸ä½ï¼Œè¦ä¹ˆæ•£çƒ­é¡¶ä¸ä½ã€‚
  - æœ‰äº†ç¬”è®°æœ¬æŽ§åˆ¶æ•£çƒ­å’Œç”µæºçš„å‰æï¼Œè®¾è®¡èŠ¯ç‰‡æ—¶ï¼Œæ‰ä¼šæŽ§åˆ¶èƒ½è€—æ¯”å’Œå‘çƒ­ï¼Œæœ€ç»ˆä¹Ÿå°±èƒ½åšå‡ºé€‚åˆitxçš„çŸ­å¡ã€åˆ€å¡ã€‚
  - ç”±äºŽnvåœ¨ç¬”è®°æœ¬å¸‚åœºçš„æŽ’æŒ¤ï¼Œamdå¾ˆéš¾æŠŠè‡ªå·±çš„èŠ¯ç‰‡æŽ¨é”€ç»™æˆç†Ÿã€æœ‰åæ°”çš„ç¬”è®°æœ¬åŽ‚å•†ï¼Œå¹¶åšå‡ºè°ƒæ•™å®Œç¾Žçš„å¥½äº§å“ã€‚

- æˆæœ¬ï¼Œå…¬ç‰ˆvegaå°±ç”¨ä¸Šäº†å‡çƒ­æ¿(è€Œä¸”å¤§å¤šæ•°é«˜ç«¯å¡ä¹Ÿéƒ½ç”¨ä¸Šå‡çƒ­æ¿äº†)ï¼Œæ‰€ä»¥NANOç”¨å‡çƒ­æ¿æ˜¯ä¸ä¼šæœ‰ä»€ä¹ˆæˆæœ¬å¢žåŠ çš„ã€‚

- ITXæ˜¾å¡å¸‚åœºæ˜¯æ˜¾å¡å¸‚åœºä¸‹çš„å¦ä¸€ä¸ªç»†åˆ†å¸‚åœºï¼Œå¤ªå°ä¼—ï¼ŒAMDä½œä¸ºå¼±åŠ¿æ–¹ä¹Ÿæ²¡ä½™åŠ›å‘å±•ã€‚
  - è€Œä¸”ITXå¡å¯¹èƒ½è€—æ¯”è¦æ±‚è¾ƒé«˜ï¼ŒAMDåœ¨è¿™æ–¹é¢æ²¡æœ‰ä¼˜åŠ¿ã€‚

- ## [5090é è¾¹è®©è®©ï¼ŒçœŸç¥žé™ä¸´â€”â€”48Gçš„4090ï¼ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/67b5809e000000000e006d0c?xsec_token=ABGeo98UKSG8fjOMNixsHiBRqoxj7iqPLj_-v2GsF7NMk=&xsec_source=pc_search&source=web_search_result_notes)
  - ã€CPUã€‘AMD R9 9950X
  - ã€ä¸»æ¿ã€‘æŠ€å˜‰ B650M AORUS PRO AX
  - ã€å†…å­˜ã€‘é˜¿æ–¯åŠ ç‰¹ TUF 64G(32GX2) D5 6400
  - ã€æ˜¾å¡ã€‘è‹±ä¼Ÿè¾¾ 4090 48G æ¶¡è½®å¡
  - ã€å›ºæ€ã€‘ä¸‰æ˜Ÿ 990PRO 2T+1T
  - ã€æœºç®±ã€‘æœºæ¢°å¤§å¸ˆ CMAX
  - ã€æ•£çƒ­ã€‘ä¹å·žé£Žç¥ž å†°æš´ 240 LCDå±
  - ã€ç”µæºã€‘å…¨æ±‰Hydro PTM X PRO 1200
  - ã€é£Žæ‰‡ã€‘æ£±é•œ 4PRO
  - ã€å®šåˆ¶ã€‘CMAXç¡…èƒ¶çº¿

- ## [ITX | å¡žä¸ªRTX5080ï¼Ÿæ²¡é—®é¢˜ï¼ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/67bc32a90000000009039a96?xsec_token=ABBUmmsfcqVOegTyFI0DTJ4zLCSJXlG34hPsmQuX6DX3M=&xsec_source=pc_search&source=web_search_result_notes)
  - èƒŒé èƒŒç»“æž„çš„ITXæœºç®±åˆšå¥½å¡žå…¥äº†ä¸€å¼ ä¸‰é£Žæ‰‡çš„RTX5080ï¼Œæµ·éŸµSPX750ä½œä¸ºæ‰Žå®žè€ç”¨çš„ç»å…¸sfxç”µæºè½»æ¾å¸¦åŠ¨äº†i5+RTX5080çš„ç»„åˆï¼Œé¡¶éƒ¨ä¸¤ä¸ªå®‰é™ä¼˜é›…çš„æµ·éŸµMagflowé£Žæ‰‡ä¸ºæœºç®±å¸¦æ¥äº†æ›´ä¼˜åŒ–çš„é£Žé“æ•£çƒ­
  - æœºç®±ï¼šFORMD T1
  - æ˜¾å¡ï¼šå½±é©°RTX5080-16Gé­”åˆƒ
  - ä¸»æ¿ï¼šå¾®æ˜ŸB760i D4 Wi-Fi
  - å†…å­˜ï¼šçš‡å®¶æˆŸddr4-4000-16g*2
  - CPUï¼ši5-14600K
  - æ•£çƒ­å™¨ï¼šè¶…é¢‘ä¸‰RC600é»‘è‰²ç”µæºï¼šæµ·éŸµSPX750W
  - é£Žæ‰‡ï¼šæµ·éŸµMagFlow RGB 120*2
  - ç”µæºï¼šæµ·éŸµSPX750W

- [é«˜é¢œå€¼ã€èƒ½è£…ä¸‰æ‰‡é•¿æ˜¾å¡çš„13å‡itxä¸»æœº - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/676e9a4f0000000014026954?xsec_token=AB_LcGHuSS1a9ZxmBLSWAdGMd-OlAMXO2f9f82oya7dHg=&xsec_source=pc_search&source=web_search_result_notes)

- ## [å°æœºç®± 5090d+9950x3d æ‹¿ä¸‹ï¼ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/67f779020000000007036603?xsec_token=ABegebsB80NsOXLuiVvWiW-lQszDh0QuWayKWLU0ABe5c=&xsec_source=pc_search&source=web_search_result_notes)
  - ã€CPUã€‘AMD RyzenTm 9 9950X3D
  - ã€æ˜¾å¡ã€‘å¾®æ˜Ÿ 5090dè¶…é¾™
  - ã€æœºç®±ã€‘æ–¹ç³–æœºæ¢°å¤§å¸ˆC+MAXé“¶è‰²
  - ã€ä¸»æ¿ã€‘å¾®æ˜Ÿ MAG B850M MORTAR WIFI
  - ã€æ•£çƒ­ã€‘TRYX PANORAMAå±•åŸŸ240æ°´å†·ARGB é»‘è‰²
  - ã€å†…å­˜ã€‘ä½°ç»´ 128Gï¼ˆ32Gx4ï¼‰DDR5 6400 C34
  - ã€å›ºæ€ã€‘ä¸‰æ˜Ÿ 9100PRO 4TB PCIe5.0*4 M.2æŽ¥å£
  - ã€ç”µæºã€‘ æ´›åŸº1200w
  - ã€é£Žæ‰‡ã€‘ è”ç«‹ç§¯æœ¨ä¸‰ä»£

- æˆ‘å’Œä½ ä¸€æ ·çš„å¡å’ŒUï¼Œè¿™æ ·è£…å†·æŽ’å¸æ˜¾å¡å°¾æ°”å†åŠ ä¸Š9953è¿™ä¸ªç«ç‚‰å¾—å¤šçƒ­å•Šæˆ‘ç”¨çš„è¿˜æ˜¯å¤§æœºç®±å’Œå±•åŸŸ360æ€§èƒ½ç‰ˆæ°´å†·ï¼Œå¾…æœºå°±è¦40å¤šåº¦äº†ï¼Œç¨å¾®æ‰“å¼€å‡ ä¸ªç½‘é¡µç™»ä¸€ä¸‹steamå°±50+äº†
  - æˆ‘æ„Ÿè§‰è¿˜èƒ½æŽ¥å—å“Žï¼Œå¾…æœºäº”åå¤šï¼Œæ‰“å¼€ C4d è½»é‡å¹²ä¸ªæ´» 70 å¤šåº¦ï¼ŒCPU åæ­£ä¹Ÿçƒ§ä¸å
- æˆ‘æ˜¯14900kæ¢è¿‡æ¥çš„ä¹‹å‰æ²¡ç”¨è¿‡x3dçš„CPUã€‚149kè™½ç„¶è€ç”µä½†æ˜¯å¾…æœºæ¸©åº¦ä¸é«˜çš„ï¼Œæµè§ˆç½‘é¡µä¸ä¼šè¶…è¿‡35åº¦ã€‚è¿˜æ˜¯å¿ƒç†ä¸Šæ²¡é€‚åº”é«˜æ¸©çš„CPU
  - é‚£æˆ‘è€é€‚åº”äº†ä¹‹å‰ç”¨çš„ i9+3080ti ç¬”è®°æœ¬

- å¦‚æžœæ˜¯ LOL è¿™ç§æ¸¸æˆçš„è¯æ˜¾å¡ä¸‰åå¤šåº¦ï¼Œcpu å…­åå¤šï¼Œ3a æ¸¸æˆå¤§æ¦‚éƒ½åœ¨ä¸ƒå…«ååº¦å·¦å³

- æ¢ä¸ªè”åŠ›a3å°±å¯ä»¥äº†ï¼Œä¾§é¢è¿˜å¯ä»¥åŠ ä¸‰æŠŠé£Žæ‰‡ï¼Œ5é¢æ‰“å­”æ•£çƒ­æ¿

- æœºæ¢°å¤§å¸ˆcç³»åˆ—ä¾§è¾¹éƒ½æ˜¯çŽ»ç’ƒï¼Œè¦æ˜¯æ¢æˆç½‘æ•£çƒ­èƒ½æ›´å¥½ç‚¹

- [C+MAXé‡‘å±žå¤§å¸ˆ GTé“¶çµæ„Ÿ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/65f446c20000000014005ff3?xsec_token=ABxIEa1q74egE8STTJo9DqtGHzgiBycDD0OoPvjAjGLJA=&xsec_source=pc_search&source=web_search_result_notes)
  - CPUï¼š12600KF
  - GPUï¼šå½±é©° é‡‘å±žå¤§å¸ˆ 4080super
  - æœºç®±ï¼šæ–¹ç³–æœºæ¢°å¤§å¸ˆ C+max æœˆå…‰é“¶Airç‰ˆ
  - ä¸»æ¿ï¼šæŠ€å˜‰ B760M A ELITE AX D5
  - æ•£çƒ­ï¼šå¥¥æ–¯è‰¾i240-B ä¸€ä½“å¼æ°´å†·
  - ç¡¬ç›˜ï¼šå…‰å¨ å¼ˆç³»åˆ— æ——èˆ°ç‰ˆ 2T
  - ç”µæºï¼šæµ·ç›—èˆ¹SF850L

- [æœºæ¢°å¤§å¸ˆ CMax è€é“æŠ„ä½œä¸šäº† 9700Xæ­ 5070T - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/67caf20b0000000029029b83?xsec_token=ABqsyDIYHWnZyXfQUxpaLc8dJaKdhuBLrkKua73Sg89IQ=&xsec_source=pc_search&source=web_search_result_notes)
  - CPUï¼šAMD 9700X ä¸­æ–‡ç›’ï¼ˆå…¨ç¨‹çƒ¤æœºä¸è¶… 70 åº¦ï¼‰
  - æ˜¾å¡ï¼šæŠ€å˜‰ RTX5070TI é›ªé¹° 16G
  - ä¸»æ¿ï¼šæŠ€å˜‰ B850M å†°é›• WiFi6E
  - æ•£çƒ­å™¨ï¼šé…·é‡Œå¥¥ p60t Pro ç™½è‰²æ€§èƒ½ç‰ˆ
  - æœºç®±ï¼šæœºæ¢°å¤§å¸ˆ Cmax
  - é˜¿æ–¯åŠ ç‰¹å¥³æ­¦ç¥žäºŒä»£ 32G å¥— 6000 c28 
  - ç¡¬ç›˜ï¼šä¸‰æ˜Ÿ 990 Pro 4TB å›ºæ€
  - ç”µæºï¼šèˆªå˜‰ sfx é¢å®š 850w ç™½é‡‘å…¨æ¨¡ atx3.1

- ## [itxæœºç®±æœ‰å•¥å¾ˆéš¾å—çš„ç¼ºç‚¹å—ï¼Œæ•£çƒ­åˆ°åº•èƒ½æœ‰å¤šå·®ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/337421059)
- ç¼ºç‚¹æ˜¯ç©ºé—´å¤ªå°ï¼Œèµ°çº¿éº»çƒ¦ï¼Œæ¢é›¶ä»¶éº»çƒ¦(æ¢çš„é¢‘çŽ‡ä¸é«˜å°±ä¸ç®—æ˜¯ç¼ºç‚¹äº†
  - æ•£çƒ­ä¹Ÿæ˜¯çœ‹æœºç®±è€Œå®šçš„
- æ•£çƒ­ä¹Ÿæ˜¯çœ‹æœºç®±è€Œå®šçš„, ç›®å‰è£…è¿‡ä¸‰å°c24 qbx geeek a4çš„æ¸©åº¦éƒ½æ²¡å•¥é—®é¢˜
  - çŽ°åœ¨å¾ˆå¤ša4 æœºç®±çš„é£Žé“éƒ½æ˜¯ä»Žä¸‹åˆ°ä¸Šï¼Œè‚¯èŠ±é’±ä¹°é£Žæ‰‡çš„è¯ï¼Œæ•£çƒ­æ•ˆæžœè¿˜æ˜¯å¯ä»¥çš„
  - å®žåœ¨ä¸è¡Œå°±æŠŠä¾§é€æ¢æˆé˜²å°˜ç½‘å‘—ï¼Œåˆèƒ½ä½Žäº”åº¦äº†

- é£Žé“è®¾è®¡åœ¨ ITX é‡Œè™½ç„¶é‡è¦ï¼Œä½†æ˜¯å®žé™…ä¸Šæœ€å½±å“æ•£çƒ­çš„æ˜¯ç¡¬ä»¶é€‰æ‹©ï¼Œæ¯”å¦‚ä½ éžè¦åœ¨ ITX é‡Œæ”¾ i9 + æ——èˆ°æˆ–æ¬¡æ——èˆ°çš„æ˜¾å¡æ³¨å®šå¥½ä¸äº†ã€‚
  - å‡ å¹´å‰ä¸ºäº†è£…ä¸ª Ubuntu å°ä¸»æœºï¼Œæžäº†ä¸€å¥— 11900K + 6600XT çš„ ITX ä¸»æœºï¼Œå¼€æœºå°±60åº¦ä»¥ä¸Šï¼ŒåŽæ¥ç»™ CPU é™åŽ‹é™é¢‘ï¼Œæ¯ä¸ªæ ¸å¿ƒéƒ½é™äº† 0.2GHzï¼Œç”µåŽ‹ 1.1v æ‰å‹‰å¼ºåŽ‹ä¸‹æ¥
  - å¦å¤–ä¸€ç‚¹å°±æ˜¯ ITX å¯¹ SSD ä¸å‹å¥½ï¼Œå¸¸è§ ITX ä¸»æ¿çš„ M.2 ä½å°‘ï¼Œä¸”æ•£çƒ­å·®ï¼Œåˆšæ‰æåˆ°çš„é‚£æœºå™¨ï¼ŒçŽ©æ¸¸æˆçš„åœºæ™¯ä¸‹ä¸ä¸€ä¼š SSD å°±èƒ½ä¸Š 70 åº¦ã€‚èƒŒé¢çš„ SSD å°±å¥½å¾ˆå¤šï¼Œåªæœ‰ 50 åº¦å·¦å³
  - å¦‚æžœæƒ³è¦ ITX çš„â€œå°â€ï¼Œé‚£ä¹ˆæŽ¨èå…¨éƒ¨ç”¨ä¸­ç«¯çš„ç¡¬ä»¶ï¼Œi5 çº§åˆ«å·¦å³ + ä¸­ç«¯æ˜¾å¡ï¼Œä¸å¸¸ç§»åŠ¨ä¸”èƒ½æŽ¥å—æ°´å†·çš„è¯å¯ä»¥ä¸Š 240 å°ºå¯¸çš„æ°´å†·ï¼Œæ˜¾å¡å¯ä»¥çœ‹çœ‹å“ç‰Œæ‹†æœºçš„æ¶¡è½®å¡ï¼Œèƒ½å¤Ÿæœ‰æ•ˆçš„é™ä½Žç®±å†…æ¸©åº¦ã€‚

- æˆ‘ä¹‹å‰æžäº†ä¸ª12500H+P4çš„itxï¼Œçƒ­çš„æ ¹æœ¬æ²¡æ³•ç”¨ï¼ŒCPUå’Œæ˜¾å¡ä¸€ç›´100åº¦ï¼Œæœ€åŽæ— å¥ˆæ¢äº†ä¸ªATXæœºç®±ï¼Œè§£å†³ï¼Œæ¸©åº¦æ²¡é«˜äºŽ60åº¦è¿‡

- å½“æ¸©åº¦ä¸ŠåŽ»åŽï¼Œå¸¦æ¥çš„æœ€ç›´è§‚åŽæžœå°±æ˜¯é£Žæ‰‡è½¬é€Ÿè¿‡é«˜å¼•èµ·çš„å™ªéŸ³å¾ˆå¤§ã€‚
  - å¦å¤–itxæœºç®±å’Œä¸»æ¿å¯¹äºŽç¡¬ç›˜æŽ§éžå¸¸ä¸å‹å¥½ã€‚M.2ä¸€èˆ¬ä¸è¶…è¿‡ä¸¤ä¸ªä¸”æ¸©åº¦è¾ƒé«˜ï¼Œ3.5æœºæ¢°ç¡¬ç›˜å®‰è£…å›°éš¾å³ä½¿è£…ä¸ŠåŽ»ä¹Ÿä¸€èˆ¬ä¼šå ç”¨ä¸€ä¸ªé£Žæ‰‡ä½é—´æŽ¥å½±å“æ•£çƒ­ã€‚
- ç¡®å®ž, æˆ‘å…‰çœ‹å°å·§ä¾¿æºåŽ»äº†, å‡ å¹´ä¹Ÿæ¬ä¸äº†ä¸€æ¬¡, itxæ¢ä¸‹æ¥æ¯”å¸¸è§„è´µä¸¤åƒ, è€Œä¸”æ€§èƒ½è¿˜å·®

- [ã€8.1Lã€‘ ä¾¿æºç§‘ç ”ITXæœ¬åœ°å°ä¸»æœºæŽ¨è1ï¸âƒ£ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/67adb5420000000029034581?xsec_token=ABakFdkTIJ1ZcM6p0CG5TD5J9V9fUMmia67ixkR6mRgtE=&xsec_source=pc_search&source=unknown)
  - æœºç®±ï¼šé—ªé³žs300 tc+usb PCIE4.0å»¶é•¿çº¿ï¼ˆ444ï¼‰
  - CPUï¼š12600kfï½›ä¹Ÿå¯14600kfï¼ˆæ¿uï¼š1889ï¼‰ï½
  - ä¸»æ¿ï¼šé“­ç‘„b760i WIFI D4ï¼ˆ1669ï¼‰
  - æ•£çƒ­ï¼šåˆ©æ°‘AXP90-x53 4çƒ­ç®¡ï¼ˆ164ï¼‰
  - å†…å­˜ï¼šé‡‘ç™¾è¾¾é“¶çˆµ3600 D4 32G*2 ï¼ˆ741ï¼‰
  - ç¡¬ç›˜ï¼šé‡‘å£«é¡¿kc3000 1T PCIE4.0 1Gç‹¬ç¼“ï¼ˆ473ï¼‰
  - æ˜¾å¡ï¼šæŠ€å˜‰é£Žé­”RTX4060ti-16Gï¼ˆ3689ï¼‰æ¯«æ— æ€§ä»·æ¯”ï¼Œå¯ä»¥è€ƒè™‘äºŒæ‰‹å¤§æ˜¾å­˜çš„å¡ã€‚
  - ç”µæºï¼šçŽ„æ­¦650sfx é‡‘ç‰Œå…¨æ¨¡ç»„ï¼ˆ359ï¼‰
- 12600kfå·²ç»å¯ä»¥æ»¡è¶³å¾ˆå¤šæ—¥å¸¸çš„ç”Ÿäº§åŠ›ä»»åŠ¡åŒæ—¶ä¸ç”¨æ‹…å¿ƒç¼©è‚›ï¼Œä½†æ˜¯å’Œ14600kfä»…æœ‰200å…ƒå·®è·ï¼Œè¯´å®žè¯æˆ‘æ›´æŽ¨è146kfï¼Œä½†æ˜¯æ— å¥ˆç¼©è‚›â€¦æœ‰åŠ¨æ‰‹èƒ½åŠ›çš„å°ä¼™ä¼´å¯ä»¥ä¸Š146kf
- é“­ç‘„b760ä¸»æ¿æ€§ä»·æ¯”é¦–é€‰ã€‚ç»™åˆ°9ä¸ªUSBæŽ¥å£å…¶ä¸­æœ‰2ä¸ª20Gbpsçš„cå£ï¼Œå¸¦WIFI6Eç½‘å¡ï¼ŒåŒæ—¶ç»™åˆ°2ä¸ªm2 2280çš„æ’æ§½ï¼Œæ”¯æŒPCIE4.0çš„é€ŸçŽ‡ã€‚å†æ­é…4ä¸ªSATAæŽ¥å£ç»™ç¡¬ç›˜æ‰©å®¹ï¼Œæ»¡è¶³é«˜å­˜å‚¨çš„éœ€æ±‚ã€‚åŒæ—¶å¯¹æ˜¾å¡æ˜¯PCIE5.0x16æ’æ§½ã€‚

- ## ðŸ§©ðŸ’¡ [ITXæœºç®±æŽ¨è 2025å¹´ç‰ˆ 80èµ·æ­¥ ï¼»æ”¯æŒMATXä¸»æ¿ã€ITXä¸»æ¿ã€å¸¸è§„ATXç”µæºã€SFXç”µæº 15L 20Lä½“ç§¯ï¼½300ä»¥å†… é«˜æ€§ä»·æ¯” å°å¼ç”µè„‘æœºç®± K88 i8 P90 è¶£é€ ç­‰ - çŸ¥ä¹Ž](https://zhuanlan.zhihu.com/p/677817218)

- resources
  - [CaseEnd filters](https://caseend.com/)

- 15å‡ã€20å‡æœºç®±çš„ç»“æž„ç±»åž‹ï¼šå¸¸è§ç»“æž„ï¼ŒåŸºæœ¬æ˜¯å‰ç½®ç”µæºï¼Œæ¨ªæ”¾æ˜¾å¡
  - æœ‰ä¸€äº›ç‰¹æ®Šçš„æœºç®±ï¼Œç»“æž„ï¼šä¸‹ç½®ç”µæºã€éœ€è¦æ˜¾å¡å»¶é•¿çº¿ã€ä¸‹åŽ‹å¼é£Žå†·ã€‚ç±»ä¼¼é…·é±¼T40ï¼Œä½†æœ¬æ–‡ä¸åšæŽ¨èï¼ˆå¤ªå°‘äº†ï¼ŒèŠ±è´¹ä¹Ÿå¯èƒ½æ¯”è¾ƒé«˜ï¼‰

- çŽ»ç’ƒä¾§æ¿ï¼šå¸¸è§çš„ä¾§æ¿æè´¨ï¼Œå®‰è£…æ—¶ï¼Œéœ€è¦æ³¨æ„è¾¹è§’ä¸èƒ½è¢«ç£•åˆ°ï¼Œå¦åˆ™å®ƒä¼šç¢ŽæŽ‰ã€‚
- äºšå…‹åŠ›ä¾§æ¿ï¼šé€æ˜Žå¡‘æ–™ä¾§æ¿ï¼Œå¦‚æžœæ¸©åº¦è¾ƒé«˜ï¼Œå¯èƒ½ä¼šæœ‰å¡‘æ–™å‘³ï¼Œæ—¶é—´é•¿äº†ï¼Œä¹Ÿä¼šå‘é»„ã€‚
- é“ä¾§æ¿ï¼šç›¸å¯¹æ¥è¯´ï¼Œæ¯”è¾ƒå…¶ä»–ç±»åž‹çš„ä¾§æ¿ï¼Œè¿™æ¬¾æ˜¯æœ€å¥½çš„ï¼Œç¢Žä¸äº†ï¼Œä¹Ÿä¸ä¼šæœ‰å¡‘æ–™å‘³ã€‚ä½†æœ‰äº›åŽ‚å®¶ï¼Œé“ä¾§æ¿ç”šè‡³ä¸å¼€å­”ï¼Œè¿™å°±ä¼šè®©æ•£çƒ­æ•ˆæžœå·®ã€‚
- é˜²å°˜ç½‘ä¾§æ¿ï¼šè¿™ç§ä¾§æ¿ï¼Œä¸€èˆ¬è‡ªå·±DIYçš„æ¯”è¾ƒå¤šï¼Œå¤šä¸ºå¡‘æ–™æè´¨ã€‚éƒ¨åˆ†æœºç®±ï¼Œæ˜¯é‡‘å±žä¾§æ¿+é˜²å°˜ç½‘çš„ç»„åˆã€‚
  - æ‰€æœ‰æœºç®±ï¼Œéƒ½å¯ä»¥è‡ªåˆ¶é˜²å°˜ç½‘ä¾§æ¿ï¼Œæˆæœ¬ä¸åˆ°10å—ï¼š

- æœ¬æ–‡æŽ¨èçš„æ‰€æœ‰æœºç®±ï¼Œä¸ªäººéƒ½åªæŽ¨èè£…åŒé£Žæ‰‡æ˜¾å¡ã€‚ åŒé£Žæ‰‡æ˜¾å¡ï¼Œé•¿åº¦ä¸€èˆ¬ä¸ä¼šè¶…è¿‡300æ¯«ç±³ï¼Œå¤šæ•°æœºç®±ï¼Œéƒ½å¯ä»¥æ”¾ä¸‹ã€‚

- æœºæ¢°å¤§å¸ˆ cmax â—‡99
  - å°ºå¯¸ï¼š392*185*284mm, 20.5L
  - æ˜¾å¡ï¼š385*160mmä»¥å†…
  - æ•£çƒ­ï¼š162æ¯«ç±³é£Žå†· æˆ– 240æ°´å†·
  - æè´¨ï¼šå†…æ¡†ï¼š1mmSPCCé’¢æ ï¼›å¤–æ¡†ï¼š2mmé“åˆé‡‘
  - ä¸»æ¿æ”¯æŒ MATX/ITX
  - ç”µæºæ”¯æŒ SFX/SFX-L/ï¼ˆ140mmä»¥å†…ï¼‰ATX
  - é£Žæ‰‡æ”¯æŒ é¡¶éƒ¨ï¼š12cm*2ï¼›å°¾éƒ¨ï¼š12cm*1ï¼›å‰é¢æ¿ï¼š8/9cm*1
  - 2.5å¯¸ç¡¬ç›˜ä½ è‡³å¤š3ä¸ª
  - 3.5å¯¸ç¡¬ç›˜ä½ è‡³å¤š1ä¸ª

- é±¼å·¢ S9 â—‡99
  - å°ºå¯¸ï¼š375Ã—188Ã—300, 21.15L
  - æ˜¾å¡ï¼š360x150é™é•¿
  - æ•£çƒ­ï¼š160æ¯«ç±³é£Žå†· æˆ– 240æ°´å†·
  - æè´¨ï¼š1.2æ¯«ç±³ é•€é”Œé’¢æ¿
  - ä¾§æ¿ï¼š~~çŽ»ç’ƒ~~
  - ç”µæºï¼šATXç”µæºï¼Œ170mmä»¥å†…
  - ä¸»æ‰“çš„å°±æ˜¯ä¾¿å®œï¼Œ99ï¼Œè¿˜èƒ½èµ°èƒŒçº¿ï¼Œè®©æœºç®±å†…æ›´ç¾Žè§‚ä¸€äº›ï¼Œè™½ç„¶èƒ½èµ°çš„ä¸å¤š

- é“å°å® E90 PRO
  - å°ºå¯¸ï¼š377Ã—187Ã—298, 21L
  - æ˜¾å¡ï¼š355x150x80mmé™é•¿
  - æ•£çƒ­ï¼š160æ¯«ç±³é£Žå†· æˆ– 240æ°´å†·
  - ç”µæºï¼šATXç”µæºï¼Œ160mmä»¥å†…, sfx/fiexç”µæºéœ€è‡ªå¤‡è½¬æŽ¥æ¿
  - é“å°å®ALBOX P90 â—‡158, è¢«E90Proå–ä»£
    - å°ºå¯¸ï¼š375Ã—188Ã—300, 21L
    - æ˜¾å¡ï¼š360x150x80mmé™é•¿
    - æ•£çƒ­ï¼š160æ¯«ç±³é£Žå†· æˆ– 240æ°´å†·
    - æè´¨ï¼š1.5æ¯«ç±³+1.0æ¯«ç±³ å†·è½§é’¢æ¿
    - ä¾§æ¿ï¼šé“ æˆ– äºšå…‹åŠ›
    - Motherboard(MM): 245 x 245
    - Power Supply(MM): 150 x 160 x 86
    - æœ¨è´¨ææ‰‹ï¼Œç®—æ˜¯è¿™ä¸ªæœºç®±çš„ç‰¹è‰²äº†ã€‚
    - ç”µæºå»¶é•¿çº¿ä½ç½®ï¼Œåœ¨æœºç®±é¡¶éƒ¨ï¼Œè£…å‡ºæ¥çš„æ•ˆæžœï¼Œå°±å‚è€ƒå®˜æ–¹è¿™ä¸ªå›¾å§ã€‚

- ç¬¨ç‰› N20 â—‡199
  - å°ºå¯¸ï¼š381Ã—199Ã—300mm, 22L
  - æ˜¾å¡ï¼šé™é•¿364x160x85mm, 16cmçš„ç”µæºé•¿åº¦æ”¯æŒ315mmæ˜¾å¡é•¿åº¦, 16cmä»¥ä¸Šç”µæºä»…æ”¯æŒ290mmæ˜¾å¡
  - æè´¨ï¼š1.5æ¯«ç±³+0.8æ¯«ç±³ å†·è½§é’¢æ¿
  - ä¾§æ¿ï¼š3æ¯«ç±³ çŽ»ç’ƒä¾§æ¿
  - æ•£çƒ­ï¼š164æ¯«ç±³é£Žå†· æˆ– 240æ°´å†·
  - èƒ½èµ°èƒŒçº¿çš„å°æœºç®±ï¼Œä¸å¤šï¼Œä¹Ÿä¸å°‘ã€‚ä¸è¿‡éƒ½åªèƒ½èµ°ä¸€ç‚¹ç‚¹ã€‚å‰é¢æ¿æœ‰å¤§é¢ç§¯å¼€å­”ï¼Œæ•£çƒ­é€šé£Žå¥½ï¼Œç”µæºä½ç½®æœ‰ä¸€ä¸ªæŒ¡æ¿ï¼Œè£…å‡ºæ¥ï¼Œé‚£å †çº¿å°±çœ‹ä¸åˆ°äº†

- åŒ…å­æ˜Ÿäºº A88Pro â—‡183
  - å°ºå¯¸ï¼š380Ã—195Ã—305, 22.6L
  - æ˜¾å¡ï¼š360æ¯«ç±³é™é•¿
  - æè´¨ï¼š1.2æ¯«ç±³ é•€é”Œé’¢æ¿
  - ä¾§æ¿ï¼šé“ æˆ– çŽ»ç’ƒ

- å…ˆé©¬è¶£é€  â—‡139
  - å°ºå¯¸ï¼š391Ã—185Ã—303
  - æ˜¾å¡ï¼š335æ¯«ç±³é™é•¿
  - æ•£çƒ­ï¼š155æ¯«ç±³é£Žå†·
  - æè´¨ï¼š1.5æ¯«ç±³+1.0æ¯«ç±³ å†·è½§é’¢æ¿
  - ä¾§æ¿ï¼šé“ æˆ– äºšå…‹åŠ›
  - è¶£é€ è¿˜æœ‰ä¸ªå…„å¼Ÿï¼Œå«åšè“å®çŸ³é“¶è§’å¤§çŽ‹ï¼Œä½†ç›®å‰åªæœ‰åº“å­˜è´§äº†ï¼Œè€Œä¸”å–çš„æ¯”è¶£é€ è´µâ€¦â€¦

- æ–‡ä¸­æåˆ°çš„è¿™äº›å“ç‰Œï¼Œå¤šæ•°éƒ½æ˜¯æœ‰10å‡çš„æœºç®±ï¼Œå¯ä»¥åŽ»æœæœçœ‹ã€‚

- æœ‰æ²¡æœ‰å¤šç›˜ä½ï¼ˆ3-5ä¸ª3.5HDDï¼‰å°æœºç®±æŽ¨è
  - æ— 

- å¦‚æžœæ‹’ç»å…‰æ±¡æŸ“ï¼Œéžé€æ˜Žä¾§æ¿çš„15å‡ï¼Œæœ‰æŽ¨èå—ï¼Ÿ
  - A88

- ## [æœ‰å“ªäº›å¯å®¹çº³ 4090 æ˜¾å¡çš„ ITX æœºç®±ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/559771286/answers/updated)
- æžé™å°ºå¯¸itxä¸æ˜¯ä¸èƒ½æžï¼Œé—®é¢˜æ˜¯æº¢ä»·å¤ªé«˜ï¼Œå®šåˆ¶çš„æœºç®±å°±è¦1k-2kå·¦å³ï¼Œä¸»æ¿ï¼ˆitxæ¿åž‹ï¼‰ï¼Œç”µæºï¼ˆï¼‰ï¼Œæ˜¾å¡ï¼ˆæœ€å®Œç¾Žçš„æ˜¯ï¼Œä¸‰é£Žæ‰‡çš„ä¸ç”¨æƒ³äº†ï¼‰å°å°ºå¯¸çš„å…¨éƒ½æœ‰æº¢ä»·ã€‚æ€»ä½“æ¯”æ­£å¸¸é…è¦è´µ30%-40%å·¦å³ã€‚
  - 4090è¿˜ç®—å¥½ï¼Œä½ é™é¢‘åˆ°3090è¿™ä¸ªæ°´å¹³çŽ©æ²¡æœ‰æ•£çƒ­é—®é¢˜ï¼Œä½†æ˜¯itxæ­£å¸¸ç”¨æ•£çƒ­é—®é¢˜å¾ˆå¤§ï¼Œå»ºè®®å¼€ç›–ï¼Œä¸ç„¶CPUå¾—ä¸Šæ°´ï¼Œæ˜¾å¡4090é™é¢‘ç”¨é—®é¢˜ä¸å¤§ï¼Œè¿˜æœ‰èƒŒéƒ¨m2çš„æ•£çƒ­ï¼Œé£Žåˆ‡å£°éŸ³é—®é¢˜ç­‰ç­‰ã€‚

- å…¬ç‰ˆ4090å’Œ3090ä¸€ä¸ªå¤§å°ï¼Œä¹°å…¬ç‰ˆç„¶åŽåŸºæœ¬ä¸ŠåŽŸæœ¬èƒ½è£…3090çš„éƒ½èƒ½è£…

- åœ¨redditä¸Šçœ‹åˆ°äº†å‡ ä¸ªæ¡ˆä¾‹ï¼Œä¸æNr200ã€Meshliciousé‚£äº›å¤§å·çš„itxæœºç®±ï¼Œå°±çœ‹10Lå·¦å³çš„ï¼š
  - Formd T1ï¼Œè¿™æ˜¯ä¸ª10Lçš„æœºç®±ï¼Œè¿™ä¸ªæœºç®±æˆ‘ä¹Ÿåœ¨ç”¨ï¼Œå¤–å½¢æˆ‘éžå¸¸å–œæ¬¢ã€‚æˆ‘è‡ªå·±çš„T1é‡Œé¢å¡žäº†ä¸ªå…¬ç‰ˆ3090ã€‚
  - è”åŠ›A4-H2Oï¼Œè¿™æ˜¯ä¸ª11Lçš„æœºç®±ï¼Œç»§æ‰¿äº†Dan A4çš„å¥½ä¼ ç»Ÿï¼Œå¢žåŠ äº†å…¼å®¹æ€§ï¼Œæˆæœ¬ä¹Ÿé™ä¸‹æ¥äº†
  - Jimu D+ V2.0ï¼Œ10.5Lçš„æœºç®±ï¼ŒåŒæ ·å¡žè¿›åŽ»äº†ä¸€ä¸ª4090FE+AIOï¼Œè¿™ä¸ªæœºç®±å¤–è§‚å’Œå†…éƒ¨è§„åˆ’è·ŸFormd T1å‡ ä¹Žå¦‚å‡ºä¸€è¾™ï¼Œä½†ä»·æ ¼è¦ä¾¿å®œäº›
  - Ncase M1ï¼Œä¸åˆ°13Lï¼Œå› ä¸ºä¸æ˜¯ä¸‰æ˜Žæ²»æ ¼å±€ï¼Œè¿™è´§ä¸ºäº†ä¸æ†‹æ­»4090æŠŠæœºç®±åž«èµ·æ¥äº†ï¼Œè€Œä¸”å¦‚æžœä¸ç”¨ä¸ª90åº¦è½¬æŽ¥å¤´çš„è¯4090çš„ç”µæºçº¿æ²¡æ³•æ’ã€‚
- åŸºæœ¬ä¸Šçœ‹åˆ°çš„å°äºŽ14Lçš„4090æ¡ˆä¾‹å°±è¿™äº›äº†ï¼Œå¦‚æžœæ”¾å®½è¦æ±‚ï¼Œredditä¸Šæœ‰å¤§é‡çš„ssupd meshliciousçš„æ¡ˆä¾‹ï¼Œè™½ç„¶ä½“ç§¯è¦å¤§ä¸å°‘ï¼Œä½†å› ä¸ºæ˜¯ç«–ç›´æ”¾ç½®çš„ï¼Œå åœ°ç©ºé—´éžå¸¸å°
  - é™¤äº†å…¬ç‰ˆå¡ä¹‹å¤–ç¬¬ä¸‰æ–¹çš„å¡åŸºæœ¬éƒ½å¡žä¸è¿›åŽ»

- ## [å„ä½å¿ƒç›®ä¸­æœ€å¥½çš„ITXæœºç®±æ˜¯ä»€ä¹ˆï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/55014071/answers/updated)
- æˆ‘è‡ªå·±DIYä¸»æœºï¼Œå–œæ¬¢åœ¨æœ‰é™çš„ç©ºé—´é‡Œï¼Œå……åˆ†å‘æŒ¥å„éƒ¨ä»¶çš„æ€§èƒ½
  - PSï¼šæˆ‘ä»Žä¸è€ƒè™‘æ°´å†·ï¼Œå› æ­¤ä¸åšæ°´å†·æŽ¨èã€‚

- é«˜æ€§èƒ½å…¼é¡¾å°ä½“ç§¯çš„é€‰æ‹©ï¼šä¹”æ–¯ä¼¯çš„Z20æœºç®±ï¼ˆ20Lï¼‰
  - é«˜æ€§èƒ½ä¸»æœºçš„æ˜¾å¡æ˜¯ä¸€å®šè¦ä¸Šä¸‰é£Žæ‰‡çš„ï¼ŒåŸºæœ¬ä¸Šæ˜¯4080ä»¥ä¸Šçº§åˆ«ï¼ŒCPUä¹Ÿæ˜¯13600ä»¥ä¸Šçš„è§„æ ¼ï¼Œè¿™å¯¹æœºç®±çš„æ•£çƒ­æœ‰ä¸å°çš„è¦æ±‚ã€‚
  - ä¹”æ–¯ä¼¯Z20æœºç®±é¡¶éƒ¨å’Œåº•éƒ¨å¯ä»¥æ”¯æŒ4ä¸ª14cmé£Žæ‰‡ï¼Œå°¾éƒ¨è¿˜å¯ä»¥è£…ä¸€ä¸ª12cmé£Žæ‰‡ï¼Œåˆç†è§„åˆ’ä¸‹è¿›ä¸Šå‡ºçš„é£Žé“ï¼Œè¶³å¤ŸåŽ‹å¾—ä½4080å’Œ13700çš„ç»„åˆã€‚
- æœ€ä½³æ€§ä»·æ¯”å°æœºç®±çš„é€‰æ‹©ï¼šæœºæ¢°å¤§å¸ˆC26ï¼ˆ12.9Lï¼‰å’Œç¬¨ç‰›U45ï¼ˆ11Lï¼‰
  - 2024å¹´è¿™ä¸ªæ—¶å€™ï¼Œä¸‰å¤§åŽ‚çš„ITXä¸»æ¿æ¯”MATXä¸»æ¿è´µäº†å°†è¿‘ä¸€å€ï¼ŒåŒæ ·çš„é…ç½®æŠŠMATXä¸»æ¿æ¢æˆITXä¸»æ¿è‡³å°‘è´µ600å—ï¼Œå®žåœ¨æ²¡ä»€ä¹ˆæ€§ä»·æ¯”ã€‚å› æ­¤é€‰æ‹©MAXTä¸»æ¿+SFXç”µæºçš„ç»„åˆï¼Œä¾¿æˆäº†å…¼é¡¾æ€§ä»·æ¯”çš„æœ€å°æœºç®±æ­é…
  - 2.1æ›´å¼ºæ•£çƒ­ï¼ŒæŽ¨èæœºæ¢°å¤§å¸ˆC26ã€‚å¯¹äºŽAMDæ˜¾å¡+CPUç»„åˆæˆ–è€…13700+4070tié«˜æ€§èƒ½ç»„åˆçš„ï¼Œæ›´æŽ¨èå¸¦å‰é¢æ¿é£Žæ‰‡ä½çš„æœºæ¢°å¤§å¸ˆC26ã€‚è¿™ä¸ªè§„æ ¼çš„æœºç®±ï¼Œé¡¶éƒ¨å’Œåº•éƒ¨åªæ”¯æŒ9cmé£Žæ‰‡äº†ï¼Œè¿™ä¸ªå¤§å°çš„é£Žæ‰‡è¿˜å¸¦ä¾§è¾¹RGBæ ·å¼çš„ï¼Œæˆ‘åªæ‰¾åˆ°é±¼å·¢çš„9cmé£Žæ‰‡ã€‚
  - ä¸ºäº†åŽ‹13700æˆ–5800Xè¿™æ ·çš„CPUï¼Œ135mmé«˜åº¦æ•£çƒ­å™¨åªèƒ½é€‰åˆ©æ°‘çš„SS135äº†ï¼Œä½†è¿™æ¬¾ä¸å¸¦RGBé£Žæ‰‡ï¼Œä¸ºäº†å’Œ9cmé±¼å·¢çš„é£Žæ‰‡rgbé£Žæ ¼ç»Ÿä¸€ï¼Œå»ºè®®è‡ªè¡Œæ›´æ¢æˆé±¼å·¢çš„12cmé£Žæ‰‡ã€‚å¦‚æžœæ˜¯13400è§„æ ¼çš„CPUï¼Œé‚£ä¹ˆåˆ©æ°‘çš„AK120miniå°±èƒ½åŽ‹å¾—ä½ï¼ŒRGBé£Žæ‰‡çš„é£Žæ ¼å°±è‡ªè¡Œå‘æŒ¥äº†
  - 2.2æ›´å…·æ€§ä»·æ¯”ä¸”æ›´ç´§å‡‘ï¼ŒæŽ¨èU45ã€‚U45æœ‰ä¸ªç¼ºç‚¹å°±æ˜¯å‰é¢æ¿æ²¡æœ‰é£Žæ‰‡ä½ï¼Œæ‰€ä»¥å»ºè®®CPUå’Œæ˜¾å¡çš„è§„æ ¼è¦ä¸‹é™ä¸€äº›ï¼Œä»¥é˜²æœºç®±é—·ç½ã€‚æ­¤å¤–ï¼ŒU45å³è¾¹é‚£ä¸ªæŒ¡æ¿è®¾è®¡ï¼Œè™½ç„¶æ–¹ä¾¿äº†ç†çº¿å’Œè—çº¿ï¼Œä½†æˆ‘æ˜¯çœŸçš„æ¬£èµä¸æ¥è¿™è®¾è®¡ã€‚

- ## [Quad 4090 48GB + 768GB DDR5 in Jonsbo N5 case : r/LocalLLaMA _202507](https://www.reddit.com/r/LocalLLaMA/comments/1m9uwxg/quad_4090_48gb_768gb_ddr5_in_jonsbo_n5_case/)
  - JONSBO N5 NAS Pc Case: W355*D403*H350mm
  - GPUs -- Quad 4090 48GB (Roughly 3200 USD each, 450 watts max energy use)
  - CPUs -- Intel 6530 32 Cores Emerald Rapids (1350 USD)
  - So some additional information. I'm located in China, where "top end" PC hardware can be purchased quite easily.

- Do they "just work" or do you need sketchy drivers?
  - On Ubuntu they just work with official drivers (either Ubuntu PPA or Nvidia). 
  - On Windows I've seen reports that they do not work with official drivers, but I have not tried (nor do I plan to run windows on this machine)

- ## [ä¹”æ€ä¼¯Z20æœºç®±å°ç™½é¦–æ¬¡è£…æœºåˆ†äº« - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/67eadb49000000001c00c0db?xsec_token=ABhwvh4o79bh1iZJod5ETLKzRMlnZYs2oM-5p3wHmKM24=&xsec_source=pc_search&source=unknown)

- [ä¹”æ€ä¼¯Z20è£…æœºåˆ†äº« - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/67e7b093000000001201ed15?xsec_token=ABhmT245aHYddZ3_znj1lt9rAgzysn8wPmPsb_KU5jWH0=&xsec_source=pc_search&source=unknown)

- ## [DIYè£…æœºä¹”æ€ä¼¯z20 9600x + 5060å»ºè®®å¸– - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/688c38a60000000025022daa?xsec_token=ABH_IcKm-CurbXXiUGZUe0iNzqulTk75YHR2Lmgz9lyY4=&xsec_source=pc_search&source=unknown)
  - ã€æ•£çƒ­ã€‘ åˆ©æ°‘PA120 MINI BLACKåŒå¡”6çƒ­ç®¡é»‘è‰²
  - ã€CPUã€‘ AMD é”é¾™ 5 9600X
  - ã€ä¸»æ¿ã€‘ å¾®æ˜Ÿ B650M GAMING PLUS WIFI
  - ã€æ˜¾å¡ã€‘ ä¸ƒå½©è™¹ æˆ˜æ–§ RTX 5060 è±ªåŽç‰ˆ 8GB
  - ã€å†…å­˜ã€‘ é‡‘ç™¾è¾¾ 32GB(16GBX2) DDR5 6000 æµ·åŠ›å£«A-dieé¢—ç²’ æ˜Ÿåˆƒ
  - ã€ç”µæºã€‘ å®‰è€ç¾Ž é‡‘ç«žè GM650 é»‘è‰²  Â¥329 @äº¬ä¸œ

- å†…å­˜ä¹°äº†å›½äº§çš„ å…¶ä»–çš„å¤ªè´µäº†
  - ç¡®å®žæ˜¯è¿™æ ·ï¼æˆ‘å†…å­˜ä¹Ÿå‡†å¤‡æ¢c30äº†
- æˆ‘æ˜¯c36 æ‹¼å¤šå¤šä¹°çš„

- é«˜uä½Žå¡äº†ï¼Œæ¢7500fï¼Œç”µæºé€‰ä¸ªå¤§åŽ‚çš„

- 9600xåŠ 5060é«˜uä½Žå¡äº†ï¼Ÿ5060é…7500fï¼Ÿ
  - 7500fæ„Ÿè§‰éƒ½é«˜äº†ï¼Œä½†è€ƒè™‘åˆ°ç½‘å‹çŽ©å®¶é‚£å·®ä¸å¤šäº†ã€‚
- é™¤éžä½ åªçŽ©1080pçš„ç½‘æ¸¸ã€‚ä½†çŽ°åœ¨ä¸»æµéƒ½æ˜¯2kæ˜¾ç¤ºå™¨æˆ–è€…æ˜¯4kåŒæ¨¡äº†ã€‚è€Œä¸”uè¿˜å¯ä»¥å°è¶…ä¸€ä¸‹ï¼Œæ˜¾å¡è€é»„ä¸ç»™ä½ è¶…çš„ã€‚

- [å¹´è½»äººçš„ç¬¬ä¸€å°ç”Ÿäº§åŠ›ä¸»æœºä¹”æ€ä¼¯Z20 - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/6777b7c8000000000900d498?xsec_token=ABnLOUzIXMWLH-jTphfigaEnUEg3qXD4FdObm05VCiLdg=&xsec_source=pc_search&source=unknown)
  - æ•£çƒ­ï¼šè¶…é¢‘ä¸‰ RZ620è‡»+è¿½é£Žè€…M25æ— å…‰

- [Jonsbo Z20 build : r/mffpc _202506](https://www.reddit.com/r/mffpc/comments/1lo5xwl/jonsbo_z20_build/)
  - CPU: AMD 9600x; 
  - GPU: Powercolor 9070xt reaper 
  - PSU: seasonic focus gx850 
  - Motherboard: Asus B850M plus wifi 
  - Memory: gskill trident 32GBx2 6000MHz CPU 
  - cooler: thermalright frozen notte 240

- [Jonsbo Z20 Build. Intel Core Ultra 7 265K + RTX 5070 : r/mffpc _202506](https://www.reddit.com/r/mffpc/comments/1lfgii7/jonsbo_z20_build_intel_core_ultra_7_265k_rtx_5070/)
  - CPU: Intel Core Ultra 7 265K
  - GPU: ASUS GeForce RTX 5070 TUF GAMING OC 12GB
  - Motherboard: MSI B860M GAMING PLUS WIFI
  - PSU: Corsair SF 850W 80 PLUS Platinum
  - RAM: 64GB Kingston Fury Beast Black RGB EXPO [2x32GB 6000MHz DDR5 CL30 DIMM]
  - SSD: Kingston FURY Renegade SSD 2TB M.2 2280
  - CPU Cooler: THERMALRIGHT Peerless Assassin 120 Digital ARGB
  - Case Fan: DEEPCOOL FC120 x3 Set

- [Jonsbo Z20 Build - RTX 5090 FE, 9800X3D : r/mffpc _202510](https://www.reddit.com/r/mffpc/comments/1nur3dl/jonsbo_z20_build_rtx_5090_fe_9800x3d/)
  - CPU - AMD Ryzen 7 9800X3D
  - GPU - RTX 5090 Founder's Edition
  - RAM - 32GB x2 Corsair Vengeance CL32 6400Mhz DDR5 RGB RAM
  - Cooler - NZXT Kraken Elite 240 RGB AIO (2024)
  - Motherboard - Asrock B650M Pro RS WiFi
  - PSU - Corsair SF1000
  - Storage - Samsung 980 Pro Gen 4 2TB, Lexar NM790 Gen 4 1TB

- [Jonsbo Z20 All white build with Gigabyte Aorus Master ICE 5090 : r/sffpc _202509](https://www.reddit.com/r/sffpc/comments/1nhzeu0/jonsbo_z20_all_white_build_with_gigabyte_aorus/)
  - Build: Mobo: Asus rog strix B850G 
  - Processor: 9950x3d 
  - GPU: Gigabyte Aorus Master ICE 5090 
  - Ram: CL28 96gb kit (2x48gb) 
  - AIO: ROG Ryujin 240mm 
  - PSU: rog loki sfx-L M.2 - 2 wd black one is 2tb gen 5 and the other is 8tb Fans: right now a mix of lian li and rog and thermaltake.

- ## [ç”¨ä¹”æ€ä¼¯Z20è£…ä¸€å°5090â€œæ‰‹æç”µè„‘â€ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/6831b59b000000002202a719?xsec_token=AB8c-JeBH72uEhbyvwZNwZ7CJy32kV-b7wXvQrGV6x6G4=&xsec_source=pc_search&source=web_search_result_notes)
  - æœºç®±ï¼šä¹”æ€ä¼¯ Z20
  - æ˜¾å¡ï¼šåŽç¡• TUF 5090D
  - CPUï¼šAMD 9700X
  - ä¸»æ¿ï¼šå¾®æ˜Ÿ B850M è¿«å‡»ç‚®
  - å†…å­˜ï¼šå¨åˆš D300 6400 32G x2
  - æ˜¾å¡ï¼šåŽç¡• TUF 5090D
  - å›ºæ€ç¡¬ç›˜1ï¼šä¸‰æ˜Ÿ 990 Pro 2T
  - å›ºæ€ç¡¬ç›˜2ï¼šè‡´æ€ 7100 2T
  - å›ºæ€ç¡¬ç›˜3ï¼šæµ·åŠ›å£« U.2 7.68T
  - ç”µæºï¼šåŽç¡• æ´›åŸº SFX-L 1200W
  - CPUæ•£çƒ­ï¼šé…·å†·è‡³å°Š Hyper 612
  - é£Žæ‰‡ï¼šè¿½é£Žè€… T30 x3

- 3.5å¯¸æœºæ¢°ç›˜å°±ä¸é€‚åˆè¿™ç§æœºç®±ã€‚æ—¢è¦ä¿è¯å°é“ç•…é€šï¼ŒCPUå’Œæ˜¾å¡å¥½æ•£çƒ­ï¼›åˆè¦ä¿è¯æœºæ¢°ç›˜æ¸©åº¦ä¸è¶…æ ‡ï¼›è¿˜è¦ç¡®ä¿æœºæ¢°ç›˜é˜²éœ‡ï¼Œéš¾ä»¥å…¼å¾—ã€‚

- æ˜¾å¡æ’å‡ æ§½å•Šï¼Œ5070tiè¿˜æœ‰æœºä¼šè£…åº•éƒ¨è¿›é£Žå—
  - ä¸€æ§½ã€‚ç”¨5070tiå¯ä»¥è£…é£Žæ‰‡ï¼Œèµ·ç è–„æ‰‡è‚¯å®šæ²¡é—®é¢˜ã€‚

- [é£Žå†·æžé™ç¨³åŽ‹14600kfï¼ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/682c48f5000000000f038872?xsec_token=ABkkbE8DDCL643O12-dpNtOGU7Vi3PMVqtoIMW9TX50Xg=&xsec_source=pc_search&source=web_search_result_notes)
  - æ•£çƒ­ï¼šåˆ©æ°‘ pa120
  - æ˜¾å¡ï¼šè®¯æ™¯ rx 9070xt 16g æµ·å¤–ç‰ˆ
  - æœ€è¿‘14600kfä»·æ ¼å¾ˆé¦™ æ‰€ä»¥æ›¿æ¢æŽ‰12600kf ç»è¿‡ä¸¤å¤©çš„è°ƒè¯• åŒå¡”6é“œç®¡é£Žå†·ä¹Ÿèƒ½æžé™åŽ‹ä½è¿™é¢—cpuå•¦
  - 2kåˆ†è¾¨çŽ‡ä¸‹ è¿™å¥—é…ç½®æ‰“æ€ªç‰©çŒŽäººè’é‡Žæœ€é«˜ç”»è´¨å¹³å‡å¸§200å‡ºå¤´ ä¹Ÿç®—æ¯”è¾ƒèˆ’æœäº† æœ¬æ¥éƒ½æ‰“ç®—æ”¾å¼ƒæ²»ç–—ä¸Š240æ°´å†·äº† æœ€åŽæŒ£æ‰Žä¸€ä¸‹æŠ¢æ•‘å›žæ¥äº† é£Žå†·ä¸‡å²ï¼æœºç®±é£Žå™ªæ˜¯çœŸçš„å¤§
- 14600kf è¿˜æ˜¯è¦é™åŽ‹çš„ è´Ÿè½½è¦æŽ§åˆ¶1.2vä»¥ä¸‹ï¼Œé«˜æ¸©åº¦å°±æŽ§åˆ¶ä½äº†
- å•å¡”é£Žå†·éšä¾¿åŽ‹ï¼Œå¹³æ—¶éƒ½ä¸å¸¦è½¬çš„

- ä½ åŠ äº†å‡ ä¸ªé£Žæ‰‡åŽ‹ä½çš„
  - æˆ‘itxæœºç®±æ²¡å•¥ç©ºé—´ å°±é¡¶éƒ¨ä¸¤ä¸ª å·¦ä¾§ä¸€ä¸ª æˆ‘æ˜¾å¡å¤ªåŽš åº•éƒ¨ä¸¤ä¸ªé£Žæ‰‡éƒ½è£…ä¸ä¸Š

- è¿™ué™åŽ‹å•å¡”ä¹Ÿèƒ½åŽ‹ï¼Œä¸€èˆ¬åŒå¡”éƒ½æ˜¯å¤Ÿçš„ï¼Œåªè¦ä¸é™é¢‘æ²¡å•¥å¥½ç„¦è™‘ ä½ è¿™ä¸ªæ¸©åº¦é«˜ä¸»è¦æ˜¯æœºç®±å·®+ä¹±è£…é£Žæ‰‡ï¼Œå‰ç½®ç”µæºå°ç®±æœ¬èº«è¿›é£Žå—é˜»é£Žé“éš¾æž„ï¼Œåº•ä¸‹ä¹Ÿæ²¡æœ‰é£Žæ‰‡è¿›é£Žçº¯é æ˜¾å¡æŠ½é£Ž(æ˜¾å¡ä¸‹è¶…è¿‡3cmï¼Œå®Œå…¨å¯ä»¥å°è¯•ä¸Š15mmè–„æ‰‡è¿›é£Ž)ï¼Œä¸Šéƒ¨çš„é£Žæ‰‡å°¤å…¶æ˜¯å‰éƒ¨çš„æ›´æ˜¯æŠŠcpuæ‰€å‰©ä¸å¤šçš„å†·æ°”æŠ½èµ°ï¼Œcpuç›´æŽ¥æ— æ°”å¯ç”¨å·§å¦‡éš¾ä¸ºæ— ç±³ä¹‹ç‚Šï¼Œpa120çš„å¡”ä½“æ˜¯å¾ˆä¼˜ç§€çš„

- [2024 ä¼¦æ•¦è‡ªç”¨æ‰‹æ4090 å°ä¸»æœº - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/6766dd2400000000130083af?xsec_token=ABboPWE_YbGyIsohkIYlHUozqKDRjLeUQCouU2QZY1chQ=&xsec_source=pc_search&source=web_search_result_notes)
  - æœºç®±ï¼šä¹”æ€ä¼¯ Z20, 180mm*298mm*370mm, 20L ðŸ“Œ
  - é£Žæ‰‡ï¼šä¹”æ€ä¼¯ ZK120W x3 + ZK120WR x3
  - åŽ‚å®¶åº”è¯¥å‡ºä¸ªå¸¦å±å¹•çš„é£Žå†·ï¼ŒæŠŠè¿™ä¸ªæ˜¾ç¤ºæ¸©åº¦çš„æ¢æŽ‰

- [Can the jonsbo Z20 support a quad-slot GPU? What is the GPU height clearance of the case? : r/mffpc _202501](https://www.reddit.com/r/mffpc/comments/1i8o5rp/can_the_jonsbo_z20_support_a_quadslot_gpu_what_is/)
  - Idk if this is considered 3 or 4 slots 4090? 360 mm length and 70mm height. I added 15mm fans on the bottom but honestly they are unnecessary as the temps were virtually the same before with less noise/interference.
  - Asus b850 strix I think itâ€™s called. Itx. If I could do it again with this case Iâ€™d get a m atx board. Only thing you gotta watch out for is the pcie placement needs to be above any m.2 slots. So most of the msi boards are not an option.

- [é»‘æ©™é£Žå†·æ‰‹æå¼å°ç”µè„‘ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/66d19e28000000001d01b98b?xsec_token=AB38kMIt8DJB5wbhI53QOtqJMabGeUPzQy1DfS21GmOko=&xsec_source=pc_search&source=web_search_result_notes)
- åº•éƒ¨å¯ä»¥åŒæ—¶è£…ä¸¤ä¸ªé£Žæ‰‡å’Œä¸€ä¸ª3.5å¯¸ç¡¬ç›˜
- æˆ‘è£…äº†è¿™ä¸ªæœºç®±ï¼Œæé†’ä¸€ä¸‹ï¼Œä¹°ä¸»æ¿çœ‹ä¸€ä¸‹ pcie æ§½çš„ä½ç½®ï¼Œå¾®æ˜Ÿè¿«å‡»ç‚®æœ‰ç‚¹åä¸‹ï¼Œæ˜¾å¡åŽšäº†å°±è´´åº•äº†ï¼Œæˆ‘çœ‹åˆ«äººåŽç¡• tuf éƒ½æŒºå¥½

- ðŸ¤” [å°é—·ç½ä¹”æ€ä¼¯Z20çš„æ•£çƒ­æ–¹æ¡ˆåŠåŒçƒ¤æµ‹è¯• - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/67b067bf0000000028028ee2?xsec_token=AB37FEjnwyYBwILr2RQtHgse2ohed1b-PXLNaQdYNbzj4=&xsec_source=pc_search&source=web_search_result_notes)
  - æ•£çƒ­å™¨ï¼šåˆ©æ°‘pa120se

- å†·ç©ºæ°”åœ¨åº•éƒ¨ï¼Œçƒ­ç©ºæ°”åœ¨ä¸Šéƒ¨ï¼Œè¿˜æ˜¯æ›´åŠ ç§‘å­¦ä¸€ç‚¹

- æ„Ÿè§‰å¯ä»¥å°¾éƒ¨æ‰‡æ”¹è¿›é£Žï¼ŒCPUæ•£çƒ­æ–¹å‘æ”¹æˆå·¦åˆ°å³ï¼Œæ­£å¥½å¯ä»¥è®©æ˜¾å¡å’ŒCPUéƒ½å¸åˆ°ä¸€æ‰‹å†·ç©ºæ°”ç„¶åŽç»Ÿä¸€åœ¨å³ä¸ŠæŽ’å‡º
  - æˆ‘è®°å¾—æœ‰upä¸»åšè¿‡æµ‹è¯•ï¼Œè¿™ç§ç±»åž‹çš„æœºç®±è¿™æ ·è£…æ¸©åº¦è¡¨çŽ°æ¯”ä¼ ç»Ÿçš„å®‰è£…æ–¹å¼æ›´å¥½ã€‚ä¸»è¦è¿˜æ˜¯è¿™ç±»æœºç®±æ²¡æœ‰å‰é¢æ¿è¿›é£Žï¼ŒCPUæ•£çƒ­å¸çš„éƒ½æ˜¯æ˜¾å¡å°¾æ°”ã€‚å…¶å®žæ”¹å®Œä¹‹åŽè¿˜æ˜¯ä¸‹è¿›ä¸Šå‡ºï¼Œåªæ˜¯æ°´å¹³æ–¹å‘åä¸€ä¸‹ã€‚
- è¿™ä¸ªä¸€ä¸ªé—®é¢˜å°±æ˜¯è¿›é£Žé‡ï¼žå‡ºé£Žé‡ï¼Œçƒ­é‡ä¼šå †ç§¯

- å…¶å®žåº•éƒ¨è¿›é£Žç”¨å¤„ä¸ç®—å¤§ï¼Œå€’æ˜¯å¯¹pcieæ§½å’ŒIOæ§½çš„ç§¯ç°æœ‰å¸®åŠ©ï¼ŒåŽŸå› æ˜¯åº•éƒ¨æœ‰é£Žé€è¿›æ¥å°±ä¸éœ€è¦å››å¤„å€Ÿé£Žäº†
  - éžå¸¸æœ‰å¸®åŠ©ï¼Œåº•éƒ¨åŠ äº†ä¸¤ä¸ª3000è½¬çš„P12 maxæš´åŠ›è¿›é£Žæ‰‡ï¼Œçƒ¤é¸¡æ˜¾å¡æ¸©åº¦ç›´æŽ¥ä»Ž76â„ƒé™åˆ°70â„ƒä»¥ä¸‹äº†ï¼Œæœ€é«˜ä¸è¶…è¿‡70ã€‚
- äº²æµ‹æ— ç”¨ï¼Œæˆ‘è¿˜æ˜¯ä¹°çš„4900è½¬å·¥ä¸šé£Žæ‰‡ï¼Œä¸¤ä¸ªåŠ åˆ°åº•éƒ¨å‘çŽ°æ²¡ä»»ä½•åµç”¨ï¼Œç„¶åŽåˆè´¹åŠ²åŠ›æ°”æ¢å›žæ™®é€šrhb

- pa120se ä¼šè·Ÿå†…å­˜æ¡å†²çªå˜›
  - æœ‰ä¸€ç‚¹ç‚¹ï¼Œè£…æ•£çƒ­å™¨å†…å­˜æ¡çš„é£Žæ‰‡ä¼šç•¥é«˜1cm

- æ™®é€šå†…å­˜åº”è¯¥æ²¡ä»€ä¹ˆé—®é¢˜ï¼Ÿå¤šé«˜æ¯”è¾ƒå¥½ï¼Ÿ
  - 40mm

- å¤©é€‰ä¸»æ¿ä¸‰ä¸ªæœºç®±é£Žæ‰‡æŽ¥å£éƒ½ç”¨ä¸Šäº†ï¼Œè¿™æ ·èƒ½å•ç‹¬æŽ§åˆ¶ä¸Šé¢ï¼Œåº•éƒ¨å’ŒåŽé¢çš„è½¬é€Ÿ
  - æ˜Žç™½äº†ï¼Œä¸»è¦æ˜¯åŒæ—¶è€ƒè™‘è—çº¿ï¼ŒæŠ€å˜‰å°é›•ä¸»æ¿æœ‰ä¸€ä¸ªé£Žæ‰‡æŽ¥çº¿æ§½å¤ªæ˜Žæ˜¾äº†ï¼Œä¸å¥½æŽ¥çº¿

- æ²¡æœ‰ç”¨é›†çº¿å™¨å•Š ä¸»æ¿ä¸Šçš„é£Žæ‰‡ä½è¶³å¤Ÿäº†

- [ä¹”æ€ä¼¯Z20è£…æœºåˆ†äº« - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/67e7b093000000001201ed15?xsec_token=ABhmT245aHYddZ3_znj1lt9rAgzysn8wPmPsb_KU5jWH0=&xsec_source=pc_search&source=web_search_result_notes)
  - æ•£çƒ­ä¸ç”¨æ‹…å¿ƒï¼Œæˆ‘åªè£…äº†ä¸€ä¸ªå•å¡”åŒé£Žæ‰‡ï¼Œå®¤æ¸©15åº¦çŽ©æ¸¸æˆå¤§æ¦‚60åº¦ã€‚å¤å¤©å¯ä»¥æŠŠçŽ»ç’ƒé¢æ¿æ¢æˆæ•£çƒ­å­”çš„ã€‚

- [å…³äºŽmatxæœºç®±ä¹”æ–¯ä¼¯z20çš„ä¸€äº›ç–‘é—® - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/67c32e800000000007036281?xsec_token=ABhMyCZP5HBuwkcA-x3g3Zb7JVfz1CaYgxzSIyUO-3Mgs=&xsec_source=pc_search&source=unknown)

- ## [ä¹”æ€ä¼¯z20é£Žé“ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/67a8bfb8000000002803576a?xsec_token=ABg64t-BlcmW2roSur4qqjBKnd-Tlemzg7qdIBUy2o41w=&xsec_source=pc_search&source=web_search_result_notes)
- å®žé™…ä¸Šéƒ½å·®ä¸å¤šï¼Œè¿™æœºç®±å°±æ˜¯ä¸ªå¤§é—·ç½ï¼Œä¾§æ¿å»ºè®®åŽ»æžå—å¼€å­”çš„äºšå…‹åŠ›
  - æˆ‘çš„c26 å¤å¤©ç›´æŽ¥å¼€ä¾§æ¿
- æœ€å¥½çš„é£Žé“å°±æ˜¯åŽ»æŽ‰ä¾§æ¿

- ä¹‹å‰ B ç«™çœ‹è¿‡æ¯ä¸ªä½ç½®çš„é£Žæ‰‡æ•£çƒ­æ•ˆæžœï¼ŒåŽå‡ºé‚£ä¸ªä½ç½®æ˜¯æ•£çƒ­æ•ˆæžœæœ€å¥½çš„ï¼Œå…¶ä»–çš„åå‘æ˜¯è¾…åŠ©è€Œå·²ï¼Œæ‰€ä»¥åŽé¢ä¸€å®šè¦å‡ºé£Žæ•ˆæžœä¼šå¥½ç‚¹
- å…¶å®žä¸ç”¨æƒ³å¤ªå¤šï¼Œæˆ‘æ°´å†·å¤§æ˜¾å¡ï¼Œåº•ä¸‹è£…ä¸äº†é£Žæ‰‡ï¼Œå°±é åŽé¢å‡ºé£Žå’Œæ°´å†·ä¸¤ä¸ªé£Žæ‰‡ï¼Œå¹å‡ºæ¥çš„é£Žå¾ˆçƒ­ï¼Œé¡¶éƒ¨ææ‰‹éƒ½æœ‰äº›çƒ«æ‰‹ï¼Œä½†æ˜¯å¼€æœºçŽ©ä¸€å¤©ä¹Ÿæ²¡äº‹ï¼Œè¿™ä¸œè¥¿80æ¥åº¦ä¸æ˜¯æ­£å¸¸å—
- ä¸Šå‡ºï¼Œçƒ­æ°”é»˜è®¤æ˜¯å¾€ä¸Šé£˜çš„ï¼Œä½ è¿™ä¹ˆä¼šæ‰°ä¹±çƒ­æµï¼Œé™¤éžä½ èƒŒé¢æ˜¯è¶…å¤§å·¥ä¸šæ‰‡
- çƒ­æ°”ä¸Šå‡å†·æ°”ä¸‹æ²‰ï¼Œéµå¾ª
- ä¸Šé¢å…¨å‡ºé£Žï¼Œè¿›é£Žä»Žä¸‹é¢
- åŽå‡ºä¸Šå‡ºï¼Œå¯ä»¥ä¸ç”¨è¿›é£Žï¼Œè´ŸåŽ‹ä¸‹æ•£çƒ­æœ€å¥½ã€‚
- ä¸‹è¿›ä¸Šå‡º å‰è¿›åŽå‡º

- è¿™ç§æœºç®±ä¸‹è¿›é£Žï¼ŒèƒŒåŽæŽ’é£Žæœ€å¥½ï¼Œæ˜¾å¡æ¸©åº¦ä½Žã€‚ä¸Šé¢ä¸å»ºè®®è£…ï¼Œæˆ–è€…åªè£…æ°´å†·ã€‚

- [é£Žé“æ±‚åŠ© - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/662673150000000004018542?xsec_token=ABw3jEHfBhULZbVbZwZh-SoQYwidgEI4Cvil6t9yvhd28=&xsec_source=pc_search&source=web_search_result_notes)
- è¿™ä¸ªæœºç®±ç”¨å•å¡”è¿˜æ˜¯åŒå¡”æ•£çƒ­åˆé€‚å•Š
  - Cpuå‘çƒ­é‡é«˜ä¸€äº›çš„è¯å°±è¦ä¸ŠåŒå¡”äº†ã€‚é™é«˜æ˜¯æŒ‡å¡”çš„é«˜åº¦ï¼Œ160èƒ½å¡žçš„åº”è¯¥ã€‚
- é¡¶éƒ¨é ç”µæºçš„é£Žæ‰‡å»ºè®®æ¢ä¸ªæ–¹å‘ï¼Œå¯¹cpuæ•£çƒ­å¾ˆæœ‰å¥½å¤„ï¼Œäº²æµ‹

- [ä¹”æ€ä¼¯ Z20 é£Žå†·ï¼Œä»¥ä¸Šä¸¤ç§é£Žé“é‚£ç§æ›´åˆç†ï¼Œå®žé™…æ•ˆæžœæ›´å¥½å‘¢ï¼Ÿ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/673ef0a000000000060178a9?xsec_token=ABXPeGOfIrwFw2csvcwJomQbdXOQnxRyaYf8eRgRHxm0A=&xsec_source=pc_search&source=web_search_result_notes)

- ## [å…³äºŽæ–¹ç³–æœºæ¢°å¤§å¸ˆc28è£…æœºæ—¶è¸©çš„ä¸€äº›å‘ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/686dd55d0000000017034ee3?xsec_token=ABosdtjmZ4IdMHAXii79bUC4njWXjrUmL9ULRNaDHexTw=&xsec_source=pc_search&source=web_search_result_notes)
  - ä¸€å¼€å§‹ä¹°é”™ç”µæºï¼Œä¸Š240æ°´å†·çš„è¯åªèƒ½æ­é…SFXå°ç”µæºï¼Œæ™®é€šATXä¼šå¡æ°´å†·é£Žæ‰‡
  - å¥½å†å‘çŽ°åŠæ—¶ï¼Œé€€äº†ATXï¼Œä½†æ˜¯ä¹°çš„æ—¶å€™SFXç”µæºä¹Ÿæœ‰ä¸ªå‘ï¼Œå› ä¸ºæˆ‘çš„æ˜¾å¡éœ€è¦16pinæŽ¥å£ï¼Œè¦æ±‚ç”µæºä¹Ÿå¿…é¡»è¦æœ‰16pinï¼ŒäºŽæ˜¯åˆé€€äº†ä¹°é”™çš„SFXï¼Œé‡æ–°è´­å…¥é‘«è°·KL-M750Gå†°å±±ç‰ˆ
  - ä½†æ˜¯è¿™ä¸ªç”µæºä¹Ÿæœ‰ä¸€ä¸ªé—®é¢˜ï¼Œè·Ÿæœºç®±çš„ç”µæºæ”¯æž¶æœ‰ç‚¹ä¸é€‚é…ï¼Œç”µæºå¼€å…³çš„è¾¹ç¼˜ä¼šå¡åˆ°æ”¯æž¶å¯¼è‡´æ— æ³•æ”¾æ­£ï¼ˆå›¾5ï¼‰ï¼Œæœ€åŽæ”¯æž¶æ˜¯å¼ºè¡ŒåŽ‹ç€ç”µæºå¼€å…³è¾¹ç¼˜è£…ä¸‹åŽ»çš„ã€‚
  - å†…å­˜é™é«˜44mmï¼Œå¸¸è§„å¸¦ç¯æ¡çš„åŸºæœ¬éƒ½è¢«é™é«˜äº†ï¼Œåªæœ‰å°‘æ•°ç¬¦åˆè¦æ±‚ï¼Œä¸€å¼€å§‹ä¹Ÿæ²¡æ³¨æ„çœ‹ï¼ŒåŽé¢åŠæ—¶é‡ä¹°äº†ã€‚ä¹°çš„æ²¡æœ‰ç¯å¸¦çš„å®åŸºæŽ å¤ºè€…é“¶ç¿¼å‡Œéœœ48g 6000 c28, 44mmä»¥ä¸Šçš„ä¼šæŠŠ240æ°´å†·çš„ä¸¤ä¸ªæ•£çƒ­é£Žæ‰‡å¡ä½
  - ç„¶åŽå°±æ˜¯æ°´å†·ï¼Œä¹°çš„æ˜¯ä¹å·žé£Žç¥žå†°åŸŸ240ï¼Œä½†æ˜¯è¿™è´§çš„ä¸¤ä¸ªé£Žæ‰‡æŽ¥å£ä¸Šè¿˜æœ‰é¢å¤–çš„æŽ¥çº¿

- ä¸€å®šè¦æ³¨æ„ä¸»æ¿æ˜¾å¡æ˜¯ä¸€æ§½è¿˜æ˜¯äºŒæ§½ äºŒæ§½åº•éƒ¨å®Œå…¨ä¸èƒ½è£…é£Žæ‰‡ å…¶æ¬¡æ˜¾å¡é•¿åº¦å¤ªæžé™çš„è¯ 9cmçš„é£Žæ‰‡æ˜¯è£…ä¸äº†çš„
  - è¿™ç§å°æœºç®± ä¸»æ¿å»ºè®®é€‰æŠ€å˜‰b650må°é›• æ˜¾å¡ä½æ˜¯ä¸€æ§½ ä¸‹é¢æœ‰æœ‰ç©ºå¯ä»¥æ”¾é£Žæ‰‡
- æˆ‘é€‰çš„æ˜¯ç”µç«žé›•850ï¼Œå’Œ650å°é›•å¸ƒå±€å¥½åƒä¸€æ ·çš„å§ã€‚åŒ…æ‹¬å¤§å°
  - å¯¹ 850å°±æ˜¯æ¯”650çš„æ§½ä½å¤šä¸€ç‚¹ æ­£å¸¸650å°±ok 850çš„è´µä¸ªä¸€ä¸¤ç™¾

- æ•£çƒ­æ€Žä¹ˆæ ·å•Š
  - æ²¡å•¥å¤§é—®é¢˜ï¼Œå¾…æœº60å†…ï¼Œæ¸¸æˆ90åº¦å†…éƒ½æ²¡é—®é¢˜

- èƒ½è£…åŒå¡”é£Žå†·å—
  - è¦çœ‹ä¸‹å°ºå¯¸ï¼Œè¯´æ˜Žä¹¦é‡Œæ˜¯è¦æ±‚162mmä»¥å†…ï¼ŒåŒå¡”é£Žå†·åº”è¯¥å¤§éƒ¨åˆ†éƒ½èƒ½æ»¡è¶³

- æˆ‘é‚£ä¸ªåˆ©æ°‘ç”µæºä¹Ÿè¿™æ ·
  - é‚£çœ‹æ¥æœºç®±çš„ç”µæºæ”¯æž¶è®¾è®¡ä¹Ÿæœ‰é—®é¢˜ã€‚ä¸è¿‡èžºä¸æ‹§æ¾ä¸€ç‚¹ç›–ä¸ŠåŽ»ä¹Ÿèƒ½å›ºå®šå¥½
- ç”µæºæ”¯æž¶æœ‰2æ¬¾ï¼Œç”¨å¦ä¸€æ¬¾çš„ç”µæºæ”¯æž¶

- è£…c26çš„å‘ï¼š 1ä¹°é£Žå†·æ²¡æ³¨æ„å¤§å°ï¼Œæ”¾ä¸è¿›åŽ» 2å¯¹é£Žæ‰‡å¤ªè¿‡è‡ªä¿¡ï¼Œä¹°å¤šäº†ï¼Œä¸Šé¢çš„é£Žæ‰‡ä½å’Œé£Žå†·æ‰“æž¶ 3æœºç®±å†…ç”µæºçº¿å¾ˆæ€ªåªèƒ½å¾€å†…æŽ’é£Žï¼Œå› ä¸ºä¸æ•¢éšä¾¿å¼¯æŠ˜çº¿ 4ä¹°äº†ä¸ªæ˜¾å¡æ”¯æž¶ï¼Œä½ç½®ä¸å¤Ÿè£…

- ## [çº¯ç™½è‰²ç¾Žå­¦è£…æœºå°å·…å³°ï¼Œæœºæ¢°å¤§å¸ˆC28 AIâ€œå­¦ä¹ æœºâ€é…ç½®åˆ†äº«](https://www.zhihu.com/tardis/zm/art/691493855?source_id=1003)
- å½©è™¹çš„ä¸»æ¿ç»å¯¹æ˜¯æœ€é«˜æ€§ä»·æ¯”ç™½è‰²ä¸»é¢˜è£…æœºçš„é€‰æ‹©ã€‚
- å†…å­˜æ˜¯æ¥è‡ªå®ç¢æŽ å¤ºè€…çš„å†°åˆƒç³»åˆ—ï¼Œå†…å­˜é¡¶éƒ¨æ˜¯å“‘å…‰åŠé€å¯¼å…‰æ¡ï¼Œç›¸å½“æ¼‚äº®ã€‚
  - å†°åˆƒçš„ç¯å…‰å¾ˆæŸ”ç¾Žï¼Œèƒ½å¤Ÿè¢«ä¸ƒå½©è™¹çš„iGame Centerç»Ÿä¸€æŽ§åˆ¶
- æ˜¾å¡æ˜¯ç´¢æ³°çš„RTX 4070 Ti Superæœˆç™½
- æ°´å†·æ˜¯åˆ©æ°‘å†°å°è§†ç•Œ240æ°´å†·ï¼Œä¸€å—LCDå±å¹•ç»™æœºç®±å¢žåŠ äº†å‡ åˆ†çµåŠ¨ã€‚
- ç”±äºŽæœºæ¢°å¤§å¸ˆC28æœºç®±å†…å­˜é™é«˜æœ€å¤š44mmï¼Œè¿™é‡Œä¸å¾—ä¸å°†åˆ©æ°‘å†°å°è§†ç•Œ240æ°´å†·å½“ä½œ120æ°´å†·æ¥ç”¨
- ç”µæºè§„æ ¼ä¸Šæ”¯æŒ140mmçš„ATXç”µæºæ­é…ITXä¸»æ¿ä½¿ç”¨ï¼Œä¹Ÿæ”¯æŒSFX/SFX-Læ­é…Matxä¸»æ¿ä½¿ç”¨ï¼Œç”µæºæ”¯æž¶å®‰è£…èµ·æ¥ä¹Ÿè›®æ–¹ä¾¿ï¼Œå…¶å®žæœºæ¢°å¤§å¸ˆçš„æœºç®±åªè¦æŠŠé“å£³å­æ‹†ä¸‹è£…æœºå°±å¾ˆç®€å•ã€‚
  - ç”±äºŽè¶…çº§ç´§å‡‘çš„æœºç®±è®¾è®¡ï¼Œç”µæºä½è¢«è®¾è®¡æœºç®±å‰ä¾§ï¼Œé€šè¿‡ç”µæºè½¬æŽ¥çº¿è¿›è¡Œè¿žæŽ¥ã€‚
- æœºç®±è®¾è®¡æœ‰4ä¸ªPCIeæ§½ä½ï¼Œåªè¦æ»¡è¶³é™é•¿çš„æ˜¾å¡ç»Ÿç»Ÿæ‹¿æï¼Œæœºç®±å‰éƒ¨å¯ä»¥ä¸Šä¸€ä¸ª9cmçš„é£Žæ‰‡ã€‚

- å‰ç½®æŽ¥å£ä¸Šç»™åˆ°äº†1åªUSB-Aä¸Ž1åªType-CæŽ¥å£

- ä¸»æ¿ï¼šä¸ƒå½©è™¹CVN B760M FROZEN WIFI D5 æˆ˜åˆ—èˆ°
  - ä¸»æ¿é‡‡ç”¨äº†12+1ç›¸ç›´å‡ºå¼åŠ å¼ºä¾›ç”µï¼ŒCPUæ ¸å¿ƒä¾›ç”µä¸º12ç›¸ï¼Œæ ¸æ˜¾ä¾›ç”µä¸º1ç›¸ï¼Œæœ€å¤§ç”µæµ55Aï¼ŒCPUä¾›ç”µæŽ¥å£ä¸º8+4è®¾è®¡ã€‚B760èŠ¯ç‰‡ç»„æœ¬å°±æ˜¯ä¸æ”¯æŒCPUè¶…é¢‘çš„ï¼Œ
  - ç›¸å¯¹B760IæŽ¨èä¸Š14600Kæ¥è¯´ï¼ŒCVN B760M FROZEN WIFI D5 V20 å°±æ›´æŽ¨èé…åˆi5-13490Fæˆ–è€…æ˜¯å¸¦æ ¸æ˜¾çš„i5-13500ä½¿ç”¨äº†ã€‚

- ä¸»æ¿æ¿è½½äº†4ä¸ªDDR5å†…å­˜æ’æ§½ï¼Œå•æ§½å®¹é‡æœ€å¤§æ”¯æŒ32GBï¼Œæ€»å…±æœ€å¤šå¯ä»¥æ”¯æŒåˆ°128GBå†…å­˜ï¼Œå†…å­˜é¢‘çŽ‡æœ€é«˜æ”¯æŒXMP 6600MHzï¼ˆOCï¼‰ï¼Œç›®å‰å¸‚é¢ä¸Šçš„é«˜æ€§ä»·æ¯”D5å†…å­˜æ™®éä»¥6000MHzã€6400MHzå±…å¤šï¼Œé€‰B760Måˆšåˆšå¥½ã€‚
- å†…å­˜æ—¶åºCL32ï¼Œå·¥ä½œç”µåŽ‹1.4ï¼Œå†…å­˜PMICä¸é”ç”µåŽ‹ï¼Œç”¨æˆ·å¯ä»¥è‡ªè¡Œä½“éªŒè¶…é¢‘çš„å¿«ä¹ï¼Œæ¯•ç«Ÿ6800MHzçš„å†…å­˜å°±è¦åŠ 400å—å‘¢

- ä¸»æ¿æä¾›äº†1ä¸ªé‡‡ç”¨äº†åˆé‡‘å¼ºåŒ–è®¾è®¡çš„PCIe 5.0 x16æ’æ§½ä»¥åŠ1ä¸ªPCIe3.0 x4æ’æ§½ï¼Œå…¶ä¸­x16æ’æ§½ç”±CPUæä¾›ï¼Œx4æ’æ§½ç”±PCHæä¾›ï¼Œå¯ä»¥ç”¨æ¥æ‰©å±•ä¸‡å…†ç½‘å¡ã€é‡‡é›†å™¨ç­‰PCIeé…ä»¶ã€‚

- ä¸»æ¿æä¾›äº†3ä¸ªM.2æŽ¥å£ï¼Œå‡ä¸ºPCIe 4.0 x4ï¼Œå…¶ä¸­é è¿‘CPUçš„M.2æŽ¥å£ç”±CPUæä¾›ï¼Œå‰©ä½™2ä¸ªM.2æŽ¥å£ç”±PCHæä¾›ï¼Œä¸‰ä¸ªM.2æŽ¥å£å‡é…å¤‡äº†ä¾¿æ·é”æ‰£ï¼Œé è¿‘CPUçš„ä¸¤ä¸ªM.2æ’æ§½æœ‰æ•£çƒ­è£…ç”²è¦†ç›–ã€‚æ­£å€¼åŒåä¸€å¤§ä¿ƒï¼ŒåŠ æ»¡M.2 SSDä¹ŸèŠ±ä¸äº†å¤šå°‘é’±ã€‚

- æœºæ¢°å¤§å¸ˆC28é…240æ°´å†·+Matxä¸»æ¿ï¼ŒSFXç”µæºæ˜¯å”¯ä¸€é€‰æ‹©ã€‚é‘«è°·SFXæ˜†ä»‘KL-750Gå†°å±±ç‰ˆATX3.0å…¨æ¨¡ç»„ç”µæºä¸»æ‰“ä¸€ä¸ªçº¯ç™½é…è‰²ï¼Œ1å—å‡ºå¤´1Wä¹Ÿè¿˜èƒ½æŽ¥å—ã€‚

- [å°é’¢ç‚®ä¹Ÿæœ‰å¤§èƒ½é‡ï½œ13600K+B760+æœºæ¢°å¤§å¸ˆC28 è£…æœºå®žå½•](https://www.zhihu.com/tardis/zm/art/616613140?source_id=1003)
- é€‰æ‹© C28 çš„ç†ç”±æ˜¯ç›¸æ¯”C26plus å®½åº¦é«˜åº¦å¤§äº† 20mmã€‚å®žç‰©å¹¶æ²¡æœ‰å¤ªå¤§çš„å°ºå¯¸å·®è·ï¼Œä½†æ¢æ¥æ›´å®½è£•å†…éƒ¨ç©ºé—´ï¼Œå¯¹äºŽæœºç®±å†…éƒ¨æ•£çƒ­è¿˜æ˜¯å¾ˆæœ‰å¥½å¤„çš„ã€‚
  - é…ä»¶æ–¹é¢ï¼Œ13600K+ B760M +6600XT ç¡¬ä»¶ç»„åˆï¼Œæ—¥å¸¸åº”ç”¨ä¸æˆé—®é¢˜ï¼ŒçŽ©æ¸¸æˆè·‘ä¸ª 2K@144 ç»°ç»°æœ‰ä½™ï¼Œç‰¹æ•ˆç¨å¾®è°ƒä½Žä¹Ÿå¯ä»¥æµç•…è¿è¡Œ 4K æ¸¸æˆã€‚
  - æ•£çƒ­æ˜¯è¶…é¢‘ä¸‰çš„é£Žå†· K4ï¼Œç”µæºå› ä¸ºè¦è€ƒè™‘åˆ°åŽç»­è¦å‡çº§ 4060tiï¼Œé€‰ç”¨æŒ¯åŽåˆšå‡ºçš„ 13cm ç™½é‡‘ç”µæº VP 1000Wã€‚ 
- æœºæ¢°å¤§å¸ˆçš„ç®±å­éƒ½è¶…çº§ç´§å‡‘ï¼Œå°ºå¯¸è¾ƒå°ï¼Œé¢œå€¼ä¹Ÿé«˜ï¼Œå¾ˆé€‚åˆæ¡Œé¢æ‘†æ”¾ï¼Œé…åˆä¾¿æºå±æ•ˆæžœä¸€æµã€‚
- æœºç®±å¯ä»¥æ”¯æŒ 335mm ä»¥å†…çš„æ˜¾å¡ï¼Œ6600XT ä½œä¸ºè¿‡æ¸¡æ˜¾å¡ï¼ŒåŽç»­ä¼šä¸Š 4060tiã€‚
- æœºç®±è™½ç„¶å°å·§ï¼Œä½†å¯ä»¥æ”¯æŒåˆ° 280 æ°´å†·ã€‚å…¶å®žæˆ‘æœ¬æ¥ä¹Ÿæ˜¯å»ºè®®ä»–ç›´æŽ¥ä¸Šæ°´å†·ï¼Œå¥ˆä½•æœ‹å‹æ€»æ˜¯æ‹…å¿ƒæ¼æ¶²ï¼Œæ­»æ´»è¦ä¸Šé£Žå†·ã€‚
  - é£Žå†·çš„è¯æ•£çƒ­é«˜åº¦é™åˆ¶åœ¨ 162mmï¼Œè¶…é¢‘ä¸‰ K4 çš„é«˜åº¦æ˜¯ 156mmï¼Œå¯ä»¥è¯´æ˜¯åˆšåˆšå¥½ã€‚
  - å››çƒ­ç®¡ + 130mm é«˜æ€§èƒ½é£Žæ‰‡ï¼Œå®˜æ–¹å®£ç§°èƒ½åŽ‹ä½ 12900Kï¼ŒåŽ‹ä¸ª 13600K åº”è¯¥æ²¡å•¥é—®é¢˜ã€‚
- æŒ¯åŽ VP1000W æ˜¯åˆšå‡ºçš„æ–°å“ï¼Œä¸»æ‰“ 13cm çŸ­æœºèº«ã€å…¨æ—¥ç³»ç”µå®¹ã€é«˜è½¬æ¢çŽ‡ã€‚æŒ¯åŽæ˜¯å…¸åž‹çš„åå‘è™šæ ‡ä¸“ä¸šæˆ·ï¼Œé¢å®š 1000W å®Œå…¨å¯ä»¥å½“ 1200W æ¥ç”¨ã€‚è€Œä¸”æ ‡é…çš„çº¿æéƒ½æ˜¯æŸ”æ€§è½¯çº¿ï¼Œå¾ˆé€‚åˆç”¨åœ¨è¿™ç§ç´§å‡‘åž‹æœºç®±é‡Œã€‚

- è£…æœºå±å¹•ç”¨çš„ INNOCN 15Q1F ï¼Œå±å¹•é‡‡ç”¨çš„ OLED æŠ€æœ¯ï¼Œæ˜¾ç¤ºæ•ˆæžœå‡ºè‰²ï¼Œæœ€å…³é”®çš„æ˜¯è¿™è´§æ”¯æŒè§¦æŽ§ï¼Œè€Œä¸”è‡ªå¸¦ç”µæ± ï¼Œè£…æœºè°ƒè¯•éƒ½ç‰¹åˆ«æ–¹ä¾¿ã€‚

- è‹±ç‰¹å°” é…·ç¿ i5-13600K CPUå¤„ç†å™¨é‡‡ç”¨æ€§èƒ½æ ¸+èƒ½æ•ˆæ ¸æ··åˆCPUæž¶æž„ï¼Œæ‹¥æœ‰6ä¸ªæ€§èƒ½æ ¸å’Œ8ä¸ªèƒ½æ•ˆæ ¸ã€‚
  - æ‹¥æœ‰ 14 æ ¸å¿ƒ 20 çº¿ç¨‹ï¼Œä¸»é¢‘è‡³é«˜å¯è¾¾ 5.1GHzï¼ŒPCIe 5.0 è‡³é«˜å¯è¾¾20é€šé“ï¼ŒDDR5 è‡³é«˜å¯è¾¾ 5600MHzï¼Œ24MB çš„ L3å’Œ 20MB L2é«˜é€Ÿç¼“å­˜ã€‚
  - æ­è½½è‹±ç‰¹å°” 770æ ¸èŠ¯æ˜¾å¡ï¼Œæ”¯æŒè¶…é¢‘å’ŒWIFI6Eç½‘ç»œã€‚

- GIGABYTE B760M AORUS ELITE AX ä¸»æ¿
  - AORUS ç³»åˆ—å±žäºŽæŠ€å˜‰äº§å“é«˜ç«¯é˜µè¥ï¼Œå®šä½è¿½æ±‚æžè‡´çš„ç”µç«žçŽ©å®¶ã€‚
  - ä¸»æ¿é‡‡ç”¨äº†14+1+1ç›¸æ ¸å¿ƒä¾›ç”µï¼Œè¾…åŠ©ä¾›ç”µä¸º 8 Pin + 4Pin 12Vè¾“å…¥ï¼Œ60A ä¾›ç”µæ™¶ä½“ç®¡ï¼Œ 2 ç›Žå¸é“œç”µè·¯æ¿ + 6 å±‚ PCB è®¾è®¡ï¼Œä¾›ç”µã€SSDã€èŠ¯ç‰‡ç»„ç­‰å…³é”®ä½ç½®ï¼Œç”šè‡³è¿žå—æ¡¥éƒ½è¦†ç›–äº†é“¶ç™½è‰²çš„æ•£çƒ­è£…ç”²ï¼Œé…åˆ 6mm çƒ­ç®¡ä»¥åŠé«˜å“è´¨å¯¼çƒ­åž«ï¼Œè®©ä¸»æ¿æ•£çƒ­æ›´ä¸ºå‡åŒ€ï¼Œå®žçŽ°é«˜æ•ˆçš„æ•£çƒ­èƒ½åŠ›ã€‚
  - ä¸»æ¿ä¸ºæ ‡å‡†çš„å››æ§½å†…å­˜è®¾è®¡ï¼Œæœ‰D4\D5 ä¸¤ä¸ªç‰ˆæœ¬å¯é€‰ã€‚D5 ç‰ˆæœ€é«˜å¯æ”¯æŒ 7600MHzï¼ˆO. Cï¼‰ï¼Œæœ€é«˜å…¼å®¹ 128GB å†…å­˜å®¹é‡ï¼Œå…¶ç‹¬æœ‰çš„è¶…é¢‘é»‘ç§‘æŠ€ï¼ˆé«˜å¸¦å®½ä½Žå»¶è¿Ÿæ¨¡å¼ï¼‰ç›®å‰ä¹Ÿåªæ­è½½åœ¨ D5 ç‰ˆä¸Šã€‚
  - æ­¤å¤–ä¸»æ¿æä¾›äº†åŒ PCI-E æ’æ§½ï¼Œé è¿‘ CPU çš„æ’æ§½é‡‡ç”¨åˆé‡‘è£…ç”²åŠ å›ºï¼Œæ”¯æŒ PCI-E 4.0 x16é€ŸçŽ‡ã€‚ä¸‹æ–¹åˆ™æ˜¯æ™®é€šæ’æ§½ï¼Œé€ŸçŽ‡ä¹Ÿåªæœ‰PCI-E4.0 x4ï¼Œé€‚åˆæ’ä¸€äº›æ‰©å±•å¡ä¹‹ç±»çš„ã€‚
  - ä¸€ä½“å¼æŒ¡æ¿æŽ¥å£ä¸°å¯Œï¼ŒæŠ€å˜‰B760Må°é›•WIFI æä¾›äº†4ä¸ªUSB 2.0 æŽ¥å£ã€1ä¸ªUSB3.2 Gen2 Type-AæŽ¥å£ï¼ˆ10Gbpsï¼‰ã€3ä¸ªUSB3.2 Gen1æŽ¥å£ï¼ˆ5Gbpsï¼‰ã€1ä¸ªUSB 3.2 Gen2 Type-CæŽ¥å£ï¼ˆ20Gbpsï¼‰ï¼ŒHDMI/DP æŽ¥å£å„1ã€ä»¥åŠ2.5Gç½‘ç»œæŽ¥å£ã€‚å½“ç„¶WiFi6æ— çº¿ç½‘å¡å¤©çº¿æŽ¥å£ä»¥åŠéŸ³é¢‘è¾“å…¥/è¾“å‡ºæŽ¥å£ã€å…‰çº¤æŽ¥å£éƒ½ä¸€ä¸€å®Œå¤‡ã€‚
  - æŠ€å˜‰ 13ä»£ ä¸»æ¿å¼€å§‹æŽ¨å‡ºçš„â€œé«˜å¸¦å®½ä½Žå»¶è¿Ÿæ¨¡å¼â€ï¼Œå¯¹äºŽå†…å­˜æ€§èƒ½æå‡æ•ˆæžœæ˜Žæ˜¾ï¼Œç‰¹åˆ«æ˜¯é«˜é¢‘å†…å­˜ï¼Œæˆ‘ä¹‹å‰æ›¾ç»ç”¨å®ƒå°† 7200MHz å†…å­˜è¶…åˆ°äº† 7800MHzï¼Œè¯»å†™æ‹·è´è¶…è¿‡ 10GB/sï¼Œå†™å…¥æ›´æ˜¯é€¼è¿‘12GB/sï¼ˆ119.18 GB/sï¼‰ï¼Œå»¶è¿Ÿæ›´æ˜¯åŽ‹åˆ°äº† 55.7nsï¼Œç‰¹åˆ«é€‚åˆå–œæ¬¢çŽ©è¶…é¢‘çš„æœ‹å‹ï¼Œæœ‰å…´è¶£çš„æœ‹å‹å¯ä»¥çœ‹çœ‹æˆ‘ä¹‹å‰åšçš„æµ‹è¯„ã€‚

- æŠ€å˜‰ä»Ž b760 D5 ä¸»æ¿å¼€å§‹ï¼ŒæŽ¨å‡ºäº†ä¸ªâ€œé«˜å¸¦å®½ä½Žå»¶è¿Ÿæ¨¡å¼â€ï¼ŒåŒæ ·çš„ DDR5 å†…å­˜æ¡åœ¨è¿™å—æ¿èƒ½è·‘å‡ºæ›´é«˜çš„è¯»å†™ï¼Œæ›´ä½Žçš„å»¶è¿Ÿï¼Œå°±æ‹¿é›·å…‹æ²™è¿™å¥—å†…å­˜æ¥è¯´ï¼ŒåŒæ ·çš„ 5200MHz å¼€å¯è¿™ä¸ªæ¨¡å¼åŽï¼Œç›¸æ¯”æ­£å¸¸XMPæ¨¡å¼ä¸‹æ•°æ®éƒ½æœ‰ä¸å°çš„æå‡ã€‚

- SSD æ˜¯é›·å…‹æ²™å®šä½é«˜ç«¯çš„ NM800PRO 1TBã€‚å•é¢PCB åº•æ¿ï¼ŒåŽšåº¦æŽ§åˆ¶ä¸é”™ï¼Œç¬”è®°æœ¬æˆ–è€…æ¸¸æˆä¸»æœºéƒ½èƒ½é€‚é…ã€‚SSD è¡¨é¢è¦†ç›–æ–°ä¸€ä»£çº³ç±³é“œç®”å¤åˆææ–™ï¼Œæ­è½½æ™ºèƒ½æ¸©åº¦æ£€æµ‹æ¨¡å¼ï¼Œæœ‰åŠ©äºŽå¿«é€Ÿé™æ¸©ï¼Œé•¿æ—¶é—´ä½¿ç”¨ä¸ç”¨æ‹…å¿ƒé«˜æ¸©å¼•å‘çš„æŽ‰ç´ é—®é¢˜ã€‚

- æ•£çƒ­ç”¨çš„æ‰‹å¤´çš„ è¶…é¢‘ä¸‰ K4ã€‚å…¶å®žæˆ‘æœ¬æ¥å»ºè®®ä¸Šæ°´å†·ï¼Œå¥ˆä½•æœ‹å‹ä¸€ç›´å¯¹æ°´å†·æœ‰åè§ï¼Œæ€»æ‹…å¿ƒæ¼æ¶²çš„æƒ…å†µã€‚K4 æ˜¯ è¶…é¢‘ä¸‰çš„é«˜ç«¯é£Žå†·ï¼Œå…¨é‡‘å±žæ‰£å…·ï¼Œæ”¯æŒ Iå®¶ / Aå®¶ å…¨å¹³å°å¤„ç†å™¨ï¼Œæ ‡é… GT-3 é«˜å¯¼çƒ­ç¡…è„‚ï¼Œèƒ½å¤Ÿå¿«é€Ÿå°† CPU äº§ç”Ÿçš„çƒ­é‡è¿›è¡Œä¼ é€’ã€‚
  - K4 é‡‡ç”¨å•å¡”å•é£Žæ‰‡è®¾è®¡ï¼Œå¡”èº«ä¸ºå…¨é»‘è‰²ç”µæ³³å·¥è‰ºï¼Œç‹¬ç«‹è£…é¥°æ€§é¡¶ç›–ï¼Œå››çƒ­ç®¡è§¦åº•å¯¼çƒ­ã€50 ç‰‡130mm é“åˆ¶æ•£çƒ­é³ç‰‡è¿›è¡Œçƒ­é‡æ•£å‘ï¼Œä¸¤è€…é€šè¿‡ç©¿Finå·¥è‰ºç»„æˆé³ç‰‡ç¾¤åŠ å¤§æ•£çƒ­é€Ÿåº¦ã€‚æ•´ä½“å·¥è‰ºè¿˜æ˜¯è›®ç²¾ç»†çš„ã€‚

- ç”µæºå®‰æŽ’çš„æŒ¯åŽ VP1000Wã€‚è¿™æ¬¾ç”µæºæœ€å¤§çš„äº®ç‚¹å°±æ˜¯é‡‡ç”¨äº†åˆ›æ–°çš„å¾®åž‹åŒ–æŠ€æœ¯ï¼Œæé«˜æ€§èƒ½çš„åŒæ—¶å°ºå¯¸ç¼©å‡åˆ° 13cm çŸ­æœºèº«ã€å¯ä»¥é‡Šæ”¾ä¸å°‘ç©ºé—´ç»™å…¶ä»–ç¡¬ä»¶ã€‚ç”µæºæœ¬èº«é€šè¿‡äº† 80plus ç™½é‡‘è®¤è¯ï¼Œè½¬æ¢æ•ˆçŽ‡é«˜ï¼ŒåŠ ä¸Šé¢å®š 1000W çš„åŠŸçŽ‡ï¼Œåˆ«çœ‹èº«æå°ï¼Œæ‹– 13900 + 4090éƒ½ä¸æˆé—®é¢˜ã€‚

- æœºæ¢°å¤§å¸ˆåœ¨ç´§å‡‘åž‹æœºç®±é‡Œæ‹¥æœ‰ä¸é”™çš„å£ç¢‘ï¼Œä¹‹å‰æˆ‘å°±è£…è¿‡ä¸€æ¬¡ C26 plusï¼Œä½“éªŒæžå¥½ã€‚è¿™æ¬¡é€‰çš„ç¨å¤§ä¸€äº›çš„ C28
  - æœºç®±çµæ´»åº¦æžé«˜ï¼Œé™¤äº†åŸºæœ¬æ¡†æž¶ï¼Œå¤§éƒ¨åˆ†é¢æ¿éƒ½æ˜¯å¯æ‹†å¼ç»„åˆï¼Œä¸è¿‡å¤§é‡èžºä¸æ‹†å¸èµ·æ¥è¿˜æ˜¯æ¯”è¾ƒç¹çï¼Œè¿™ä¹Ÿæ˜¯å…¶è¢«å¹¿å¤§ç½‘å‹æˆç§°ä¸ºâ€œèžºä¸å¤§å¸ˆâ€çš„åŽŸå› ã€‚
- èƒŒæ¿å¯æ‹†ï¼Œæ–¹ä¾¿èµ°çº¿çš„åŒæ—¶å®‰è£…é…ä»¶æ›´åŠ è½»æ¾ã€‚æœ‰äº›ä¸»æ¿ m.2 æ˜¯åœ¨ä¸»æ¿èƒŒé¢ï¼Œç”¨è¿™ä¸ªæœºç®±å°±å¯ä»¥åœ¨ä¸æ‹†ä¸»æ¿çš„æƒ…å†µä¸‹åŠ è£… SSDã€‚
- é¡¶éƒ¨è¿˜æ”¯æŒ åŒ 12cm é£Žæ‰‡æˆ–è€… 240 æ°´å†·ã€‚è¯è¯´åˆ«çœ‹ C28 ä½“ç§¯å°±æ¯” C26plus å¤§äº†ä¸€ç‚¹ï¼Œä½†è£…æœºä½“éªŒå¥½äº†ä¸å°‘ã€‚

- ä¾¿æºå±ï½œINNOCN 15Q1F
  - è£…æœºæˆ‘éƒ½æ˜¯ä¹ æƒ¯ç”¨ä¾¿æºå±ã€‚INNOCN 15Q1Fé‡‡ç”¨çš„ OLED å±å¹•
  - é‡é‡ 0.94kg ï¼Œå•æ‰‹æ¡æŒæ¯«æ— åŽ‹åŠ›ï¼Œé•¿æ—¶é—´ä½¿ç”¨æœ‰ä¸“ç”¨çš„çš®å¥—æä¾›å€¾æ–œè§’åº¦ã€‚æŽ¥å£æ˜¯ Type C X 2 +Mini HDMI ç»„åˆï¼Œå¯ä»¥å®žçŽ°ä¸€çº¿è¿žåŠŸèƒ½ï¼ˆä¾›ç”µä¸Žä¿¡å·ä¼ è¾“ä¸€çº¿è¾¾æˆï¼‰ã€‚
  - è¿™æ¬¾ä¾¿æºå±æ”¯æŒæ‰‹æŒ‡ç›´æŽ¥æ“ä½œï¼Œåç‚¹è§¦æŽ§+å†…ç½®çš„è§¦æ‘¸OSDé¢æ¿
  - ç”šè‡³è¿˜æ”¯æŒæ— çº¿è¿žæŽ¥ã€‚INNOCN 15Q1Fè‡ªèº«æ­è½½äº† WiFi æ¨¡å—ï¼Œé€šè¿‡å®ƒå¯ä»¥å°†ä¸»æœºã€æ‰‹æœºæˆ–è€…ç¬”ç”µçš„ç”»é¢ç›´æŽ¥æŠ•å±æ˜¾ç¤ºï¼ŒæŽ§åˆ¶åˆ™é€šè¿‡è§¦æ‘¸å®žçŽ°
  - ä¾¿æºå±è¿˜å†…ç½® 5000mAH ç”µæ± ï¼Œå¯ä»¥è„±ç¦»çº¿æè¿žæŽ¥çš„ä¸ä¾¿ï¼Œç»­èˆªæ—¶é—´èƒ½è¾¾åˆ° 4å°æ—¶å·¦å³ï¼Œå®Œå…¨å°±æ˜¯å°å¹³æ¿ç”µè„‘ã€‚

- [ã€17.9Lã€‘C28è¿·ä½ æ‰‹æä¸»æœº - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/664881a50000000014018c4a?xsec_token=ABjcFKpzYqPfIG6C1AnlqDTFCINPxDCJ7dN5lu4n9saWI=&xsec_source=pc_search&source=web_search_result_notes)
  - å¼€ç›–é£Žå†·éƒ½è¡Œ

- ## [é—ªé³žG300æ”¯æŒ164mmé«˜åº¦é£Žå†· - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/66cd695b000000001f03a713?xsec_token=ABX2Viv4Qebp0rD6T3QkbAt8L2lTvl7qp8ds1dlZ-amvc=&xsec_source=pc_search&source=web_search_result_notes)
  - matx, æ˜¾å¡340mmï¼Œæ²¡æœ‰çŽ»ç’ƒä¾§æ¿
- å¦‚æžœç”¨itxç”µæºï¼Œç”µæºåº•ä¸‹èƒ½åŠ 12cmé£Žæ‰‡å—
  - ä¸èƒ½
  - å› ä¸ºè¿™ä¸ªå¦‚æžœåœ¨æ˜¾å¡åº•ä¸‹è£…é£Žæ‰‡å™ªéŸ³ä¼šæ¯”è¾ƒé«˜ï¼Œå‰åŽå„ä¸€æ¯”è¾ƒåˆç†çš„

- [æœ‰æ²¡æœ‰é—ªé³ž g300 å¹³æ›¿ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/68bfeedd000000001b03777b?xsec_token=AB7fK2DtVB9-Uox-1NRYZeZJRfF0RaYQ3O2_pLevARsAQ=&xsec_source=pc_search&source=web_search_result_notes)
  - æœ‰æ²¡æœ‰æ¯”é—ªé³ž 300 ä¸€æ ·ä½†æ˜¯æ˜¯é“çš„æœºç®±å‘€ï¼Œéœ€è¦æžé™å°ºå¯¸çš„æœºç®±ï¼Œä¸»æ¿æ ‡å‡† matxï¼Œsfx ç”µæºï¼Œæ˜¾å¡æ˜¯ 7800xt è¶…ç™½é‡‘ç‰ˆï¼Œ
  - ä¸éœ€è¦è£…æ°´å†·ï¼ˆg300 å› ä¸ºå¯ä»¥è£…æ°´å†·ï¼Œæ‰€ä»¥æœºç®±æ¯”è¾ƒåŽšï¼‰ï¼Œ
  - éœ€è¦èƒŒéƒ¨ç†çº¿ï¼Œå¯æ‹†å¸ pcie æŒ¡æ¿ï¼ˆèƒ½æ‹†å¸åŽæ¿ä¹Ÿè¡Œï¼Œå› ä¸ºæ˜¾å¡é•¿ 320ï¼‰

- å·²ç»çœ‹äº†å°å–†çš„ï¼Œb3ï¼Œc2pï¼Œä½†æ˜¯æ²¡æœ‰èƒŒéƒ¨ç†çº¿ï¼Œc2p ä¸çŸ¥é“å¯ä¸å¯ä»¥æ‹†åŽæ¿ï¼Œéƒ½ä¸å¤§è¡Œ

- G300å°±æŒºå¥½çš„, åº•éƒ¨é£Žæ‰‡å’Œå±è‚¡é£Žæ‰‡æˆ‘éƒ½æ²¡è§ï¼Œæ•£çƒ­å®Œå…¨è¶³å¤Ÿ

- åº•éƒ¨èƒ½è£…ä¸‰æŠŠé£Žæ‰‡å—
  - åªèƒ½è£…2ä¸ª

- é“çš„ä¸è¡Œå—ï¼Ÿ
  - g300ï¼Œ3.2kgï¼Œå°å“² b3ï¼Œ1.8kg

- Ncase M3.. åº”è¯¥æ˜¯ç»¼åˆæ€§æ¯”è¾ƒå¥½çš„äº†

- [é—ªé³žG300 9700xâž•5070tié£Žå†·æ”¹é€ æ–¹æ¡ˆ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/68be261e000000001c03c453?xsec_token=ABL-IFl_t7vNlynLFA54jExvARox4t1Q4sD_V7oRMh-_U=&xsec_source=pc_search&source=web_search_result_notes)
  - ç¬¬ä¸€æ¬¡è£…æœºæ²¡ç»éªŒï¼Œé£Žå†·ä¹°äº†ä¹”æ€ä¼¯CR1000maxï¼Œç»“æžœå‘çŽ°æ ¹æœ¬åŽ‹ä¸ä½ï¼Œéšéšä¾¿ä¾¿æ’ž95åº¦å¢™ã€‚
  - åŽæ¥æœºç®±å°¾éƒ¨åŠ äº†ä¸ªåˆ©æ°‘c12proï¼Œæ•£çƒ­å¡”é£Žæ‰‡æ¢æˆäº†é›¶åº¦ä¸–å®¶é£Žå°Št30coï¼ˆå¡”è¿˜æ˜¯ä¹”æ€ä¼¯çš„æ²¡æ¢ï¼‰ã€‚çŽ°åœ¨æ•£çƒ­è¡¨çŽ°å¦‚ä¸‹ï¼ˆçƒ¤é¸¡10åˆ†é’Ÿï¼Œå‡ä¸ºCPUæ¸©åº¦ï¼‰ï¼šå•çƒ¤CPU77
- ä¹”æ€ä¼¯çš„æ•£çƒ­å™¨æ‹‰å®Œäº†
- è¿™ä¸ªç®±å­æ²¡å•¥åŠ çš„ä½™åœ°äº†ï¼Œä¸‹é¢åŠ é£Žæ‰‡ç¦»æ˜¾å¡å¤ªè¿‘äº†ï¼Œå±žäºŽæ˜¯å‰¯ä¼˜åŒ–äº†ï¼Œé¡¶éƒ¨åŠ é£Žæ‰‡è¦è‡ªå·±é…ç£å¸èžºä¸ï¼Œè¿˜æ˜¯æ•£çƒ­å™¨æ¢å¥½ç‚¹çš„æ”¹å–„æœ€æ˜Žæ˜¾

- æ¢ä¸ªåŒå¡”ä¸å°±å¥½äº†ã€‚è€Œä¸”ä¸åƒæ˜¾å¡å°¾æ°”ä¸å¯èƒ½çš„ï¼Œè¿™æœºç®±ä¹Ÿå°±è¿™æ ·äº†ã€‚
  - å¥½çš„ï¼ŒåŒå¡”æœ‰äººè¯´p60tæœ€å¼ºï¼ˆä¹°å¡”è‡ªå·±é…é£Žæ‰‡ï¼‰ï¼Œè¿™ä¸ªæ˜¯çœŸçš„å—
- å¯ä»¥çš„ï¼Œæ”¾è¿œç‚¹å…¶å®žä¹Ÿä¸æ˜¯å¾ˆåµ

- [ç»ˆäºŽèµ¶åœ¨åŒåä¸€æœ«å°¾ä¹°é½äº† - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/673030e6000000001b012544?xsec_token=ABwBx_0AZ3zhOiWwQ_EVFjfonKMxsn0Fki4JP09JVTi8g=&xsec_source=pc_search&source=web_search_result_notes)
- 4070såŠŸçŽ‡é‚£ä¹ˆé«˜ä½ å°±ä¹°ä¸ª650wçš„ç”µæºï¼Ÿ
  - å“ªæ€•æƒ³åŽç»­å‡çº§ï¼Œè‡³å°‘ä¹°ä¸ª850wçš„ä¹Ÿè¡Œå•Š
- g300é€šé£Žåšè¿˜è¡Œï¼Œä½†æ˜¯åŠ ä¸ªé£Žæ‰‡ä¿é™©ç‚¹
- å°¾éƒ¨é£Žæ‰‡æœ€é‡è¦â€¦â€¦4070såŽšåº¦è¿˜å¥½ï¼Œåº•éƒ¨ä¹Ÿèƒ½æŒ‰ï¼Œä¸è¿‡æ•´å¥—åŠŸè€—ä¸ç®—å¾ˆé«˜ï¼Œæœ‰ä¸ªå°¾æ‰‡è¶³å¤Ÿç”¨

- [é—ªé³žg300æ”¹è£…æ€è·¯ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/6810d0cf000000002100613c?xsec_token=AB_QqkK7_ZF3_KbwyW1ZB1W22MKjj0BCjU-aVf69KLO5s=&xsec_source=pc_search&source=web_search_result_notes)
  - é—ªé³žg300æŒºå¥½çŽ©ï¼Œåœ¨åšåˆ°å°½å¯èƒ½å¤šå…¼å®¹ï¼Œæ”¯æŒ340mmé•¿åº¦æ˜¾å¡ï¼Œ14cm atxç”µæºå’Œ164mmé£Žå†·çš„æƒ…å†µä¸‹ï¼Œèƒ½å°½å¯èƒ½ç¼©å°ä½“ç§¯ï¼Œåšåˆ°åª²ç¾Žitxæœºç®±çš„ä½“ç§¯ï¼Œæ˜¯æˆ‘æœ€çˆ±çš„æœºç®±ã€‚
  - åœ¨æ¢è£…é—ªé³žg300æœºç®±åŽï¼Œæˆ‘å…ˆæ˜¯ä¸Šäº†åŒå¡”æ•£çƒ­å™¨ak620proï¼Œç„¶è€Œæ•´æœºå°†è¿‘20æ–¤çš„è´¨é‡ï¼Œè®©ä»–å˜å¾—ä¸é‚£ä¹ˆå¯ç§»åŠ¨ï¼Œ
  - å¯¹è¿™ä¸ªçª˜å¢ƒï¼Œæˆ‘å°†ç›®å…‰ç§»å‘ä¸‹åŽ‹å¼æ•£çƒ­ï¼Œä¸ºæ­¤æ›´æ¢idcooling-isxt67ï¼Œå¹¶æ›´æ¢æ•£çƒ­ä¸º12025çš„ä¹å·žé£Žç¥žft12ã€‚isxt67å¡”ä½“å…¼å®¹æ€§ç¡®å®žä¸é”™ï¼Œåœ¨åšåˆ°å°½å¯èƒ½ç¾Žè§‚çš„åŒæ—¶ä¹Ÿä¸é®æŒ¡ä»»ä½•å†…å­˜æ§½ã€‚åŽç½®é£Žæ‰‡ä½åšè¿›é£Žå¤„ç†ï¼Œä¸ºé¿å…é£Žåˆ‡å£°ï¼Œéœ€è¦å°†é£Žæ‰‡ç§»åˆ°å¤–é¢
  - idcooling-isxt67å¡”ä½“ä¼˜ç§€ï¼Œæ›´æ¢é£Žæ‰‡ä¹‹åŽèƒ½ç¨³å®šåŽ‹åˆ¶180wçš„13600kfï¼ˆæ¸²æŸ“æœ€é«˜æ¸©åº¦80â„ƒï¼‰ï¼ŒåŒæ—¶ç”±äºŽé£Žæ‰‡æ•°é‡å°‘ï¼Œåšåˆ°æ›´é™éŸ³ï¼Œæ˜¯ä¸€ä¸ªä¸é”™çš„æ”¹è£…æ€è·¯ã€‚

- æŠ€å˜‰m650å°é›•ä¸»æ¿ï¼Œç”¨å“ªæ¬¾åŒå¡”ä¸æŒ¡å†…å­˜å‘¢ï¼Œæˆ‘çœ‹æ‚¨è¿™ä¸ªé£Žå†·å¥½åƒå¾ˆå°
  - æˆ‘è¿™ä¸ªæ˜¯ä¸‹åŽ‹å¼é£Žå†·ï¼ŒåŸºæœ¬ä¸Šç”¨matxä¸»æ¿éƒ½å¯ä»¥ä¸æŒ¡å†…å­˜ï¼Œå¦‚æžœä½ æ˜¯9700xä»¥ä¸‹çš„cpué»˜é¢‘åº”è¯¥éƒ½æ˜¯èƒ½åŽ‹å¾—ä½çš„ï¼Œå¼€pboçš„è¯è¡¨çŽ°å¯èƒ½ä¸å¥½ã€‚åŒå¡”é£Žå†·ï¼Œä½ å¯ä»¥çœ‹çœ‹ä¹å·žé£Žç¥žé˜¿è¨è¾›å››æˆ–è€…é˜¿è¨è¾›4sã€‚

- åŒæ¬¾æœºç®±ï¼Œè¯·é—®ä¹‹åŽæ¢çš„ä¸‹åŽ‹å¼ï¼Œæ¯”620proæ•£çƒ­å¦‚ä½•å‘€
  - åŒä¸€ä¸ªCPUç›¸æ¯”ä¸€ä¸‹é«˜äº†å¤§æ¦‚10åº¦

- [ç¬¬ä¸€å°matxï¼Œé—ªéºŸg300ï¼Œå°±å–œæ¬¢è¿™ç§å¡žæ»¡æ»¡çš„æ„Ÿè§‰ï¼Œä¸‹ä¸€æ­¥å‡†å¤‡æ¢ä¸ªå¤§æ˜¾å¡ï¼Œç„¶åŽæŠŠæœºç®±ç«‹èµ·æ¥æ‘†æ”¾ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/687222ef000000001203f6cb?xsec_token=ABMrApDT4vX1zr_5qUgsvW1ie38sgqbr-KgLksPrLadcA=&xsec_source=pc_search&source=web_search_result_notes)
- è¯·é—®å³ä¸‹9cmé£Žæ‰‡æ˜¯æ­£å¶è¿˜æ˜¯åå¶ï¼Œè¿›é£Žçš„å—ï¼Ÿå åŠ ä¸‰ä¸ªä¸ºå•¥
  - å‡ºé£Žï¼Œä¸»è¦ä¾§é¢æ¢æˆäºšå…‹åŠ›é€æ˜Žæ¿ï¼Œæ˜¾å¡æ¸©åº¦ä¸å¥½ä»Žä¾§é¢å‡ºåŽ»ï¼Œæ‰€ä»¥é è¿™ä¸‰ä¸ªé£Žæ‰‡æŠŠé£Žä»Žå‰é¢å¼•å‡ºåŽ»ï¼Œå…¶å®žä¸¤ä¸ªå°±å¤Ÿäº†ï¼Œä¸‰ä¸ªæ˜¯ä¸ºäº†é¥±æ»¡å¥½çœ‹
- å¡žè¿™ä¹ˆæ»¡ä¼šä¸ä¼šå½±å“æ•£çƒ­å•Šï¼Ÿ
  - æœ‰é£Žé“çš„ï¼Œä¾§è¿›åŽå‡º
- å³ä¸‹è§’é£Žæ‰‡æ˜¯å•¥
  - åˆ©æ°‘9cmé£Žæ‰‡ï¼Œ tl-p9w-s

- 300æ˜¯ä¸æ˜¯æ²¡æœ‰é¡¶éƒ¨é£Žæ‰‡ä½
  - æ²¡æœ‰ï¼Œä½†æ˜¯ç©ºé—´å¤Ÿè£…è–„æ‰‡ï¼Œå°±æ˜¯å¦‚ä½•å›ºå®šè¦è‡ªå·±æƒ³åŠžæ³•

- å¤§ä½¬ç”¨çš„å†…å­˜é£Žæ‰‡æ˜¯ç”¨çš„ä»€ä¹ˆæ”¯æž¶ï¼Ÿ
  - ä¹”æ€ä¼¯NF-1å†…å­˜æ¡é£Žæ‰‡è‡ªå¸¦çš„

- æ˜¾å¡åŠè£…æ¸©åº¦ä¼šå‡é«˜å¾ˆå¤šï¼Œå°¤å…¶æ˜¯å°æœºç®±å¤§æ˜¾å¡
  - è¿™ä¹Ÿæ²¡åŠè£…å•Šâ€¦â€¦ç›´æ’çš„
- ä»–è¯´è¦æ¢å¤§æ˜¾å¡ç„¶åŽæŠŠæœºç®±ç«‹èµ·æ¥

- ç”µæºé‚£é‡Œç½‘å­”æŒ¡æ¿å“ªæ¥çš„å•Š
  - å‰é¢æ˜¯è®¢åšé€æ˜Žäºšå…‹åŠ›æ¿ï¼Œç”µæºæ—è¾¹å°é£Žæ‰‡ç½‘æ ¼æ¿æ˜¯å†…å­˜é£Žæ‰‡è‡ªå¸¦çš„

- è¿™ä¸ªæœºç®±æ”¯æŒéžæ¨¡ç»„ç”µæºä¹ˆ
  - æ”¯æŒçš„ï¼Œä½†çº¿å †åœ¨ä¸€èµ·æ¯”è¾ƒéš¾å…³ä¾§æ¿

- è¿™ä¹ˆç´§å‡‘æ•£çƒ­è·Ÿå¾—ä¸Šå—ï¼Ÿ
  - 4060å’Œ12490Fï¼Œé…ç½®ä¸é«˜ï¼Œç›®å‰æ¸©åº¦ç¨³å®šï¼Œæ˜¾å¡æœ€é«˜åˆ°72

- ## [æ–°å“é¢„å‘Šï¼šé—ªé³žG350æœºç®± - å°çº¢ä¹¦ _202504](https://www.xiaohongshu.com/explore/680b49e4000000000f03025e?xsec_token=ABmVEaGHnouuW4by4cF_K2PztIm78YN2rgioigqEQn8-4=&xsec_source=pc_search&source=web_search_result_notes)
- g300åŠ é¡¶éƒ¨é£Žæ‰‡æ”¯æŒå—ï¼Œå¤ªå¿ƒåŠ¨å•¦
  - g350æ”¯æŒä¸¤ä¸ªé¡¶éƒ¨é£Žæ‰‡
  - ç”µæºåº•ä¸‹æ²¡æœ‰ï¼Œæœºç®±ä¸€å…±5ä¸ªé£Žæ‰‡ä½

- å’Œg300å•¥åŒºåˆ«
  - å¤šäº†èƒŒæ’ï¼Œ16åŽ˜ç±³ç”µæºå…¼å®¹ï¼Œé¡¶éƒ¨ä¸¤ä¸ªé£Žæ‰‡ä½ï¼Œä¾§é€

- ç”µæºæ”¯æŒ15ï¼Ÿ
  - 16cm

- èƒ½ä¸èƒ½å‡ºä¸ªmeshæ¿ï¼ŒæŠŠçŽ»ç’ƒæ¢æˆç½‘å­”

- ## [æœºç®±è¯´Â¹ - ä¹”æ€ä¼¯å’Œæœºæ¢°å¤§å¸ˆè°èµ¢äº† - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/66a61571000000002701010c?xsec_token=AB-NVtDH_xyoN48IVgN-otrQDhbPhG6D8S77xA6fATSDM=&xsec_source=pc_search&source=web_search_result_notes)
  - c+maxå°ºå¯¸:392mm*284mm*185mm  20.5lä½“ç§¯
  - z20  å°ºå¯¸:370mm*295mm*186mm  20lä½“ç§¯
  - z20æœ€å¥½çš„æ–¹æ¡ˆæ˜¯é£Žå†·+atxçš„ç»„åˆ
  - c+maxæœ€ä½³æ–¹æ¡ˆæ˜¯æ°´å†·+atxçš„ç»„åˆ
  - c28åœ¨å®‰è£…240æ°´å†·çš„æƒ…å†µä¸‹ï¼Œå¤§éƒ¨åˆ†ä¸»æ¿ä¸æ”¯æŒatxç”µæºã€‚

- ç»„è£…çš„è¯æˆ‘æ„Ÿè§‰å·®ä¸å¤šï¼Œz20å¯¹æ–°æ‰‹æ›´å¥½å§ï¼Œé˜²å°˜åŒä¸€æ°´å¹³ã€‚

- æ¯”è¾ƒå–œæ¬¢æœºæ¢°å¤§å¸ˆï¼Œç”¨æ–™æ˜¯çœŸåŽšå®žï¼Œé…ä»¶ç›¸å¯¹æ¥è¯´ä¹Ÿå¤šä¸€ç‚¹ï¼Œä¸è¿‡æ€§ä»·æ¯”æ¥çœ‹æ¯”ä¸äº†ä¸€ç‚¹
  - é“åˆé‡‘å’Œé’¢çš„ï¼Œææ–™å°±ä¸ä¸€æ ·ï¼Œé‡é‡ä¹Ÿè½»äº†ã€‚ä¸ç„¶å’‹é™ä¸æ¥ä»·æ ¼

- ä¸¤æ¬¾éƒ½ç”¨è¿‡ï¼Œä¸ªäººå€¾å‘äºŽz20, è¶…çº§å¥½çœ‹

- [æœºæ¢°å¤§å¸ˆ c28 - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/6717559e0000000016021389?xsec_token=ABE6Ld3Qrhhpu6tuNb5p51L1Q3oe3WokQOP0_Eksi_ke4=&xsec_source=pc_search&source=web_search_result_notes)
  - é€‰æ‹©äº† c28ï¼Œè£…æœºæˆåŠŸ
  - å’Œæœ‹å‹çš„ z20 å¯¹æ¯”å°é‚£ä¹ˆä¸€ä¸¢ä¸¢ï¼Œc28 è¿˜æ˜¯å»ºè®®ç”¨ sfx ç”µæºï¼Œè¿™æ ·å¥½è—çº¿äº›ï¼atx ç”µæºç¡®å®žå¤§äº†ç‚¹æžé™å®‰è£…
- é£Žæ‰‡æ˜¯å“ªä¸ªåž‹å·
  - åˆ©æ°‘s12

- [æœºæ¢°å¤§å¸ˆc28å¸…æ— æ•Œï¼Œ9700x+5070ï¼Ÿ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/68af1a1d000000001d02d18f?xsec_token=ABx7Z2Y7-KnOKMOASaKY8sp7br1TF0G7T40iVw6hcK7ww=&xsec_source=pc_search&source=web_search_result_notes)
  - é¦–å…ˆè¯´ä¸€ä¸‹ä¸ºå•¥é€‰æ‹©è¿™ä¸ªæœºç®±ã€‚æ·±åº¦400mmæ¡Œé¢ï¼Œæ‰¾äº†å¾ˆä¹…å”¯ä¸€å…¼å®¹é£Žå†·æ°´å†·çš„æœºç®±ã€‚è€ƒè™‘çš„èƒŒåŽæ’ç”µæºçº¿å’Œå‡ºé£Žã€‚æŠ›å¼ƒäº†z20ï¼Œé€‰ç”¨é•¿åº¦350mmå·¦å³æœºç®±å®žæ–½è¯æ˜Žåˆšåˆšå¥½ã€‚è¿˜æœ‰ä¸¤æ¬¾æœºç®±æ˜¯è¿™ä¸ªå¹³æ›¿ä½†æ˜¯ä¸æ”¯æŒæ°´å†·
  - å†è¯´æ•£çƒ­ï¼Œæ•£çƒ­å…¶å®žhyp612ï¼Œak620ï¼Œp60téƒ½æŒºå¥½ã€‚æœ¬æ¥æƒ³è¦æ•°æ˜¾ç‰ˆæœ¬çš„ï¼ŒåŽé¢åˆ·åˆ°ç›®å‰æ•°æ˜¾bugå¤ªå¤šï¼Œæ”¾å¼ƒäº†ã€‚
  - ç”µæºè¿™ä¸ªçº ç»“æœ€ä¹…ï¼ŒæŒ‰ç†è¯´è€ƒè™‘å…¼å®¹æ€§åº”è¯¥ä¸€æ­¥åˆ°ä½sfxã€‚ä½†æ˜¯sfx850wå‘å¤ªå¤šäº†ã€‚æœ€åŽé€‰äº†è¿™ä¸ªé‘«è°·çš„ï¼Œè¿™ä¸ªç”µæºå¥½å¤„æ˜¯120mmï¼Œå’Œsfxlä¸€æ ·é•¿ï¼Œç”µæºçº¿å‡ºå£ä¸å¤ªå®¹æ˜“å’Œæ˜¾å¡å¹²ä¸Š

- ## [ä¹”æ€ä¼¯Z20 or æœºæ¢°å¤§å¸ˆC26 - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/66d70459000000001f01e720?xsec_token=ABFpKqSuGzHOELX8EkCIc8ArGFoGzwbK104D0gsq2YzyU=&xsec_source=pc_search&source=web_search_result_notes)
  - æœºæ¢°å¤§å¸ˆC26: 315*160*265mm, 13.3L
  - ä¹”æ€ä¼¯T6: 13.7L
  - å°±çŽ©ä¸‹é»‘æ‚Ÿç©ºæ˜¯é€‰æ‹©12600kfè¿˜æ˜¯12490fï¼Œç„¶åŽå°±æ˜¯æœºç®±ä¹”æ€ä¼¯Z20 or æœºæ¢°å¤§å¸ˆC26ï¼Œæ€Žä¹ˆçœ‹éƒ½å¥½çœ‹å°±æ˜¯ä¸çŸ¥é“æ€Žä¹ˆé€‰äº†

- çŽ©é»‘ç¥žè¯124å°±è¶³å¤Ÿäº†ï¼ŒçŽ°åœ¨126å¤ªè´µäº†

- c28 å¤§ä¸€äº›å¯ä»¥ç”¨ atx ç”µæºï¼Œc26 è£… sfx ç”µæºå’Œ c28 è£… atx ç”µæºå·®ä¸å¤šï¼Œè—çº¿æœ‰äº›å›°éš¾ï¼Œçœ‹ä¸­æœºæ¢°å¤§å¸ˆä¾¿æºå’Œé¢œå€¼ï¼Œæ•£çƒ­åŠ è£…äº”æŠŠé£Žæ‰‡å®Œå…¨å¤Ÿç”¨

- z20å¯ä»¥atxç”µæº+240æ°´å†· c28åªèƒ½sfx+240
  - ä¸ç”¨itxçš„å“‡ä»–ä¿©éƒ½æ”¯æŒmatxçš„å“‡

- 5æŠŠé£Žæ‰‡ï¼Œä¸Šä¸‹14cmï¼ŒåŽç½®12cmï¼Œåˆšåˆšå¥½
- ä¸»æ¿å¾®æ˜ŸB650M GAMING WIFI

- ä¸‹é¢æ”¾ä¸¤ä¸ª14å°±æ²¡åœ°æ–¹æ”¾æ˜¾å¡æ”¯æž¶äº†å§
  - æ˜¯çš„ï¼Œå°æ˜¾å¡ä¹Ÿä¸éœ€è¦

- z20å¯ä¸é—·ï¼Œä¸æ˜¯ä»¥å‰çš„ç‚¼ä¸¹ç‚‰äº†

- Z20å¥½ï¼Œåº•éƒ¨å¯ä»¥è£…2æŠŠ12cmé£Žæ‰‡å’Œ1å—3.5è‹±å¯¸æœºæ¢°ç›˜ã€‚è£…æœºä¹Ÿæ¯”èžºä¸å¤§å¸ˆçœåŠ›ã€‚é¢œå€¼ä¸Šæˆ‘ä¸ªäººæ˜¯å–œæ¬¢Z20çš„ç®€æ´æ„Ÿ

- ## [é—ªé³žg350è¿˜æ˜¯ä¹”æ€ä¼¯z20 - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/68b462bb000000001d02a8a5?xsec_token=ABHRfK0CgtuFDQhWIxlZF5BI37zGCq6uwnRe3ZkLYVd3I=&xsec_source=pc_search&source=web_search_result_notes)
  - æ˜¾å¡29cmæ¶¡è½®3090ï¼Œè®¡åˆ’ç”¨é£Žå†·ã€‚å¤–è§‚ä¸Šåå‘g350ã€‚æœ‰æ•£çƒ­ç„¦è™‘ï¼Œè€ƒè™‘cpuå’Œç”µæºè¿™ä¸€ä¸²çš„æ•£çƒ­ï¼Œ
- è´¨æ„Ÿåšå·¥æ˜¯z20æ›´å¥½ä¸€äº›ï¼Œæ•£çƒ­æˆ‘ç”¨ç€æ„Ÿè§‰å·®ä¸å¤šï¼Œé—ªé³žä¼˜åŠ¿åœ¨å‰ç½®æŽ¥å£å¤ªé¡¶äº†

- æˆ‘éƒ½ç”¨è¿‡æ•£çƒ­åŸºæœ¬æ²¡åŒºåˆ«

- sfxç”µæºåŠ çŸ­æ˜¾å¡å¯ä»¥å‚è€ƒè¿™ä¸ªï¼Œæˆ‘g350å¡žäº†ä¸ª338çš„æ˜¾å¡å°±æ²¡è¾™äº†
  - æˆ‘ç”¨çš„146kfåŠ å¾®æ˜Ÿb760måˆ€é”‹é’›ï¼Œæ¿uå¥—è£…2300
  - å¦å¤–æ¶¡è½®å¡ä¸ç”¨æœ‰æ•£çƒ­ç„¦è™‘ï¼Œè¿˜æ˜¯æ¯”è¾ƒä¾èµ–è‡ªèº«æ¶¡è½®é£Žæ‰‡çš„
- æˆ‘æƒ³ç”¨14700cpuæœ‰å¿…è¦ç”¨zä¸»æ¿å—æƒ³ä¹°ä¸€ä¸ªb760mçš„ç®—äº†
  - ç¨³å®šè¿è¡Œéœ€è¦æŒ‘å—ä¾›ç”µå¥½çš„ä¸»æ¿ï¼Œçœ‹è¶…ä¸è¶…é¢‘å’Œå·®ä»·å§

- å‰ç½®ç”µæºçš„å°±åˆ«æƒ³ç€æ•£çƒ­å¥½ï¼Œæ²¡æœ‰å‰è¿›é£Žçš„éƒ½æ˜¯ç„–ç½
  - ä¹å·žçš„ch160æœ‰å‰è¿›é£Žï¼Œç¨å¾®æ¯”ä½ å‘çš„è¿™ä¸¤å¤§ä¸€ç‚¹

- g350çš„è¯æœ€å¥½ä¹°èƒŒæ’ä¸»æ¿ï¼Œçœ‹ç€å¥½çœ‹ä¸€ç‚¹ï¼Œæ•£çƒ­æ„Ÿè§‰ç”¨å“ªä¸ªéƒ½è¡Œä¸ç”¨æ‹…å¿ƒ

- è¿™ä¿©å…¶å®žå·®ä¸å¤šï¼Œçœ‹ä½ æ˜¯æƒ³è¦UIå¤šä¸€ç‚¹å„¿è¿˜æ˜¯èƒ½æ›¿æ¢çŽ»ç’ƒæ¿ï¼ŒZ20çš„çŽ»ç’ƒæ¿æ˜¯å¯ä»¥æ¢æˆç§äººå®šåˆ¶çš„äºšå…‹åŠ›æ¿è¿™ä¸ªæ˜¯éœ€è¦è‡ªå·±ä¹°ï¼ŒG350ä»–çš„è¿™ä¸ªæ¿å­æ˜¯æ²¡æ³•æ›¿æ¢çš„

- [æƒ³æ¢å°æœºç®± - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/68ce8bd3000000001300fcdc?xsec_token=ABp12HvDLqm3bcBXz75MLag9SHKyM4ALJFCDd6jzfp9_c=&xsec_source=pc_search&source=web_search_result_notes)
- g300 ä¹Ÿè¡Œå—ï¼Œå°±ä¸€ä¸ªé£Žæ‰‡ä½å“Žï¼Œæ„Ÿè§‰ä¼šå¾ˆé—·å•Šï¼Œæ•£çƒ­æ€§çš„è¯å…¶å®žæƒ³é€‰ g300ï¼Œå› ä¸ºæœ€å°
- g300çš„é—®é¢˜æ˜¯ç”µæºå‡ºé£Žåœ¨æœºç®±å†…ï¼Œå®¹æ˜“è¢«cpuæ•£çƒ­å™¨æŠ½èµ°

- g350 æœ‰ç‚¹å¤§ï¼Œæˆ‘çŽ°åœ¨æœ‰ç‚¹çº ç»“ z20 å’Œ g300
  - ä¸€æ ·é•¿ï¼Œé«˜äº†1.5cmåº•ä¸‹å¯ä»¥å¤šå¡žä¸¤ä¸ªé£Žæ‰‡ï¼Œå®½å¤šäº†2.4cmå¢žåŠ èƒŒçº¿ç©ºé—´è¿˜å¯ä»¥è£…æœºæ¢°ç¡¬ç›˜ã€‚
  - 300é£Žæ‰‡å°‘å„æœ‰ä¼˜åŠ¿ã€‚é€‰300ä½ å¯ä»¥å¯¹æ¯”ä¹”æ€ä¼¯c6å§ï¼ŒZ20æ˜¯å’Œg350åŒçº§åˆ«ä½“ç§¯20Lå•Š

- g350å¤ªå¤§äº† ä¹°äº†æœ‰ç‚¹åŽæ‚” ï¼Œä¹‹å‰çš„æœºç®±åˆç›–ä¸ä¸Šç›–å­ é£Žå†·å¤ªå¤§ æœºæ¢°å¤§å¸ˆc28åˆå¤ªè´µäº†

- å°æœºç®±é£Žé“éƒ½å·®ï¼Œè¦èˆæ‰æœ‰å¾—ï¼Œè¿™æ¬¾æœºç®±èƒ½æ”¾ 240 æ°´å†·å’Œ atx ç”µæºï¼Œå¿˜è®°æœ‰æ²¡æœ‰ç†çº¿ç©ºé—´äº†ï¼Œæˆ‘å°±é€‰äº† ch160plusï¼Œä¸æ˜¯å¾ˆæŽ¨è ch160plusï¼Œç”µæºçº¿æå¤ªé•¿å¤ªç¡¬å°±å¾ˆéš¾å¡žï¼Œè£…æœºè´¼éš¾å—

- ä¹”æ€ä¼¯z20çš„æ•£çƒ­ä½ å®Œå…¨ä¸ç”¨æ‹…å¿ƒï¼æˆ‘å°±åœ¨ç”¨ï¼ï¼
- æ•£çƒ­æ²¡é—®é¢˜çš„ æˆ‘146+5080ç”¨çš„z20

- ## [å°æœºç®±ä¹”æ€ä¼¯z20å’Œé—ªé³žg300é€‰å“ªä¸ª ](https://www.xiaohongshu.com/explore/66f7512b000000001b022ed4?xsec_token=ABeOr8Ft0HNW3FbtvsjZTd5rWYn4gt7MDLAuGVYnlQiIQ=&xsec_source=pc_search&source=web_search_result_notes)
- ä¹”æ€ä¼¯Z20, é£Žæ‰‡åˆ©æ°‘TL-S12ï¼Œæ­£åå¶éƒ½æœ‰
  - ä¹°çš„äºŒæ‰‹æ•£çƒ­ä¸æ€•åï¼Œç„¶åŽæ–°çš„é£Žæ‰‡æ­ä¸€ä¸‹
  - ä¸»è¦æ˜¯ç”¨äº†åˆ©æ°‘çš„pa120é£Žå†·å’Œtl-s12å…‰åœˆé£Žæ‰‡
  - é»‘è‰²ç”µæºéšä¾¿ä¸Šï¼Œä¸æŒ‘

- z20åº•ä¸‹ä¸å‡†å¤‡è£…é£Žæ‰‡äº†å—
  - æˆ‘æ˜¯å•å¡”é£Žå†·ï¼Œcpuå•çƒ¤åŠä¸ªé’Ÿä¸è¶…è¿‡95åº¦ï¼Œå¹³å¸¸å¾…æœºçœ‹è§†é¢‘ç­‰34åº¦ï¼ŒçŽ©é»‘æ‚Ÿç©º70åº¦å·¦å³ï¼Œæ„Ÿè§‰æ²¡ä»€ä¹ˆé—®é¢˜
- è¿™ç§æœºç®±æ‰“å¼€ä¾§æ¿æ¯”è£…é£Žæ‰‡æœ‰ç”¨
  - ä¾§æ¿æ²¡å¼€çš„ï¼Œå› ä¸ºå…»äº†çŒ«ï¼Œæ¯›å¤ªå¤šä¸æ•¢å¼€
  - æ•£çƒ­å™¨ä¹å·žé£Žç¥žï¼Œå…·ä½“åž‹å·å¿˜äº†ï¼Œä½ æœä¸€ä¸‹æœ‰æ•°æ˜¾çš„åº”è¯¥å¾ˆå¥½æ‰¾

- çœ‹ä½ é…ç½®ï¼Œz20çš„ç¼ºç‚¹æ˜¯ä¾§é€ä¸æ˜¯å¿«æ‹†è®¾è®¡ï¼Œç»å¸¸æƒ³æ‰“å¼€æ•£çƒ­å°±å¾ˆç—›è‹¦

- 15Ã—15 å¥½åƒå¡žä¸è¿› G300
- æ˜¯çš„ï¼Œåªèƒ½ç”¨åˆ©æ°‘750çš„ï¼Œä½†æ˜¯æ€§ä»·æ¯”ä¸å¦‚çŽ„æ­¦850 
  - æˆ‘ä¹Ÿå‡†å¤‡è£…ï¼Œæ‰“ç®—çŽ„æ­¦ 650k çš„ï¼Œç»“æžœå¤§äº† 1 åŽ˜ç±³
- å§æ§½åˆ©æ°‘pa120æ™®é€šç‰ˆ+é‘«è°·å†°å±±ç‰ˆ+z20è·Ÿæˆ‘ä¸€æ ·è¯¶
  - æ˜¯ï¼Œåˆ©æ°‘pa120mini+è¿½é£Žè€…650W

- z20å§ g300æ²¡æœ‰èƒŒéƒ¨èµ°çº¿æ„Ÿè§‰å¤ªéš¾è£…äº† è™½ç„¶è¿™ä¸ªæœºç®±ä¹Ÿå¾ˆéš¾è£…

- é£Žå†·g300ï¼Œæ°´å†·z20
  - z20æ¯”g300å¤§ä¸€ç‚¹ï¼Œæˆ‘ç”¨çš„é£Žå†·ï¼Œæ¯”è¾ƒåå‘äºŽg300å¡žæ»¡çš„æ„Ÿè§‰ï¼Œå¦‚æžœç”¨240æ°´çš„è¯z20æ¯”è¾ƒå¥½çœ‹

- æˆ‘çŽ°åœ¨è§‰å¾—æ— è„‘g300 é—ªé³žçš„meshæ¿å®žåœ¨å¤ªå¥½çœ‹äº† è€Œä¸”ä½“ç§¯å°ä¸Šé¢ä¸¤é£Žæ‰‡åŠ ä¸åŠ ä¹Ÿæ²¡é‚£ä¹ˆé‡è¦
  - æ„Ÿè§‰ä½ æ˜¯å¯¹çš„ï¼Œå…³é”®åœ¨äºŽé£Žé“ï¼Œg300ç”¨é£Žå†·çš„è¯ï¼Œä¸Šé£Žæ‰‡ä¸é‡è¦ï¼Œå…³é”®åœ¨ä¸‹é£Žæ‰‡çš„è¿›é£Žèƒ½åŠ›å’Œä¾§é¢æŽ’é£Žèƒ½åŠ›

- æˆ‘é€‰çš„g300ï¼Œä¸å–œæ¬¢çŽ»ç’ƒä¾§æ¿çš„ï¼Œå®¹æ˜“çˆ†ï¼Œè€Œä¸”æ•£çƒ­å·®

- Z20å¥½çœ‹ï¼Œè´¨æ„Ÿå¾ˆå¥½

- æˆ‘ä¹Ÿæ˜¯åœ¨è¿™ä¸¤ä¸ªä¹‹é—´çŠ¹è±«ï¼Œæˆ‘ä¹‹å‰æ·˜æ±°ä¸‹æ¥çš„æ¿Uæƒ³è£…ä¸ªå°æœºç®±å¸¦åˆ°å•ä½æ‘¸é±¼ç”¨ï¼Œå› ä¸ºç”µæºæ˜¯SFXçš„ï¼ŒG300æƒ³è£…sfxç”µæºï¼Œè¿˜è¦å¦å¤–è´­ä¹°å¥—ä»¶ï¼Œæ³¨æ„è¿™ä¸ªå¥—ä»¶æ˜¯æ°´å†·æ”¯æž¶+ç”µæºè½¬æ¢å¥—ä»¶ï¼Œæ˜¯æ†ç»‘é”€å”®çš„ï¼Œæˆ‘åˆä¸ç”¨æ°´å†·æˆ‘å¹²å˜›æŽè¿™ä¸ªé’±ï¼Œè¿™ä¸€ç‚¹è®©æˆ‘å¾ˆä¸çˆ½ï¼Œæˆ‘å°±ä¹°äº†Z20

- ## [ä¸ªäººè´­æœºï¼Œä¸»è§‚è¯„ä»·ï¼Œæ¬¢è¿Žæé—®ï¼ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/68c0238f000000001d004524?xsec_token=ABFuZAkrrSKYsMlqCenxgM1Y6uNePfwC_HGRX06HHxyp4=&xsec_source=pc_search&source=web_search_result_notes)
  - 1. åšåŠŸç”¨æ–™æœ€å¥½çš„æ˜¯ä¹”æ€ä¼¯çš„Z20ï¼Œæ¿ææœ€åŽšæœ€æœ‰è´¨æ„Ÿã€‚
  - D32PRDä¸ŽCH260å°ºå¯¸éƒ½éžå¸¸æŽ¥è¿‘ã€‚
  - D32PROçš„ç†çº¿å¸ƒå±€ç»å¯¹æ˜¯è¿™å››å°å°æœºç®±ä¸­æœ€åˆç†çš„ï¼Œè¿™ä¸€ä¸ªç”µæºæŒ¡æ¿å¯ä»¥æŒ¡å¾ˆå¤šçº¿ã€‚èµ°çº¿ä¹Ÿä¼šæ›´è½»æœºã€‚æˆ‘ä¸ªäººè®¤ä¸ºæœ€éš¾çš„æ˜¯CH160plusï¼Œå‰é¢æ²¡æŒ¡æ¿. åŽé¢ä¹Ÿæ²’æœ‰ï¼Œèµ°çº¿å…¨æš´éœ²ã€‚
  - CH260å’ŒCH160plusæ˜¯ä¸èƒ½è£…åº•éƒ¨é£Žæ‰‡çš„ã€‚

- å…­å°é‡ŒZ20æ˜¯æœ€åŽšçš„ï¼Œæœ‰äº›æ¯”ä»–å¤§çš„è¿˜æ²¡å®ƒé‡å‘¢ã€‚é—·ä¸è‡³äºŽï¼Œå¯ä»¥åº•è¿›ä¸Šå‡ºã€‚å‰é¢æ¿æœ‰ç©ºæ´žçš„ï¼Œç•™ç»™ç”µæºæ•£çƒ­çš„ã€‚
- ä¸€èˆ¬éƒ½æ˜¯åŽé¢éƒ½æ˜¯å‡ºé£Žçš„ï¼Œå‡ºçš„å¤šè¿›çš„å°‘ï¼Œå°±ä¼šé€ æˆè´ŸåŽ‹ï¼Œæœºç®±å†…å°±ä¼šè‡ªå·±å¸è¿›ç©ºæ°”

- ä¾§æ¿é‡‘å±žæ¿æ˜¯ä¸æ˜¯å¥½ç‚¹
  - æ˜¯çš„

- ## ðŸ“Œ [itxæœºç®±é€‰å“ªä¸ª - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/67fa9cc6000000000b02cb14?xsec_token=ABufSAS9QghohUw1fzyX0iVNfOBOR7ae1CsQsryEQvDrQ=&xsec_source=pc_search&source=web_note_detail_r10)
  - ç›®å‰å¸‚é¢ä¸Šçš„é—ªé³žL300/400ï¼Œé…·å†·ncoreï¼Œä¹å·žé£Žç¥žch170/270ç­‰éƒ½çœ‹è¿‡äº†ï¼Œæ„Ÿè§‰ä¸æ˜¯é¢œå€¼ä¸å¤Ÿå°±æ˜¯ä½“ç§¯å¤ªå¤§ï¼Œå…¶ä»–çš„itxåªèƒ½æ¨ªæ”¾ï¼Œæ‰€ä»¥é€‰äº†è¿™ä¸¤ä¸ªè¿›å†³èµ›åœˆã€‚
  - ä½†è¿™ä¸¤ä½hyte revolt3çš„å¯çŽ©æ€§æ›´é«˜ï¼Œå¯ä»¥è£…240æ°´å†·ï¼Œé£Žå†·ä¹Ÿæœ‰140mmå……è¶³çš„å°åŒå¡”æˆ–è€…ä¸‹åŽ‹æ•£çƒ­ç©ºé—´ï¼Œä½†ä½“ç§¯å°±æ¯”fdt1å¤§äº†3Lè€Œä¸”é¢œå€¼è‚¯å®šè¿˜æ˜¯formdå¥½çœ‹
  - formd t1 v2.5ä»·æ ¼ç›¸å¯¹é«˜ï¼Œä½†æ˜¯ä½“ç§¯å°ï¼ŒæŠ•å½±é¢ç§¯ä¹Ÿå°ï¼Œé¢œå€¼é«˜ã€‚ç›¸å¯¹æ•£çƒ­èƒ½é€‰å¾ˆè–„çš„ä¸‹åŽ‹é£Žå†·ï¼Œ240å†·æŽ’å€’æ˜¯ä¹Ÿèƒ½å®‰ï¼Œçƒ¦æ¼æ˜¯æˆ‘è§‰å¾—cpuæ•£çƒ­ä¼šæœ‰é£Žåˆ‡å£°ï¼Œè€Œä¸”98x3dçš„åŠŸè€—ä¹Ÿä¸ä½Žã€‚

- [ä¾¿æºä¸»æœºå°æœºç®±æŽ¨èï¼å¸¦é…ç½®æŽ¨è - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/67ccf00b000000000603b048?xsec_token=ABb9QlEEv4edez8zXqcCpR1c6L8yELfSKA3oNbbrletUs=&xsec_source=pc_search&source=web_search_result_notes)
  - åŽé¢é™„å¸¦ä¸¤å¥—æ€§èƒ½éžå¸¸ä¸é”™çš„é…ç½®æ–¹æ¡ˆã€‚
  - å°ä¸»æœºçš„å®‰è£…éš¾åº¦ä¼šæ¯”è¾ƒå¤§ï¼Œç´§å‡‘çš„æœºç®±ç©ºé—´å¯¹äºŽé…ä»¶çš„å®‰è£…é¡ºåºä»¥åŠç†çº¿éƒ½æ˜¯æ¯”è¾ƒè®²ç©¶çš„ï¼Œæœ‰æ—¶å€™å¯èƒ½å®‰è£…é¡ºåºé”™äº†å°±å¾—æ‹†å¼€é‡æ¥ï¼Œä¼šæœ‰ä¸€å®šçš„æŠ˜è…¾å±žæ€§ï¼Œæ— è®ºæ–°æ‰‹è¿˜æ˜¯æœ‰ç»éªŒè€æ‰‹éƒ½è¦åšå¥½å¿ƒç†å‡†å¤‡

- [cpuæ•£çƒ­æ­é… ä¸€çœ‹å°±ä¼š - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/68bd273b000000001c006781?xsec_token=AB3IlccEHpLqWO68RcyJXC3wJqTzyJEBj3EjpFo1z1Bhg=&xsec_source=pc_search&source=web_note_detail_r10)
  - åªè¦ä¸è¶…é¢‘ åŽŸè£…æœºå¤Ÿç”¨

- [formd t1 itxé£Žå†·é…ç½®åˆ†äº«+ç»éªŒ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/66d53972000000001f03a988?xsec_token=AB36raZON7rhJOGKgOTp2CP7HXu79wn9eyAjSxKYmydXE=&xsec_source=pc_search&source=web_note_detail_r10)
  - cpu+æ˜¾å¡ï¼š12600kf+4070så…¬ç‰ˆï¼ˆt1å¯2.25æ§½ï¼Œæ•£çƒ­é™é«˜68ï¼‰ï¼ˆcpuæ€•åŽ‹å¼¯å¯ä»¥ä¹°ä¸ªæ‰£å…·ï¼‰
  - é£Žæ‰‡ï¼šcpuæ˜¯æ•£çƒ­åŽŸè£…ï¼Œæœºç®±æ˜¯2ä¸ªT30ï¼Œå°æœºç®±å§çƒ­é‡æŽ’é™¤æ‰æ˜¯å…³é”®ï¼Œå«Œåµå¯ä»¥æ¢çŒ«æ‰‡ï¼Ÿä¹Ÿå¯ä»¥ç”¨fan controlï¼ˆå¼€æºçš„ï¼‰è‡ªå·±ç²¾ç¡®è®¾å®šè½¬é€Ÿæ›²çº¿ã€‚

- [æžè‡´itxé£Žå†·ä¸»æœºï¼ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/680779ab000000001c01d6ea?xsec_token=AB4Cx2A5MWHbcyCyxcg0yIjXwSumOkgsgXOeULyDbKBQE=&xsec_source=pc_search&source=web_note_detail_r10)
  - ncase m2
  - 9950x3dâž•5080å…¬ç‰ˆ
  - è¿™æ˜¯å•¥ç®±å­ï¼Ÿå…­é¢å…¨é€å•Šï¼Œä¸é”™ä¸é”™ï¼Œå…¶å®žä¸‹é¢çš„é£Žæ‰‡ä¸ªäººè§‰å¾—æ²¡å•¥å¤ªå¤§å¿…è¦åŠ ï¼Œä¸‹é¢åŸºæœ¬è´´åœ°äº†
  - å…­é¢å…¨é€ï¼Œæœ€å¥½çš„æ˜¯åŽç¡•AP201å†°ç«‹æ–¹æœºç®±ã€‚
  - é£Žæ‰‡å¹²äº†å°ä¸¤åƒ

- [åä»£CPUï¼Œé»‘è‹¹æžœæœ€åŽçš„å€”å¼º - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/65499801000000002202c90b?xsec_token=AB-kwWy_ndn0QOUFCU234Q6f2t_yjutR9JJFSe8XxQYy4=&xsec_source=pc_search&source=web_search_result_notes)
  - æœºæ¢°å¤§å¸ˆc28: 342*185*284mm, 18L ðŸ“Œ
  - è¿™ä¸ªæœºç®±ä¸é”™å•Šï¼Œè¿›3å‡º3ï¼Œå¤–åŠ å¡”å¼ï¼Œå…¶å®žå¡”å¼åŽé¢è¿˜èƒ½æ”¾ä¸ªé£Žæ‰‡ç»„æˆ9é£Žæ‰‡ï¼Œèµ·ç æ•£çƒ­ä¸ç”¨æ„
  - åªæ˜¯åœ¨itxé‡Œæ•£çƒ­è¿˜ä¸é”™è€Œå·²ï¼Œè·Ÿå¡”å¼æ²¡å¾—æ¯”ã€‚é£Žæ‰‡å¤šå™ªéŸ³ä¹Ÿå¤§ï¼Œå°æœºç®±ç†çº¿ä¹Ÿéš¾ï¼ˆè¿™æœºç®±è£…æœºåŠå°æ—¶ç†çº¿3å°æ—¶ï¼‰ï¼Œä¸€åˆ‡éƒ½æ˜¯ä¸ºäº†é¢œå€¼çš„å¦¥å
  - è¿™ä¸ªæ­£å¥½ï¼Œæ¯”å¾ˆå¤šå¤§é—·ç½å¥½çœ‹å¤šäº†ï¼Œè¿™ä¸ªæ•£çƒ­ä¸å·®ï¼Œä½ åœ¨ç»™æ•£çƒ­å™¨åŠ ä¸ªé£Žæ‰‡åŒå¡”ä¸‰é£Žæ‰‡ï¼Œå…¼é¡¾ç¾Žè§‚å’Œæ•£çƒ­ï¼ŒæŒºå¥½çš„ï¼Œæˆ‘çŽ°åœ¨æœºç®±å°±æ˜¯9ä¸ªé£Žæ‰‡çš„matx, é…·å†·è‡³å°Š MCB-Q500L-KANN-S00 : 386 x 230 x 381mm, 33L, ä¹Ÿå°±æ‰“æ¸¸æˆæ•£çƒ­è¿˜è¡Œï¼Œtopazè¯¥èžºæ—‹æ¡¨è¿˜æ˜¯èžºæ—‹æ¡¨ï¼Œè¿˜æ˜¯å¾—å¼€ä¾§æ¿

- [9950Xç”¨é£Žå†·å®žé™…ä½“éªŒ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/68415da50000000022005234?xsec_token=ABni7f4b-fffCPxt0H6aLouKtK6gxBT1LF2_CCDAkgMZo=&xsec_source=pc_search&source=web_search_result_notes)
  - å¯¹å¤§å¤šæ•°äººæ¥è¯´éƒ½çœ‹ä¸å¤§å‡ºæ¥ï¼Œæˆ–è€…åƒæˆ‘è¿™ç§ä¸æ€Žä¹ˆçŽ©FPSçš„ï¼Œå°±ä¸ç”¨è€ƒè™‘è¶…é¢‘è¿™äº›äº†ï¼Œé»˜é¢‘å®Œå…¨å¤Ÿç”¨
  - æˆ‘æ„Ÿè§‰æ›´é‡è¦çš„æ˜¯é…ä¸€ä¸ªé£Žé“æœºç®±(æˆ‘ç”¨çš„æ˜¯è”åŠ›207)ï¼Œç„¶åŽä¸Šä¸ªåŒå¡”åº”è¯¥å°±å¤Ÿç”¨äº†(å•å¡”é‡Œä¹Ÿæœ‰Hyper 612 Apexè¿™æ ·çš„é«˜æ‰‹åœ¨)ï¼Œæˆ‘ç”¨çš„æ˜¯160+æ·˜æ¥çš„äºŒæ‰‹åˆ©æ°‘PS120EVOï¼Œä¸ƒçƒ­ç®¡åŒå¡”ï¼Œç”šè‡³è¿˜æœ‰ç‚¹æ­ªæ­ªçš„ï¼Œä¸è¿‡100+ä¹°æ¥çš„ä¾¿å®œè´§æˆ‘ä¹Ÿå°±éšä¾¿äº†ï¼Œèƒ½ç”¨å°±è¡Œ

- [å°æœºç®±ç»é…ï¼ŒåŒå¡”é€†é‡åŠ›çƒ­ç®¡ï¼Œåˆ©æ°‘å°é“¶é­‚ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/6389ca410000000022028074?xsec_token=ABFaT5DIfPsJIcxbjZdwSLk05zjfIEy_AtMNX-25fkBN0=&xsec_source=pc_search&source=web_search_result_notes)
  - æœºç®±æ˜¯æœºæ¢°å¤§å¸ˆC26 plusï¼Œæ°´å†·å…¼å®¹æ€§æžå·®ï¼Œé£Žå†·ä¹Ÿé™åˆ¶åœ¨140mmä»¥å†…ï¼Œçœ‹æ¥çœ‹åŽ»è¿˜æ˜¯åˆ©æ°‘è¿™æ¬¾å°é“¶é­‚æœ€åˆé€‚ï¼Œé¡ºæ‰‹å…¥äº†ä¸ªç™½è‰²çš„
  - æ•£çƒ­å™¨å°ºå¯¸ä¸º120 X 135 X 94ï¼ˆmmï¼‰ï¼Œè¿·ä½ åŒå¡”ï¼Œç™½è‰²æ¶‚è£…ï¼Œæ­é… TL-D12PRO-G ä¼ºæœçº§é£Žæ‰‡ï¼Œä¸ç®¡æ˜¯æ€§èƒ½è¿˜æ˜¯å°ºå¯¸éƒ½å¾ˆæ»¡è¶³æˆ‘è¿™å¥—ä¸»æœºçš„æ•£çƒ­éœ€æ±‚

- [ç”µè„‘å°æœºç®±è¯¥æ€Žä¹ˆé€‰ï¼Ÿ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/66518b9a0000000005007b1f?xsec_token=ABgsZawth9QaYeqFGFhvroUrQnp2-uJiFwrxEDnmydBiE=&xsec_source=pc_search&source=web_search_result_notes)
- ä¹”æ€ä¼¯(JONSBO) Z20ï¼Œ ä¸»ä½“å°ºå¯¸é•¿å®½é«˜ 370*186*295 çº¦20L, 
  - æ”¯æŒ240æ°´å†· 163mmåŒå¡”é£Žå†·
  - æ”¯æŒé™é•¿363mmé«˜æ€§èƒ½æ˜¾å¡&å…¨å°ºå¯¸MATXä¸»æ¿
  - æ”¯æŒèƒŒèµ°çº¿ ç”µæºæ”¯æŒATXç”µæºä¾§è£… ç«–è£…
- åŽç¡•AP 201, ä¸»ä½“å°ºå¯¸é•¿å®½é«˜460*205*350, 33L
  - æ”¯æŒ360æ°´å†· 17cmé£Žå†·
  - æ˜¾å¡æ”¯æŒ358mm 6é¢é€šé£Ž 4ä¸ªç¡¬ç›˜ä½

- ## ðŸ¤”ðŸ’¡ [æœ‰æ²¡æœ‰é€‚é…è¾ƒå°æœºç®±çš„é«˜æ€§èƒ½é£Žå†·æŽ¨èï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/491647469)
- å¦‚æžœæ˜¯å°ä¸»æœº å¯ä»¥è€ƒè™‘ä¸‹åŽ‹å¼çš„é£Žå†·
  - ä¸‹åŽ‹å¼6ç®¡ï¼Œ åŒé£Žæ‰‡ è¿˜æœ‰RGBå¯ä»¥é€‰ å¯ä»¥è¯´æ˜¯DIYçŽ©å®¶å¾ˆåˆé€‚äº†ã€‚
- ä¸¤ç§ç±»åž‹ ä¸€ç§å¯ä»¥éšæ„ä¼¸ç¼© ä¸€ç§æ˜¯PCIEçš„ä¾§å¹ å¯ä»¥å¹ ç»„é£Žé“ã€‚

- ðŸ¤” ä¸Žå…¶è‡ªå·±ç ”ç©¶é£Žå†·æ°´å†·é£Žé“ï¼Œå¦‚ä½•ç›´æŽ¥å‚è€ƒæŒ‡å®šcpu/gpuçš„æœºç®±æ¡ˆä¾‹

- [é—ªé³žg300ï¼Œç»ˆäºŽå®Œå…¨ä½“ï¼Œæžœç„¶ç«–ç€æ‰æ˜¯æœ€å¥½çœ‹çš„  ](https://www.xiaohongshu.com/explore/68baad38000000001d028c54?xsec_token=ABltSBPxJJg2hpuRLt4eQMLjBIAoL5YNYMLjtqKfRi9_Q=&xsec_source=pc_search&source=web_search_result_notes)
  - ä¸»æ¿ï¼šç²¾ç²¤B760M-KD4 wifi 
  - å¤„ç†å™¨ï¼š12490F 
  - æ˜¾å¡ï¼šå½±é©°4060å¤§å°†ç™½è‰² 
  - ç¡¬ç›˜ï¼šçˆ±å›½è€…P7000Z 1TB 
  - å†…å­˜ï¼šé‡‘ç™¾è¾¾é“¶çˆµDDR4 3600 
  - é£Žå†·ï¼šåˆ©æ°‘PA140WHITE+2ä¸ªé£Žæ‰‡TL-M12RW+2ä¸ªæ˜¾å¡æ”¯æž¶ 
  - å†…å­˜é£Žæ‰‡ï¼šä¹”æ€ä¼¯NF-1 
  - ç”µæºï¼šçŽ„æ­¦650Kç™½è‰² 
  - æœºç®±é£Žæ‰‡ï¼šåº•éƒ¨1ä¸ª15mmåŽšåº¦è–„æ‰‡åˆ©æ°‘TL-H12015W-S, æ˜¾å¡å³è¾¹9cmé«˜åº¦3ä¸ªå°é£Žæ‰‡åˆ©æ°‘TL-P9W-S
- æ˜¾å¡ä¸Šè¾¹å°é£Žæ‰‡å’‹å›ºå®šçš„å‘¢ï¼Ÿæˆ‘G350ä¹Ÿæƒ³æžä¸ªå¹æ˜¾å¡
  - æ‰Žå¸¦ç»‘å°±å¥½äº†ï¼Œä½†æˆ‘è¿™ä¸ªæ˜¯å¸é£Žï¼ŒæŠŠé£Žä»Žé¡¶é¢æŽ’å‡ºåŽ»

- [å¯ä»¥å¸¦ä¸Šé£žæœºçš„é£Žå†·å°é’¢ç‚®ï¼Œ5070tié…ç½®åˆ†äº« - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/6809bcaf000000001c02e3f2?xsec_token=ABmERV5M2HyK5KDotkEXLkb7DeMGpfr5ndFUkECpUJvJQ=&xsec_source=pc_search&source=web_explore_feed)
  - ã€æœºç®±ã€‘é—ªé³ž G300 é»‘è‰²: 188 x 345 x 260 mm, 16.8L ðŸ“Œ
  - ã€æ•£çƒ­ã€‘åˆ©æ°‘ PA140ç»åŒåˆºå®¢ 6çƒ­ç®¡åŒå¡”
  - ã€æ˜¾å¡ã€‘å½±é©° RTX5070Ti é‡‘å±žå¤§å¸ˆé»‘é‡‘ç‰ˆ O16G
  - å…³æ³¨äº†å¾ˆä¹…çš„é£Žå†·ä¸»æœºï¼Œåšä¸»æ­é…çš„é…ç½®åˆç†ï¼Œè¿™ä¸€å¥—åŸºæœ¬ä¹Ÿèƒ½æ»¡è¶³2ké«˜ç”»è´¨æ¸¸æˆéœ€æ±‚äº†ï¼Œè¿˜å¯ä»¥æŠŠä¸»æ¿æ˜¾å¡ç›’éƒ½å¯„æ¥äº†ï¼Œéžå¸¸æ»¡æ„

- [ã€æžé±¼ç”µè„‘ã€‘5Ké¢„ç®—, æ‹¿ä¸‹RTX4060+i5 12400F - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/6707ad20000000001b023290?xsec_token=ABq7KokyP4l816ahZYziBBvJYC4Qak58_fLCWW_pIxj94=&xsec_source=pc_search&source=web_search_result_notes)
  - ã€æœºç®±ã€‘ï¼šé—ªé³ž G300 ç™½è‰²
  - ã€æ•£çƒ­ã€‘ï¼šä¹”æ€ä¼¯ CR1000EVO ARGB ç™½è‰²
  - ã€æ˜¾å¡ã€‘ï¼šå½±é©° RTX4060 8G å¤§å°†
  - ã€CPUã€‘ï¼šIntel i5 12400F

- [å¯ä»¥æ‰‹æä¸Šé£žæœºçš„5070tiè¿·ä½ ä¸»æœº - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/68148ed3000000002202ac13?xsec_token=AB-Uvho_Y0GpiJDp6zmaglVYdYNGTBg3XQwcDpwK8pUMA=&xsec_source=pc_user)
  - ã€æœºç®±ã€‘é—ªé³ž G300 æ‰‹ææ¡Œé¢å°æœºç®±
  - ã€æ•£çƒ­ã€‘ä¹å·žé£Žç¥ž é˜¿è¨è¾›4S é«˜ç«¯é£Žå†·
  - ã€æ˜¾å¡ã€‘å½±é©° RTX5070Ti é‡‘å±žå¤§å¸ˆ é»‘é‡‘OC 16G

- [æœ‰æ²¡æœ‰åŒå¡”é£Žå†·æ•£çƒ­å™¨é€‚ç”¨äºŽè¿«å‡»ç‚®ä¸»æ¿ä¸åŽ‹å†…å­˜ï¼Œèƒ½åŽ‹ä½9600Xçš„ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/67f87bc0000000001c001bd9?xsec_token=ABLUYzRFk1yrCyyZARJhGbzYFAAIgFouS3rVw01NAec2U=&xsec_source=pc_search&source=web_note_detail_r10)
  - ä½ ä¸è¶…é¢‘çš„è¯ï¼Œå•å¡”éƒ½è¡Œ
  - å¯ä»¥å•å¡”+å¼€ä¾§æ¿+ç”µé£Žæ‰‡
- æˆ‘å‡†å¤‡ä¸Šcmaxï¼Œæˆ‘çœ‹ä½ ç”µæºä¸‹é¢è£…äº†ä¸€ä¸ªè¿›æ°”å—ï¼Ÿ
  - CMAXå¯ä»¥çš„ï¼Œæ˜¾å¡é€‰æ‹©æ›´å¤šï¼Œå‰é¢æ¿æ˜¯ä¸ª9cmé£Žæ‰‡ï¼Œå‰ä¸‹è¿›é£Žï¼ŒåŽä¸Šå‡ºé£Ž
- åˆ©æ°‘rk120se
  - ä½ è¿™ä¸ªæ•£çƒ­åŽ‹çš„æ˜¯å•¥uå•Šï¼Œè¿™ä¸ªå’Œé…·å†·è‡³å°Š612åœ¨çº ç»“ã€‚ã€‚
  - C28ï¼ŒåŽ‹çš„9700xï¼Œè¿™ä¸ªå’Œé…·å†·ä¹Ÿä¸æ˜¯ä¸€ä¸ªä»·ä½çš„å•Šï¼Œåˆ©æ°‘è¿™ä¸ªè‚¯å®šå¤Ÿç”¨

- åˆ©æ°‘æœ‰ä¸€æ¬¾ï¼ŒçŽ°åœ¨æ­£åœ¨ç”¨, åŒå¡”ï¼Œ6çƒ­ç®¡ï¼Œä¸æŒ¡å†…å­˜
- æˆ‘ç”¨çš„åˆ©æ°‘pa120 b650ä¸»æ¿ä¸åŽ‹å†…å­˜, åŒå¡”å°±è¡Œ å¼€pboçƒ¤é¸¡145w æ¸©åº¦æœ€é«˜92
  - æˆ‘çš„b650eå¤©é€‰ç”¨ä¸äº†åŒå¡”ï¼Œå·¦è¾¹ä¸€å—é“å³è¾¹æ˜¯å†…å­˜ï¼Œä½†æ˜¯è£…çš„æ—¶å€™æ²¡è¯•è¿‡æŠ¬é«˜
- åˆ©æ°‘FC140
- åˆ©æ°‘RK120
- å•å¡”åŒæ‰‡å…­çƒ­ç®¡å°±è¶³å¤Ÿï¼Œåˆ©æ°‘åˆ¶è£ï¼Œæˆ‘å°±åœ¨ç”¨ï¼Œæ•£çƒ­ç›¸å½“ç»™åŠ›
- æˆ‘9700Xç”¨çš„åˆ©æ°‘PA120SEï¼Œç›®å‰æ¸©åº¦æ­£å¸¸
- æˆ‘9700Xéƒ½åªç”¨åˆ©æ°‘X53ä¸‹åŽ‹ï¼Œæ²¡é‚£ä¹ˆç„¦è™‘

- é‚£äº›è¯´å››çƒ­ç®¡å°±éšä¾¿åŽ‹çš„æ˜¯çœŸæ²¡å®žé™…ç”¨è¿‡9ç³»èŠ¯ç‰‡ï¼Œå°±å•è¯´9600Xï¼Œç¿é¢‘5.4çš„èŠ¯ç‰‡ï¼Œç”¨4çƒ­ç®¡æ•£çƒ­å™¨åªèƒ½è®©CPUè·‘åˆ°4.6èµ«å…¹ï¼Œå»ºè®®ä¸ŠåŒå¡”é£Žå†·æˆ–è€…240åŠä»¥ä¸Šæ°´å†·

- å•å¡”612apexè¶³çŸ£å®Œå…¨ä¸æ¡£

- [9950x3då¯¹itxæœºç®±å¤ªå‹å¥½äº†ï¼Œæ—¢å®‰é™åˆé«˜æ•ˆï¼Œå¾…æœº42åº¦ï¼ŒçŽ©æ¸¸æˆ60å¤šåº¦è¿˜é™éŸ³ï¼ŒåŒçƒ¤180w+450w ](https://www.xiaohongshu.com/explore/67ede5d3000000001202edf1?xsec_token=ABTemFrBXmKvmdgQwWJU9gnNkp5wlW6bL0Dk9uWTiJWBE=&xsec_source=pc_search&source=web_search_result_notes)
  - é…ç½®æ˜¯9950x3d+4090+åˆ©æ°‘120x67ä¸‹åŽ‹å¼é£Žæ‰‡ï¼Œ
  - åˆ©æ°‘120x67 å’Œ12015é£Žæ‰‡ï¼Œé¡¶éƒ¨ä¸€ä¸ª12025ä¸€ä¸ª12015
  - ä¸‹ä¸€æ­¥å‡†å¤‡æŠŠ4090æ¢æˆ5090d
  - æˆ‘åˆ©æ°‘90x47 åŽ‹98x3d çŽ©ä¸ªæ¸¸æˆè½»æ¾80åº¦ï¼Œæ—©çŸ¥é“ä¸ä¸Šé‚£ä¹ˆæžé™çš„itxäº†ï¼Œæƒ³é—®é—®åšä¸»ä½ çš„æœºç®±ä¾¿æºæ€§å¦‚ä½•ï¼Œä¸Šé£žæœºæ–¹ä¾¿å—ï¼Œé¡ºä¾¿æƒ³é—®é—®å…¶ä»–äººçš„
  - è¿™å°±æ˜¯æˆ‘ä»¬ itx çŽ©å®¶ï¼Œç›¯ç€ä¸ç‰ˆä¹°å“ˆå“ˆ
  - æˆ‘ç”¨æ¥ç”Ÿäº§åŠ›çš„è™½ç„¶ä¸æ˜¯æ¯æ—¶æ¯åˆ†éƒ½åœ¨è·‘ä»»åŠ¡
    - é‚£å»ºè®®ä¸Šä¸ªå¥½ç‚¹çš„æ°´å†·æˆ–è€…åŒå¡”é£Žå†·

- [é—²ç½®é…ä»¶é‡ç»„ï¼Œå°æœºç®±é‡Œå¡žä¸€å¼ 4090 - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/679000e6000000002900d92c?xsec_token=ABMD6mhQ-2BymdWDpwL5hvfM8OOubZz_p0mUadq6O7lw8=&xsec_source=pc_search&source=web_search_result_notes)
  - C+MAXçš„ç®±å­ï¼Œç™½çŒ›ç¦½4090 oc
  - æœºæ¢°å¤§å¸ˆC34pro: è¿™éƒ½å¿«ä¸­å¡”äº†ï¼Œæœ‰äº›å¤§äº†

- [æ‰“é€ æœ€å¼ºITXä¸»æœºï¼Œä»…12Lçš„I9+RTX4090å°é’¢ç‚® - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/65a92ab2000000002a033278?xsec_token=ABSBEXLTFElYGee4WjQ7FQrmAnS3M78y8zG87vi2iVIac=&xsec_source=pc_search&source=web_search_result_notes)
  - åˆ†å½¢å·¥è‰ºRidge

- [èƒ½è£…4090çš„10Lè¶…è¿·ä½ é¡¶é… itxä¸»æœºï¼ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/66feab5b000000001902e426?xsec_token=ABlu4J6--wKooejNGxnEt8DN6ozr-DSEM4a2kEPukXYkI=&xsec_source=pc_search&source=web_search_result_notes)
  - èƒ½åœ¨è¿™ä¹ˆå°çš„ä½“ç§¯è£…ä¸‹9950xâž•4090ï¼Œä¼°è®¡åªæœ‰ è”åŠ› T1 äº†ã€‚

- [æ•´ä¸ªä¸–ç•Œéƒ½å®‰é™äº†ï¼Œè£…å…¥5080æ˜¾å¡çš„é£Žå†·ä¸»æœº - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/67d78dda000000000d017cfa?xsec_token=ABlo-M2mkEksa4R6fDVfvdseBp4z5h5kgTVaUZl9pOpYg=&xsec_source=pc_search&source=unknown)
  - åˆ†åž‹å·¥è‰º Torrent Nano å¯ä»¥è¯´æ˜¯æœ€å¼ºé£Žå†·ITXæœºç®±ï¼Œå¡žå…¥æ——èˆ°CPUå’Œ5080/5090Dæ˜¾å¡æ²¡æœ‰é—®é¢˜ï¼Œç¡¬ä»¶é€‰æ‹©å’Œèµ°çº¿æ–¹æ¡ˆç»è¿‡å¤šæ¬¡è¿­ä»£è¶‹è¿‘å®Œç¾Ž
  - CPUï¼šAMD é”é¾™ 7 9800X3D
  - æ˜¾å¡ï¼šå½±é©° GeForce RTX 5080 é‡‘å±žå¤§å¸ˆç™½é‡‘ç‰ˆ OC
  - æœºç®±ï¼šåˆ†å½¢å·¥è‰º Torrent Nano RGB ç™½è‰², ä½“ç§¯å¤ªå¤§

- [é«˜é¢œå€¼135mmå°å¡”ï¼Œåˆ©æ°‘PA120 MINIå¼€ç®±å®‰è£…ï¼_å“”å“©å“”å“©\_bilibili](https://www.bilibili.com/video/BV1DH4y177Q2/?vd_source=deff4d2e2efa3273948dd6911a08fd39)
  - å¡”ä½“ï¼Œæ€»é«˜åº¦135mm

- ðŸ’¡ðŸŒ¹ [é™¤äº†éš¾è£…ï¼Œä»€ä¹ˆéƒ½æŒºå¥½ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/683a78d60000000023012638?xsec_token=AB_w2cD0Ez3Uraiu24sIOdVCNVjGP6ywl00WVNctWCHeY=&xsec_source=pc_search&source=unknown)
  - å¦‚æžœéœ€æ±‚çš„æ ‡ç­¾è¦æ»¡è¶³å¤§æ˜¾å¡ã€MATXã€æ ‡è§„ç”µæºã€åŒå¡”é£Žå†·ã€ç´§å‡‘ï¼Œé—ªé³žG350æ˜¯ä¸é”™çš„é€‰æ‹©ã€‚
  - G350: 21 x 34 x 28 cm, 20L ðŸ“Œ
  - åº•éƒ¨é£Žæ‰‡æ˜¯ åˆ©æ°‘TL-C12PRO, å£°éŸ³è¿˜èƒ½æŽ¥å—
  - å¦‚æžœæƒ³ç”¨16cmç”µæºæ¥æ»¡è¶³è¿›é£Žé£Žæ‰‡åœ¨å‰é¢æ¿å·¦å³å±…ä¸­ä½ç½®ï¼ˆå¼ºè¿«ç—‡ï¼‰ã€åº•éƒ¨åŒè¿›é£Žæ‰‡ï¼Œæ³¨æ„ä¾›ç”µçº¿ã€é¢æ¿çº¿éƒ½è¦é¢„åŸ‹åˆ°ä¸»æ¿ä¸‹æ–¹
  - ROG B850å°å¹é›ªã€ä¹å·žé£Žç¥žé˜¿è¨è¾›4VCè‡³å°Šç‰ˆæ–°å“é›†åˆé¦–ç§€ï¼Œå…¨ç™½è¾¾æˆã€‚
  - 98x3dï¼ŒRog b850-gï¼Œ32g 8000é˜¿æ–¯åŠ ç‰¹ï¼ŒRog ç™½é‡‘é›·é¹°1000wï¼Œé˜¿è¨è¾›4vcè‡³å°Šç‰ˆã€‚
  - æ˜¾å¡å’Œå›ºæ€æ²¡å‚è€ƒä»·å€¼ï¼Œ5æŠŠæœºç®±é£Žæ‰‡çœ‹ä¸ªäººå–œå¥½
  - è¿™æœºç®±è‡ªå¸¦æ˜¾å¡æ”¯æž¶
- ä½ è¯´g350çš„æ—¶å€™å¿˜äº†å®ƒæœ€å¤§çš„ç‰¹ç‚¹ï¼ŒèƒŒæ’
  - æ— è®ºå¸‚åœºå æ¯”è¿˜æ˜¯ç”¨æˆ·æŽ¥å—ç¨‹åº¦ï¼ŒèƒŒæ’è¿™ä¸ªç‚¹ä¸ªäººå®žåœ¨æ˜¯ä¸å¤ªå…³å¿ƒã€‚ã€‚ä½•å†µamdå¹³å°çš„ä¸€çº¿èƒŒæ’ç‰ˆå¥½åƒæ˜¯ä¸€ä¸ªæ‰‹æ•°çš„å‡ºæ¥
- G300é¡¶éƒ¨é£Žæ‰‡ä½éƒ½æ²¡æœ‰ï¼Œå’Œè¿™ä¸ªæ¯”ï¼ŸåŠ å®½çš„éƒ¨åˆ†åœ¨æˆ‘çœ¼é‡Œä»·å€¼å°±èƒ½ç”¨å¤§ç”µæºå’Œå¥½ç†çº¿ï¼Œè€Œä¸æ˜¯æ ¹æœ¬æ²¡å‡ ä¸ªåž‹å·å¯ä»¥é€‰è€Œä¸”æ®‹å€¼ç‚¸è£‚çš„èƒŒæ’é…ä»¶ã€‚èƒŒæ’äº§å“çš„é”€é‡èƒ½ä¸èƒ½è®©è¿™ä¸ªæ–¹æ¡ˆæ’‘è¿‡é˜µç—›æœŸéƒ½æ˜¯é—®é¢˜

- 800å¤šçš„é£Žå†· ç–¯äº†å—
  - ä¸ºé¢œå€¼ä¹°å•

- æˆ‘ä¹°çš„620ï¼Œæ„Ÿè§‰åˆ°æ—¶å€™ä¹ŸæŠŠä¸»æ¿é®ä½äº†
  - å—¯å‰è£…æŒ¡å†…å­˜åŽè£…æŒ¡ä¸»æ¿

- æˆ‘è£…å®Œäº†ï¼Œä½†æ˜¯çŽ©æ¸¸æˆçš„æ—¶å€™æ‹‰æ»¡CPU80â„ƒä¸åˆ°ï¼Œgpu60å¤šâ„ƒæ­£å¸¸å—
  - å¾ˆä½Žå•Šï¼Œ75ä¸é«˜çš„

- è¿™ä¸ªtypc æŽ¥å£ä½ ä»¬çš„çº¿èƒ½å…¨æ’è¿›åŽ»å— æˆ‘çš„è‹¹æžœæ•°æ®çº¿ä¸èƒ½å®Œå…¨æ’è¿›åŽ»
  - å¯ä»¥æ’ï¼Œçº¿è·Ÿæœºå™¨æ²¡æœ‰å®Œå…¨è´´åˆ æ˜¯æœ‰ç¼éš™çš„

- ç”µæºå‰ç½®è¿˜æ˜¯ä¸é€‚åˆé£Žå†·å§ï¼Œch260/270è¦åˆé€‚ç‚¹å§
  - èƒ½ä¸æ’žå¢™é™é¢‘å°±ç®—èƒ½ç”¨ï¼ŒG350å¯¹æ ‡çš„æ˜¯ch160/170ï¼Œæ‰‹æç®±å˜›è‚¯å®šæ²¡æ³•å…­è¾¹å½¢
- ç´§å‡‘åž‹ç›´æ’æœºç®±çš„ç”µæºä¸€èˆ¬éƒ½æ˜¯è¿™ä¹ˆè£…å•Šï¼Œå‰é¢å†²ç½‘è¿›é£Ž

- è¿™ä¸ªçš„è£…æœºéš¾åº¦å¾ˆé«˜å“¦
  - ç”¨16cmç”µæºä¼šç¨æœ‰éš¾åº¦
- è¿™ä¸ªåŒå¡”é£Žå†·é€ åž‹å¾ˆå–œæ¬¢ï¼Œä¾§çœ‹é‡Œé¢å¾ˆåƒä¸€å—ä¸€å—å½•éŸ³å®¤çš„éš”éŸ³æ£‰
- æ˜¾å¡é™é•¿å¤šå°‘å•Šï¼Œæˆ‘335çš„å¡å¥½æ€•è£…ä¸è¿›åŽ»
  - 340

- ioçº¿è·Ÿåº•éƒ¨é£Žæ‰‡æ’žå¾—ä¸€è¨€éš¾å°½
  - å› ä¸ºæœºç®±å‡ºåŽ‚è®¾è®¡æ²¡ç»™è¶³å¤Ÿçš„å¼¯æŠ˜ç©ºé—´

- [åˆ©æ°‘æœ€æ–°æ€§ä»·æ¯”é£Žå†·ä¹‹çŽ‹ï¼ŸPA120åŽç»§æœ‰äººï¼Ÿ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/68a25df0000000001d008b69?xsec_token=AB6eEiv8Jga5YuqGHfqLGMKBS62nhuM7ceSyfjW0FC3fM=&xsec_source=pc_search&source=web_search_result_notes)
  - ä¸¤æ¬¾ï¼šRoyal Pretor 130Â å’Œ Royal Knight 120 ï¼ˆä¸æ˜¯SEï¼ï¼SEé£Žæ‰‡æ˜¯æ—§æ¬¾ï¼ï¼‰

- [ç›˜ç‚¹åˆ©æ°‘éšæœºåæ¬¾äº§å“ï¼Œä»Žå¤¯åˆ°æ‹‰äº”ä¸ªçº§åˆ« - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/68b86a8a000000001d037f1d?xsec_token=ABTE1Axv-5o-X12XW6KbsOFY6VCPlbEhwKmVzBccY4g40=&xsec_source=pc_search&source=web_search_result_notes)
  - U120exå•å¡”é£Žå†·
  - åŒå¡”é£Žå†·pa140ï¼ŒæŒ‘ä½“è´¨ï¼Œæ¢ä¸ªé…æ‰‡è¡¨çŽ°å°šå¯ï¼Œè¿™é‡Œç»™åˆ°äººä¸Šäºº

- ## [æµè¨€é£žèµ·çš„æ—¶ä»£ï¼Œ4090çœŸçš„å€¼å¾—å…¥æ‰‹å—ï¼Ÿ - å“”å“©å“”å“©](https://www.bilibili.com/opus/859701664964149281?from=search)
- 4090å…¶å®žåˆ†ä¸ºä¸¤ä¸ªç‰ˆæœ¬ä¸€æ¬¾æ˜¯ä¸“é—¨ç”¨äºŽæ¸¸æˆé¢†åŸŸçš„æ˜¾å¡åä¸ºé£Žæ‰‡å¡ï¼Œå¦ä¸€æ¬¾åˆ™æ˜¯ç”¨äºŽæ·±åº¦å­¦ä¹ é¢†åŸŸåä¸ºæ¶¡è½®å¡ã€‚ä¸¤è€…è™½ç„¶éƒ½æ˜¯4090å®žåˆ™å†…éƒ¨ç»“æž„ã€ç›®æ ‡äººç¾¤ã€è¿ç”¨åœºæ™¯å…¶å®žéƒ½æ˜¯ä¸åŒçš„
- é£Žæ‰‡å¡ä¸Žæ¶¡è½®å¡çš„ä¾›ç”µæŽ¥å£ä½ç½®ä¸åŒï¼Œæ¶¡è½®å¡çš„ä¾›ç”µæŽ¥å£ä½ç½®åœ¨æŽ¥å£å°¾éƒ¨ï¼Œä¾›ç”µçº¿æ¯”é£Žæ‰‡å¡çš„çº¿æ›´çŸ­ï¼Œè¿™æ ·æ˜¯æ–¹ä¾¿åœ¨æœºç®±å†…éƒ¨å®‰è£…å’Œç†çº¿ï¼Œ
  - è€Œé£Žæ‰‡å¡ä¾›ç”µæŽ¥å£ä¸€èˆ¬åœ¨æ˜¾å¡é¡¶éƒ¨ï¼ŒæŽ¥çº¿åŽçº¿ç¼†ä¼šé«˜äºŽæœºç®±æœ€é«˜é¢ï¼Œå¦‚æžœåœ¨æœåŠ¡å™¨ä¸­ä½¿ç”¨é£Žæ‰‡å¡ï¼ŒæœåŠ¡å™¨ç›–æ¿ç›–ä¸ä¸Šã€‚
- åœ¨æ•£çƒ­æ–¹å‘ä¸Šé¢ï¼Œæ¶¡è½®å¡æ•£çƒ­æ–¹å‘æ˜¯æœå°¾éƒ¨æ•£çƒ­ï¼Œå¹¶äºŽæœåŠ¡å™¨é£Žå‘æ˜¯ä¸€è‡´çš„ï¼Œ
  - è€Œé£Žæ‰‡å¡çš„æ•£çƒ­æ˜¯æœå››é¢å…«æ–¹æ¥æ•£çƒ­çš„ï¼Œå¹³å¸¸çš„PCæœºç®±æ”¾ä¸€å¼ æ˜¯å¯ä»¥é€‚åº”çš„ï¼Œä½†ç”¨ä½œæœåŠ¡å™¨ä¸Šï¼ˆå¾ˆå¤šæ—¶å€™æ˜¯å¤šå¡ï¼‰å°±ä¸é€‚åˆäº†ï¼Œå¾ˆå®¹æ˜“å› ä¸ºæ•£çƒ­ä¸å‡ºæœºç®±å¯¼è‡´æœºç®±å†…éƒ¨æ¸©åº¦è¿‡é«˜å‡ºçŽ°å®•æœºã€‚

- é£Žæ‰‡å¡çš„å°ºå¯¸ä¸€èˆ¬æ˜¯2.5-3å€å®½è®¾è®¡ï¼Œè€Œæ¶¡è½®å¡çš„å°ºå¯¸å¤§å°æ˜¯åŒå®½è®¾è®¡ï¼Œ
  - å› ä¸ºæ¶¡è½®å¡ä¸ºäº†æ–¹ä¾¿æ”¾å…¥æœåŠ¡å™¨é‡Œï¼Œæ‰€ä»¥æ¶¡è½®å¡çš„å°ºå¯¸å’Œé«˜åº¦éƒ½è¿œè¿œä½ŽäºŽé£Žæ‰‡å¡ï¼Œä»Žè€ŒæœåŠ¡å™¨å¯ä»¥æ”¯æŒ4å¡æˆ–è€…8å¡ï¼Œå¦‚æžœç”¨é£Žæ‰‡å¡ä»£æ›¿æ¶¡è½®å¡è£…åœ¨æœåŠ¡å™¨é‡Œï¼Œé‚£ä½ç½®å¤Ÿä¸å¤Ÿè¿˜æ˜¯ä¸€å›žäº‹å„¿å‘¢ã€‚

- ## [æœºç®±å°å½±å“CPUæ•£çƒ­å—ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/335865142)
- æœºç®±å°è‚¯å®šå½±å“æ•£çƒ­çš„ã€‚ä½†æ˜¯é£Žé“ä¹Ÿå¾ˆé‡è¦ï¼Œæœ‰åˆç†çš„é£Žé“ï¼Œå°±å¯ä»¥ä½¿å°æœºç®±ä¹Ÿèƒ½æœ‰ä¸é”™çš„æ•£çƒ­ã€‚
- ä»¥æˆ‘èµ„æ·±æ•£çƒ­æŽ§çš„èº«ä»½å‘Šè¯‰ä½ ï¼Œæœºç®±å¤§å°ä¸æ˜¯å…³é”®ï¼Œæ‰€è°“çš„é£Žé“ä¹Ÿä¸æ˜¯å…³é”®ï¼Œå…³é”®æ˜¯å‡ºé£Žå£ï¼Œä¼ ç»Ÿæ–¹å¼æ¥è¯´å°±æ˜¯ä¸»æ¿åŽæŒ¡æ¿ä¸Šé¢é‚£ä¸ªé£Žæ‰‡å£ã€‚
  - çŽ°åœ¨å¤§å¤šæ˜¯å•é£Žæ‰‡ä½ï¼Œä»¥å‰è¿˜æœ‰è¿‡åŒé£Žæ‰‡ä½ï¼Œè¿™ä¸ªä½ç½®ä¸€å®šè¦ä¸Šä¸€ä¸ªå¤§é£Žé‡ä¼˜è´¨é£Žæ‰‡ï¼Œè½¬é€Ÿå†é€‚å½“è°ƒé«˜ç‚¹ã€‚
  - è¿›é£Žå£ä¹Ÿä¸€å®šè¦æœ‰ï¼Œä½†æ˜¯ä¸æ•æ„Ÿï¼Œå¤§å¤šæ•°æœºç®±è¿›é£Žå£éƒ½åœ¨å‰éƒ¨ï¼Œä½ å¯ä»¥ç”¨ä½Žè½¬é€Ÿï¼Œè‡³å°‘è¦ä¿è¯ä¸€ä¸ªé£Žæ‰‡å§ï¼Œä¸¤ä¸ªæœ€å¥½ï¼Œæ²¡é£Žæ‰‡ï¼Œæˆ–è€…æ²¡æœ‰è¿›é£Žå£ä¹Ÿæ˜¯ä¸è¡Œçš„ã€‚

- é£Žé“è®¾è®¡ååˆ†é‡è¦ï¼Œå¦‚æžœä½ çš„æœºç®±å†…é£Žé“æ²¡æœ‰è®¾è®¡ï¼Œæ¯”å¦‚å°æœºç®±CPUæ•£çƒ­ç›´æŽ¥å¹åˆ°æ²¡æœ‰å­”çš„æœºç®±ä¾§æ¿æˆ–ä¸Šæ¿ä¸Šï¼Œçƒ­å…¨éƒ½é”åœ¨é‡Œé¢ï¼Œé‚£ä¹ˆè‡ªç„¶å¾…æœº50æ¥åº¦ã€‚
  - å¯¹äºŽä¸Šé¢æ— è„‘ä¸Šæ°´å†·çš„ï¼Œæˆ‘åªæƒ³è¯´ï¼Œæœ¬æ¥æœºç®±å°±å·²ç»å¾ˆå°äº†ï¼Œä½ æ°´ç®±å’Œå†·æŽ’æ”¾åœ¨å“ªé‡Œå‘¢ï¼Œæ›´ä½•å†µå…¥é—¨çº§æ°´å†·çš„æ•£çƒ­æ•ˆæžœæ¯”å¤§éƒ¨åˆ†é£Žå†·è¦å·®è¿™æ˜¯äº‹å®žï¼Œå°æœºç®±è¿˜æ˜¯è®¾è®¡å¥½é£Žé“è®©ç©ºæ°”åœ¨æœºç®±é‡ŒæµåŠ¨èµ·æ¥æ•ˆæžœæœ€å¥½äº†ã€‚

- [æˆ‘30æ¥å¹´diyæ‰æ˜Žç™½ï¼Œæœ€å¥½çš„å®¶ç”¨æœºç®±å°±æ˜¯å¼€æ”¾å¼æœºæž¶ï¼Œé£Žé“ä»€ä¹ˆéƒ½æ˜¯éª—äººçš„ - çŸ¥ä¹Ž](https://zhuanlan.zhihu.com/p/1931289802654855351)
  - æˆ‘åƒæƒŠçš„å‘çŽ°ï¼Œå¼€æ”¾æœºç®±ï¼Œåªè¦æœºç®±é£Žæ‰‡è½»è½¬ï¼Œå°±èƒ½å½¢æˆå‡åŒ€å……æ²›çš„æ°”æµï¼Œæ ¹æœ¬æ— éœ€æœºç®±ç»“æž„å¯¼é£Ž ï¼Œå¼€æ”¾æœºæž¶æœ€é…·çš„æ˜¯å¯ä»¥å åŠ ï¼Œè€ç”µè„‘å’Œæ–°ç”µè„‘åšåœ¨ä¸€èµ·ï¼Œæ··åˆæŽ¥å‡ å°æ˜¾ç¤ºå™¨ï¼Œé”®é¼ å¼„å‡ å¥—ï¼Œçµæ´»æ€§æ— ä»¥ä¼¦æ¯”
  - åªè¦å®¶é‡Œæœ‰å®‰å…¨çš„ç©ºé—´ï¼ˆä¸è¢«äººæ³¼æ°´ å® ç‰©ç ´åç­‰ç­‰ï¼‰ï¼Œå¼€æ”¾æœºç®±å°±æ˜¯diyæœ€ç»ˆå½’å®¿ã€‚
  - æ¿å¡å—åŠ›å¥½ï¼Œç¨³å®šå¯¿å‘½é•¿ï¼Œé£Žæ‰‡é¿å…äº†æœ€ä¸å¥½çš„æ ‡ç­¾å‘ä¸‹çš„æ‘†æ”¾ã€‚ç»´æŠ¤ç®¡ç†ä¹Ÿè¶…çº§æ–¹ä¾¿ã€‚ç°å°˜ä¹Ÿä¸ä¸¥é‡ï¼Œæ²¡ä»€ä¹ˆæ€ªå¼‚çš„ä¹±æµï¼Œå°±æ²¡ä»€ä¹ˆé¡½å›ºçš„ç°å°˜ç§¯ç´¯ã€‚æ—è¾¹æ”¾å°ç©ºæ°”å‡€åŒ–å™¨æ›´ä½³ã€‚
- å®¶é‡Œæ²¡æ–°é£Žç³»ç»Ÿçš„åˆ«è¯•äº†â€¦â€¦ç°å°˜å’Œæ‰¬å°˜ä¸æ˜¯æ¯ä¸ªåœ°ç†ä½ç½®éƒ½æŽ§åˆ¶å¾—å¥½çš„
- ç°å¤ªå¤§äº†ï¼Œä¸è¡Œçš„ï¼Œæˆ‘æ·±åœ³ç¦»æµ·è¾¹åªæœ‰3å…¬é‡Œ30æ¥¼é‚£ç°å¤§çš„ã€‚ã€‚

- ## [å°æœºç®±æ˜¯æ€Žä¹ˆè§£å†³æ•£çƒ­çš„ï¼Ÿ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/6710a2ab000000002100583d?xsec_token=ABM6aePzBDdvEmqW7AP7IWy2aQbrM8b-WUMg-puQ2H2DU=&xsec_source=pc_search&source=unknown)
  - éžå¸¸ç»å…¸çš„æœºæ¢°å¤§å¸ˆC24ï¼Œæ¨±èŠ±ç²‰é…è‰²ï¼Œ9.9Lçš„ä½“ç§¯
  - å°æœºç®±æ•£çƒ­åˆ°åº•è¡Œä¸è¡Œï¼Ÿåªä¸Šé£Žå†·åˆ°åº•èƒ½ä¸èƒ½åŽ‹å¾—ä½æ¸©åº¦ï¼Ÿ
  - C24çš„æœºç®±æž„é€ é‡‡ç”¨äº†è±å½¢çš„å¼€å­”é€æ°”çš„ä¾§æ¿ï¼Œä¹Ÿæ˜¯éžå¸¸æœ‰ç‰¹è‰²çš„ä¸€ä¸ªè®¾è®¡ï¼ŒåŒæ—¶ä¸Šä¸‹ä¸¤é¢ä»¥åŠèƒŒé¢éƒ½æœ‰åšå¼€å­”è®¾è®¡ï¼Œä¿è¯äº†è‰¯å¥½çš„é€æ°”æ€§èƒ½ï¼›
  - è€Œå°æœºç®±çš„ç©ºé—´ç´§å‡‘ï¼Œèƒ½å¤Ÿå®žçŽ°æœ€ä¼˜é£Žé“æ–¹æ¡ˆçš„ï¼Œå…¶å®žå°±æ˜¯æœºç®±å°¾éƒ¨çš„é£Žæ‰‡ï¼Œå¯ä»¥è¯´æ˜¯ç¥žæ¥ä¹‹ç¬”ï¼ŒåŠ è£…ä¹‹åŽæ‰èƒ½å‘æŒ¥å°æœºç®±çš„çŸ­é£Žé“ä¼˜åŠ¿
  - æ˜¾å¡å¦‚æžœæ­é…ä¸€å¼ åŒé£Žæ‰‡çš„æ˜¾å¡æ¸©åº¦åˆ™å¯ä»¥è¿˜è¦ä½Žä¸Šå‡ åº¦ï¼›

- [è”åŠ›åˆä¸€ä¸ªæœ‰çˆ†æ¬¾æ½œè´¨çš„æœºç®± - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/66e30ddd00000000120107c2?xsec_token=ABofaNF4fkho52iws-yq8ScYcAYtNeg2kdaya4XViqLIc=&xsec_source=pc_search&source=unknown)
  - ä¹‹å‰æœ‰äººé—®è¿‡å°åž‹ä¸€ç‚¹çš„MATXæœºç®±æŽ¨èï¼Œæœ€è¿‘åˆšå¥½å¯ä»¥å‚è€ƒè¿™å°æ–°ä¸Šå¸‚çš„è”åŠ›A3ã€‚
  - å®ƒæ˜¯è”åŠ›å’ŒDAN Caseè”æ‰‹è®¾è®¡çš„ã€‚
  - MATXç»“æž„ï¼Œå¦‚æžœç”¨ITXçš„è¯ç”µæºå¯ä»¥ä¸‹ç½®ï¼Œè™½ç„¶ç©ºé—´è¾¾åˆ°äº†26Lå¤šï¼Œä½†æ˜¯æ¯•ç«Ÿå®ƒæ˜¯MATXï¼Œåœ¨é…ä»¶æ”¯æŒä¸Šä¹Ÿèƒ½å¤Ÿæ›´åŠ è‡ªç”±ä¸€äº›ï¼Œé£Žå†·æ”¯æŒæœ€é«˜165mmï¼ŒåŸºæœ¬ä¸Šå¸‚é¢å¸¸è§„é£Žå†·éƒ½èƒ½æ”¯æŒï¼Œæ°´å†·ä¹Ÿèƒ½å¤Ÿæ”¯æŒåˆ°360mmçš„ä¸€ä½“æ°´å†·ã€‚æ˜¾å¡æ”¯æŒåˆ™è¾¾åˆ°äº†æ¯”è¾ƒå¤¸å¼ çš„415mmï¼Œå¹¶ä¸”æ”¯æŒç«–è£…ã€‚æ•´ä½“æ¨¡å—åŒ–è®¾è®¡ï¼Œè£…æœºéš¾åº¦ä¸é«˜ã€‚

- ## [ä½ ä»¬çš„å°æœºç®±åŠ ä¸åŠ æ•£çƒ­é£Žæ‰‡å•Šï¼Ÿæ„Ÿè§‰å¥½é—·ï¼Œå¥½çƒ« ](https://www.xiaohongshu.com/explore/68499022000000000f033b1b?xsec_token=ABEAH8XqEXMtphXMAXSQfa7ARcpcy6sEhThq_QezV-_NI=&xsec_source=pc_search&source=unknown)
- çœ‹ä½ åŠŸè€— æ•´æœº150wä»¥å†…éšä¾¿åŠ ä¸åŠ  è¶…è¿‡å»ºè®®åŠ ä¸¤æŠŠé£Žé“æœ‰è¿›æœ‰å‡ºå³å¯ï¼Œæˆ‘è¿™æ—¥å¸¸ç”¨å¤§æ¦‚350wå·¦å³æ•´æœºåŠŸè€—ç”¨äº†4æŠŠ ï¼Œå…¶å®žä¸‰æŠŠä¹Ÿå¤Ÿäº†ã€‚è¿˜æœ‰å°±å¦‚æžœä¸æ˜¯å¾ˆåŽšå®žçš„ç®±å­ï¼Œé£Žæ‰‡è¶Šå¤šè¶Šå®¹æ˜“ä½Žé¢‘å…±æŒ¯ã€‚

- çŽ°åœ¨çš„ç”µæºå¥½åƒéƒ½æ˜¯500ç“¦åŠä»¥ä¸Šçš„ï¼Œç”¨ä¸äº†é‚£ä¹ˆå¤šï¼Œæƒ³ä¹°å°ä¸€ç‚¹çš„éƒ½æ²¡æœ‰
  - æ²¡å¿…è¦ä¹°å¤ªå°ï¼ŒçŽ°åœ¨650wä»¥ä¸‹éƒ½æ˜¯ç™½èœä»·200å—é’±ä¸åˆ°è¿™ä¸ªé’±å°±åˆ«çœäº†ã€‚å¤šç‚¹å†—ä½™çš„è¯ä¸å…‰æ˜¯å¸¦è®¾å¤‡ä¸åƒåŠ›ï¼Œå‘çƒ­å°äº†é£Žæ‰‡è½¬é€Ÿä½Žä¸€ç‚¹è¿˜æ›´å®‰é™ã€‚

- çœ‹äº†ä½ çš„æœºç®±å¸ƒå±€ï¼Œè¿˜æ˜¯å¯ä»¥å¤šåŠ å‡ æŠŠçš„ï¼Œæœºç®±å°¾éƒ¨ï¼Œé¡¶éƒ¨ï¼Œä»¥åŠæ˜¾å¡ä¸‹åŠ è–„æ‰‡ï¼Œè‚¯å®šå¯¹æ•£çƒ­æœ‰æå‡
  - é‚£åŸºæœ¬å°±åŠ æ»¡äº†ï¼ŒçŽ°åœ¨å…ˆåŠ ä¸€ä¸ªåœ¨æœºç®±åŽé¢ï¼Œè¯•è¯•æ¸©åº¦
- ä¸æƒ³åŠ å¤šçš„è¯é¡¶éƒ¨æ­£å¯¹ç€é£Žå†·æœ€å¥½ä¹ŸåŠ ä¸€ä¸ª

- æ­£å¸¸ä½¿ç”¨35åº¦çš„GPUï¼Œ40åº¦çš„CPU

- ## [å°æœºç®±æ•£çƒ­æœ‰é—®é¢˜å—ï¼Ÿ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/66cbb2f2000000001f016917?xsec_token=AB-BTjol0N_mwqMM3wA24XS93uB6WGXYwkAz6dvKjlB30=&xsec_source=pc_search&source=unknown)
- ä¸è¦çœ‹å®ƒå°ï¼Œè¿™é‡Œæœ‰ä¸‰ä¸ªé£Žæ‰‡æŠŠçƒ­é‡æ•£å‡ºåŽ»ï¼Œå…¶å®žè·Ÿæ™®é€šæœºç®±æ²¡å·®çš„
- ä¸ä¼šï¼Œå…¶å®žä¸‰é¢å¼€ç½‘é£Žé“åè€Œä¼šæ›´å¥½ã€‚

- å°æœºç®±ï¼Œ4ä¸ªé£Žæ‰‡å¤Ÿç”¨äº†

- æˆ‘è¿™çº¯é—·ç½éƒ½æ²¡é—®é¢˜
- æ€•æ•£çƒ­ä¸è¡Œå°±æ‰“å¼€ä¾§ç›–å‘—

- ä¾¿æºæœºç®±å°±æ˜¯å› ä¸ºè¦æ¥å›žé£žå¸¦ç€æ–¹ä¾¿ï¼Œæ°´å†·ä¸èƒ½ä¸Šé£žæœºï¼Œä¾¿æºè¿˜æœ‰ä»€ä¹ˆæ„ä¹‰

- æ•£çƒ­æ²¡é—®é¢˜çš„ï¼Œæˆ‘ä¹Ÿæ˜¯ç´§å‡‘matxï¼Œå…¬ç‰ˆ3080æ»¡è½½ä¹Ÿå°±70å¤šåº¦ï¼Œè´¯ç©¿é£Žé“

- æˆ‘7700+7900xtéƒ½éšä¾¿åŽ‹

- æœ¬èº«atxç”µæºå‰ç½®å°±æ˜¯ä¸å¾—ä¸å‘ç©ºé—´é æ‹¢ï¼Œè€Œèˆå¼ƒäº†è¿›é£ŽäºŽå¦¥åçš„ä¸€æ­¥ï¼Œæ•£çƒ­ä¸å¥½æ˜¯å…ˆå¤©ç¼ºé™·ã€‚ä¸è¿‡ä¸ºäº†ä¸å½±å“è¿›é£Žï¼Œå¯ä»¥é€‰æ‹©æ˜¾å¡cpuåŒ240å†·æŽ’ï¼Œå¹¶å°†å°¾éƒ¨çš„é£Žæ‰‡ä½œä¸ºè¿›é£Žä½¿ç”¨ï¼Œæˆ–è€…ä¸è¿½æ±‚ä¾§é€çš„è¯ï¼Œç›´æŽ¥å¼€å­”æ˜¯æœ€ç®€å•çš„

- è¿™ä¹ˆå¤§å·²ç»ä¸å«å°æœºç®±äº† 10-15å‡çš„å¤§å°æˆ‘éƒ½å«Œå¤§

- ## [å°æœºç®±è£…æœºè¡€æ³ªæ•™è®­â€”â€”ä¹”æ€ä¼¯d41 - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/67cd3148000000000e007149?xsec_token=ABQ2_O_qG8QQbUy7d9Jl_OsA4fk-MLl7s4Y__ZMDEuIUM=&xsec_source=pc_search&source=unknown)
- æç¤ºï¼šç¡¬ä»¶èŒ¶è°ˆçš„è£…æœºæ•™ç¨‹æ˜¯ä¸ªå¾ˆå¥½çš„å°ç™½æ•™ç¨‹ï¼Œè£…æœºç»†èŠ‚å®Œå…¨å¯ä»¥å‚è€ƒï¼Œä½†æ˜¯å°æœºç®±è£…æœºé¡ºåºä¸èƒ½å®Œå…¨å‚ç…§ä»–çš„æ¥ï¼ä¸ç„¶ä½ å°±ä¼šè·Ÿæˆ‘ä¸€æ ·ï¼Œæ‹†äº†è£…è£…äº†æ‹†è£…äº†æ‹†æ‹†äº†è£…
- å°æœºç®±è£…æœºç¬¬ä¸€æ­¥ï¼šå¸¦ä¸Šæ‰‹å¥—
- å°æœºç®±è£…æœºç¬¬äºŒæ­¥ï¼šæ‹†å¼€æœºç®±ï¼Œå–å‡ºç”µæºç›’ï¼Œå‡†å¤‡ä¸€ä¸ªå°ç›’å­ï¼ˆå¿…å¤‡ï¼ï¼ï¼ï¼‰æ”¾æœºç®±ä¸Šæ‹†ä¸‹æ¥çš„é›¶æ•£ä»¶ï¼šèžºä¸ã€æŒ¡æ¿ç­‰ç­‰ã€‚
- å°æœºç®±è£…æœºç¬¬ä¸‰æ­¥ï¼šåƒä¸‡ä¸è¦è„‘å­ä¸€çƒ­å°±åŽ»è£…æ•£çƒ­å™¨ï¼å…ˆç»™æˆ‘æ‹¿å‡ºä¸»æ¿ï¼Œè£…ä¸Šcpuå’Œssdï¼ˆNVMeï¼‰ï¼Œå†…å­˜æ¡è¿™ä¼šå¯è£…å¯ä¸è£…ï¼Œ
  - ç„¶åŽæŠŠä¸»æ¿è£…åˆ°æœºç®±é‡Œé¢ï¼ŒåŠ›é“è¦æ°åˆ°å¥½å¤„ï¼Œæ—¢ä¸è¦å¤ªé‡ä¹Ÿä¸è¦å¤ªè½»ã€‚
- å°æœºç®±è£…æœºç¬¬å››æ­¥ï¼šåƒä¸‡ä¸è¦è„‘å­ä¸€çƒ­å°±åŽ»è£…æ•£çƒ­å™¨ï¼å…ˆç»™æˆ‘æŠŠæœºç®±è¿žæŽ¥çº¿æ’åˆ°ä¸»æ¿ä¸Šï¼ï¼ï¼
  - å¦‚æžœæœ‰æ˜¾å¡å¹¶ä¸”æ‰“ç®—è£…ssdï¼ˆsataï¼‰å’Œæœºæ¢°ç¡¬ç›˜çš„ï¼Œè¯·åƒä¸‡å…ˆç»™æˆ‘æŠŠsataçº¿ä¹Ÿå…ˆæ’åˆ°ä¸»æ¿ä¸Šï¼
  - é‡è¦è¡¥å……ï¼šcpuç”µæºä¸€å®šè¦æ’å¥½ï¼ä¸ç„¶åŽé¢ä½ è¦ä¹ˆæ‹†é£Žæ‰‡è¦ä¹ˆåœ¨é£Žæ‰‡å’Œä¸»æ¿çš„å¤¹ç¼ä¸­æŒ£æ‰Žï¼
- å°æœºç®±è£…æœºç¬¬äº”æ­¥ï¼šè¿™ä¼šä½ å¯ä»¥è£…æ•£çƒ­å™¨äº†ï¼Œåªè¦è®°ä½ï¼šåž‚ç›´é£Žæ‰‡éƒ½æœä¸‹ï¼Œæ°´å¹³é£Žæ‰‡éƒ½æœå‰ï¼
  - å…ˆæ’é£Žæ‰‡çº¿ï¼Œå†å›ºå®šæ•£çƒ­å™¨ï¼
  - å¦‚æžœç”¨æ°´å†·æ•£çƒ­å™¨ï¼ŒçŽ°åœ¨æ°´å†·é£Žæ‰‡ä¸€èˆ¬å·²ç»å›ºå®šåœ¨æ°´å†·ä¸Šäº†ï¼Œæ°´å†·å’Œé£Žæ‰‡åº”è¯¥åˆ†åˆ«æ’åœ¨pump_fanå’Œcpu_fanä¸Šï¼ˆ
- å°æœºç®±è£…æœºç¬¬å…­æ­¥ï¼šå…¨æ¨¡ç»„ç”µæºï¼Œä»€ä¹ˆé”…é…ä»€ä¹ˆç›–ï¼Œä»€ä¹ˆè‰²æ’ä»€ä¹ˆè‰²çš„çº¿ï¼Œæ’å¥½å…ˆæŠŠç”µæºè£…è¿›ç”µæºç›’ï¼ŒæŠŠæœºç®±ç”µæºçº¿æ’å…¥ç”µæºï¼ˆåˆ«å¿˜äº†æ‰“å¼€ç”µæºå¼€å…³ï¼ï¼ï¼ï¼‰ï¼Œå†æŠŠç”µæºç›’å›ºå®šåˆ°æœºç®±ä¸Šã€‚
  - æœ‰æ˜¾å¡å…ˆè£…æ˜¾å¡ï¼Œæ²¡æ˜¾å¡ç›´æŽ¥æ’çº¿ç†çº¿ã€‚
- å°æœºç®±è£…æœºå³å°†å®Œæˆï¼šè¦è£…ssdï¼ˆsataï¼‰å’Œæœºæ¢°ç¡¬ç›˜çš„ï¼Œè¿™ä¼šå°±å¯ä»¥æŠŠä»–ä»¬åˆ°å›ºå®šä½ç½®æˆ–è€…ç¡¬ç›˜æž¶ä¸Šï¼Œæ’ä¸Šsataçº¿å’Œç”µæºçº¿ã€‚
  - åˆ«å¿˜äº†ï¼Œä¹‹å‰è¦æ˜¯æ²¡æ’å†…å­˜æ¡çš„è¦æ’ä¸Šå†…å­˜æ¡ï¼ŒæŒ‰ç…§ 2 â†’ 4 â†’ 1 â†’ 3 é¡ºåºæ’æ»¡ï¼Œç¡®ä¿åŒé€šé“ç”Ÿæ•ˆã€‚

- ## [æ”¯æŒå¤šæŒ‡è§¦æŽ§çš„å¼€æºè§¦æŽ§æ¿æ¥å•¦ï¼ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/6711d2b30000000021006a5d?xsec_token=ABBAVIU5BmyEoOSC1_U-awDuJr92L8j26jKmwMyo1z8q4=&xsec_source=pc_search&source=web_search_result_notes)
  - Ploopyå› å…¶å¼€æºã€3Dæ‰“å°çš„PCå¤–è®¾åœ¨å°ä¼—å¸‚åœºä¸­äº«æœ‰ç››èª‰ï¼Œå…¶æœ€æ–°äº§å“Ploopy Trackpadä¹Ÿå»¶ç»­äº†è¿™ä¸€é£Žæ ¼ã€‚è¿™æ¬¾â€œ3Dæ‰“å°ã€å¼€æºçš„å¤§åž‹è§¦æŽ§æ¿â€é€‚ç”¨äºŽæ¡Œé¢å’Œç¬”è®°æœ¬ç”µè„‘ï¼Œå°ºå¯¸ä¸º190 Ã— 140 Ã— 20æ¯«ç±³ï¼Œæ¯”Appleçš„Magic Trackpadè¿˜å¤§ä¸€äº›ã€‚
  - å®ƒæ”¯æŒWindowså’ŒLinuxä¸Šçš„æœ€å¤šäº”æŒ‡å¤šç‚¹è§¦æŽ§æ‰‹åŠ¿ï¼Œä½†ç”±äºŽmacOSä¸ŽQMKå›ºä»¶ä¹‹é—´å­˜åœ¨é™åˆ¶ï¼Œè‹¹æžœè®¾å¤‡çš„æ‰‹åŠ¿æ”¯æŒå—é™
  - Ploopy Trackpadçš„å¤–å£³å’Œè§¦æŽ§è¡¨é¢éƒ½ç”±PLAå¡‘æ–™3Dæ‰“å°è€Œæˆï¼ŒPloopyå£°ç§°è¿™ç§ææ–™æ¯”ABSæ›´è€ç£¨å¹¶ä¸”ä½¿ç”¨èˆ’é€‚ã€‚è™½ç„¶æœ€åˆè®¡åˆ’ä½¿ç”¨çŽ»ç’ƒè¡¨é¢ï¼Œä½†æœ€ç»ˆé€‰æ‹©äº†ABSï¼Œå› ä¸ºå®ƒåœ¨ä¸åŒæ“ä½œç³»ç»Ÿå’Œè®¾å¤‡ä¸Šæä¾›äº†æ›´ä¸€è‡´çš„è·Ÿè¸ªæ•ˆæžœã€‚é‰´äºŽPloopyçš„å¼€æºè®¾è®¡å’Œæ´»è·ƒçš„ç¤¾åŒºï¼Œæœªæ¥å¯èƒ½ä¼šæœ‰ç”¨æˆ·å®žçŽ°çŽ»ç’ƒè§¦æŽ§è¡¨é¢çš„æ”¹è¿›ã€‚

- ## [å¦™æŽ§æ¿æœ‰æ²¡æœ‰å¹³æ›¿ Appleä¹Ÿå¤ªè´µäº† èˆä¸å¾— #å¦™æŽ§æ¿ #Apple #è‹¹æžœ#Macmini - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/6822f22b000000002202f95b?xsec_token=AB7ZPhxG4yCtuySva103gpkHVwVRQu1KHJQbB5APshtUc=&xsec_source=pc_search&source=web_search_result_notes)
- æ²¡æœ‰ï¼Œè€Œä¸”å¦™æŽ§æœ‰çº¿>è“ç‰™è¿žmac>è“ç‰™è¿žipad proï¼Œå¾ˆè¿½æ±‚æ‰‹æ„Ÿçš„è¯è¿˜è¦é…ä¸€æ ¹é•¿çº¿ï¼Œæ˜¯è¿ž60hzçš„å±éƒ½èƒ½åˆ†è¾¨å‡ºåŒºåˆ«çš„ç¨‹åº¦
- æ²¡æœ‰ï¼Œå°¤å…¶æ˜¯ç ´ç½—æŠ€ï¼Œä¸€ç”Ÿé»‘

- ä¹°äºŒæ‰‹çš„å§ï¼Œè¿™ä¸ªå¾ˆè€ç”¨çš„ï¼ŒäºŒæ‰‹æˆè‰²å¥½å’Œæ–°çš„ä¹Ÿæ²¡å•¥åŒºåˆ«
- ä¹°ä¸€ä»£çš„äºŒæ‰‹ä¹Ÿå°±ä¸€ç™¾å¤šå•Š

- æ˜¯çš„ï¼Œè€Œä¸”éžå¸¸å»ºè®®ç”¨æœ‰çº¿è¿žæŽ¥ï¼Œæ²¡æœ‰è“ç‰™çš„å»¶è¿Ÿï¼Œä½¿ç”¨ä½“éªŒå’Œmbpè‡ªå¸¦çš„åŸºæœ¬ä¸€æ ·

- [æˆ‘çš„mac miniç©·é¬¼å¥—é¤ï¼Œä¸å¤±ä½“éªŒ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/68320649000000000c03825f?xsec_token=ABF0XhwOtoKDBQhKUo195eNCcCz6x5xwHH_366uEQDqSo=&xsec_source=pc_search&source=web_search_result_notes)
  - ä¸€ä»£å¦™æŽ§æ¿å¯ä»¥é…m4çš„ï¼Œæ‰“å¼€å°±ç›´æŽ¥è¿žä¸Šäº†

- [è‹¹æžœè§¦æŽ§æ¿ç†æƒ³å¹³æ›¿ 150å—èƒ½å®žçŽ°80%åŠŸèƒ½ï¼Ÿ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/6728d5db000000001b01018c?xsec_token=ABXrx-jUlKOXDJg4dJl1XMWqHF5XtUK6_hozrpAJbVH9Q=&xsec_source=pc_search&source=web_search_result_notes)

- ## [æœ€ä½³å¤–æŽ¥ç‹¬ç«‹è§¦æ‘¸æ¿ç½—æŠ€casa touchä½“éªŒ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/6804c1f0000000001201c88a?xsec_token=ABZ7BagZ46pJM6c6btbNXwLHXUCDQ3iVwDsgN_a75SKZ8=&xsec_source=pc_search&source=web_search_result_notes)
  - å¤ªé•¿ä¸çœ‹ï¼Œæœ€ä½³å¤–ç½®è§¦æ‘¸æ¿-å¦™æŽ§æ¿æ›¿ä»£å“ï¼Œå¯ä»¥æ— è„‘ä¸‹æ‰‹ã€‚
  - ç½—æŠ€23å¹´æŽ¨å‡ºäº†ä¸€æ¬¾pop-up desktopäº§å“ï¼Œé‡Œé¢åŒ…å«äº†ä¸€ä¸ªå¤–ç½®è§¦æ‘¸æ¿ï¼Œä¸Šä¸€æ¬¡ç½—æŠ€æŽ¨å‡ºç‹¬ç«‹çš„è§¦æ‘¸æ¿è¿˜æ˜¯åœ¨åå‡ å¹´å‰ã€‚
  - å¤§å°å’Œç¬”è®°æœ¬ä¸Šçš„å·®ä¸å¤šï¼Œæœ‰é»‘è‰²/ç™½è‰²å’Œç²‰çº¢è‰²ã€‚è¡¨é¢æè´¨æ˜¯çŽ»ç’ƒï¼Œè¢«å¡‘æ–™è¦†ç›–ã€‚é‡é‡157.6å…‹ï¼Œå¦™æŽ§æ¿æ˜¯230å…‹ï¼Œè§¦æ‘¸é¢ç§¯æ¯”å¦™æŽ§æ¿2å°å¾ˆå¤šï¼Œ
  - å¯ä»¥ç”¨boltå’Œè“ç‰™è¿›è¡Œè¿žæŽ¥ï¼Œæœ‰ä¸‰æ¨¡ï¼Œæ¯ä¸€ä¸ªéƒ½å¯ä»¥å•ç‹¬è¿žæŽ¥boltå’Œè“ç‰™ï¼Œ
  - Mac/Windows/ChromeOSï¼ˆfydeOSï¼‰/iPadOSéƒ½æ”¯æŒæ‰€æœ‰åŠŸèƒ½å’Œæ‰‹åŠ¿ã€‚
  - å¯ä»¥è¿žæŽ¥ä¸‰å°è®¾å¤‡ï¼Œä¸‰ä¸ªè®°å¿†ç‚¹
- æ²¡æœ‰å›½è¡Œ
  - é—²é±¼å–å…‰äº†ï¼Œå¯èƒ½è¦ä¹°å¥—è£…äº†

- æ¯”hukeå¥½ç”¨å¤ªå¤šäº†

- ## [MacBookå¤–æŽ¥é”®ç›˜ä½¿ç”¨åˆ†äº« - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/66fbde7b000000002a034d62?xsec_token=ABuws2tsgaoDnK4grUvCbFCBwKv3VPGL8ZVJ0p8qGnHec=&xsec_source=pc_search&source=web_search_result_notes)
  - ä¸€ã€è‹¹æžœå¦™æŽ§é”®ç›˜ - æ¡Œæ¿è½´ ç»™ Mac é…å¤‡çš„ç¬¬ä¸€ä¸ªé”®ç›˜æ˜¯å¦™æŽ§é”®ç›˜ã€‚è¿™æ¬¾é”®ç›˜åœ¨é€‚é…æ€§æ–¹é¢å ªç§°æœ€ä½³ã€‚æ— è®ºæ˜¯é¢œå€¼ã€é‡é‡ã€é”®ä½ã€å¤šåŠŸèƒ½é”®è¿˜æ˜¯ç»­èˆªï¼Œéƒ½ä¸Ž Mac å®žçŽ°äº†æ— ç¼è¡”æŽ¥ã€‚å”¯ä¸€ä»¤äººåæ§½çš„åœ°æ–¹åœ¨äºŽæŒ‰é”®æ‰‹æ„Ÿï¼Œå‡ ä¹Žæ²¡æœ‰ä»»ä½•åé¦ˆï¼Œæ‰“å­—çš„æ—¶å€™ï¼Œä½ å¯ä»¥æƒ³è±¡è‡ªå·±æ˜¯åœ¨æ•²æ¡Œå­ï¼Œå®Œå…¨æ²¡æœ‰è¾“å…¥çš„ä¹è¶£ã€‚å€˜è‹¥ä½ ä¸åœ¨æ„æ‰‹æ„Ÿï¼Œé‚£ä¹ˆè¿™æ¬¾é”®ç›˜æ˜¯æˆ‘çš„é¦–è¦æŽ¨èã€‚
  - äºŒã€äº¬é€  K2- çº¢è½´ å—å¤Ÿäº†æ•²æ¡Œå­èˆ¬çš„æ— èŠæ‰‹æ„ŸåŽï¼Œæˆ‘æ¢äº¬ä¸œäº¬é€  K3 çº¢è½´é”®ç›˜ï¼ˆä¸Ž Keychron è´´ç‰ŒåŒæ¬¾ï¼Œå½“æ—¶ä¼—å¤šè‡ªåª’ä½“éƒ½åœ¨å®‰åˆ©çš„ç½‘çº¢æ¬¾ï¼Œå·ç§°æ˜¯ Mac çš„ç¬¬ä¸‰æ–¹æœ€ä½³é€‚é…é”®ç›˜ï¼‰ã€‚ è¿™æ¬¾é”®ç›˜çš„é¢œå€¼å½“æ—¶ä¸é”™ï¼Œé»‘æ©˜é…è‰²ï¼Œä½†æ˜¯ä¼šæ‰“æ²¹ï¼Œè¿žæŽ¥æ–¹å¼ä¸ºè“ç‰™å’Œæœ‰çº¿åŒæ¨¡å¼ï¼Œè½´ä½“æ˜¯ä½³è¾¾éš†çº¢è½´ï¼Œç›´ä¸Šç›´ä¸‹ï¼Œæ¯”è¾ƒè½»ç›ˆã€‚ä½¿ç”¨äº†ä¸€æ®µæ—¶é—´åŽï¼Œä½“éªŒå°šå¯ã€‚æ§½ç‚¹æ˜¯é”®å¸½è¾ƒé«˜ï¼Œä½¿ç”¨æ—¶æ‰‹éƒ¨æ‚¬ç©ºï¼Œé•¿æ—¶é—´ä½¿ç”¨ä¼šæ¯”è¾ƒç´¯ã€‚ å†…ç½®ç”µæ± å¾…æœºæ—¶é—´çŸ­ï¼Œå……ç”µè¾ƒä¸ºé¢‘ç¹ã€‚å¯¹äºŽå¼ºè¿«ç—‡æ‚£è€…æ¥è¯´ï¼Œæœ€éš¾ä»¥å¿å—çš„æ˜¯è“ç‰™æ–­è”å’Œç¡çœ å”¤é†’æ…¢ï¼Œè¿˜ä¼šåžå­—ã€‚
  - ä¸‰ã€ç½—æŠ€ MX Mechanical-çº¢è½´ æ°å¥½ç½—æŠ€æ–°ä¸Šå¸‚äº†ä¸€æ¬¾ MX Mechanical çŸ®è½´æœºæ¢°é”®ç›˜ï¼Œè¶…é•¿å¾…æœºã€ä¸‰æ¨¡è¿žæŽ¥ï¼Œæ»¡è¶³æˆ‘çš„éœ€æ±‚ï¼ŒäºŽæ˜¯å…¥æ‰‹äº†ä¸€æŠŠèŒ¶è½´æ¬¾ã€‚è¿™æ¬¾é”®ç›˜çš„è½´ä½“ä¸Žä¼ ç»Ÿè½´ä½“æœ‰æ‰€ä¸åŒï¼ŒèŒ¶è½´æœ‰ç‚¹ç±»ä¼¼äºŽé»‘è½´ï¼Œæ‰‹æ„Ÿå¾ˆé‡ï¼Œä¸å¤Ÿè½»ç›ˆï¼Œä¸å¤ªé€‚åº”ï¼Œæ¢æˆäº†ç›´ä¸Šç›´ä¸‹çš„çº¢è½´ã€‚è¿™ä¸ªçŸ®è½´ç›¸æ¯”é«˜è½´çš„çº¢è½´ï¼Œå›žå¼¹ç¨å¾®é‡äº†ä¸€äº›ã€‚çŸ®è½´é•¿æœŸä½¿ç”¨ä¸ä¼šé‚£ä¹ˆç´¯äº†ï¼Œè¿žæŽ¥é€Ÿåº¦ä¹Ÿå¾ˆå¿«ï¼Œæ²¡æœ‰æ–­è”å’Œåžå­—çš„æƒ…å†µï¼Œæ•´ä½“æ¥è¯´è¿˜æ˜¯æ¯”è¾ƒæ»¡æ„çš„ã€‚è¿™æ¬¾é”®ç›˜ç›®å‰æˆ‘ä¹Ÿä¸€ç›´åœ¨ä½¿ç”¨ä¸­ã€‚è¯´ç¼ºç‚¹çš„è¯ï¼Œé”®å¸½æ¯”è¾ƒå°ä¼—ï¼Œæ²¡æœ‰å®Œç¾Žæ›¿æ¢çš„ï¼Œå°‘äº†äº›ä¹è¶£ã€‚é”®è½´ä¹Ÿä¸æ”¯æŒçƒ­æ’æ‹”ã€‚
  - å››ã€Nuphy Air75-è¶Šæ©˜è½´ ç»™ Mac ä¸»æœºé…é”®ç›˜ï¼Œé€‰æ‹©äº† Nuphy çš„ Air75 ä¸€ä»£ã€‚é”®ç›˜çš„åŒ…è£…å’Œåšå·¥å¾ˆç²¾è‡´ï¼Œé¢œå€¼æ˜¯æœ€é«˜çš„ï¼Œé”®å¸½å¥½çœ‹ï¼Œä¸‰æ¨¡è¿žæŽ¥ï¼Œé‡‡ç”¨ä½³è¾¾éš†çƒ­æ’æ‹”çŸ®è½´ï¼Œè¿žæŽ¥é€Ÿåº¦å¿«ï¼Œä¸ä¼šå‡ºçŽ°æ–­è”å’Œåžå­—çš„æƒ…å†µã€‚åŽæœŸæ¢äº†Air75 äºŒä»£ï¼Œæé«˜äº†è¿žæŽ¥é€Ÿåº¦å’Œç»­èˆªï¼Œå¢žåŠ æ–°çš„è½´ä½“ï¼Œæ–°çš„è½´ä½“å’Œåž«æ£‰å¸¦æ¥äº†æ›´å¥½çš„æ‰‹æ„Ÿã€‚å¼€å§‹ä¹°çš„æ˜¯èŠ¦èŸè½´ï¼Œå¤ªè½»ï¼Œåé¦ˆå¼±ï¼Œå®¹æ˜“è¯¯è§¦ã€‚æ¢æˆäº†è¶Šæ©˜è½´ï¼Œè¿™ä¸ªè½´ç±»ä¼¼äºŽ â€œHiFi éº»å°†éŸ³â€ï¼Œæ‰‹æ„Ÿé‡ä¸€äº›ï¼Œæœ‰æ›´å¥½çš„åé¦ˆåŠ›ä¸ä¼šè¯¯è§¦ï¼Œé•¿æ—¶é—´æ‰“å­—ä¹Ÿä¸ä¼šç´¯ã€‚

- åˆšå…¥æ‰‹keychron K4 pro é¦™è•‰è½´ï¼Œæ‰‹æ„Ÿä¸é”™ï¼Œé€‚åˆåŠžå…¬æ‰“å­—ã€‚å…³é”®æ˜¯å¯ä»¥viaæ”¹é”®ä½ï¼Œå¾ˆé¦™
  - å£°éŸ³ä¸å¤§ï¼ŒæŒºæŸ”è½¯ï¼Œé€‚åˆåœ¨åŠžå…¬å®¤ç”¨ã€‚

- [è‹¹æžœç”µè„‘å¦™æŽ§é”®ç›˜ æœ€å¼ºå¹³æ›¿ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/67cc2e4f00000000290198e4?xsec_token=ABb9QlEEv4edez8zXqcCpR1avO8fI6BvZ09MtS_ONM62k=&xsec_source=pc_search&source=web_search_result_notes)

- [Mac bookå¤–æŽ¥è®¾å¤‡åˆ†äº«ï¼ˆç©·é¬¼ç‰ˆï¼‰ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/67de16ad000000001d017c2e?xsec_token=ABYgeab4C5E3b9gpHBDeBL8QBz3tky0SCWCe9j92RoGQg=&xsec_source=pc_search&source=web_search_result_notes)
  - é”®ç›˜âŒ¨ï¸ï¼šäº¬ä¸œäº¬é€ k3 maxï¼ˆðŸ’°340rï¼‰
  - é¼ æ ‡ðŸ–±ï¼šèœ»èœ“VXE R1 SE+ï¼ˆðŸ’°70rï¼‰
  - æ‹“å±•åžï¼šç»¿è”äº”åˆä¸€ï¼ˆðŸ’°158rï¼‰

- [å¯ä»¥æ”¯æŒMac çš„æ— çº¿æœºæ¢°é”®ç›˜ï¼Œè½»ä¾¿é™éŸ³ï¼Œé€‚åˆé•¿æœŸæ‰“å­—åŠžå…¬å…šçš„ï¼Œå®å­ä»¬æœ‰æ²¡æœ‰æŽ¨èå‘€ï¼Ÿè°æ‡‚æ‰“å­—æ‰‹æŒ‡å…³èŠ‚ç—›å‘€ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/67a2ca1400000000290289d0?xsec_token=ABVfm3DcCUe0ysKmPGx8coQmEZCkPFcCZi28IS-M-_rUg=&xsec_source=pc_search&source=web_search_result_notes)
  - å¯ä»¥æ”¯æŒMac çš„æ— çº¿æœºæ¢°é”®ç›˜ï¼Œè½»ä¾¿é™éŸ³ï¼Œé€‚åˆé•¿æœŸæ‰“å­—åŠžå…¬å…šçš„ï¼Œå®å­ä»¬æœ‰æ²¡æœ‰æŽ¨èå‘€ï¼Ÿè°æ‡‚æ‰“å­—æ‰‹æŒ‡å…³èŠ‚ç—›å‘€
- Nuphy Airç³»åˆ—æˆ–è€…Keychron Kç³»åˆ—, Nuphyæ˜¯é™éŸ³çš„
- nuphy airç³»åˆ—ï¼Œé“åŽ‚ MG65 éƒ½å¾ˆå¥½

- å®èŠé™ç”µå®¹ mirco plum 84 35gç‰ˆæœ¬

- å®˜æ–¹å¦™æŽ§é”®ç›˜ è½»è–„ é™éŸ³

- nuphyï¼Œ æ´›æ–ï¼Œæ¸´åˆ›ï¼Œéƒ½æ˜¯æ”¯æŒè‹¹æžœçš„æˆå“é”®ç›˜

- äº¬ä¸œk3maxï¼Œkeychronä»£å·¥çš„ï¼Œæˆ‘ç”¨ç€è¿˜å¯ä»¥ã€‚çŸ®è½´ä¸éœ€è¦è…•æ‰˜ã€‚

- ## [Macå¤–æŽ¥æ˜¾ç¤ºå™¨ä½¿ç”¨çš„ä¸€äº›å»ºè®®å’Œä¼˜åŒ–æ–¹æ¡ˆ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/67d823340000000007036b64?xsec_token=ABi4D7ISTN18_diLmfrK_nWQFIh4EdsPayzksbNRkvRgQ=&xsec_source=pc_search&source=web_search_result_notes)
- Macå¤–æŽ¥ä½Žåˆ†è¾¨çŽ‡æ˜¾ç¤ºå™¨å‡ºçŽ°çš„æ¨¡ç³Šé—®é¢˜
  - å½“è´­ä¹°äº†Macbookæˆ–è€…MacåŽ æˆ‘ä»¬é€‰æ‹©å¤–æŽ¥æ˜¾ç¤ºå™¨ é€šå¸¸é€‰æ‹©åˆ†è¾¨çŽ‡æ˜¯ 4kæˆ–è€… 5kçš„å±…å¤š ä½†ä¹Ÿæœ‰ä¸€äº›å°ä¼™ä¼´ç”¨çš„æ˜¯1080Pæˆ–è€…æ˜¯2kçš„æ˜¾ç¤ºå™¨ å¯¼è‡´Macåœ¨æ­¤ç±»æ˜¾ç¤ºå™¨ä¸Šä¼šå‡ºçŽ°å­—ä½“å‘è™šã€æ¨¡ç³Šç­‰é—®é¢˜ 
  - å› ä¸ºMacé»˜è®¤ 4kä»¥ä¸Šåˆ†è¾¨çŽ‡çš„æ˜¾ç¤ºè®¾å¤‡æ‰ä¼šå¼€å¯HiDPi  
  - æ‰€ä»¥è§£å†³æ­¤ç±»é—®é¢˜ä¹Ÿå¾ˆç®€å• åˆ©ç”¨è½¯ä»¶å¼ºåˆ¶å¼€å¯HiDPiå³å¯ è¿™é‡ŒæŽ¨èRDM ä¸ä»…å¼€å¯HiDPi è¿˜èƒ½å¼€å¯æ˜¾ç¤ºå™¨é«˜åˆ· å½“ç„¶æœ‰æ¡ä»¶çš„è¯ è¿˜æ˜¯æŽ¨èæ¢é«˜åˆ†è¾¨çŽ‡çš„æ˜¾ç¤ºè®¾å¤‡
- å¤–æŽ¥æ˜¾ç¤ºå™¨åŽæ— æ³•åˆ©ç”¨å¤–æŽ¥é”®ç›˜è°ƒèŠ‚æ˜¾ç¤ºå™¨äº®åº¦å’ŒéŸ³é‡
  - ç¬¬ä¸€æ¬¡ä½¿ç”¨Macå¤–æŽ¥æ˜¾ç¤ºå™¨ ç”¨çš„å¤–ç½®é”®ç›˜ å´æ— æ³•è°ƒèŠ‚æ˜¾ç¤ºå™¨çš„äº®åº¦ ç”šè‡³éŸ³é‡ä¹Ÿæ— æ³•æŽ§åˆ¶ è¿™é‡ŒæŽ¨èä¸€æ¬¾è½¯ä»¶ å³å¯è§£å†³æ­¤ç±»é—®é¢˜ Monitor Control æ˜¯githubä¸Šå…è´¹å¼€æºè½¯ä»¶
- MacBooké•¿æ—¶é—´å¤–æŽ¥æ˜¾ç¤ºå™¨æ»¡ç”µä½¿ç”¨ç”µæ± å¯¿å‘½é—®é¢˜
  - è¿™ä¸ªé—®é¢˜ä¹Ÿæ˜¯å¤§å®¶å¾ˆåœ¨æ„çš„ æ¯•ç«Ÿæ–°ä¹°çš„è®¾å¤‡éƒ½æ¯”è¾ƒçˆ±æƒœ è¿™é‡ŒæŽ¨èå¤§å®¶ä¸€æ¬¾AIDenteçš„è½¯ä»¶ å¯ä»¥å°†è®¾å¤‡ç”µé‡ðŸ”‹æŽ§åˆ¶åœ¨ 80%  è¿˜èƒ½æŽ§åˆ¶MagSafeå……ç”µç¯ å……ç”µçš„åŒæ—¶ä¸»åŠ¨æ”¾ç”µåˆ° 80% çš„å¥åº·ç™¾åˆ†æ¯”ç­‰ è¿˜å¯ä»¥ç›‘æŽ§å……ç”µåŠŸçŽ‡ è®¡åˆ’å……ç”µç­‰ ç½‘å‹è¯„ä»·å¾ˆé«˜ éƒ¨åˆ†åŠŸèƒ½åœ¨Proç‰ˆæœ¬ä¸Šéœ€è¦ä»˜è´¹ ä½†ä¸€èˆ¬åŸºç¡€åŠŸèƒ½å…è´¹å¼€æ”¾
- Mac mini m4 æœ¬èº«æ˜¯æ”¯æŒ æœ€é«˜ 4k 240hz çš„æ˜¾ç¤ºå™¨ å¤šå°è¿žæŽ¥ä¹Ÿæœ‰ 4k 120 hzæˆ–è€… 4k 144hz åŠžå…¬ 60hzè¶³å¤Ÿ ä½†æ˜¯é«˜åˆ·ä½“éªŒæ›´ä½³ æ¯”å¦‚æµè§ˆç½‘é¡µæ›´ä¸æ»‘ æ‹–åŠ¨çª—å£ä¹Ÿä¸æ»‘ æœ‰è¶³å¤Ÿé¢„ç®—é€‰æ˜¯æœ€ä¼˜è§£

- ## [ä¹°äº†ä¸ªè¶…é«˜æ¸… 4K 23.8 å¯¸ ä¾¿æºæ˜¾ç¤ºå™¨ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/6810c50000000000090174b8?xsec_token=AB_QqkK7_ZF3_KbwyW1ZB1W-4U-ahovczyytBjBGhW3_A=&xsec_source=pc_search&source=web_search_result_notes)
  - å¦‚æžœæ˜¯é•¿æœŸè‡ªç”¨åŠžå…¬å’Œç§‘ç ”ï¼Œè‡³å°‘è¦2Kä»¥ä¸Šï¼Œæžè‰ºæœ¯çš„æœ€å¥½æ˜¯4Kã€‚
  - sculptor23.8å¯¸ 4K æ˜¾ç¤ºå±

- ## ðŸ“Œ [ä¾¿æºå±æŒ‘é€‰å»ºè®® - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/678deac90000000018029a17?xsec_token=AByy4GMp8bWndvumxKkA0t2zCapY5R9quZuyaVsMR8Y_w=&xsec_source=pc_search&source=web_search_result_notes)
  - é¦–å…ˆæ˜Žç¡®éœ€æ±‚: åŠžå…¬è¿˜æ˜¯æ¸¸æˆï¼ŸSwitchã€ä¸»æœºæˆ–ç”µè„‘ï¼Ÿ
  - ç›®å‰å¸‚åœºä¸»æµå“ç‰Œå‡ä¸ºéžä¸€çº¿åŽ‚å•†ï¼Œä½†ä¸ä»£è¡¨äº§å“ä¸è¾¾æ ‡ï¼Œè´¨é‡ä¹Ÿæœ‰å¾ˆä¸é”™çš„ã€‚
  - ä¸»æµå“ç‰Œæœ‰ï¼ŒARZOPAé˜¿å“å¸•ã€é›•å¡‘å®¶ã€EIMIOã€CFORCEç­‰ï¼Œå„æœ‰ç‰¹è‰²ã€‚å…¶ä»–å“ç‰Œï¼Œè‹¥é¢„ç®—ä¸è¶³ï¼Œè¦æ±‚ä¸é«˜ï¼Œä¹Ÿå¯é€‰æ‹©ã€‚ 
  - ä¸»è¦æœ‰ä¸¤ä¸ªå‚æ•°éœ€è¦æ³¨æ„
  - å¸§çŽ‡:60hzé€‚åˆåŠžå…¬ä»¥åŠè½»åº¦æ¸¸æˆï¼ŒåŒ…æ‹¬switchã€psä¸»æœºã€ç”µè„‘ç«¯ã€‚ç„¶åŽå°±æ˜¯144hzåŠä»¥ä¸Šï¼Œé€‚åˆFPSç­‰ç«žæŠ€æ¸¸æˆï¼Œä¾‹å¦‚CS2
  - è‰²åŸŸ: ä¸»è¦æ ‡å‡†æœ‰sRGBã€Adobe RGBã€DCI-P3ã€NTSCã€‚åŸºæœ¬ä¸ŠsRGBå¤§äºŽ75%å°±æœ‰è¾ƒå¥½çš„é¢œè‰²è¡¨çŽ°äº†ï¼Œå½“ç„¶è¶Šé«˜è¶Šå¥½ã€‚
- æˆ‘ç›¸ä¿¡1080på·²ç»æ»¡è¶³ç»å¤§å¤šæ•°äººéœ€æ±‚ï¼Œæ›´é«˜åˆ†è¾¨çŽ‡ä¸å¦‚ç›´æŽ¥ä¸Šå°æ˜¾ï¼Œå¯¹è®¾å¤‡æ€§èƒ½è¦æ±‚ä¹Ÿä¼šæ›´é«˜ã€‚
  - è¿™ä¹Ÿæ˜¯ä¸ºå•¥åªæµ‹è¯•äº†1080pçš„ç‰ˆæœ¬ï¼Œè¶³å¤Ÿæ¸…æ™°äº†ï¼Œå±å¹•åˆå°ï¼Œé’±èŠ±åœ¨åˆ€åˆƒä¸Šã€‚

- ## [mac mini ä¾¿æºæ˜¾ç¤ºå™¨éš¾å¾—æ‰¾ä¸ªå®Œç¾Žçš„ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/67be8dff00000000280368be?xsec_token=ABatyUb9Lx1XYXALQpMcvmTBAo775B3MvozPzD4EZe9RI=&xsec_source=pc_search&source=web_search_result_notes)
  - ç»è¿‡å¤šæ–¹å¯¹æ¯”ï¼Œæ‹¿ä¸‹arzopa 16å¯¸çš„2.5kä¾¿æºæ˜¾ç¤ºå™¨ï¼Œèœå•æ–¹ä¾¿ï¼Œè¿žæŽ¥ä¸€æ ¹çº¿å³å¯ï¼Œæ˜¾ç¤ºæ•ˆæžœä¸é”™ï¼Œä¸è¿‡è¿™ç±»æ˜¾ç¤ºå™¨å¾ˆéš¾æ”¯æŒhidpiï¼Œç›®å‰å°±1280-800è¿˜è¡Œï¼Œä¸è¿‡æ„Ÿè§‰ç¼©æ”¾æœ‰ç‚¹å¤§ï¼ŒåŽŸå§‹åˆ†è¾¨çŽ‡å­—åˆå¾ˆå°

- è¦ä¹ˆ4kè¦ä¹ˆ1080ï¼Œmç³»åˆ—å°±æ˜¯hidpæœ‰é—®é¢˜ï¼Œå¾—è¿™ä¸¤ä¸ªåˆ†è¾¨çŽ‡ï¼Œäº”å¹´äº†éƒ½æ²¡è§£å†³å¾ˆæ— è¯­ã€‚intelç‰ˆå°±ä¸ä¼š
  - ç†è§£ä¸ºæ²¡æ³•ç‚¹å¯¹ç‚¹å°±è¡Œ

- æ‰€ä»¥å¾ˆå¤šåšä¸»æŽ¨èè‹¹æžœé…4kæ˜¾ç¤ºå™¨ï¼Œå°±æ˜¯è¦å®ƒé»˜è®¤1080pçš„hidpiã€‚æœ€é‡è¦çš„ä¸€ç‚¹æ˜¯macçš„åº”ç”¨ä¸èƒ½éšæ„æ”¹å˜çª—å£å¤§å°ï¼Œå¿…é¡»è€ƒè™‘è¿™ä¸ªé—®é¢˜ï¼ˆ720påœ¨ç”¨QQéŸ³ä¹å¯èƒ½ä¼šä¸Žç¨‹åºåžé‡å ï¼‰

- ä¸€èˆ¬æ¥è¯´2kæ˜¾ç¤ºå™¨é»˜è®¤720pçš„hidpi

- [Macå¤–æŽ¥ä¾¿æºå± - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/68b697cf000000001d03b010?xsec_token=ABUJretia2o2VefwJarjPWkuB5UQVMIEKT9s7nuAqwVcs=&xsec_source=pc_search&source=web_search_result_notes)
  - è¦ä¸ç„¶ 1080 è¦ä¸ç„¶ 4kï¼Œmac ç”¨ 2.5 æ˜¯ä¸è¡Œçš„
  - mac çš„ hidpi å¯¼è‡´åˆå¹¶åƒç´ å˜æˆ 720pï¼Œç›´æŽ¥çœ‹ 2.5k çš„è¯å°çš„æ²¡æ³•çœ‹ï¼Œå…¶å®ƒåˆ†è¾¨çŽ‡ä¼šç³Š
  - é‡æ–°ä¹°äº†ä¸€ä¸ª4kçš„ æ„Ÿè§‰ä¸é”™

- [Mac mini + 2.5k è§¦æ‘¸ä¾¿æºåŒå± - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/677691f1000000000902d752?xsec_token=AB-RIwo7Ptt2-VRNMWpcTa4IqKO9_fbiWVFPRQBKISJ7U=&xsec_source=pc_search&source=web_search_result_notes)
  - 2.5k è™½ç„¶å¼€äº† hidpi åªæœ‰1260*800åˆ†è¾¨çŽ‡ï¼Œ ä½†åœ¨16å¯¸å±å¹•ä¸Šå­—ä½“æ˜¾ç¤ºæ¯”è¾ƒèˆ’æœï¼Œä¸ä¼šåƒåŠ›ï¼Œç¼ºç‚¹æ˜¯åŒå±è§¦æ‘¸å±å¾ˆé‡ï¼ˆ2.1kgï¼‰ï¼Œå·²ç»ä¸èƒ½ç®—ä¾¿æºäº†

- ## [macæ€Žä¹ˆé€‰ä¾¿æºå¤–æŽ¥å±ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/539704864)
- ä¾¿æºçš„è¯å°±ipadproå¾ˆé€‚åˆï¼Œå¹³æ—¶å¯ä»¥å½“padç”¨ï¼Œçœ‹çœ‹ç”µå½±ï¼Œè®°è®°ç¬”è®°ï¼Œå¹²æ´»çš„æ—¶å€™å°±å¯ä»¥ä½œä¸ºå¤–æŽ¥å±ï¼Œå¾ˆæ–¹ä¾¿ã€‚

- ## [è‹±ç‰¹å°”æ€Žä¹ˆå¯èƒ½ä¸€å¹´ä¹‹é—´å°±æ²¡è½äº†ï¼Ÿ - çŸ¥ä¹Ž _202410](https://www.zhihu.com/question/2005473234)
- pcç«¯åªæ˜¯è¡¨è±¡ï¼ŒçœŸæ­£æ‰“æ–­inteléª¨å¤´çš„æ˜¯æœåŠ¡å™¨ç«¯ã€‚zenåˆšæŽ¨å‡ºçš„æ—¶å€™ï¼Œ16~32æ ¸çº¿ç¨‹æ’•è£‚è€…ï¼Œå¹³å‡æ¯æ ¸æˆæœ¬å’Œå”®ä»·æ¯”å¿—å¼ºä½Žï¼Œçº¿ç¨‹æ’•è£‚è€…ä¸€æŽ¨å‡ºå°±æ”¶åˆ°å¸‚åœºå¥½è¯„ï¼Œ28æ ¸ä»¥ä¸‹çš„å¿—å¼ºå¸‚åœºç«‹åˆ»é­å—çº¿ç¨‹æ’•è£‚è€…çš„ç“œåˆ†ã€‚
  - åŽç»­zen2æž¶æž„ä¸‹ï¼ŒæŽ¨å‡ºæœ€é«˜64æ ¸å¿ƒ128çº¿ç¨‹çš„éœ„é¾™æœåŠ¡å™¨ï¼Œå¿—å¼ºå¹³å°ä¸€ä¸ªèƒ½æ‰“çš„éƒ½æ²¡æœ‰ï¼Œè®ºæ€§èƒ½ï¼Œæ‹¼ä¸è¿‡ï¼Œè®ºä»·æ ¼æ‹¼ä¸è¿‡ï¼Œè®ºèƒ½è€—ï¼Œæ‹¼ä¸è¿‡ï¼Œå”¯ä¸€å¯ä»¥æ‹¿å‡ºæ‰‹è¯´è¯çš„å°±æ˜¯å¿—å¼ºçš„å†…å­˜å»¶è¿Ÿæ›´ä½Žã€‚
  - åˆ°äº†zen3æ—¶æœŸï¼Œéœ„é¾™æœåŠ¡å™¨ç¼“å­˜è¿›ä¸€æ­¥å¢žå¤§ï¼Œå»¶è¿Ÿç›¸æ¯”å¿—å¼ºç”šè‡³ç•¥æœ‰ä¼˜åŠ¿ï¼ŒIPCä¹Ÿæ¯”å¿—å¼ºå¥½ï¼ŒåŠŸè€—ä¹Ÿæ›´ä½Žï¼Œä¸€é¢—64æ ¸å¿ƒ128çº¿ç¨‹çš„éœ„é¾™Uï¼Œä»·æ ¼ä¸€ä¸‡å¤šç¾Žå…ƒï¼Œè€ŒIntelè¿™è¾¹è¿Ÿè¿ŸæŽ¨ä¸å‡ºæ–°ä¸€ä»£å¿—å¼ºï¼Œè¿˜æ˜¯28æ ¸å¿ƒ56çº¿ç¨‹çš„å¿—å¼ºå½“é“ï¼Œä»·æ ¼ä¹Ÿè¦1ä¸‡å¤šç¾Žå…ƒï¼Œä½ æ˜¯å•†å®¶ï¼Œä½ é€‰è°ï¼Ÿ
  - zen4æ—¶æœŸï¼Œéœ„é¾™ç»§ç»­é¢†å…ˆï¼Œå¿—å¼ºè¿˜æ˜¯è¢«åŽ‹ç€æ‰“ï¼Œåªèƒ½åƒåƒè€æœ¬ï¼ŒæŽä¸å‡ºä»€ä¹ˆè®©äººæ»¡æ„çš„æ–°Uã€‚
- å¸‚åœºç»Ÿè®¡ï¼Œå¿—å¼ºä»½é¢è¿˜æ˜¯é¢†å…ˆäºŽéœ„é¾™ï¼Œä½†æ˜¯é‚£æ˜¯åŽ†å²ï¼Œæ²¡ä»€ä¹ˆåµç”¨ï¼Œæ–°çš„å¤§è®¢å•åŸºæœ¬æ˜¯éœ„é¾™åƒä¸‹äº†ï¼Œå¿—å¼ºåªèƒ½åƒåƒè€æœ¬çš„æ›´æ–°æ¢ä»£ï¼Œæ ¹æœ¬ä¸è§£æ¸´ã€‚
- Intelçš„å›°å±€æœ¬è´¨ä¸Šæ˜¯æ€§èƒ½æ›´é«˜çš„å¿—å¼ºå¹³å°å·²ç»å¾ˆä¹…æ²¡æ›´æ–°æŠ€æœ¯ï¼ŒæŠ€æœ¯ä¸‹æ”¾æ›´æ˜¯æ— ä»Žè°ˆèµ·ã€‚PCç«¯çš„ç¼ç¼è¡¥è¡¥è¿˜èƒ½å’Œamdæ‰“å¾—æœ‰æ¥æœ‰å›žï¼Œæ··ä¸ª28å¼€ã€46å¼€ã€55å¼€ï¼ŒæœåŠ¡å™¨ç«¯çœŸçš„æ˜¯ä¸€è´¥æ¶‚åœ°ã€‚

- ä¸çŸ¥é“çš„ä»¥ä¸ºè‹±ç‰¹å°”è¿˜åœ¨æŒ¤ç‰™è†ï¼Œå…¶å®žæ˜¯è‹±ç‰¹å°”è‚šé‡ŒçœŸæ²¡è´§ã€‚

- æœåŠ¡ç«¯æ±‚ç¨³ï¼Œï¼Œè·¯å¾„ä¾èµ–ç»™Intelåƒè€æœ¬äº†ä¸¤å¹´ï¼Œzen2çš„æœåŠ¡å™¨æˆ‘å°±æµ‹è¿‡äº†ï¼ŒçœŸæ˜¯æ€§ä»·æ¯”åŠæ‰“Intelï¼Œè€Œä¸”ä¸ºäº†å¥½è¿ç§»ç¨‹åºAMDç»å¸¸æ˜¯å•è·¯å¯¹åŒè·¯

- æ—§çš„è¶…ç®—ä¸­å¿ƒéƒ½æ˜¯iUï¼Œç¨å¾®æ–°çš„å°±æ˜¯AUäº†ï¼›å½“ç„¶å›½äº§Uä¹Ÿæœ‰ï¼Œç”¨è¿‡å›½äº§æµ·å…‰X86
  - åŽä¸ºçš„å‰é˜¶æ®µå›½å®¶è¿˜æœ‰è¡¥è´´ï¼Œå¯¹äºŽå°å¾®ä¼ä¸šè¿˜æ˜¯æœ‰ç›¸å½“å¸å¼•åŠ›ï¼Œæ¯•ç«Ÿäº‘ä¸»æœºèƒ½ç”¨ä»·æ ¼ä½Žå°±æ˜¯çŽ‹é“ã€‚

- å°±å›½å†…å¸‚åœºè€Œè¨€ï¼Œæˆ‘è§‰å¾—æ˜¯è¢«æµ·å…‰æ‰“è´¥çš„ï¼Œæˆ‘å¸å·²ç»2å¹´æ²¡é‡‡è´­intelçš„æœåŠ¡å™¨äº†ï¼Œå…¨æ˜¯æµ·å…‰å’Œé²²é¹ã€‚
- æµ·å…‰å°±æ˜¯zen1æž¶æž„

- æ€§èƒ½å¼ºçš„çš„æœ‰amdï¼Œä½ŽåŠŸè€—çš„æœ‰armçš„ã€‚è¢«æŒ¤äº†ã€‚

- intelæŠ€æœ¯å‡ºçŽ°äº†ä»€ä¹ˆé—®é¢˜äº†ï¼Ÿ
  - ä¸€åˆ‡æºè‡ª10nméš¾äº§â€¦â€¦å·¥è‰ºä¸Šä¸åŽ»å¾ˆéš¾å †æ ¸â€¦å †æ ¸äº†å‘çƒ­å’ŒåŠŸè€—å€å¢žå¯¹dcæˆæœ¬ä¸åˆ’ç®—â€¦â€¦
  - å †ä¸äº†æ ¸ï¼Œæž¶æž„å‡çº§ä¸äº†

- epyc å¯¹äºŽä¼ä¸šæ¥è¯´çœçš„è¿œä¸æ­¢æ˜¯ cpu å·®ä»·çš„é’±ï¼Œæ•´å°æœåŠ¡å™¨é™¤äº† cpu å¤–çš„å…¶ä»–ç¡¬ä»¶ã€æœºæŸœã€ç”µåŠ›ç­‰ï¼Œç”¨ epyc ä¸€å°èƒ½é¡¶è‡³å¼ºå¥½å‡ å°ï¼Œçœä¸‹çš„é’±å¯ä¸æ˜¯ä¸ªå°æ•°å­—

- PC DIYå¸‚åœºå¯¹äºŽåŽ‚å®¶è€Œè¨€æ˜¯æœ€é¸¡è‚‹çš„ï¼Œåˆ©æ¶¦ä¸é«˜ä½†éŸ³é‡å¾ˆå¤§ã€‚å•†ç”¨ã€ä¸“ä¸šé¢†åŸŸç”šè‡³æ¸¸æˆä¸»æœºéƒ½æ˜¯æ›´ä¼˜è´¨çš„å¸‚åœºã€‚ä½†æ˜¯å¯¹äºŽä¸€ä¸ªäº§å“å¯¼å‘çš„å…¬å¸æ¥è¯´ï¼Œä»–ä¸ä¼šéšæ„ä¸¢å¼ƒæŸä¸ªå¸‚åœºï¼Œåªæ˜¯æ”¯æŒåŠ›åº¦çš„é—®é¢˜ã€‚PC DIYå¸‚åœºåœ°ä½åœ¨ç›®å‰åŸºæœ¬å°±å’Œè®¨é¥­çš„å·®ä¸è¿œ

- æœ‰æ²¡æœ‰å¯èƒ½ï¼Œä»Žåå¹´å‰å°±å¼€å§‹æ²¡è½äº†ã€‚intel7ï¼ˆ10nmï¼‰è¿™ä¸ªå·¥è‰ºåº”è¯¥åœ¨2016å¹´å°±å‡ºæ¥çš„ï¼Œç»“æžœåˆ°2024å¹´äº†è¿˜åœ¨ç¼©è‚›ã€‚

- intelå²‚æ­¢æ˜¯åœ¨cpuä¸Šæ‹‰èƒ¯äº†ï¼Œè¿™å‡ å¹´ç äº†å¤šå°‘æ–¹å‘äº†ï¼Ÿç äº†ï¼ŒFPGAæ‹†åˆ†äº†ï¼Œæ”¾å¼ƒã€‚è¯´æ˜¯è¦æŠŠå·¥ä½œé‡å¿ƒæ”¾åœ¨cpuä¸Šï¼Œå¯æ˜¯å·¥è‰ºæ—©å°±è¢«å°ç§¯ç”µç”©å¼€ã€‚æœ€é‡è¦çš„æœåŠ¡å™¨é¢†åŸŸç”šè‡³æ‹¿ä¸å‡ºå’ŒAMDæ——èˆ°åž‹å·å¯¹æ ‡çš„äº§å“ã€‚è¦æˆ‘è¯´çŽ°åœ¨è¿™ä¸ªè¡°é€€é€Ÿåº¦è¿˜ç®—æ…¢çš„ï¼Œè¦ä¸æ˜¯æœ‰ä½¿ç”¨æƒ¯æ€§ï¼Œintelåº”è¯¥æ›´åž®ä¸€äº›ã€‚

- ## [çº¿ç¨‹æ’•è£‚è€…è¿™ç§æ ¸å¿ƒè¶…å¤šçš„CPUä¸»è¦èƒ½ç”¨æ¥åšä»€ä¹ˆï¼Œæ¥ä½¿ç”¨æŽ‰ç»å¤§éƒ¨åˆ†æ ¸å¿ƒï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/500819181/answers/updated)
- å¯¹äºŽæ™®é€šå®¶ç”¨ç”µè„‘æ¥è¯´ï¼Œåˆ«è¯´8æ ¸å¿ƒï¼Œ4æ ¸å¿ƒåŸºæœ¬å°±èƒ½æ»¡è¶³è®¸å¤šéœ€æ±‚äº†ï¼Œè¿™æ˜¯å› ä¸ºå¤§éƒ¨åˆ†çš„å¸¸ç”¨è½¯ä»¶å¹¶æ²¡æœ‰å¯¹å¤šæ ¸å¿ƒå¤„ç†å™¨è¿›è¡Œä¼˜åŒ–ï¼Œå³ä½¿ä½ çš„CPUæ ¸å¿ƒæ•°é‡å†å¤šä¹Ÿç”¨ä¸åˆ°ï¼Œç›¸å½“äºŽæµªè´¹ï¼Œä½†æ˜¯åƒ[çº¿ç¨‹æ’•è£‚è€…]è¿™æ ·çš„è¶…å¤šæ ¸å¿ƒCPUå¯ä»¥åœ¨ä¸“ä¸šé¢†åŸŸæ–¹é¢å‘æŒ¥å¾ˆå¤§çš„ä½œç”¨ã€‚
  - 3Då›¾å½¢æ¸²æŸ“ã€æ•°æ®ä¸­å¿ƒå’Œè§†é¢‘å¤„ç†è¿™äº›å·¥ä½œéƒ½å¯ä»¥éžå¸¸å¥½çš„åˆ©ç”¨å¤šæ ¸å¿ƒå¤„ç†å™¨çš„æ€§èƒ½ï¼Œæ›´å¤šçš„æ ¸å¿ƒå°±èƒ½èµ·åˆ°æ›´å¤šçš„ä½œç”¨
- å¦å¤–ï¼ŒCPU [X86æž¶æž„] ç»è¿‡å¤šå¹´çš„å‘å±•ï¼Œå¦‚ä»Šæƒ³è¦å¤§å¹…åº¦æå‡å•æ ¸æ€§èƒ½å·²ç»å¾ˆéš¾äº†ï¼Œæ‰€ä»¥è‹±ç‰¹å°”å’Œ[AMD] éƒ½åœ¨æƒ³æ–¹è®¾æ³•å¢žåŠ CPUæ ¸å¿ƒæ•°é‡ï¼Œé€šè¿‡å¤šæ ¸ååŒå·¥ä½œæ¥æå‡CPUæ€§èƒ½ï¼Œæœªæ¥è¿˜ä¼šæœ‰è¶Šæ¥è¶Šå¤šçš„è½¯ä»¶å’Œæ¸¸æˆå¯¹å¤šæ ¸å¤„ç†å™¨è¿›è¡Œä¼˜åŒ–ï¼Œæ‰€è°“çš„â€œä¸€æ ¸æœ‰éš¾ï¼Œå…«æ ¸å›´è§‚â€çš„å°´å°¬åœºæ™¯ä¼šè¶Šæ¥è¶Šå°‘

- å¼ºè®¡ç®—ç”Ÿäº§åŠ›ç”¨é€”åŒ…æ‹¬3Dæ¸²æŸ“ï¼Œå½±è§†åˆ¶ä½œæ¸²æŸ“ï¼ŒCGåŠ¨ç”»ï¼Œæœ‰é™å…ƒåˆ†æžCFDï¼Œ[Fluent]ï¼ŒSASï¼ŒPythonï¼Œé‡åŒ–äº¤æ˜“ï¼Œ[è‚¡ç¥¨é‡åŒ–ç­–ç•¥]ï¼Œå›žæµ‹ï¼Œé«˜é¢‘äº¤æ˜“ï¼Œæ·±åº¦å­¦ä¹ å’Œæœºå™¨å­¦ä¹ ï¼Œè‡ªåŠ¨æ ‡è®°ï¼Œè®­ç»ƒï¼ŒæŽ¨ç†ï¼Œå¹³é¢ç¾Žå·¥ï¼Œæ¸¸æˆç¨‹åºå¼€å‘ï¼Œèƒ½èµšé’±çš„æ¸¸æˆç›´æ’­ä¸»æ’­ï¼Œæ¸¸æˆå·¥ä½œå®¤ç­‰ç­‰

- å·¥ä½œç«™ï¼ŒæœåŠ¡å™¨ï¼Œå¤šå¼€è™šæ‹Ÿæœºã€‚

- ç¼–è¯‘ ~ æ¯”å¦‚chromiumï¼Œè™šå¹»å¼•æ“Ž 100æ ¸ä¹Ÿä¸å¤šâ€¦

- ## [é«˜ç«¯æ˜¾å¡ä¹°å“ªä¸ª 4090-48g vs 5090-32g - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/685fdabf000000002400c5fb?xsec_token=ABXvcJCtj5SgpnxaAuvQTSjGIPWgAdou5ozGSko5ifxSI=&xsec_source=pc_search&source=web_explore_feed)
  - 48GBç‰ˆæœ¬4090æ˜¯æ¶¡è½®ç‰ˆé­”æ”¹çš„ï¼Œæ€§èƒ½æ¯”4090ä¸»æœºç‰ˆä½Ž20%æ€§èƒ½ã€‚å¹¶ä¸”è¢«æ”¹çš„å¡ä¸ä¸€å®šæ˜¯ä¸€æ‰‹å¡ï¼Œä¹Ÿæ²¡æœ‰å®˜æ–¹è´¨ä¿ã€‚åº—å®¶ä¼šä¿ä¸€å¹´ã€‚
  - 5090ç›®å‰çš„é€‚é…å¹¶ä¸å®Œå–„ï¼Œè¦æ±‚æ–°é©±åŠ¨ã€‚å¯¹å°‘æ•°æ·±åº¦å­¦ä¹ é¡¹ç›®æœ‰å…¼å®¹æ€§é—®é¢˜ã€‚

- æˆ‘å…¶å®žä¸å¤ªç†è§£ä¸ºå•¥5090æ‰ç»™32g
  - åˆ€æ³•ï¼Œç»™å¤šäº†å½±å“ç®—åŠ›å¡å‡ºå”®ã€‚åŽç»­çš„å¡å¯èƒ½ä¼šå–ä¸åŠ¨ã€‚
  - GTXå®šä½ä¸æ˜¯è·‘æ¨¡åž‹ï¼ŒæŒ‰æœ€åˆçš„è®¾æƒ³ï¼Œç®—åŠ›å¡æ‰æ˜¯è·‘æ¨¡åž‹çš„ã€‚è¿™æ ·å°±èƒ½é€šè¿‡NvlinkæŠ€æœ¯å…±äº«æ˜¾å­˜ã€‚
- äººå®¶å®šä½å°±æ˜¯æ¸¸æˆæ˜¾å¡ï¼Œä»€ä¹ˆæ¸¸æˆèƒ½ç”¨çˆ†32Gæ˜¾å­˜ï¼Ÿè·‘æŽ¨ç†è®­ç»ƒåŽ»ä¹°pro6000å•Š

- 5090è¯´ä¸å®šèƒ½æ”¹64GBï¼Œè¯´ä¸å®šä¹‹åŽä¼šæœ‰äººæ”¹
  - å¾ˆéš¾ï¼Œæ²¡æœ‰bios

- ç›®å‰ç”¨ 8 å¼  4090-48 æŒºç¨³å®šçš„
- æ¶¡è½®å¡å—ï¼Ÿ
  - æˆ‘å¬è¯´æ”¹48GBçš„åŸºæœ¬ä¸Šæ˜¯æ¶¡è½®ç‰ˆï¼Œå› ä¸ºè¿™æ ·åˆ©æ¶¦æœ€å¤§ã€‚
  - ä¸ä½†æ˜¯åˆ©æ¶¦ï¼Œæ¶¡è½®å¡æ˜¯åŒæ§½ï¼Œä¸€ä¸ªæœºç®±å†…å¯ä»¥å¡žæ›´å¤šçš„å¡

- 48GBé­”æ”¹ç‰ˆå¯ä»¥å¤šå¼ å¡å åŠ æ˜¾å­˜å˜›
  - å¯ä»¥å¼ é‡å¹¶è¡Œéƒ¨ç½²æ›´å¤§çš„æ¨¡åž‹
- ç¨³å®šçš„è¯åº”è¯¥æ²¡é—®é¢˜ï¼Œç»„é‡Œæœ‰åå‡ å¼ éƒ½æ²¡å•¥é—®é¢˜
- ä¸èƒ½ï¼Œå¤šå¡å åŠ æ˜¾å­˜å¿…é¡»åŽ»ä¹°è€é»„çš„ä¸“ä¸šaiè®¡ç®—å¡

- æžRTX pro 6000ï¼Œä¸€å¼ å°±96Gæ˜¾å­˜äº†
  - 8ä¸‡å¤šå¯ä»¥æžå››å¼ äº†
  - çŽ°åœ¨ä»·æ ¼6w5å·¦å³

- è¿˜æ²¡ä¹°ï¼Œæˆ‘æ¯”è¾ƒä¿å®ˆï¼Œæ€•48GBçš„æœ‰é—®é¢˜ï¼Œå€¾å‘äºŽ5090ã€‚
  - å­˜åœ¨å…¼å®¹æ€§å·®çš„é—®é¢˜ï¼ŒåŒè¯¾é¢˜ç»„æœ‰äººä¹°äº†5070ï¼Œä»–è¯´è¦æ±‚æ›´ç‰ˆæœ¬çš„pytorchï¼ˆå› ä¸ºæ”¯æŒçš„cudaç‰ˆæœ¬å¿…é¡»é«˜ï¼‰ï¼Œæ‰€ä»¥ä½Žç‰ˆæœ¬çš„pytorché¡¹ç›®è·‘ä¸èµ·æ¥ã€‚
  - 12.8ç­‰é«˜ç‰ˆæœ¬çš„pytorchä¸æ”¯æŒå¾ˆå¤šé¡¹ç›®é¡¹ç›®çš„

- æ‰“æ¸¸æˆå°±è€è€å®žå®žä¹°5090ï¼Œaiéƒ½æ˜¯ä¼ªéœ€æ±‚ï¼Œæ²¡å‡ ä¸ªç”¨å¾—ä¸Šçš„ï¼ŒçœŸæ­£æœ‰éœ€æ±‚çš„ä¼šåŽ»ä¹°aiå¡
  - è·‘æ¨¡åž‹ä¸ºå•¥è¦ä¹°Geforceï¼Œä¹°telsaçš„H200ï¼ŒH100ä¸é¦™ä¹ˆï¼Œå†æ¬¡ç‚¹Quadroè¿™ç§ä¸“ä¸šå¡éƒ½æœ‰Pro 6000ï¼Œè·‘aiå®Œå…¨åŠæ‰“5090ï¼ŒçœŸçš„æœ‰éœ€æ±‚çš„äººä¹°ä¸èµ·ä¹Ÿä¼šåŽ»ç§Ÿçš„

- 5090é…çŽ¯å¢ƒè¿˜æ˜¯éº»çƒ¦ï¼Œå¹²æ´»çš„çŽ°åœ¨ç”¨4090ä¸€å¹´åŽå†è€ƒè™‘5090

- ## [8Ké…çš„å·¥ä½œç«™åŠ 4090 48G æˆåŠŸè·‘èµ·Deepseek - å°çº¢ä¹¦ _202504](https://www.xiaohongshu.com/explore/67fa372d000000001e00ba5a?xsec_token=ABufSAS9QghohUw1fzyX0iVOG5KQLPpvxE2fkT2okUTlk=&xsec_source=pc_search&source=web_explore_feed)
  - è¿è¡Œçš„æ˜¯ikawrakow/ik_llama.cpp/è¿™ä¸ªåº“ï¼Œä»–ç”¨ AVX2 æŒ‡ä»¤é›†åšäº†è®¸å¤šä¼˜åŒ–
  - è¿è¡Œçš„æ˜¯ Q2 çš„ç‰ˆæœ¬çš„ deepseek v3ï¼Œå ç”¨å†…å­˜ 222Gï¼Œæ˜¾å­˜ 20Gï¼Œæ‰€ä»¥æ™®é€š 4090 ä¹Ÿèƒ½è·‘èµ·æ¥
  - è¾“å…¥ 41 t/s, è¾“å‡º 8 t/s
  - æˆ‘ç”¨çš„æ˜¯è”æƒ³ P620å‡†ç³»ç»Ÿ+256 å†…å­˜ 8K å¤šç‚¹çš„ä»·æ ¼
  - è¿™ä¸ª P620 å‡†ç³»ç»Ÿä¹Ÿä¸å·® 5945ws çº¿ç¨‹æ’•è£‚è€… è”æƒ³é”æœº U å¯ä»¥è·‘åˆ° 4.5G ååˆ†ä¾¿å®œ 5 6 ç™¾å·¦å³å§
  - PCIE æ’æ§½å¤š 128é€šé“ï¼Œæ¯ä¸ªæ’æ§½éƒ½å¯ä»¥æ‹†åˆ†ï¼Œä»¥åŽæ‰©å±•æ¯”è¾ƒæ–¹ä¾¿
  - 8 é€šé“ DDR4 3200å†…å­˜ï¼Œä¸æ¯” DDR5 æ…¢ï¼Œä¸€æ¡ 32G 200 å·¦å³
  - å”¯ä¸€ç¼ºç‚¹ï¼Œä¸»æ¿çš„1000w ç”µæºæ²¡æ³•æ›´å¤§äº†ï¼Œä¸»æ¿æ’æ§½ä¹Ÿä¸æ”¯æŒä¸¤ä¸ªé«˜åŠŸçŽ‡æ˜¾å¡ï¼Œæ‰€ä»¥æƒ³åœ¨è¿™ä¸ªç³»ç»Ÿä¸Šæ’åŒ 4090 æ˜¯æ²¡æˆï¼Œä½†å¯ä»¥æ’ 2 ä¸ª A6000ã€‚
  - åŒä»·ä½çš„ PC æ˜¯å®Œå…¨æ²¡æ³•æ¯”çš„ã€‚è™½ç„¶æˆ‘è¿™äº›éƒ½æ˜¯äºŒæ‰‹ï¼Œä½†å‡ ç™¾å—çš„ cpu å°±æ˜¯åäº†æ¢ä¸€ä¸ªä¹Ÿæ²¡å•¥å¿ƒç–¼
  - æˆ‘è°ƒæŸ¥è¿‡å…¶ä»–çš„å·¥ä½œç«™æœåŠ¡å™¨ï¼Œepyc å¿—å¼ºï¼Œæˆ‘è§‰å¾—éƒ½ä¸å¦‚çº¿ç¨‹æ’•è£‚è€…ï¼Œå¹³æ—¶å½“ AI æœåŠ¡å™¨ï¼Œå¶å°”è¿˜å¯ä»¥å‰ªå‰ªç‰‡å­æ€§èƒ½ä¹Ÿå¾ˆå¥½ã€‚

- æˆ‘ä¹°çš„å¸¦cpuçš„å‡†ç³»ç»Ÿï¼Œè¿™ä¸ªcpué”è”æƒ³çš„ä¸»æ¿ï¼Œæ‰€ä»¥ä¾¿å®œ

- é—®ä¸‹è¿™ä¸ªæœºå™¨çš„ç”µæºæ€Žä¹ˆæŽ¥ï¼Œæœºå™¨æœ¬èº«ç”µæºåªæœ‰ä¸¤æ ¹æ˜¾å¡ç”µæºæŽ¥å£çš„çº¿ï¼Œ4090è‡³å°‘è¦ä¸‰æ ¹
  - ä¸¤æ ¹8pinè½¬ 4090 16pinçš„å°±å¯ä»¥äº†

- è¿™ç§é­”æ”¹çš„æ˜¾å­˜å®˜æ–¹é©±åŠ¨æ”¯æŒå—
  - æ”¯æŒ

- ## [æˆ‘çš„RTX 4090 48Gæ·±åº¦ä½“éªŒæŠ¥å‘Š - å°çº¢ä¹¦ _202503](https://www.xiaohongshu.com/explore/67ca95ca000000000d015047?xsec_token=ABqsyDIYHWnZyXfQUxpaLc8ZkBUCid6Z7dPfToCAZBfTA=&xsec_source=pc_search&source=web_explore_feed)
  - ç”¨4K OLEDç”µè§†æµ‹äº†ã€Šèµ›åšæœ‹å…‹ï¼šå¾€æ—¥ä¹‹å½±ã€‹ï¼Œè·¯å¾„å…‰è¿½å…¨å¼€+DLSS 3.5æ’å¸§ï¼Œç”»é¢æ¯›å‘åå…‰çœŸå®žåˆ°ç¦»è°±â€¦å¸§æ•°å±…ç„¶ç¨³åœ¨98ï¼ä»¥å‰3080ç›´æŽ¥æŽ‰åˆ°40çš„é…’å§éœ“è™¹ç¯åœºæ™¯ï¼ŒçŽ°åœ¨ä¸æ»‘åˆ°æƒ³å“­
  - ç”¨Blenderæ¸²æŸ“å…¬å¸æ–°é¡¹ç›®åœºæ™¯ï¼Œ32GBæ˜¾å­˜ç›´æŽ¥åƒæ»¡ï¼å¦‚æžœæ¢æˆè€æ˜¾å¡ä¼°è®¡è¦å´©â€¦ä½†4090 48Gå±…ç„¶èƒ½è¾¹æ¸²æŸ“è¾¹å¼€ç€AEåšç‰¹æ•ˆé¢„è§ˆï¼Œè¿™æ‰æ˜¯çœŸæ­£çš„â€œç”Ÿäº§åŠ›è§£æ”¾â€
  - å·å·è¯•äº†æœ¬åœ°éƒ¨ç½²70äº¿å‚æ•°AIæ¨¡åž‹ï¼Œ48Gæ˜¾å­˜è·‘å›¾+è®­ç»ƒåŒæ—¶è¿›è¡Œ
  - ç”µæºå»ºè®®1000Wé‡‘ç‰Œèµ·æ­¥ï¼æˆ‘æ—§ç”µæºå¸¦ä¸åŠ¨ç–¯ç‹‚é—ªé€€
  - æœºç®±å°ºå¯¸å¿…é¡»é‡å¥½ï¼Œè¿™å¼ å¡æ¯”iPhone 15è¿˜é•¿2cm
  - éžåˆšéœ€æ…Žå…¥ï¼é™¤éžä½ æ˜¯8Kå‰ªè¾‘/AIè®­ç»ƒ/å¯Œå“¥

- é€‚åˆç¬”è®°æœ¬å—ï¼Ÿ
  - è¿™æ˜¯æ¡Œé¢çº§æ ¸å¼¹ï¼ç¬”è®°æœ¬è¯·è®¤å‡†4090ç§»åŠ¨ç‰ˆï¼ˆå®Œå…¨ä¸æ˜¯ä¸€ä¸ªä¸œè¥¿ï¼‰

- è·‘æ¸¸æˆå’Œæ™®é€š4090æ— ä»»ä½•åŒºåˆ«ã€‚ç”šè‡³åœ¨æ²¡çˆ†æ˜¾å­˜çš„åŸºç¡€ä¸Šï¼Œè·‘AIä¹Ÿå’Œæ™®é€š4090é€Ÿåº¦æ˜¯ä¸€æ ·çš„ï¼Œä¸è¦å¹»æƒ³æœ‰äº†48Gå°±ä¼šæ›´å¿«ã€‚éœ€è¦æŒ‡å‡ºçš„æ˜¯ï¼Œè·‘70bæ¨¡åž‹ç¡®å®žèƒ½å‘æŒ¥48Gçš„ä¼˜åŠ¿ï¼Œä¸å†æ˜¯ä¸€ä¸ªå­—ä¸€ä¸ªå­—è¹¦ã€‚æœ€åŽï¼Œæ¶¡è½®é£Žæ‰‡å™ªéŸ³æžå¤§ï¼Œéƒ¨åˆ†ç”¨æˆ·å¯èƒ½æ— æ³•æŽ¥å—ã€‚

- ## [åŒé¢„ç®—ï¼Œæˆ‘å‘çŽ°äº†æ¯”4090 48gæ›´ä¼˜çš„å¡ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/68933df200000000250232c0?xsec_token=ABJcKpAiG7_wvbIBshcL_hTstuY3ZuJRr7DRybbzYqQno=&xsec_source=pc_search&source=web_explore_feed)
  - å…¬å¸ƒç»“æžœï¼š5880 ada 48gæ˜¾å¡ï¼Œ
  - æŒ‰ç…§nvidiaå®˜æ–¹å‘å¸ƒçš„datasheetï¼Œç®—åŠ›å·®è·åœ¨20%ã€‚æ¯•ç«Ÿè¿™ä¸ªä»·ä½ã€‚è€ƒè™‘ç¨³å®šæ€§ï¼Œå’Œå¤§æ˜¾å­˜ï¼Œè¿™å¡è¿˜æ˜¯æ¯”è¾ƒå¥½çš„é€‰æ‹©
- a6000ä¸ºå•¥æ¯”5880adaè¿˜è´µï¼Ÿ
  - a6000æœ‰ä¸¤ä¸ªç‰ˆæœ¬ï¼Œä¸€ä¸ªæ˜¯a6000 ä¸€ä¸ªæ˜¯6000adaï¼Œä½ è¯´çš„è´µçš„ï¼Œæ˜¯adaç‰ˆæœ¬ï¼Œå±žäºŽæ˜¯4090ä¸€ä»£äº§å“ï¼Œ5880æ˜¯6000adaçš„é˜‰å‰²ç‰ˆ

- 4090çš„æ˜¾å­˜bandwidthå¤ªä½Žäº†
  - å°ä½œåŠæ„Ÿè§‰ä¹Ÿå¤Ÿç”¨äº†ï¼Œæ¯•ç«Ÿè€å¸ˆä»¬çš„ç»è´¹ä¹Ÿä¸è§å¾—èƒ½ä¹°h100è¿™ç±»ã€‚

- è¿™ä¸ªä»·æ ¼æˆ‘åªèƒ½æƒ³åˆ°æ˜¯L20äº†ï¼Œå·®ä¸å¤šçš„ä»·æ ¼ï¼Œæ˜¾å­˜æ¯”4090 48Gå¤§ï¼Œå…³é”®æ˜¯å¯ä»¥ä¸ŠNVLinkè”åˆæ˜¾å­˜ï¼Œæ€§ä»·æ¯”çœŸçš„é«˜ã€‚

- ## [4090 48GçœŸçˆ½ï¼Œç»™å¥³å„¿çš„äººå·¥æ™ºèƒ½å®žéªŒæˆåŠŸ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/67de13d1000000000b0151d1?xsec_token=ABYgeab4C5E3b9gpHBDeBL8cszeX4XJpIaX3RvHVudVRc=&xsec_source=pc_search&source=web_explore_feed)
  - å¾ˆå¤šæœ‹å‹å…³å¿ƒè¿™å—4090 48gã€‚æˆ‘çš„é…ç½®ä¹Ÿè¯´ä¸€ä¸‹ï¼Œæˆ‘æ˜¯è”æƒ³P620 5945wçš„çº¿ç¨‹æ’•è£‚è€…åŠ 256å†…å­˜ï¼Œè¿™ä¸€å¥—ç³»ç»Ÿå¤§æ¦‚8Kï¼Œæ¯”èµ·PCçº§çš„é…ç½®ï¼Œç»æµŽå®žæƒ ï¼Œä¸»è¦æ˜¯PCIEæ‰©å±•å¯ä»¥æœ‰å¾ˆå¤šï¼Œå†…å­˜é€šé“ä¹Ÿå¤šï¼Œå†…å­˜ä¾¿å®œã€‚
  - è·‘å¤§æ¨¡åž‹ï¼Œ32bå¹¶å‘16èƒ½åˆ°400å¤št, è®­ç»ƒæ—¶ï¼Œæ»¡ç²¾åº¦åªèƒ½è·‘1.5b, å¦‚æžœæ˜¯loraå°±æ— æ‰€è°“äº†ï¼Œ32bä¹Ÿå¯ä»¥è·‘ã€‚

- å°æ¨¡åž‹å‚æ•°ä¸å¤ŸæŽ¨ä¸å‡ºæ¥æ€Žä¹ˆåŠžï¼Ÿæ„Ÿè§‰æœ‰å¥½å¤šä¸ç¡®å®šæ€§
  - åªè¦æƒ³åŠžæ³•è®©å®ƒé€šè¿‡æ€è€ƒè¾“å‡ºå’Œagentä»»åŠ¡ç›¸å…³çš„token, æ‰§è¡Œä»»åŠ¡æˆåŠŸçŽ‡å°±ä¼šå¾ˆé«˜ï¼Œä»¥å‰é é•¿cotæ˜¯æ²¡æ³•åœ¨å°æ¨¡åž‹åšçš„ï¼Œé€šè¿‡RLè®­ç»ƒè§£å†³äº†è¿™ä¸ªä»»åŠ¡ï¼Œå¦‚æžœåªè®­ç»ƒç‰¹å®šé¢†åŸŸæˆæœ¬ä¹Ÿä¸é«˜
- ä¸ªäººè®¤ä¸ºå°æ¨¡åž‹æŽ¨ä¸å‡ºæ¥åè€Œæ˜¯ç¡®å®šæ€§å¤ªå¼ºï¼Œè¿‡äºŽä¾èµ–æç¤ºè¯ï¼Œç”¨èµ·æ¥è¯­è¨€æ¨¡åž‹åƒæ–‡ç”Ÿå›¾ä¼¼çš„
  - å…¶å®žä½ è¿™æ ·æƒ³ï¼Œå­¦ä¼šä»Žå¤§é‡å·¥å…·ä¸­æŒ‘é€‰å¯¹çš„ï¼Œä»¥åŠå†™å¯¹å‚æ•°ï¼Œè¿™äº›æ˜¯ä¸éœ€è¦å¤§é‡çŸ¥è¯†çš„ï¼Œåªéœ€è¦è¾“å‡ºç¬¦åˆé€»è¾‘çš„tokenä½œä¸ºä¸Šä¸‹æ–‡ï¼Œå®ƒå°±èƒ½å®Œæˆä»»åŠ¡ã€‚RL+GRPOç»™äº†ä¸€ç§è§£å†³å°æ¨¡åž‹æå‡å¹²æ´»èƒ½åŠ›çš„æ€è·¯

- ## [å¦‚ä½•è¯„ä»· Framework ç¬”è®°æœ¬ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/475249794/answers/updated)
- å–œæ¬¢æŽ¥å£å¤šæƒŠé¸¿14å°±æœ‰3A2Cï¼ŒHKCï¼Œæœºæ¢°é©å‘½è¿™äº›æ‰æ˜¯çœŸçš„æ‡‚å¹³æ°‘äº§å“è¯¥ä»€ä¹ˆæ ·å­çš„åŽ‚å®¶ã€‚
  - framework? äº§é‡å’Œé”€é‡ä¸Šä¸åŽ»ï¼Œåˆæ²¡æœ‰æ—¥ç³»çš„æº¢ä»·çš„æƒ…å†µä¸‹æ ¹æœ¬æ²¡æ³•åšå¥½å“æŽ§ï¼Œé‚£å°±åªèƒ½æ ¹æ®çŽ°æœ‰çš„æ¨¡å…·æ”¹ä¸€æ”¹ã€‚

- è¦æ¨¡å—åŒ–æ²¡é—®é¢˜ï¼Œé¦–å…ˆå…ˆæŠŠæ˜¾å¡å¯æ¢ï¼Œå†…å­˜ï¼Œç½‘å¡ï¼Œç¡¬ç›˜ï¼ŒCPUï¼Œå…¨éƒ¨å¯æ¢ï¼Œä½ å¾—åŽ»è¯´æœintelè®©å®ƒåˆ«æ”¹é’ˆè„šï¼Œä¸ç„¶ä½ è¿™æ”¹ä¸ªCå£å°±æ¨¡å—åŒ–äº†ï¼Ÿ
  - æ˜¯å•Šï¼Œå¯¹äºŽçœŸçš„ç”¨ç¬”è®°æœ¬çš„äººæ¥è¯´ï¼Œæ¨¡å—åŒ–åº”è¯¥æ˜¯åƒ00-10å¹´ä»£ä¸»æµç¬”è®°æœ¬ä¸€æ ·ï¼Œèµ·ç èƒ½è‡ªè¡Œæ›´æ¢cpuå§ã€‚frameworkçš„ä¼ªæ¨¡å—åŒ–åªæ˜¯å¯¹å¤–æŽ¥å£æ¨¡å—åŒ–ç½¢äº†ã€‚

- frameworkè¦åšçš„è¯¥æ˜¯ç¬”è®°æœ¬çš„pcæž¶æž„æ ‡å‡†ï¼Œè¿™ä¸æ˜¯ä¸€ä¸ªå…¬å¸å¯ä»¥åšåˆ°çš„ï¼Œè€Œä¸”è¿˜éœ€è¦æ—¶é—´åŽ»æ‹“å±•ç¡¬ä»¶ç”Ÿæ€

- cpuã€æ˜¾å¡ä¸Žä¸»æ¿ç»‘å®šï¼Œæ›´æ¢ç›´æŽ¥æ¢æ•´ä¸ªä¸»æ¿ï¼Œæ‰€è°“çš„æ¨¡å—åŒ–æ˜¾å¡å°±æ˜¯æŽ¥æ˜¾å¡åžä¹‹å‰è¿˜å¾—å†åŠ ä¸ªæ¨¡å—è½¬æ¢æŽ¥å£ä¹ˆï¼Ÿï¼Ÿå¤§æ¦‚äº†è§£äº†ä¸€ä¸‹è¿™ä¸ªäº§å“çš„çŽ°æœ‰ä¿¡æ¯ï¼Œæˆ‘åªèƒ½è¯´ï¼Œçœ¼å‰ä¸€é»‘ã€‚ä¸ºäº†æ¨¡å—åŒ–è€Œæ¨¡å—åŒ–çš„äº§å“ï¼Œè¯·ä¸è¦æ‰“diyçš„å¹Œå­å™¶éŸ­èœäº†ã€‚

- æ€»ç»“ä¸€ä¸‹ä¸Šè¿°å›žç­”ï¼šè½»è–„å’Œæ¨¡å—åŒ–æ˜¯ä¸å¯å…¼å¾—çš„é±¼å’Œç†ŠæŽŒã€‚ç›®å‰å¾ˆéš¾åœ¨å®Œå…¨è½»è–„å’Œæœ€å¤§ç¨‹åº¦æ¨¡å—åŒ–ä¸­é—´æ‰¾åˆ°ä¸€ä¸ªèƒ½è®©å¾ˆå¤šäººæ»¡æ„çš„â€œåº¦â€ã€‚

- ## ðŸ› [æœ‰æ²¡æœ‰å‰æœŸå°†å°±ç”¨åŽæœŸå¯ä»¥å‡çº§æ‰©å±•åˆ°é¡¶çº§çš„ç”µè„‘é…ç½®ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/15227206505)
- ä½ æƒ³æœ‰é’±äº†å†æžæ‰©å±•ï¼Œæœ€å…³é”®çš„å°±æ˜¯ä¸»æ¿ä¸€å®šè¦ä¹°å¥½çš„ï¼Œå¤§æ¿æ˜¯å¿…é¡»çš„ï¼Œè€Œä¸”æ˜¯è¿‘æœŸå‡ºçš„
  - å¦‚æžœä¸»æ¿ä¹°çš„è€ã€æ—§ã€ä¸ç‰ˆï¼Œé‚£åŽæœŸæ²¡æ³•å‡çº§ï¼Œåªèƒ½å…¨æ¢
  - å…¶ä»–CPUã€æ˜¾å¡ã€å†…å­˜ã€ç¡¬ç›˜ã€ç”µæºéƒ½å¯ä»¥å‡çº§

- ä¸å­˜åœ¨ã€‚æˆ‘çŽ°åœ¨çš„é…ç½®æ˜¯2070Sï¼Œæƒ³å‡çº§ï¼Œè®¡åˆ’ä¿ç•™ç”µæºï¼Œç¡¬ç›˜å’Œå†…å­˜ã€‚ç»“æžœå‘çŽ°ddr5çš„ç‰©ç†æŽ¥å£éƒ½æ”¹äº†ï¼Œæƒ³è¦é‡Šæ”¾æ–°æ˜¾å¡ï¼Œå°±å¿…é¡»è¿žå†…å­˜ä¸€èµ·æ¢äº†ã€‚
  - æ‰€ä»¥ä½ è¦æ˜¯ç”¨ä¹…äº†å†å‡çº§ï¼Œä¼šå‘çŽ°å½“å‰é›¶ä»¶å…¨è¿‡æ—¶äº†ã€‚è€ŒçŸ­æ—¶é—´ä¹‹åŽå°±å‡åˆ°é¡¶é…ï¼Œé‚£ä¸å¦‚å†ç­‰ç­‰ç›´æŽ¥å…¥æ‰‹é¡¶é…ï¼Œæ¯•ç«Ÿç”µå­äº§å“ï¼ŒäºŒæ‰‹ä»·æ ¼æ˜¯è…°æ–©çš„ã€‚
- ä¸€èˆ¬ç”µè„‘å‡çº§ï¼Œå°±æ˜¯é™¤äº†ç¡¬ç›˜ï¼Œç”µæºå¯ä»¥ä¿ç•™ï¼Œå…¶ä»–å…¨æ¢ã€‚

- å…ˆä¹°ä¸€ä¸ªè”æƒ³çš„P620å‡†ç³»ç»Ÿï¼Œå®ƒè‡ªå¸¦äº†æœºç®±ã€80PLUSé“‚é‡‘ç”µæºã€ä¸»æ¿ã€CPUæ•£çƒ­å™¨ä»¥åŠå†…å­˜æ•£çƒ­å™¨ï¼Œè¿™ä¸ªæ˜¯æœ€è´µçš„ï¼Œå¤§æ¦‚æ˜¯5000å…ƒå·¦å³ï¼Œå…¶ä»–çš„æˆ‘ä»¬éƒ½ä¹°ä¸ä¸­ä¸
  - CPUå…ˆç”¨ä¸€é¢—æœ€ä½Žç«¯çš„çº¿ç¨‹æ’•è£‚è€…5945WXï¼Œè”æƒ³é”çš„å¤§æ¦‚700-800å…ƒï¼ŒåŒºåŒº12æ ¸24çº¿ç¨‹çš„ä½Žç«¯CPU
  - å†…å­˜å…ˆç®€å•æ¥4æ¡32Gçš„ [ä¸‰æ˜ŸDDR4 2R] x4 2666MHzçš„ECCå†…å­˜ï¼Œå‡‘ä¸€ä¸ª128Gçš„å†…å­˜å®¹é‡ï¼Œå¤§æ¦‚700å…ƒå·¦å³
  - ç¡¬ç›˜å¦‚æžœå›Šä¸­ç¾žæ¶©ï¼Œå¯ä»¥å…ˆæ¥ä¸€æ ¹[è¥¿æ•°çš„SN7100] 1Tè¿‡æ¸¡ä¸€ä¸‹ï¼Œä¸è¿‡æœåŠ¡å™¨ä¸»æ¿æœ‰éžå¸¸ä¸°å¯Œçš„PCIEæ’æ§½ï¼Œç›´æŽ¥æ’PCIEå›ºæ€æˆ–è€…ç”¨U2å›ºæ€ä¹Ÿæ˜¯éžå¸¸å¥½çš„é€‰æ‹©ï¼Œå¦‚æžœéœ€è¦ç´ ææ¯”è¾ƒå¤šå¯ä»¥è€ƒè™‘ä¸Šä¸€ä¸ªæœºæ¢°ç¡¬ç›˜
  - æ˜¾å¡æˆ‘ä»¬å¯ä»¥æŒ‘ä¸€ä¸ªäº®æœºå¡ï¼Œæ¯”å¦‚[P1000]ï¼Œè¿™å°±åªè¦200å…ƒäº†ï¼ŒUGã€CADå¹¶ä¸æ˜¯ç‰¹åˆ«åƒæ˜¾å¡çš„è½¯ä»¶ï¼Œä¹°P1000è¿™ç§ä½Žç«¯çš„ä¸“ä¸šå›¾å½¢å¡å³å¯
  - è¿™æ ·å­ä¸€å°ç®€ç®€å•å•çš„å»ºæ¨¡å·¥ä½œç«™å°±OKäº†
  - æ—¥åŽæƒ³å‡çº§å¾ˆç®€å•ï¼ŒCPUæ¢æˆ5995WXï¼Œè¿™æ˜¯64æ ¸128çº¿ç¨‹çš„çœŸ çº¿ç¨‹æ’•è£‚è€…ï¼Œå†…å­˜ç®€ç®€å•å•æ‰©å±•åˆ°256Gï¼Œç¡¬ç›˜å¾€æ­»é‡ŒåŠ å°±OK
- è¿™æœºç®±çœŸæ¼‚äº®ã€‚çŽ©è£…æœºï¼ŒçŽ©åˆ°æœ€åŽå°±æ˜¯æœºç®±ã€‚

- è¿™ç§å‡†ç³»ç»Ÿå·¥ä½œç«™ä¸€ä¸ªå¾ˆå®¹æ˜“å¿½ç•¥çš„é—®é¢˜æ˜¯å°±æ˜¯æ˜¾å¡æ— æ³•å®‰è£…æ¸¸æˆçš„æ˜¾å¡ï¼Œæœºç®±ç©ºé—´æœ‰é™è£…ä¸äº†ï¼Œè€Œä¸”è¿™ç§æœºç®±è®¾è®¡æœ¬èº«å°±æ˜¯é¢å¯¹å·¥ä½œç«™æ–¹å‘è®¾è®¡çš„ï¼Œè€Œä¸”åªèƒ½è£…é‚£ç§å·¥ä½œç«™ä¸“ç”¨çš„æ¶¡è½®æ˜¾å¡ï¼Œé‚£ä¸ªå£°éŸ³å¾ˆé…¸çˆ½æœ‰å¤Ÿä½ å—çš„ã€‚
  - åŽæ¥æˆ‘ç”¨å¤–æŽ¥æ˜¾å¡æ–¹å¼è§£å†³äº†æ¸¸æˆæ˜¾å¡ä¸èƒ½è£…å·¥ä½œç«™çš„é—®é¢˜ï¼Œå®žçŽ°äº†èƒ½ç”¨å¤§å†…å­˜åˆèƒ½ç”¨é«˜æ€§èƒ½æ¸¸æˆæ˜¾å¡ã€‚
  - çŽ°åœ¨æ¸¸æˆæ˜¾å¡åŸºæœ¬ä¸Šéƒ½æ˜¯è®¾è®¡å¾ˆé«˜ï¼Œè€Œå·¥ä½œç«™å¯¹æ˜¾å¡é«˜åº¦æ˜¯æœ‰é™åˆ¶çš„ï¼Œé‡Œé¢ç©ºé—´ä¹Ÿå¾ˆå°ä¹Ÿä¸åˆ©äºŽæ•£çƒ­ï¼Œæ‰€ä»¥å¦‚æžœå¯ä»¥é‡æ–°é€‰æ‹©æˆ‘ä»¥åŽä¼šå€¾å‘äºŽç”¨æ¸¸æˆä¸»æœºæ¥åšè®¾è®¡ã€‚

- è¿™é—®é¢˜ä¸æ˜¯å°±ç»™AM5å®šåˆ¶çš„å—ï¼Ÿ
  - ä¸»æ¿ï¼šB850Må¸¦WiFiï¼Œ1200å·¦å³ï¼Œè€ƒè™‘åŽæœŸå‡çº§ä¸€å®šè¦å¼„å—å¥½ç‚¹çš„æ¿å­ï¼Œè¦ä¸ç„¶å‡çº§ä¾›ç”µå¸¦ä¸èµ·æ¥ã€‚
  - CPUï¼šå‡‘åˆç”¨9600Xæˆ–è€…7500Fï¼Œå‰è€…1200åŽè€…800ï¼Œæœªæ¥å¯ä»¥å‡9800X3Dæˆ–è€…9950X3Dï¼Œæ¸¸æˆç”Ÿäº§åŠ›éƒ½å¯ä»¥å…¼é¡¾ã€‚æˆ–è€…æžå—8500Gç”¨æ ¸æ˜¾ï¼Œè¿žäº®æœºå¡éƒ½å¯ä»¥çœã€‚
  - å†…å­˜ï¼š16GÃ—2 6000MHzæˆ–è€…6400Mhzï¼ŒAMDä¸ç”¨ä¸Šé«˜é¢‘å†…å­˜ï¼Œ6000é¢‘çŽ‡åŒé¢‘ç”¨è¿˜çœé’±ï¼ŒåŽæœŸddr5æ™®åŠä¹‹åŽå¯ä»¥å‡çº§32GÃ—2 8000MHzåˆ†é¢‘ç”¨ã€‚
  - æ˜¾å¡ï¼šå‡‘åˆç”¨éšä¾¿æ·˜å¼ äº®æœºå¡å°±è¡Œï¼Œå‡çº§ä¸»æ¿æ”¯æŒpcie5.0ï¼Œåˆ«è¯´5090ï¼Œå°†æ¥6090éƒ½èƒ½è·‘çš„æ»¡ã€‚
  - ç¡¬ç›˜ï¼šå…ˆä¹°å—4.0çš„å›ºæ€ç”¨ç€ï¼Œå°†æ¥å¯ä»¥æ¢pcie5.0çš„å›ºæ€ã€‚
  - ç”µæºï¼šäºŒæ‰‹æ¯”è¾ƒåˆ’ç®—300å—å¯ä»¥æ·˜åˆ°æµ·éŸµ750Wï¼Œå¤§ç‰Œç¨³å®šå¯é è¿˜å®‰é™ï¼Œå‡çº§æ˜¾å¡ä¹Ÿæ²¡ä»€ä¹ˆç“¶é¢ˆï¼Œä¸å¸¦90çº§åˆ«æ˜¾å¡éƒ½æ²¡ä»€ä¹ˆåŽ‹åŠ›ã€‚
  - æœºç®±ï¼šæ­£å¸¸å°ºå¯¸æœºç®±ï¼Œçœ‹ä¸ªäººå–œå¥½ã€‚

- ## [è¿„ä»Šä¸ºæ­¢ï¼Œä½ ç”¨è¿‡çš„æœ€å¥½ç”¨çš„æ•°ç äº§å“æ˜¯ä»€ä¹ˆï¼Ÿå¤¸ä¸€å¤¸? - çŸ¥ä¹Ž](https://www.zhihu.com/question/14769217934)
- è”æƒ³P620å·¥ä½œç«™ï¼Œæœ€ä¾¿å®œçš„çº¿æ’•å·¥ä½œç«™ï¼ŒåŒæ—¶å„ç§æ‹“å±•ç»™å¤Ÿï¼Œæœ‰ä¸‡å…†ã€é›·ç”µã€u2ã€nvmeï¼Œè¿˜æœ‰å››æ§½æƒ³å’‹æ‹†åˆ†å°±å’‹æ‹†åˆ†çš„PCIe4.0x16ï¼Œä¹Ÿä¸ä¼šåƒt7960é‚£æ ·å„ç§ä¸è®¤ç›˜ï¼Œç»§æ‰¿è€æ¿ä»¬çš„é”å¹³å°çº¿æ’•CPUè¿˜èƒ½å†çœä¸€æ¯”é©¬å†…ï¼Œ
  - é™¤äº†ä¸Šä¸äº†æœºæž¶å’Œç”µæºç“¦æ•°åä½Žä¹‹å¤–æ²¡æœ‰ä»»ä½•ç¼ºç‚¹ï¼Œå½“ç„¶ä½ æ”¾åˆ°æœºæŸœæœ€åº•ä¸‹çš„æ‰˜ç›˜ä¹Ÿä¸æ˜¯ä¸è¡Œ
  - æƒ³èµ·æ¥æ²¡å¾—bmcç”¨ï¼Œè¿™ç¡®å®žæ˜¯æœ€å¤§çš„æ§½ç‚¹ï¼Œä¸è¿‡è¦æ˜¯æ‹¿æ¥å½“homelabçš„è¯é‚£å…¶å®žç”¨ä¸å¤ªåˆ°ï¼Œä¸å¦‚å°ç±³æ™ºèƒ½æ’åº§

- [æœåŠ¡å™¨é‡Œçš„åŸºç‰ˆç®¡ç†æŽ§åˆ¶å™¨ï¼ˆBMCï¼‰æ˜¯å“ªä¸ªï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/54716507)
  - BMCæ˜¯ä¸€ä¸ªç‹¬ç«‹äºŽæœåŠ¡å™¨ç³»ç»Ÿçš„å°åž‹æ“ä½œç³»ç»Ÿï¼Œä½œç”¨æ˜¯æ–¹ä¾¿æœåŠ¡å™¨è¿œç¨‹ç®¡ç†ã€ç›‘æŽ§ã€å®‰è£…ã€é‡å¯ç­‰æ“ä½œã€‚BMCæŽ¥é€šç”µæºå³å¯åŠ¨è¿è¡Œï¼Œç”±äºŽç‹¬ç«‹äºŽä¸šåŠ¡ç¨‹åºä¸å—å½±å“ï¼Œé¿å…äº†å› æ­»æœºæˆ–è€…é‡æ–°å®‰è£…ç³»ç»Ÿè€Œè¿›å…¥æœºæˆ¿ã€‚
  - BMCåªæ˜¯ä¸€ä¸ªé›†æˆåœ¨ä¸»æ¿ä¸Šçš„èŠ¯ç‰‡ï¼ˆä¹Ÿæœ‰é€šè¿‡PCIEç­‰å„ç§å½¢å¼æ’åœ¨ä¸»æ¿ä¸Šï¼‰ï¼Œå¯¹å¤–è¡¨çŽ°å½¢å¼åªæœ‰ä¸€ä¸ªæ ‡å‡†RJ45ç½‘å£ï¼Œæ‹¥æœ‰ç‹¬ç«‹IPã€‚æ™®é€šç»´æŠ¤åªéœ€ä½¿ç”¨æµè§ˆå™¨è®¿é—®IP: PORTç™»å½•ç®¡ç†é¡µé¢ï¼ŒæœåŠ¡å™¨é›†ç¾¤ä¸€èˆ¬ä½¿ç”¨BMCæŒ‡ä»¤è¿›è¡Œå¤§è§„æ¨¡æ— äººå€¼å®ˆæ“ä½œã€‚
  - ä¸€èˆ¬æœåŠ¡å™¨BMCç½‘å£æ˜¯ç‹¬ç«‹çš„ï¼Œä»”ç»†çœ‹å°æœ‰BMCå­—æ ·ã€‚ä½†æ˜¯ä¹Ÿæœ‰å°åž‹æœåŠ¡å™¨BMCç½‘å£å’Œé€šä¿¡ç½‘å£æ˜¯äºŒåˆä¸€çš„ã€‚
  - å½“ç„¶ä¹Ÿæœ‰ä¸å«BMCçš„ï¼Œåªè¦éµå®ˆIPMIåè®®ï¼Œéƒ½æ˜¯ç±»ä¼¼çš„ã€‚

- ## [æ¼«æ­¥è€…G1500BRAéŸ³å“æµ‹è¯„ - å°çº¢ä¹¦](https://www.xiaohongshu.com/explore/66d12cf8000000001f038e03?xsec_token=AB38kMIt8DJB5wbhI53QOtqHIYVOHf_3EnOAptaC3-TWM=&xsec_source=pc_search&source=web_search_result_notes)
  - æ€§ä»·æ¯”é«˜ã€7.1çŽ¯ç»•çš„éŸ³æ•ˆã€æœ‰çº¿è¾“å…¥å’Œæ’ç”µæ˜¯USBäºŒåˆä¸€ã€å†…ç½®å£°å¡å¯è°ƒèŠ‚ç­‰
  - æ•´ä½“éžå¸¸ç®€çº¦ï¼ŒåŒ…è£…é‡Œæœ‰éŸ³å“æœ¬ä½“ã€è¯´æ˜Žä¹¦ã€å“ç‰Œè´´çº¸ã€å¯æ’æ‹”éº¦å…‹é£Žï¼Œçº¿æ˜¯ä¸€ç›´åœ¨ä¸Šé¢çš„
  - è™½ç„¶æœ‰ä¸¤ç§è¿žæŽ¥æ–¹å¼ï¼Œè“ç‰™å’Œæœ‰çº¿ï¼Œä½†å®ƒè¿˜æ˜¯æ¯”è¾ƒå€¾å‘äºŽæœ‰çº¿ï¼Œé™¤éžä½ æ‰‹æœºæˆ–è€…å…¶ä»–ä¸èƒ½æ’USBçš„è®¾å¤‡ä½¿ç”¨ï¼Œå¯ä»¥æ’åœ¨æ’åº§ä¸Šï¼Œå¼€å¯è“ç‰™æ¨¡å¼ï¼Œä½†æˆ‘ä¹°å›žæ¥ä¸»è¦æ˜¯ç»™ç”µè„‘ç”¨
  - å¦‚æžœæ˜¯ç”µè„‘æœ‰çº¿ä½¿ç”¨ï¼Œè¿˜å¯ä»¥åŽ»å®˜ç½‘ä¸‹è½½å£°å¡è½¯ä»¶ï¼Œå£°å¡è½¯ä»¶é‡Œçš„åŠŸèƒ½éžå¸¸å¤šï¼Œè™½ç„¶å®ƒé»˜è®¤çš„éŸ³æ•ˆå·²ç»å¾ˆå®Œç¾Žäº†å“ˆå“ˆï¼Œä½†æ˜¯å¯ä»¥è‡ªå®šä¹‰éŸ³æ•ˆï¼Œé€‚åˆä¸åŒäººçš„éœ€æ±‚
  - 7.1çŽ¯ç»•éŸ³æˆ‘ä¸€å¼€å§‹æ˜¯ä¸äº†è§£çš„ï¼Œç›´åˆ°æˆ‘ç”¨äº†è¿™æ¬¾éŸ³å“ä»¥åŽï¼Œå£°éŸ³å°±åƒåŒ…è£¹äº†ä½ çš„è€³æœµä¸€æ ·ï¼Œéžå¸¸æœ‰æ²‰æµ¸æ„Ÿ
  - éŸ³å“æœ‰ä¸‰ç§æ¨¡å¼ï¼ŒéŸ³ä¹æ¨¡å¼å°±æ˜¯ä½ŽéŸ³ä¼šå¼ºä¸€äº›ï¼Œæ¸¸æˆæ¨¡å¼å»¶è¿Ÿä½Žï¼Œå£°éŸ³å¤§ï¼Œç”µå½±æ¨¡å¼å£°éŸ³è¦å°ä¸€äº› æ²‰æµ¸æ„Ÿå¼º
  - éº¦å…‹é£Žç¦»è¿œç‚¹å°±å·®åŠ²äº†ï¼Œæ”¾åœ¨æ˜¾ç¤ºå™¨ä¸‹é¢ï¼Œç¦»å˜´å·´å¤ªè¿œï¼Œåˆ«ä¹°äº†

- ä¸é€‚é…ps5çœŸçš„å¾ˆæ— è¯­
  - ä½†æ˜¯ä»–é€‚é…switch

- æ„Ÿè§‰æˆ‘çš„å¤–æ”¾å£°éŸ³å¥½å°
  - æ¸¸æˆæ¨¡å¼ä¼šå¤§ä¸€äº›

- å¼€å…³æœºçš„å£°éŸ³åªéœ€è¦æŒ‰4 G å’Œ5 éŸ³é‡åŠ  ä¸¤ç§’å°±èƒ½å…³æŽ‰äº†

- ## [ä¸ºä»€ä¹ˆçŽ°åœ¨çš„éŸ³å“å¤§éƒ½æ˜¯è“ç‰™éŸ³å“ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/658012042)
- ä¸€èˆ¬å¥½ç‚¹çš„é‚£äº›ï¼Œéƒ½å«ã€ŠéŸ³ç®±ã€‹ï¼Œè€Œå«ã€ŠéŸ³å“ã€‹çš„ï¼Œéƒ½æ˜¯åªæœ‰çŽ©å¾—ä¸å¤šçš„äººæ‰ä¼šæœç´¢çš„ã€‚

- å‡ ä¹Žæ‰€æœ‰çš„æœ‰æºéŸ³ç®±éƒ½æ˜¯æœ‰æœ‰çº¿è¿žæŽ¥çš„ï¼Œä¸€èˆ¬æ ‡æ³¨ä¸ºï¼šAUXæŽ¥å£ï¼Œ

- ä¸€ä¸ªæ–°é€‰æ‹©â€”â€”Wi-FiéŸ³ç®±ã€‚ä¼ è¾“éŸ³é¢‘çš„æ–¹å¼ï¼Œåªèƒ½ç”¨è“ç‰™å—ï¼Ÿæ˜¯ä¸æ˜¯æœ‰å…¶ä»–æ–¹å¼ï¼Ÿå”‰ï¼Œé‚£å°±å¯¹äº†ï¼â€œWi-Fiå°±æ˜¯å…¶ä¸€ã€‚â€Wi-FiéŸ³ç®±å…¶å®žå·²ç»æŽ¨å‡ºå¸‚åœºå¾ˆä¹…ï¼Œåªæ˜¯åœ¨å›½å†…å°‘æœ‰äººçŸ¥é“ã€‚

- [ä¸ºä»€ä¹ˆæœ‰çº¿éŸ³ç®±å°‘äº†ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/514579467)ã€‘
  - æ²¡æœ‰å°‘ï¼Œåªæ˜¯æœ‰çº¿éŸ³å“ï¼ˆä¸€èˆ¬æŒ‡æœ‰æºéŸ³ç®±ï¼‰ã€‚å¥½ç‚¹çš„éƒ½å¸¦è“ç‰™åŠŸèƒ½ï¼Œæ–¹ä¾¿æ‰‹æœºå¹³æ¿æ— çº¿è¿žæŽ¥

- ## [è”æƒ³æŽ¨å‡ºæ‰¬å¤© M4000q å°å¼æœºï¼Œi5-12400 + 16GB å†…å­˜ï¼Œè¯¥æ¬¾äº§å“æ˜¯å¦å€¼å¾—å…¥æ‰‹ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/518095107)
- DIYçŽ©å®¶æ¥è¯´è‚¯å®šæ˜¯çœ‹ä¸ä¸Šçš„ï¼Œæ²¡æœ‰3080ï¼Œæ²¡æœ‰16ä¸ªPCIeé€šé“ã€‚ä½†æ˜¯ä½ æŠŠä»–çœ‹ä½œä¸€ä¸ªåŠžå…¬ä¸»æœºï¼Œæˆ‘è§‰å¾—æ˜¯éžå¸¸é¦™çš„ã€‚è¿™ä¸ªåŠžå…¬æœºä¸æ¯”é‚£äº›é‡‡è´­ç”¨çš„è‡­é±¼çƒ‚è™¾ä»€ä¹ˆ6ä»£i5è‰¯å¿ƒå¤šäº†ã€‚
  - é…ç½®ä¸Šçœ‹èµ·æ¥å’Œè”æƒ³çš„å®¶ç”¨å¤©é€¸510s æ¯”è¾ƒç±»ä¼¼ï¼Œä¹Ÿéƒ½æ˜¯7Lå°æœºç®±

- ## [ä»Žç¬”è®°æœ¬è½¬ç”¨å°å¼æœºå±å¹•åˆ†è¾¨çŽ‡éƒ½æ˜¯2kï¼Œä½†ä»Ž16å¯¸åˆ°27å¯¸æŒ‰ç†è¯´ä¼šå˜ç³Šï¼Œä¸ä¼šä¸é€‚åº”å—ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/662562760)
- ä¸ä¼šï¼Œå› ä¸ºå°å¼æœºå’Œç¬”è®°æœ¬æœ‰ä¸ªæœ€å¤§çš„åŒºåˆ«ï¼Œå°±æ˜¯è§†è·ã€‚
  - ç¬”è®°æœ¬æ˜¯æ²¡åŠžæ³•çš„ï¼Œä½ æ‰‹æ˜¯è¦æ”¾åˆ°é”®ç›˜ä¸Šçš„ï¼Œè§†è·å‡ ä¹Žå’Œè‡‚é•¿å·®ä¸å¤šï¼Œå¿…é¡»ç¦»è¿‘äº†çœ‹ï¼Œæ‰€ä»¥ppiä¸å¤Ÿçš„è¯ï¼Œé¢—ç²’æ„Ÿå°±ä¼šè®©äººå¾ˆéš¾å—
  - å°å¼æœºåˆ†è¾¨çŽ‡2kå°±å·²ç»å¤Ÿç”¨äº†ï¼Œåªè¦ä½ ä¸æ˜¯è¿‘è§†çœ¼è´´ç€å±å¹•çœ‹ï¼Œ4kå’Œ2kä½“éªŒå·®è·å¹¶ä¸å¤§

- ä¸ºäº†èƒ½è®©27å¯¸æ˜¾ç¤ºå™¨çœ‹èµ·æ¥èƒ½æœ‰ä¸€ä¸ªèˆ’é€‚çš„è§†é‡ŽèŒƒå›´ï¼Œé¢˜ä¸»è‡ªå·±ï¼Œä¸ç”±è‡ªä¸»åœ°å°±ä¼šåœ¨æ›´è¿œäº›ä½ç½®æ¥ä½¿ç”¨
  - æ— è®ºæ˜¯16å¯¸è¿˜æ˜¯27å¯¸ï¼Œä¸ºäº†å¾—åˆ°æ›´å¥½åœ°è§†è§‰ä½“éªŒï¼Œçœ¼ç›ä¸Žå±å¹•çš„è·ç¦»æ˜¯ä¸åŒçš„

- ## [æƒ æ™®æˆ˜99å°å¼æœºå€¼å¾—ä¹°ä¸ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/588726682)
- è¿™æ˜¯æœ‰å²ä»¥æ¥æ€§ä»·æ¯”æœ€é«˜çš„å“ç‰Œæœºäº†è¿™ä¸ªæœºå™¨æˆ‘ä¹Ÿç”¨äº†4ä¸ªæœˆäº†ï¼Œç»™å—æ¡¥ã€å›ºæ€ç¡¬ç›˜åŠ äº†æ•£çƒ­å™¨å’Œæ·»åŠ åŒåž‹å·å†…å­˜æ¡ï¼Œæ”¹è£…ç”µæºå¹¶æ‰©å±•äº†ä¸€å¼ AMD W6400æ˜¾å¡ï¼Œè§£å†³äº†ä¸»æ¿è¿‡çƒ­é—®é¢˜ï¼Œåœ¨2kçŽ¯å¢ƒä¸‹æµç•…è¿è¡Œã€‚æ‰€ä»¥åªèƒ½è¯´ï¼Œè¿™ä¸ªæœºå™¨å¯¹å¾—èµ·è¿™ä¸ªä»·æ ¼ã€‚

- æˆ‘ä¹°çš„æˆ˜99æ¬¾å¼æ˜¯14500é›†æ˜¾æ¬¾ï¼Œä¹Ÿæ‹†æœºç ”ç©¶äº†å†…éƒ¨ï¼Œæˆ‘æ¥è¯´ä¸€ä¸‹ä»–å‡ ä¸ªç¼ºç‚¹å§ï¼š
  - 1. ä¸»æœºå™ªéŸ³è¿‡å¤§
  - 2. å†…å­˜æ¡æ˜¯å•é€šé“ æˆ‘å› ä¸ºæ˜¯æ ¸æ˜¾ï¼Œæƒ³è¿½æ±‚åŒé€šé“åŠ äº†600å…ƒä»Ž16gå‡çº§åˆ°32g, å…¶å®žè¿™æœ¬èº«å·²ç»æº¢ä»·äº†ï¼Œä½†æ²¡æƒ³åˆ°è¿™ä¸æ˜¯ä¸¤æ ¹16g, è€Œæ˜¯ä¸€æ ¹32g
  - 3. å¼€æœºæŒ‰é’®å¤ªç»† å› ä¸ºæŒ‰é’®æ˜¯çªåœ¨æœºå™¨é‡Œï¼Œé æŒ‡è…¹æ ¹æœ¬æŒ‰ä¸ä¸‹åŽ»ï¼Œå¾—ç”¨æŒ‡ç”²æŽã€‚å¾ˆä¸æ–¹ä¾¿ã€‚

- DDR5 å•æ ¹ä¹Ÿæ˜¯åŒé€šé“

- ## [çŽ°åœ¨æœ‰æ”¿åºœ20%è¡¥è´´ï¼ŒåŒæ ·é…ç½®ä¹°å°å¼æœºæ•´æœºæ˜¯å¦æ¯”è‡ªå·±æ•£è£…è¦æ›´åˆ’ç®—å‘¢ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/666757762)
- æ‰“å…«æŠ˜åŽæ•´æœºç¡®å®žæœ‰ä¸€å®šä¼˜åŠ¿ï¼Œå°¤å…¶æ˜¯æ‡’å¾—åŠ¨æ‰‹æˆ–è€…ä¸å¤ªæ‡‚DIYçš„ç”¨æˆ·ï¼Œæœ¬æ¥DIYè¿˜æœ‰ä»·æ ¼ä¼˜åŠ¿ï¼ŒçŽ°åœ¨è¿™æ³¢å…«æŠ˜ä»·æ ¼ä¼˜åŠ¿å‡ ä¹Žè¢«æŠ¹å¹³äº†ã€‚
- çœ‹äº†ä¸€åœˆç”µè„‘çš„ï¼Œè¡¥è´´ä¸»è¦é’ˆå¯¹çš„å“ç‰Œæ•´æœºç¬”è®°æœ¬ä¸€ä½“æœºè¿™ç±»ï¼Œå•ç‹¬é…ä»¶ä¸èƒ½å•ç‹¬è¡¥è´´å§ï¼Œä¹Ÿå°±æ˜¯å¥½åƒä¸èƒ½è‡ªå·±æ”’æœºå™¨é¢†è¡¥è´´å§

- å³ä½¿æ˜¯æœ‰20%æ”¿åºœè¡¥è´´åŽä¾æ—§æ²¡çœ‹åˆ°æ€§ä»·æ¯”å¾ˆé«˜çš„æ•´æœºï¼Œå¦‚æžœæœ‰ï¼Œéº»çƒ¦è¸¢æˆ‘ä¸€è„šã€‚

- æƒ³ä¹°æƒ æ™®æš—å½±ç²¾çµ10+æ˜¾ç¤ºå™¨å¥—è£…14ä»£i5+4060ti+27å¯¸2kæ˜¾ç¤ºå™¨æ‰“æŠ˜åŽ6500è¿™ä¸ªä»·ä½ï¼Œæœ‰ç‚¹ä¹°ä¸»æœºé€æ˜¾ç¤ºå™¨çš„æ„Ÿè§‰

- æˆ‘ä¹Ÿçœ‹äº†ï¼Œç¡®å®žæ²¡æœ‰ã€‚è€Œä¸”è¡¥è´´çš„éƒ½æ˜¯é«˜ä»·æ•´æœºï¼Œä»–é‚£ä¸ªä»·æ ¼ï¼Œä½ èƒ½è‡ªå·±æŒ‘é…ç½®æ”’ä¸€ä¸ªæ›´å¥½çš„ã€‚

- ä½ å¦‚æžœåŽ»äº¬ä¸œæ·˜å®ä¹°é‚£å‡ ä¸ªé”€é‡æœ€é«˜çš„ä¸»æœºåº”è¯¥æ˜¯æ¯”è‡ªå·±ç»„è£…æ›´åˆ’ç®—çš„ï¼Œå“ªæ€•ä¸éœ€è¦è¡¥è´´

- ## [ä¸ºä»€ä¹ˆå°å¼ PC è¿˜å¤„åœ¨ç»„è£…ï¼ˆDIYï¼‰é˜¶æ®µï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/1899923881755678262)
- PCå¹³å°çš„DIYä¼˜åŠ¿ï¼Œä½¿å¾—å®ƒçš„æ¯ä¸€ä¸ªç»†èŠ‚éƒ½ä¸“é—¨åŒ–ã€ä¸“ä¸šåŒ–ï¼Œå› ä¸ºå®ƒå¼€æ”¾

- æˆ‘è§‰å¾—æ‰€æœ‰æ¶ˆè´¹ç”µå­äº§å“éƒ½åº”è¯¥æ¨¡å—åŒ–, PCæ˜¯å”¯ä¸€èµ°åœ¨å‰é¢çš„

- æ‰€è°“çš„å°å¼æœºDIYï¼Œè¯´éš¾å¬ç‚¹ï¼Œä¸è¿‡æ˜¯ä¸€å—å¤§æ¿å„ç§æ’ï¼Œå†æ‹§è¿›ä¸€ä¸ªè¶³å¤Ÿå¤§çš„ç®±å­é‡Œã€‚
  - æˆ‘çš„è§‚ç‚¹å¾ˆç®€å•ï¼Œæ‰‹æœºå‘å±•ä¸å‡ºDIYå¸‚åœºï¼Œæœ¬è´¨ä¸Šæ˜¯å› ä¸ºæ™®é€šäººéƒ½æ˜¯æ‰‹æ®‹ï¼ŒåŽ‚å•†èƒ½æ”¾å¿ƒæŠŠä¸€å †å°ä¸œè¥¿æ‰”ç»™ä½ è‡ªå·±è£…ï¼Ÿ

- 
- 
- 

# discuss-pc-amd/apu
- ## 

- ## 

- ## [AMDé‡å¯å¤šæ˜¾å¡æ”¯æŒï¼æœ€å¤šå››å—ã€192GBæ˜¾å­˜ - å°çº¢ä¹¦ _202406](https://www.xiaohongshu.com/explore/6675185b000000001c025603?xsec_token=ABmlt9aXNo6GSeaJUrfgo6BtVy5GhYovAzw9hCuf6rrE0=&xsec_source=pc_search&source=unknown)
  - AMDæœ€æ–°å‘å¸ƒçš„ROCm 6.1.3å¼€å‘å¥—ä»¶å°±æ”¯æŒåœ¨å•ä¸ªç³»ç»Ÿä¸­é…ç½®å¤šå¼ GPUå¡ã€‚
  - ROCm 6.1.3åœ¨ç‰¹å®šRDNAæ˜¾å¡ä¸Šæ”¯æŒTensorFlowï¼Œåˆæ­¥æ”¯æŒé€šè¿‡Windows WSLå­ç³»ç»Ÿè¿è¡ŒROCmã€‚
  - AMDé‡å¯å¤šæ˜¾å¡æ”¯æŒï¼æœ€å¤šå››å—ã€192GBæ˜¾å­˜, ç›®å‰æ”¯æŒå¤šå¡å¹¶è¡Œçš„åž‹å·ä»…é™RDNA3 Navi31æ ¸å¿ƒçš„é«˜ç«¯ç³»åˆ—ï¼Œ
  - å…·ä½“åŒ…æ‹¬ï¼šRX 7900 XTXã€RX 7900 XTã€RX 7900 GREã€PRO W7900(åŒæ’æ§½)ã€PRO W7900ã€PRO W7800ã€‚
  - å…¶ä¸­ï¼Œ7900 XTXã€PRO W7900å¯ä»¥åŒå¡å¹¶è¡Œï¼Œé¦–æ¬¡æ­£å¼æ”¯æŒçš„PRO W7900(åŒæ’æ§½)å¯ä»¥æœ€å¤šå››å¡å¹¶è¡Œã€‚
  - ä»¥ä¸Šæ‰€æœ‰éƒ½ä»…é™Ubuntu 22.04.3 HWEæ“ä½œç³»ç»Ÿï¼Œéœ€è¦æ­é…Linux 24.10.3ç‰ˆæ˜¾å¡é©±åŠ¨

- ## [howâ€™s inference looking now in AMD GPUs? I donâ€™t have one so thatâ€™s why asking here. : r/LocalLLaMA _202510](https://www.reddit.com/r/LocalLLaMA/comments/1nw9tny/hi_hows_inference_looking_now_in_amd_gpus_i_dont/)
- if you can do with a single AMD AI 395 128GB do it, that's the dirty cheapest solution.
  - Also there is the option to run 2 different models on 2 x 395s and used a 3rd machine for AI Agent hooked to those local LLMs. Like a AMD 370. This whole setup consumes less energy than a single 3090.
  - The idea is extremely simple. You run the LLM/LLMs you want on the 395 and connect the Agent 0 from the third machine. Because A0 allows for multiple LLMs to be connected to, either local or remote eg ChatGPT, can even run a model for some of the quick menial work on the 780M of the second machine hooked to A0.

- How does R9700 compare to W7900? Gigabyte offers both as part of their AI TOP lineup, you're supposed to be able to slot those in your PC and do local training, but I see W7900 has 48G VRAM compared to R9700's 32G
  - R9700 is wayyyyy faster on Inference than the W7900.

- I only have AMD GPUs. They work great with llama.cpp/Vulkan.

- Other people have already pointed out the 8x MI50 approach, so I won't repeat what they have said, but will point out that that puts out 2, 400 watts of heat under full load.
  - If you don't mind paying a lot more up front, but cutting your power draw and heat output in half, and getting better performance, you could pick up 4x MI210 instead. These are going for about $4, 500 on eBay, have 64GB instead of 32GB, and support a wider variety of FP/BF/INT types than MI50.
  - The 8x MI50 seems like the more affordable option, but my own homelab is running up against power and cooling limitations, which complicates the math.

- 8 x Mi50 will get you to 256GB vram. They're not 3090s and you need to buy fan shrouds for them on eBay but they're fine for what they are and quite cheap.

- prompt processing will be a lot slower than your nvidia counterparts, but token-gen is pretty damn close to what you'd expect given memory bandwidth.

- 8 mi50 32gb or 8 v620 or 8 mi100, in order of cost and perf

- connecting more than two 3090 is tricky, you need motherboard with multiple PCIE slots

- [Whats your PC tech spec? : r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/comments/1nxny65/whats_your_pc_tech_spec/)
# discuss-os-linux/win/macos
- ## 

- ## 

- ## 

- ## ðŸ’¡ [æ—¶è‡³ä»Šæ—¥ winæœ¬é˜µè¥æœ‰èƒ½å¯¹æ ‡MacBookçš„äº§å“å˜›? - çŸ¥ä¹Ž](https://www.zhihu.com/question/630359957)
- MacBookåœ¨æ¢ç”¨äº†è‡ªå®¶çš„Mç³»åˆ—èŠ¯ç‰‡ä¹‹åŽï¼Œèƒ½è€—æ¯”å¸¦æ¥çš„ç»­èˆªé—®é¢˜å®Œå…¨ä¸æ˜¯ä¸€ä¸ªé‡çº§çš„ã€‚
  - Windowsæœ¬åªèƒ½ä¸»æ‰“é€šç”¨æ€§ï¼Œå¼€æ”¾çš„ç³»ç»ŸçŽ¯å¢ƒå’ŒMacBookçš„å°é—­ç³»ç»Ÿä¸Šä¸ä¸€æ ·ã€‚
  - MacBookçš„å·¥è‰ºå’Œå“æŽ§ä¹Ÿæ˜¯æœ€å¼ºçš„ï¼ŒCNCä¸€ä½“æˆåž‹çš„å·¥è‰ºã€è‹¹æžœé«˜æˆæœ¬è½¬è½´æ–¹æ¡ˆï¼Œå¤§å¤šæ•°Windowsæœ¬éƒ½æ— æ³•åŒ¹æ•Œã€‚

- å¹» 13ï¼Œå¯¹æ ‡ MacBook airã€‚å±å¹•å’ŒMacBook airåŒæ ·å°ºå¯¸åŒæ ·ç”»è´¨ï¼Œè€Œä¸”æ˜¯è§†ç½‘è†œé«˜åˆ·å±ï¼Œå¼ºmacä¸€æ‰‹ï¼Œç»­èˆªå¤§æ¦‚æœ‰ Macçš„80%ï¼Œ13æ€§å¯¸ç»™äº† 75wå¤§ç”µæ± ã€‚
  - æ’ç”µåŽå¼€å¯ç‹¬æ˜¾ç›´è¿žï¼Œæ€§èƒ½å¼º mac ä¸€å¤§æˆªï¼Œå¯Œå“¥ä»¬è¿˜å¯ä»¥æ’ 4090 æ˜¾å¡åžï¼ŒåŠžå…¬æœ¬çž¬é—´å˜æˆå°å¼æœºæ€§èƒ½ã€‚
  - æ§½ç‚¹å°±æ˜¯æ¶²é‡‘åç§»å’Œ 16g å†…å­˜ï¼Œä¸è¿‡ä¸è¦ä¿ä¿®çš„è¯ 16g å†…å­˜å¯ä»¥ tb å‡çº§åˆ° 32ï¼Œæˆ–è€…ä¹°æµ·å¤– 4070æ¬¾ã€‚
  - æ€§èƒ½ï¼Œå±å¹•ï¼Œç»­èˆªä¸‰è€…éƒ½è€ƒè™‘çš„è¯ï¼Œè¿™æ¬¾æœºå­åŒå°ºå¯¸æ²¡æœ‰å¯¹æ‰‹ï¼Œå¦‚æžœè€ƒè™‘è§¦å±çš„è¯åªæœ‰è¿™ä¸€æ¬¾å¯ä»¥è€ƒè™‘ã€‚

- å®žè´¨ä¸Šæ˜¯å¯¹æ ‡è‹¹æžœçš„æ˜¯å°ç±³ï¼Œ4000å—çš„ç¬”è®°æœ¬ç”µè„‘éƒ½ç”¨CNCé¡¶çº§å·¥è‰ºã€‚ã€‚ã€‚åªä¸è¿‡å¸‚åœºè¡¨çŽ°æ¯”è¾ƒæƒ¨æ·¡ã€‚
- è¿˜æœ‰ä¸€äº›å¯¹æ ‡çš„ï¼Œå‡ºå¸ˆæœªæ·èº«å…ˆæ­»ã€‚ä¾‹å¦‚ThinkPad X1 Nanoï¼Œ2024å¹´å°±è¦æ²¡æœ‰äº†ã€‚æˆ´å°”XPSç³»åˆ—ä¹Ÿä¸€ç›´è¯•å›¾å¯¹æ ‡ï¼Œä½†æ˜¯ç›¸åŽ»ç”šè¿œï¼Œå‡ ä¹Žæ²¡æœ‰å¯¹å¾—ä¸Šã€‚

- å°ç±³çš„è¿˜æ˜¯åšä¸åˆ°é‚£ä¹ˆè–„ï¼Œæ¯•ç«Ÿæ˜¯ç»„è£…ï¼Œcpuä¸»æ¿ä»€ä¹ˆçš„ä¸åƒmacçš„

- åŽä¸ºæœ‰å‡ æ¬¾ï¼Œç²—çœ‹è¿˜å¯ä»¥ï¼Œä½†æ˜¯ç¿»è¿‡æ¥çœ‹åˆ°åº•éƒ¨æ»¡æ˜¯æ•£çƒ­å­”ï¼Œæ„Ÿè§‰å°±ä¸æ€Žä¹ˆèˆ’æœäº†ã€‚

- Microsoft Surface Laptopï¼šè¿™æœ¬æ¥åº”è¯¥èƒ½æˆä¸ºåƒMacBookä¸€æ ·è½¯ç¡¬ç»“åˆçš„å…¸èŒƒï¼Œæ— å¥ˆWindows Phoneä¸ç»™åŠ›æ—©æ—©è¢«æ”¾å¼ƒï¼Œè¿™æ¬¾å½“åˆçš„Windowsè½»è–„æœ¬æ ‡æ†ç”±äºŽ5å¹´æ²¡æ¢æ¨¡å…·ï¼ŒçŽ°åœ¨å·²ç»ç›¸å½“è½ä¼äº†ã€‚

- å› ä¸ºåˆ©æ¶¦åœ¨cpuå’Œç³»ç»Ÿï¼Œåšç¡¬ä»¶çš„å°±é‚£ä¹ˆå¤šåˆ©æ¶¦ï¼Œå¤–è§‚å¥½è‡ªç„¶åˆ«çš„åœ°æ–¹å°±å¾—çœ

- ä¸ªäººè®¤ä¸ºï¼Œç›¸æ¯”äºŽWindowsç¬”è®°æœ¬ï¼ŒMacBookæœ€å¥½ç”¨çš„åœ°æ–¹ï¼Œåœ¨äºŽè§¦æŽ§æ¿çš„ä½“éªŒã€‚æˆªè‡³ç›®å‰ï¼Œåº”è¯¥è¿˜æ²¡æœ‰Windowsç¬”è®°æœ¬çš„è§¦æŽ§æ¿èƒ½è¾¾åˆ°MacBookè§¦æŽ§æ¿çš„ä½“éªŒã€‚

- é›·è›‡å•Šï¼Œçµåˆƒ15ï¼Œæ±Ÿæ¹–äººé€æŽªå·é»‘è‹¹æžœã€‚

- 
- 
- 

- ## [å›½äº§ç³»ç»Ÿå¤§è‡´æ¯”è¾ƒå’Œåˆ†æžï¼ˆä¼˜éº’éºŸã€å¼€æ”¾éº’éºŸã€æ·±åº¦deepinã€ç»Ÿä¿¡UOSã€é“¶æ²³éº’éºŸã€ä¸­æ ‡éº’éºŸï¼‰ - çŸ¥ä¹Ž](https://zhuanlan.zhihu.com/p/661508663)

### æ¡Œé¢çº§ç³»ç»Ÿ

- ä¼˜éº’éºŸæ˜¯ Ubuntu å®˜æ–¹è¡ç”Ÿç‰ˆï¼Œå¾—åˆ°æ¥è‡ªDebianã€Ubuntuã€LUPAåŠå„åœ°Linuxç”¨æˆ·ç»„ç­‰å›½å†…å¤–ä¼—å¤šç¤¾åŒºçˆ±å¥½è€…çš„å¹¿æ³›å‚ä¸Žå’Œçƒ­æƒ…æ”¯æŒã€‚
  - é’ˆå¯¹ä¸­å›½å¸‚åœºåŠ å…¥å¤§é‡æœ¬åœ°ä¼˜åŒ–åŠŸèƒ½ã€‚æ¯”å¦‚æ”¯æŒä¸­æ–‡è¾“å…¥æ³•ã€å†œåŽ†ã€å¤©æ°”æ’ä»¶
  - ä¼˜éº’éºŸçš„æ¡Œé¢çŽ¯å¢ƒé‡‡ç”¨UKUIè½¯ä»¶ã€‚UKUI æ˜¯ä¸€æ¬¾è½»é‡çº§çš„ Linux æ¡Œé¢çŽ¯å¢ƒï¼ŒåŸºäºŽ GTK å’Œ QT è¿›è¡Œå¼€å‘ã€‚

- openKylinå¼€æ”¾éº’éºŸæ˜¯ä¸­å›½é¦–ä¸ªæ¡Œé¢æ“ä½œç³»ç»Ÿå¼€å‘è€…å¹³å°ç”±å›½å®¶å·¥ä¸šå®‰å…¨å‘å±•ç ”ç©¶ä¸­å¿ƒç­‰å•ä½è”åˆæˆç«‹ï¼Œå°†æ‰“é€ å…·æœ‰è‡ªä¸»åˆ›æ–°æŠ€æœ¯çš„å¼€æºæ¡Œé¢æ“ä½œç³»ç»Ÿï¼Œå®šä½äºŽæ¡Œé¢æ“ä½œç³»ç»Ÿæ ¹ç¤¾åŒº ã€‚

- å¼€æ”¾éº’éºŸå’Œé“¶æ²³éº’éºŸæ¡Œé¢æ“ä½œç³»ç»Ÿçš„å…³ç³»ç±»ä¼¼äºŽæ·±åº¦deepinå’Œç»Ÿä¿¡UOSã€‚å‰è€…ä¸ºæ ¹ç¤¾åŒºç‰ˆæœ¬ï¼ŒåŽè€…æ˜¯ä¸Šæ¸¸å•†ä¸šç‰ˆæœ¬ã€‚ç¤¾åŒºç‰ˆæœ¬æ›´æ³¨é‡åŠŸèƒ½ä¹Ÿæ›´æ¿€è¿›ï¼Œå•†ä¸šç‰ˆæœ¬åˆ™æ›´æ³¨é‡ç¨³å®šã€‚

- deepinæ˜¯ç”±æ­¦æ±‰æ·±ä¹‹åº¦ç§‘æŠ€æœ‰é™å…¬å¸åœ¨DebianåŸºç¡€ä¸Šå¼€å‘çš„Linuxæ“ä½œç³»ç»Ÿï¼Œå…¶å‰èº«æ˜¯Hiweed Linuxæ“ä½œç³»ç»Ÿã€‚
  - deepinæ“ä½œç³»ç»Ÿå†…éƒ¨é›†æˆäº†DDEï¼ˆDeepin Desktop Environmentï¼‰æ·±åº¦æ¡Œé¢çŽ¯å¢ƒï¼‰ï¼Œå¹¶æ”¯æŒdeepin storeã€deepin Musicã€deepin Movieç­‰ç¬¬ä¸€æ–¹åº”ç”¨è½¯ä»¶ï¼Œå®šä½äºŽæ¡Œé¢æ“ä½œç³»ç»Ÿæ ¹ç¤¾åŒº ã€‚

- ç»Ÿä¿¡UOS ç”±æ·±åº¦ï¼ˆdeepinï¼‰ä¸ºåŸºç¡€ï¼Œç»è¿‡å®šåˆ¶è€Œæ¥çš„äº§å“ã€‚
  - UOS æ‹¥æœ‰ å®¶åº­ç‰ˆã€ä¸“ä¸šç‰ˆã€æœåŠ¡å™¨ç‰ˆ ä¸‰ä¸ªåˆ†æ”¯ã€‚

### æœåŠ¡å™¨çº§ç³»ç»Ÿ

- é“¶æ²³éº’éºŸé«˜çº§æœåŠ¡å™¨æ“ä½œç³»ç»ŸV10æ˜¯é’ˆå¯¹ä¼ä¸šçº§å…³é”®ä¸šåŠ¡ï¼Œé€‚åº”è™šæ‹ŸåŒ–ã€äº‘è®¡ç®—ã€å¤§æ•°æ®ã€å·¥ä¸šäº’è”ç½‘æ—¶ä»£å¯¹ä¸»æœºç³»ç»Ÿå¯é æ€§ã€å®‰å…¨æ€§ã€æ€§èƒ½ã€æ‰©å±•æ€§å’Œå®žæ—¶æ€§ç­‰éœ€æ±‚
  - é“¶æ²³éº’éºŸé«˜çº§æœåŠ¡å™¨æ“ä½œç³»ç»Ÿæ±²å–æœ€æ–°çš„äº‘å’Œå®¹å™¨å¼€æºæŠ€æœ¯ï¼Œèžåˆäº‘è®¡ç®—ã€å¤§æ•°æ®ã€äººå·¥æ™ºèƒ½æŠ€æœ¯ï¼ŒåŠ©åŠ›ä¼ä¸šä¸Šäº‘
  - äº§å“åŒæºæ”¯æŒé£žè…¾ã€é²²é¹ã€é¾™èŠ¯ã€ç”³å¨ã€æµ·å…‰ã€å…†èŠ¯ç­‰è‡ªä¸»å¹³å°ï¼Œå¹¶é’ˆå¯¹ä¸åŒå¹³å°åœ¨å†…æ ¸å±‚ä¼˜åŒ–å¢žå¼ºã€‚

- åŸºäºŽRHELç³»ç»Ÿå¼€å‘

- ä¸­æ ‡éº’éºŸé«˜çº§æœåŠ¡å™¨æ“ä½œç³»ç»Ÿè½¯ä»¶V7.0æ˜¯åœ¨å¤šå¹´Linuxç ”åˆ¶ç»éªŒåŸºç¡€ä¸Šï¼Œé€‚åº”è™šæ‹ŸåŒ–ã€äº‘è®¡ç®—ã€å¤§æ•°æ®ï¼Œæ»¡è¶³ä¸šåŠ¡å¯¹æ€§èƒ½ã€æ‰©å±•æ€§ã€å®‰å…¨ç­‰è¦æ±‚

### ðŸ‘¥

- å®˜æ–¹ä¸»è¦æ˜¯éº’éºŸã€‚deepinåŽŸæ¥æ˜¯æ°‘é—´çš„ï¼Œä½†æ˜¯åè€Œå£ç¢‘æœ€å¥½ï¼Œæ‰€ä»¥å°±è½¬æ­£ï¼Œå•†ä¸šåŒ–æˆuosäº†ã€‚è¦æ˜¯è¯´å¼€æ”¾æ€§å’Œå‰é€”ï¼Œæˆ‘ç«™uos

- è¿˜æœ‰è¿žæŽ¥æ‰“å°æœºä¸å¥½ç”¨

- ä¸­æ ‡å’Œé“¶æ²³è¿˜å±žäºŽä¸åŒå…¬å¸ï¼Œä¸­æ ‡ä¸€ç›´æ˜¯çº¢å¸½ç³»çš„ï¼Œé“¶æ²³æœ€æ—©ä»¥FreeBSDä¸ºä¸»çš„å››æ ¸èžåˆï¼ŒåŽæ¥éš¾åº¦å¤ªå¤§ï¼Œä¾¿å€’å‘äº†çº¢å¸½ç³»ã€‚
  - æ·±åº¦åˆ™æ˜¯ä»Žä¸€å¼€å§‹å°±æ˜¯åŸºäºŽubuntuï¼ŒåŽæ¥æ”¹æˆäº†åŸºäºŽDebianï¼Œå†åŽæ¥é˜¿é‡Œã€åŽä¸ºåˆ†åº­æŠ—ç¤¼ï¼Œå°±åˆæžå‡ºæ¥aç‰ˆå’Œeç‰ˆï¼Œä½†ä¸»åŠ›å¼€å‘çš„è¿˜æ˜¯dç‰ˆ
- å…¶å®ždeepinä¸€å¼€å§‹å°±æ˜¯åŸºäºŽDebianä¸ç¨³å®šç‰ˆï¼ŒåŽæ¥æ”¹ä¸ºäº†åŸºäºŽubuntuï¼Œå†åŽæ¥å°±æ”¹æˆäº†åŸºäºŽDebianç¨³å®šç‰ˆï¼ŒçŽ°åœ¨åˆæ”¹æˆäº†ç›´æŽ¥åŸºäºŽlinuxå†…æ ¸ä½†æ˜¯ï¼Œç”±äºŽè¿‡äºŽæ¿€è¿›ï¼ŒäºŽæ˜¯åœ¨çŽ²ç‘ç”Ÿæ€èµ·æ¥ä¹‹å‰ï¼Œä¹Ÿå…¼å®¹äº†Debianç”Ÿæ€ï¼Œç±»ä¼¼äºŽé¸¿è’™çŽ°åœ¨çš„è·¯çº¿ã€‚é¸¿è’™ä¹Ÿæ˜¯åœ¨è‡ªå®¶ç”Ÿæ€èµ·æ¥ä¹‹å‰å…ˆå…¼å®¹å®‰å“ç”Ÿæ€

- çœŸæ˜¯æ‰¯æ·¡ï¼Œä¸€ä¸ªç¡¬ä»¶åŽ‚å®¶ä¸€å¥—å›ºä»¶ä¸€å¥—è½¯ä»¶ã€‚ä½ è®©å¼€å‘è€…æ€Žä¹ˆåšé€‚é…ï¼Œ

- ## [ç»Ÿä¿¡UOSä½•æ—¶è¢«é¸¿è’™HarmonyOSæ›¿ä»£ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/644762431)
- ç»Ÿä¿¡UOSå¯ä»¥è¯´æ˜¯ç›®å‰æœ€å¥½çš„ä¿¡åˆ›æ“ä½œç³»ç»Ÿï¼Œé€‚é…x86ã€armã€loongarchã€+swç­‰æŒ‡ä»¤é›†çš„å›½äº§CPUï¼ŒåŒ…æ‹¬æµ·å…‰ã€å…†èŠ¯ã€é²²é¹ã€é£žè…¾ã€é¾™èŠ¯ã€ç”³å¨ç­‰ 

- openHarmonyå’ŒHarmony NEXTçš„ç”Ÿæ€æ˜¯äº’é€šçš„å§ï¼›NEXTæœ¬èº«å°±åŸºäºŽopenHarmonyï¼›
  - UOSå·²ç»å‘å¸ƒäº†åŸºäºŽopenHarmonyçš„ç‰ˆæœ¬ï¼Œä½ å¯ä»¥ç†è§£ä¸ºUOSå°±æ˜¯ä¸€å¥—ç±»ä¼¼MIUIçš„ä¸œè¥¿ï¼Œåº•å±‚åŽŸæ¥æ˜¯Linuxï¼ŒçŽ°åœ¨æ¢æˆopenHarmonyï¼Œ

- é¸¿è’™PCç‰ˆå’Œæ‰‹æœºç‰ˆç”Ÿæ€æ˜¯äº’é€šçš„ï¼Œè¿™æ„å‘³ç€éšç€æ‰‹æœºç‰ˆçš„å‘è¡ŒæŽ¨å¹¿ï¼Œæœªæ¥æŽ¨å‡ºçš„PCç‰ˆä¸€å‡ºç”Ÿå°±æœ‰æµ·é‡çš„åº”ç”¨ï¼Œè¿™ç§æƒ³è±¡ç©ºé—´æ˜¯å·¨å¤§çš„

- ä½ ä»¬ä¸Šæ¬¡ä¹Ÿæ˜¯è¿™ä¹ˆè¯´openeulerçš„ï¼ŒçŽ°åœ¨å¿«ä¸€ç»Ÿå›½å†…å¸‚åœºäº†

- ä¸éœ€è¦æ›¿ä»£ï¼ŒuosæœåŠ¡å™¨ç‰ˆæœ¬æ¥å°±æœ‰åŸºäºŽopeneulerçš„ç‰ˆæœ¬ï¼Œuosæ¡Œé¢ç‰ˆå¼„ä¸ªopenharmonyç‰ˆå°±è¡Œäº†ã€‚

- æœ¬æ¥è°·æ­ŒåŽä¸ºæ˜¯æ‰“ç®—ä¸€å—æžfuchsiaçš„ï¼Œç›®æ ‡æ˜¯æŠŠchrome oså’Œå®‰å“å…¨æ¢è¿™çŽ©æ„ï¼Œç„¶åŽä¼—æ‰€å‘¨çŸ¥çš„åŽŸå› fuchsiaé»„äº†ï¼ŒåŽä¸ºå•å¹²çš„å°±æ˜¯çŽ°åœ¨çš„é¸¿è’™äº†

- ## [å¦‚ä½•è¯„ä»·å›½äº§ç»Ÿä¿¡UOSç³»ç»Ÿï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/594635253)
- ç»Ÿä¿¡è¿™ç ´ç³»ç»Ÿå®Œç¾Žåœ°æ”¾å¼ƒäº†Linuxç±»ä¼¼ç‰©çš„æ‰€æœ‰ä¼˜ç‚¹ï¼Œå­¦ä¹ äº†å°é—­å¼ç³»ç»Ÿçš„æ‰€æœ‰ç¼ºç‚¹ï¼šä¸€å°æœºå™¨çš„ä¸€å¹´æŽˆæƒè´¹å‡ ç™¾å—ï¼Œæ¿€æ´»ç è¿‡æœŸåŽä¸“é—¨ç¦ç”¨å¾®ä¿¡å’Œwpsï¼Œä¸èƒ½æ›´æ–°ä¸‹è½½è½¯ä»¶ï¼Œå¾®ä¿¡wpså®˜ç½‘çš„linuxç‰ˆæœ¬å®‰è£…åŒ…å…¨éƒ¨ä¸èƒ½ç”¨ï¼Œç¬¬ä¸‰æ–¹å®‰è£…åŒ…é€šé€šæŠ¥é”™ä¸å…¼å®¹ï¼Œåªèƒ½ä»Žè‡ªå¸¦å•†åº—ä¸‹è½½åº”ç”¨ã€‚è¦è¯´å¡è„–å­è¿˜æ˜¯è‡ªå·±äººæœ€åœ¨è¡Œ

- ä»Žå¼€å‘è€…çš„è§’åº¦æ¥çœ‹ï¼Œè¿™ç³»ç»Ÿéžå¸¸é€†å¤©ã€‚
  - é¦–å…ˆUOSä¸“ä¸šç‰ˆæ˜¯æ”¶è´¹ç³»ç»Ÿï¼Œ700å…ƒï¼Œä¸åŒæž¶æž„çš„ä»·æ ¼è¿˜ä¸ä¸€æ ·ï¼Œä¸ç¡®å®šæ˜¯å¦é€šç”¨ã€‚å¦‚æžœä¸è´­ä¹°æŽˆæƒï¼Œè¯•ç”¨æœŸ3ä¸ªæœˆï¼Œè¿‡äº†è¯•ç”¨æœŸå°±ä¸èƒ½å†æ›´æ–°å’Œå®‰è£…è½¯ä»¶äº†ã€‚è¿‡äº†è¯•ç”¨æœŸä¸ç»™rootæƒé™ã€‚

- å¬è¯´å®¶åº­ç‰ˆä¸ç”¨èŠ±é’±ï¼Œä½†æ˜¯ä¸å¼€æ”¾ä¸‹è½½ï¼Œéœ€è¦å…ˆæäº¤ç”³è¯·ã€‚è¿˜æœ‰å°±æ˜¯å®¶åº­ç‰ˆç³»ç»Ÿå¾—ç»‘å®šUOSè´¦æˆ·ï¼Œ1ä¸ªè´¦æˆ·æœ€å¤šæ¿€æ´»5å°æœºå™¨ï¼Œå¤šäº†å°±å¾—è§£ç»‘

- UOSæŠŠè‡ªå·±çš„è½¯ä»¶ç”Ÿæ€æžå¾—å¦‚æ­¤å°é—­ï¼Œå¯¹äºŽä¸å¤ªæ‡‚è®¡ç®—æœºçš„ç”¨æˆ·æ¥è¯´ï¼ŒåŸºæœ¬ä¸Šåªèƒ½ä»Žä»–è‡ªå®¶çš„åº”ç”¨å•†åº—å®‰è£…åº”ç”¨è½¯ä»¶ï¼Œç®€ç›´æ¯”è‹¹æžœè¿˜éœ¸é“ã€‚

- ä¸­æ ‡éº’éºŸå·²ç»è¢«é“¶æ²³éº’éºŸåˆå¹¶äº†ï¼ŒçŽ°åœ¨ä¸»è¦æ˜¯é“¶æ²³éº’éºŸä¸Žç»Ÿä¿¡ä¸¤å®¶ã€‚

- ## [é“¶æ²³éº’éºŸå’Œç»Ÿä¿¡å“ªä¸ªå¥½? - çŸ¥ä¹Ž](https://www.zhihu.com/question/581675808)
- é“¶æ²³éº’éºŸä¸æ¿€æ´»å¯ä»¥æ— é™åˆ¶ä½¿ç”¨å…¨éƒ¨åŠŸèƒ½ï¼Œåªæ˜¯æ²¡æœ‰æŠ€æœ¯æ”¯æŒã€‚
  - UOSä¸æ¿€æ´»ä¸èƒ½è®¿é—®è½¯ä»¶æºï¼Œä¸èƒ½å¯ç”¨å¼€å‘è€…æ¨¡å¼ã€‚
- é“¶æ²³éº’éºŸè·¨SPçš„å¤§ç‰ˆæœ¬å‡çº§éœ€è¦æ”¶å–é¢å¤–çš„è´¹ç”¨æ‰èƒ½æ¿€æ´»ï¼ŒUOSä¼¼ä¹Žä¸éœ€è¦ã€‚

- é“¶æ²³éº’éºŸè½¯ä»¶å®‰è£…å’Œæƒé™ç®¡ç†å’Œå…¶ä»–debç³»Linuxæ¯”è¾ƒä¸€è‡´ã€‚
  - UOSæƒé™è¿‡äºŽå°é—­ï¼Œä¸å¯ç”¨å¼€å‘è€…æ¨¡å¼ä¸èƒ½èŽ·å–rootæƒé™ï¼Œä¸å…è®¸å®‰è£…éžå•†åº—åŒ…ï¼Œä¸”è½¯ä»¶æºçš„åŒ…ä½¿ç”¨deepin-elf-verifyåŒ…é˜»æ­¢åœ¨å…¶ä»–Debianç³»ç³»ç»Ÿä¸Šå®‰è£…ã€‚è€Œä¸”å¯¹rootæƒé™çš„é™åˆ¶ä¸ä»…é’ˆå¯¹ç”¨æˆ·ä¹Ÿé’ˆå¯¹å¼€å‘è€…ã€‚ç¨‹åºä¸èƒ½ç›´æŽ¥ç”¨sudoè¯·æ±‚è¾“å…¥rootå¯†ç ææƒè€Œéœ€è¦é€šè¿‡DbusæŽˆæƒã€‚

- ç»Ÿä¿¡æ˜¯ç»™çº¯å°ç™½ç”¨çš„ï¼Œæ€•ç»™çŽ©å„¿åäº†ï¼Œæ‰€ä»¥ä¸ç»™rootæƒé™ï¼Œè·Ÿå®‰å“ä¸€æ ·ã€‚å¼€å‘è€…å¤§æ¦‚ä¹Ÿä¸ä¼šæ”¾ç€deepinä¸ç”¨åŽ»ç”¨ç»Ÿä¿¡ã€‚

- UOSå¯¹æ‰“å°æœºé©±åŠ¨çš„æ”¯æŒæ¯”éº’éºŸå®Œå–„ï¼Œå› ä¸ºå®ƒè‡ªå·±åšäº†å¯¹Windowsçš„æ‰“å°é©±åŠ¨æ”¯æŒã€‚

- æˆ‘å¸ä¿¡åˆ›è½¯ä»¶å”®åŽ95%25ä»¥ä¸Šé—®é¢˜çš„éƒ½æ˜¯ç»Ÿä¿¡çŽ¯å¢ƒå‡ºçš„ï¼Œç”šè‡³éœ€è¦å•ç‹¬å‡ºåŒ…ç»™ç»Ÿä¿¡ç­¾åï¼Œéº’éºŸåŸºæœ¬æ²¡å•¥å”®åŽé™¤éžsudoersæ–‡ä»¶è¢«æ•…æ„æ”¹è¿‡ 

- ä»Žå¼€æ”¾æ€§ä¸Šæ¥è¯´ï¼ŒUOSç»Ÿä¿¡æ›´å¥½ä¸€ç‚¹ï¼ŒåŽŸå› æ˜¯UOSä½¿ç”¨çš„DDEæ¡Œé¢å¼€æ”¾æ€§æ›´å¥½ï¼Œæç‚¼å‡ºäº†ä¸€å¥—DTKå¥—ä»¶ï¼ŒåŸºäºŽQTï¼Œè¿™ç‚¹æ„Ÿè§‰æœ‰å‘å±•å‰é€”ï¼Œä¹Ÿæ˜¯ä¸€ä¸ªå¾ˆå¥½çš„æ€è·¯ï¼Œå¸Œæœ›åœ¨è¿™æ¡å¼€æºçš„é“è·¯ä¸Šæ›´è¿›ä¸€æ­¥ï¼Œå½¢æˆè‡ªå·±çš„ç‰¹è‰²ã€‚
  - é“¶æ²³éº’éºŸä¸çŸ¥é“æ€Žä¹ˆè¯´ï¼Œä¹Ÿæœ‰è‡ªå·±çš„æ¡Œé¢UKUIï¼Œä½†æ˜¯ä¸ªäººæ„Ÿè§‰å¼€æ”¾æ€§ä¸å¥½ï¼Œè—ç€æŽ–ç€ï¼Œåªèƒ½è®©äººè§‰å¾—åšçš„ä¸å¥½ï¼

- é“¶æ²³é¢å‘æœåŠ¡å™¨ï¼Œç»Ÿä¿¡é¢å‘åŠžå…¬ï¼Œé¢å‘å®¶åº­å¨±ä¹ï¼Œå„å¸å…¶èŒï¼Œå¤šå¥½ã€‚

- ## ðŸ†š [å¸¦æ‚¨äº†è§£æ˜Ÿå…‰éº’éºŸå’Œé“¶æ²³éº’éºŸçš„å·®åˆ« - çŸ¥ä¹Ž](https://zhuanlan.zhihu.com/p/14101203674)
- æ˜Ÿå…‰éº’éºŸé‡‡ç”¨å¾®å†…æ ¸è®¾è®¡ï¼Œé€šè¿‡å°†éžæ ¸å¿ƒåŠŸèƒ½ç§»åˆ°å†…æ ¸ä¹‹å¤–ï¼Œå¤§å¤§æå‡äº†ç³»ç»Ÿçš„å®‰å…¨æ€§ï¼Œåœ¨é¢ä¸´å¤–éƒ¨æ¶æ„æ”»å‡»æ—¶ï¼Œå¾®å†…æ ¸çš„æ”»å‡»é¢æ›´å°ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæŠµå¾¡ç—…æ¯’å’Œé»‘å®¢çš„å…¥ä¾µã€‚
  - ä¸»è¦é¢å‘ç§‘ç ”ä¸Žè¶…ç®—é¢†åŸŸï¼Œèƒ½å¤Ÿç²¾å‡†åœ°å¤„ç†å¤æ‚çš„æ•°æ®æ¨¡åž‹ï¼Œä½†å…¶å±€é™æ€§åœ¨äºŽå¯¹æ¶ˆè´¹çº§ç¡¬ä»¶çš„é€‚é…æ€§è¾ƒå·®ï¼Œæ™®é€šç”µè„‘å¯èƒ½æ— æ³•å‘æŒ¥å…¶ä¼˜åŠ¿ï¼Œä¸”åœ¨è½¯ä»¶ç”Ÿæ€æ”¯æŒä¸Šç›¸å¯¹è–„å¼±ã€‚

- é“¶æ²³éº’éºŸç³»ç»Ÿ
  - æ‹¥æœ‰å¼ºå¤§çš„å¤šä»»åŠ¡å¤„ç†èƒ½åŠ›ï¼Œå›¾å½¢ç•Œé¢å‹å¥½ï¼Œæ“ä½œä¾¿æ·ï¼Œå¯¹äºŽæ™®é€šç”¨æˆ·å’Œä¸“ä¸šäººå‘˜éƒ½èƒ½æä¾›è‰¯å¥½çš„ä½¿ç”¨ä½“éªŒï¼Œ
  - åŒæ—¶ï¼Œå¯¹å¤šç§ç½‘ç»œåè®®æœ‰ç€å¹¿æ³›çš„æ”¯æŒï¼Œä¿éšœäº†åœ¨ä¸åŒç½‘ç»œçŽ¯å¢ƒä¸‹çš„ç¨³å®šé€šä¿¡ã€‚
  - å¤šå±‚æ¬¡çš„å®‰å…¨è®¿é—®æŽ§åˆ¶æœºåˆ¶ï¼Œä¸¥æ ¼é™åˆ¶ä¸åŒç”¨æˆ·çš„æƒé™ï¼Œä¿éšœç³»ç»Ÿå®‰å…¨ç¨³å®šè¿è¡Œã€‚
  - æ˜Ÿå…‰éº’éºŸçš„è½¯ä»¶ç”Ÿæ€ç›¸å¯¹å°ä¼—ï¼Œé›†ä¸­äºŽç§‘ç ”ç­‰ç‰¹å®šé¢†åŸŸï¼Œé“¶æ²³éº’éºŸåˆ™åœ¨æ°‘ç”¨å’Œå·¥ä¸šç­‰å¤šé¢†åŸŸæž„å»ºäº†è¾ƒä¸ºä¸°å¯Œçš„è½¯ä»¶ç”Ÿæ€ï¼Œä¸Žä¼—å¤šç¬¬ä¸‰æ–¹è½¯ä»¶æœ‰è‰¯å¥½çš„å…¼å®¹æ€§ã€‚
# discuss-os-arm
- ## 

- ## 

- ## 

- ## [2024å¹´ arm windows ç”¨æ¥å†™ä»£ç èƒ½èƒœä»»å—? - çŸ¥ä¹Ž](https://www.zhihu.com/question/725977971)
- NodeJSã€Pythonã€. NET å’Œ OpenJDK éƒ½æœ‰ ARM ç‰ˆï¼ŒVS ä¹‹ç±» IDE ä¹Ÿæœ‰ï¼Œä½†ä½ è¦æ³¨æ„ï¼š
  - å¾ˆå¤šæ’ä»¶å¯èƒ½æ²¡æœ‰ ARM ç‰ˆã€‚
  - ä½ çš„é¡¹ç›®å¯èƒ½ä¼šæœ‰å¥‡æ€ªçš„ native ä¾èµ–ï¼Œä¸è¿‡å‰ç«¯å·¥å…·çš„è¯åº”è¯¥è¿˜å¥½ï¼Ÿ
  - å¦‚æžœä½ æ¶‰åŠåˆ° Native è°ƒè¯•ï¼Œé‚£ ARM å¤„ç†å™¨ä¸å°‘ç¡¬ä»¶è°ƒè¯•åŠŸèƒ½æ˜¯æ¯”ä¸è¿‡ x86 çš„ï¼Œæ¯”å¦‚å†…å­˜æ–­ç‚¹å°±å¾ˆæ®‹åºŸã€‚
  - ARM çš„ CIï¼ˆæŒç»­é›†æˆï¼‰äº§ä¸šè¿˜å¾ˆåŽŸå§‹ï¼Œå› ä¸ºâ€”â€”åœ°çƒä¸Šåˆ°çŽ°åœ¨å°±æ²¡å‡ å° ARM æœåŠ¡å™¨ã€‚Github Actions çš„ ARM runner æ˜¯ä»Šå¹´æ‰ä¸Šçº¿çš„ï¼Œä¸”ä¼¼ä¹Žè¿˜æ”¶è´¹ã€‚

- è·‘ä¸äº†, netty ä»–å¯¹x86æœ‰ä¸“é—¨ä¼˜åŒ–ï¼Œåœ¨armä¸Šè¿è¡Œä¸€å †bugï¼Œåªæœ‰æ¯•ç”Ÿjdkæ‰æŠŠarmçš„å‘è¸©å®Œäº†

- éš¾åº¦æ¯”è¾ƒå¤§ã€‚pythonåœ¨winodwsè·‘å·²ç»å¾ˆéº»çƒ¦äº†ï¼ŒarmçŽ¯å¢ƒæ›´æ˜¯é›ªä¸ŠåŠ éœœã€‚

- è¿™ä¸ªé—®é¢˜å¯ä»¥å…³é—­äº†ï¼Œlunar lakeçš„å®žæœºæµ‹è¯•å·²ç»æœ‰äº†ï¼ŒXEliteå’ŒWindows on ARMå¯ä»¥è¿›æ£ºæäº†ã€‚

- 2025å¹´6æœˆäº†ï¼Œè¿™ä¸ªé—®é¢˜å·²ç»ç»“æŸäº†ã€‚Lunar Lakeå°±æ˜¯ä¸€ä¸ªå¸‚åœºçš„å¤±è´¥å“ã€‚
  - lunar lakeå¤±è´¥æ˜¯å› ä¸ºè¢«amdæ‰“æ­»äº†ï¼Œè€Œä¸æ˜¯è¾“ç»™äº†elite

- ARMç”¨åœ¨ç¬”è®°æœ¬ä¸Šä¸å…·æœ‰ä»»ä½•ä¼˜åŠ¿ã€‚çœŸæƒ³è¦çš„è¯åŽ»æ”¶ä¸ªæ·˜æ±°çš„é£žè…¾ä¿¡åˆ›ç¬”è®°æœ¬ï¼Œè®°å¾—è¦AMDæ˜¾å¡çš„ï¼Œç„¶åŽè‡ªå·±è£…Gentoo. ä¸œè¥¿éƒ½æ˜¯åŽŸç”Ÿçš„ã€‚

- å¦‚æžœè¦å†™ C/C++ é…åˆ intrinsics çš„è¯æŒºéº»çƒ¦çš„ã€‚ä¸»è¦å°±æ˜¯ä¸‰å¥—ç¼–è¯‘å™¨ MSVCã€GCCã€Clang
# discuss
- ## 

- ## 

- ## 

- ## 

- ## ðŸ¤” [å›½å†…å“ç‰Œç¬”è®°æœ¬ç”µè„‘è¿‘å¹´æ¥å¸‚åœºå æœ‰çŽ‡è¶Šæ¥è¶Šé«˜ï¼ŒèƒŒåŽæœ‰å“ªäº›æ–¹é¢çš„å› ç´ ï¼Ÿ - çŸ¥ä¹Ž](https://www.zhihu.com/question/663854470)
- ç¬”è®°æœ¬æ—©å°±å·²ç»æ˜¯ä¸€å›½ä¸¤å²¸çš„å“ç‰Œç»Ÿæ²»å…¨çƒå¸‚åœºäº†
  - æ¾³æ´²å¸‚åœºç”šè‡³éƒ½æ˜¯å›½äº§å“ç‰Œé€šåƒï¼Œå¤§é™†çš„è”æƒ³ï¼Œå¯¹å²¸çš„å¾®æ˜ŸåŽç¡•ï¼ŒåŸºæœ¬æŠŠè‹¹æžœä»¥å¤–çš„é«˜ç«¯åƒæ»¡äº†ï¼Œæƒ æ™®åªèƒ½åƒç‚¹ä½Žç«¯å¸‚åœº

- æˆ‘æƒ³è¯´å†…åœ°é”€é‡æŽ’è¡Œé‡ŒHPå’ŒDellå¸¸å¹´å‰äº”ï¼ˆè”æƒ³ç¨³å®šç¬¬ä¸€ï¼‰ï¼ŒASUSè™½ç„¶é”€é‡ä¹Ÿä¸å°ä½†å¸¸å¹´othersï¼ŒMSIè¿™ç§åªåšæ¸¸æˆæœ¬è¿˜æ­»æ’‘æº¢ä»·çš„é‚£å°±æ˜¯othersä¸­çš„othersäº†
  - æƒ æ™®æˆ´å°”çº¯å±žè¢«ä¼ä¸šé‡‡è´­æ’‘èµ·æ¥çš„ï¼Œç¦»å¼€ä¼ä¸šé‡‡è´­å•¥ä¹Ÿä¸æ˜¯

- æ¯å¹´è‹±ç‰¹å°”å’Œ AMD çš„æ–°CPUå‘å¸ƒéƒ½æ˜¯å‘¨æœŸæ€§çš„ï¼Œä»¥å‰æ˜¯1å¹´ä¸ºå•ä½ï¼ŒçŽ°åœ¨å·®ä¸å¤šæ˜¯ä¸‰ä¸ªå­£åº¦ä¸ºå•ä½ã€‚
- è‹±ä¼Ÿè¾¾è¿‘æ¥éƒ½æ˜¯2å¹´ä¸€ä¸ªå‘¨æœŸï¼Œ30ç³»ï¼Œ40ç³»ï¼Œ50ç³»æ˜¾å¡ã€‚
- éœ€è¦åœ¨ä¸€ä¸ªå‘å¸ƒå‘¨æœŸé‡Œï¼Œå°½å¿«åœ°å¡åœ¨3æœˆå¼€å­¦å­£ï¼Œ6æœˆ618å¤§ä¿ƒï¼Œ9æœˆå¼€å­¦å­£ï¼ŒåŒ11ï¼Œè¿™å››ä¸ªèŠ‚ç‚¹ï¼Œå®Œæˆç ”å‘ï¼Œè°ƒè¯•ï¼Œåˆ¶é€ ï¼Œå¤‡è´§ï¼Œæ¸ é“å‡ºè´§ï¼ŒåŒæ—¶è¥é”€å›¢é˜Ÿä¹Ÿè¦ç»™åŠ›åšå¥½å®£ä¼ ï¼Œæœ€åŽèµ¶åœ¨åŒ12æ¸…åº“å­˜ï¼Œå‡†å¤‡è¿ŽæŽ¥ä¸‹ä¸€æ³¢çš„æ–°ä¸€ä»£å…¨æ–°å¤„ç†å™¨ã€‚
  - è¯´ç™½äº†ï¼Œå°±ä¸€ä¸ªå­—ï¼Œå·ã€‚

- å¦‚æžœæ˜¯å›½å†…å¸‚åœºçš„è¯ï¼Œå›½å¤–çš„å“ç‰Œä¸»è¦å°±è‹¹æžœã€æƒ æ™®å’Œæˆ´å°”ã€‚å›½äº§åŽ‚å•†ä»½é¢çš„æå‡ï¼Œä¸»è¦é‚£å°±ä¸Žæˆ´å°”è¿™ä¸¤å¹´çš„æ“ä½œæœ‰å…³
  - å‰ä¸¤å¹´æˆ´å°”çªç„¶è¢«è‡ªå·±äººâ€œå¡è„–å­â€äº†ï¼ˆä¸è®©ç”¨ä¸­å›½çš„å…ƒå™¨ä»¶è¿˜æ˜¯å•¥çš„ï¼‰ï¼ŒäºŽæ˜¯è¦é€æ¸é€€å‡ºä¸­å›½å¸‚åœº

- å¦‚æžœæœ‰ä¸€å¤©ï¼Œå›½äº§ç¬”è®°æœ¬å“ç‰Œä¸ä»…å±å¹•æ˜¯äº¬ä¸œæ–¹ã€åŽæ˜Ÿå…‰ç”µï¼Œç¡¬ç›˜ä¹Ÿéƒ½æ˜¯é•¿å­˜ï¼Œæ˜¾å¡ä¹Ÿéƒ½æ˜¯æ‘©å°”çº¿ç¨‹äº†ï¼Œæ•´ä¸ªå›½äº§ä¾›åº”é“¾â€œä¸€æ¡é¾™æœåŠ¡â€ï¼Œé‚£æˆ´å°”ã€æƒ æ™®ä¹‹æµè¿˜èƒ½æœ‰ä»€ä¹ˆç«žäº‰åŠ›å¯è¨€ï¼Ÿ

- åŽä¸ºæ‰‹æœºã€å°ç±³æ‰‹æœºåœ¨äº’è”ç½‘æ—¶ä»£çš„èƒŒä¹¦ï¼Œå¤§å®¶å¯¹å›½äº§ç”µè„‘çš„è®¤çŸ¥ä¹Ÿåœ¨ä¸€ç‚¹ç‚¹å‘ç”Ÿå˜åŒ–ï¼Œå½“ç„¶äº§å“ä¹Ÿç¡®å®žåšçš„è¶Šæ¥è¶Šå¥½

- ä¸å…‰æ˜¯å›½å†…æ•´æœºå“ç‰Œçš„å æœ‰çŽ‡é«˜ï¼Œè€Œä¸”ä½ çœ‹çŽ°åœ¨ä¹°ç”µè„‘æ˜¯ä¸æ˜¯å¤§éƒ¨åˆ†é…ä»¶éƒ½æ˜¯å›½äº§çš„ï¼Œå†…å­˜ç¡¬ç›˜å±å¹•ç”µæ± åŸºæœ¬éƒ½æ˜¯å›½äº§äº†

- å›½äº§ç¬”è®°æœ¬æ°´å¹³çŽ°åœ¨æ¯”å›½å¤–æŸäº›è€ç‰Œå·å¾—å¤š

- ## ä¸‡èƒ½çš„æŽ¨ï¼Œç›®å‰æˆ‘çš„ç½‘ç»œç»“æž„æ˜¯è¿™æ ·ï¼šï¼ˆå…‰çŒ«æ¡¥æŽ¥æ¨¡å¼ï¼‰
- https://twitter.com/haozes/status/1728252250114715882
  - 1. å…‰çŒ«->è½¯è·¯ç”±->å°ç±³è·¯ç”±ï¼Œæ‰‹æœºç”µè„‘æ˜¯è¿žå°ç±³çš„ wifi ã€‚ä½†æ­¤æ—¶è®¾å¤‡æ— æ³•é€šè¿‡ IPV6 è¿žæŽ¥æµ‹è¯•ã€‚
  - 2. æˆ‘è¯•è¿‡ï¼Œå¦‚æžœåŽ»é™¤è½¯è·¯ç”±ã€‚ä»…å…‰çŒ«-å°ç±³è·¯ç”±ï¼Œç”¨å°ç±³ PPOP æ‹¨å·ï¼Œè®¾å¤‡è¿žå°ç±³WIFI æ˜¯èƒ½é€šè¿‡ ipv6 æµ‹è¯•çš„ã€‚
  - æ€Žä¹ˆè§£å†³æ–¹æ¡ˆ1ä¸‹çš„ipv6  ï¼Ÿ
- å·²ç»éƒ½è§£å†³ã€‚çŽ°åœ¨ç”¨è½¯è·¯ç”±ç›´æŽ¥æ‹¨å·ï¼Œå°ç±³è·¯ç”±å½“APæœ‰ä¸¤ä¸ªå‘ï¼š
  1. openclash æ’ä»¶ä¼šæœ‰ç‚¹å†²çªï¼Œå¾—å…ˆå…³æŽ‰ï¼Œæµ‹è¯•ipv6çš„è¿žé€šæ€§
  2. openclash  å–æ¶ˆâ€œipv6â€æµé‡ä»£ç†ï¼Œâ€œå…è®¸ipv6 dns è§£æžâ€ä¸¤ä¸ªè®¾ç½®ï¼Œé¿å…å®ƒå½±å“ã€‚å¦å¤–å¯ä»¥ç”¨å›½å†…ç«™ç‚¹æµ‹è¯•ï¼Œé¿å…å®ƒç›´æŽ¥èµ°äº†clashï¼š
- openwrtå•¥éƒ½æœ‰å•Šï¼Œç¿»å¢™éƒ½æ˜¯è¾…åŠ©åŠŸèƒ½ã€‚
- æ–°ä¸€ç‚¹çš„ç±»ä¼¼çš„openwrtæ— çº¿è·¯ç”±å™¨ æŽ¥åˆ°çŒ«ä¸Šç¡¬ä»¶ä¸€ç«™å¼å…æŠ˜è…¾ã€‚æŠ˜è…¾è½¯ä»¶å°±å¯ä»¥äº†ã€‚

- ## ä¸‰å¹´å‰æˆ‘æ¬æ–°å®¶ï¼Œé…ç½®äº†ä¸€å¥—ç²¾å¦™æ— æ¯”çš„ç±³å®¶æ™ºèƒ½å®¶å±…ç”Ÿæ€ç³»ç»Ÿã€‚ æ˜Ÿç½—æ£‹å¸ƒçš„éšè—ä¼ æ„Ÿå™¨ï¼Œè®©æˆ‘ä½“éªŒä¸æ»‘æ— ç¼ã€‚ 
- https://twitter.com/XDash/status/1690655450927112193
  - ä¸‰å¹´è¿‡åŽ»äº†ï¼ŒZigbee å’Œ Mesh åè®®çš„ä¼ æ„Ÿå™¨ï¼Œä¹Ÿè¯¥æ›´æ¢çº½æ‰£ç”µæ± äº†ã€‚ 
  - æ˜Ÿç½—æ£‹å¸ƒçš„éšè—ä¼ æ„Ÿå™¨ï¼Œå®³æˆ‘æ‰¾éæ¯ä¸ªåœ°ç¼ã€‚
- æˆ‘ä¹Ÿå·®ä¸å¤šä¸‰å¹´å‰å¼„çš„å…¨å±‹æ™ºèƒ½ç³»ç»Ÿï¼ŒçŽ°åœ¨ä½¿ç”¨çŽ‡ä¹Ÿå°±20%
- æƒ³æƒ³å‰©ä¸‹çš„ç”µæ”¹é€ çš„é’±ï¼Œä¸‰å¹´ä¸€æ¢çœŸé¦™ã€‚
- æ‰€ä»¥è¦æŽ¥çº¿
