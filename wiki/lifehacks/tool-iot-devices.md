---
title: tool-iot-devices
tags: [iot, tool]
created: 2019-08-11T07:36:17.519Z
modified: 2022-01-16T15:52:31.293Z
---

# tool-iot-devices

# watch

- 不使用录音笔，而使用录音手表

- [智能手表录音功能总结 - 知乎](https://zhuanlan.zhihu.com/p/592180358)
  - 社畜们需求很简单 能息屏一键录音 录到没电 能同步到手机 且可以导出文件 有血氧 心率监控等健康功能 手表分运动产品线和商务产品线 质感做到最好 这表我出3000
  - 后台录音
  - [胖表哥小课堂：Amazfit GTS4>R4手表录音功能测评，能否息屏录音？音质如何？\_哔哩哔哩\_bilibili](https://www.bilibili.com/video/BV1vm4y1v7yY/?vd_source=deff4d2e2efa3273948dd6911a08fd39)

- [分析华米Amazfit T-Rex和GTR对比区别？](http://bbs.mydigit.cn/read.php?tid=2831142)
  - GTR支持录音
  - 功能是一样的，就是外观不同的，我自己也是才购的，新品trex的，样式很不错，很运动的感觉
# U盘
- U盘的优点主要在于，
  - U盘的使用不需要依赖网络，
  - 并且U盘能够保护用户的隐私和数据安全。
  - 另外，将电脑文件从本地上传至U盘的传输速度很快。
- U盘的主要缺点在于，
  - 价格可能相对昂贵，能够储存的数据容量有限，通常以GB为单位。
  - 此外，U盘作为一个物理硬件容易被丢失，U盘中的文件也没办法随着本地文件修改进度而进行实时更新。
  - U盘间进行数据传输也比较麻烦。
- 云盘的优点在于，
  - 用户通常可以免费体验云盘所带来的服务。
  - 云盘能够提供较大的数据容量，通常以T为单位。
  - 云盘中的文件可以与电脑中保存的本地文件进行实时同步。（微软的OneDrive和百度云都是很好的例子）
  - 云盘之间想要传输文件也会相对便捷。云盘也会带有一定的网络社交属性。
- 云盘的缺点在于，
  - 云盘的使用需要依赖于网络，并且处于某些原因储存在云盘中的文件会被第三方查阅、修改或者删除。
  - 这样就会导致云盘用户的个人隐私和数据安全得不到保障。
  - 文件上传至云盘的速度还会受到网速的限制。
# screen resolution
- guide
  - 除了分辨率，还要考虑使用场景，如系统分屏、多窗口排列
  - 还要考虑持续更新、消费的能力
  - [Screen Resolution Stats Worldwide](https://gs.statcounter.com/screen-resolution-stats)

- android
  - ldpi: 240x320, 240x432
  - mdpi: 320x480, 480x800, 480x854, 1024x600, 1280x800
  - hdpi: 480x800
  - xhdpi: 720x1280, 1200x1290, 2560x1600
  - xxhdpi: 1080x1920
  - tvdpi: 1280x800
- [Screen sizes and densities](https://developer.android.com/about/dashboards/index.html)
  - ldpi/0.001, mdpi/0.062, tvdpi/0.027, hdpi/0.179, xhdpi/0.45, xxhdpi/0.281

- desktop
  - **1920x1080**/0.215, 1366x768/0.201, 1536x864/0.096, 1440x900/0.064, 1280x720/0.054, 1600x900/0.036

- mobile
  - 360x640/0.106, 414x896/0.072, 360x780/0.057
# android
- vulkan version
  - none: 0.42
  - v1.03: 0.22
  - v1.1: 0.36

- opengel es version
  - v2.0: 0.105
  - v3.0: 0.141
  - v3.1: 0.079
  - v3.2: 0.675
# 设备使用问题
- 强制全家桶
- 手机管家/安全管家
- 推送消息太多
- 隐私数据
# laptop-笔记本
- 要点
  - 键盘的上下左右4个方向键要大小相同
# Fuchsia OS

# 阿里YunOS/AliOS

- 2011年7月28日，阿里巴巴正式推出YunOS，基于linux kernel，设计借鉴了Android
- YunOS兼容Android应用，YunOS的虚拟机还是Dalvik虚拟机修改版
- 魅族支持过YunOS，但坚持使用魅族UI，在一个商业化的操作系统中，核心层并不核心
- YunOS应用在电视盒子上后私自删除用户软件，强迫使用YunOS自带软件
- 改名为AliOS后专注于汽车，与android区别越来越大，linux内核+运行库
# 华为HarmonyOS鸿蒙系统
- 特点：分布架构、高性能、内核安全、生态共享、开源
# discuss-tv
- 参数配置
  - 尺寸
  - 屏幕技术
  - 分辨率
  - 刷新率
  - 亮度
  - 色域
  - CPU
  - RAM
  - 边框

- ## 

- ## [互联网电视不能装网络浏览器…也是醉了 - 小红书](https://www.xiaohongshu.com/explore/6700c411000000001a0223db?xsec_token=ABoe1ug9YJJDbnOMEN4Q6C0fZ0dK1qg9_RVKDLAdWF5b8=&xsec_source=pc_search&source=web_explore_feed)
- 法规要求，电视上的内容必须管起来，浏览器上的内容管不了，不让装。

- ## [Why Chrome browser is not available on Android TV (Google TV)? : r/AndroidTV _202304](https://www.reddit.com/r/AndroidTV/comments/12yc3mi/why_chrome_browser_is_not_available_on_android_tv/)
- I don't know the reason but TV Bro does a great job instead.

- Google doesn't think you need to browse the web in your TV. That's just for consuming media.

- Mozilla used to have a Firefox for Fire TV (and then generic ATV) but they killed that years ago as well.
  - firefox continues to work on ATV but it requires a mouse to operate correctly.

- ## [小米电视不用挂墙，就装个底座为啥还要安装费 - 小红书](https://www.xiaohongshu.com/explore/686c7ba7000000000b02db9e?xsec_token=ABL7n_fleKY2d2yJ0Kl5bHj7o_Vw4sUjrEkqzyYIDNIto=&xsec_source=pc_search&source=web_explore_feed)
- 就拧四颗螺丝这么简单，何须花50块，自己装不就行了吗？

- 其实安装很简单，就是电视太大了要两个人装

- 首先再简单也要时间成本。其次只要过手了就会有风险。

- ## [小米电视没法装第三方软件？看这里！ - 小红书](https://www.xiaohongshu.com/explore/6885f1cc000000001c037e3d?xsec_token=ABFqR2NYsx0tMZ2_1jW9XRC31wt0kSyS-GYe02iCV-ca8=&xsec_source=pc_search&source=web_explore_feed)
- 小米电视安装第三方软件第一步，电视恢复出厂设置。这一步是为了清除电视内的app黑名单。
  - 恢复出厂设置后电视重启，进入新电视设置阶段，一定不要联网，跳过WiFi无线网络选择。保持断网的状态就不会更新黑名单。
  - 打开电视的设置-账号与安全-选择允许安装未知来源的应用。
  - 安装需要的APP：将下载好的app的apk文件拷贝到U盘，把U盘插入电视的USB接口，打开U盘。找到APK文件，点击确定进行安装即可。弹窗提示可能存在未知风险，选择继续安装。软件安装成功。

- ## [红米电视解决底座螺丝难拧的小技巧 - 小红书](https://www.xiaohongshu.com/explore/6794beb00000000029032fe0?xsec_token=ABvhnSCS5ukgPATsbc3yLg8-KBvtXyfeWGHlUGivnnbQQ=&xsec_source=pc_search&source=web_explore_feed)
  - 刚买了个红米电视, 家里人说底座装不上, 查了网上很多人说螺丝难拧
  - 其实只要装支架前螺丝先拧进孔里再拧出来，之后安装就很简单了
- 就是先不带架子单独拧一遍螺丝，然后螺丝拿出来之后再重新安架子不？
  - 对，拧的时候小心点，用巧劲别死摁
- 先别装支架，把孔拧松

- ## [红米电视apro系列和a系列有什么区别？Redmi A55 Pro和a55 2025款怎么选？ - 知乎](https://zhuanlan.zhihu.com/p/721352900)
- 处理器
  - 红米a55pro：四核A55、3GB+64GB
  - 红米a55 2025款：四核A35、2GB+32GB

- 红米a55pro采用NFC遥控器，支持一触投屏；红米a55 2025款采用的是红外遥控器。

- 红米a55pro支持2.4G&5G双频wifi，红米a55 2025款支持2.4G，红米a55pro网速更稳定。

- [小米电视redmi A55和小米电视redmi X50哪个好一点？ - 知乎](https://www.zhihu.com/question/466093554)
  - 参数对比图

- ## [为什么小米电视突然就没人关注了？ - 知乎](https://www.zhihu.com/question/662395651)
- 电视机下一代打法应该是卖65 75寸的显示器，不带任何内容功能，仅提供外接接口，此时合规审查的任务就会落到电视盒子这个东西上面。

- 不是小米电视没人关注了，是整个电视行业都黄了而已，各种会员收费基本把电视这个行业搞残废了。
- 客厅的电视，俩月没打开了，浪费空间

- 小米电视舆论最火的时候, 是华为和荣耀要进军“智慧屏”前后, 现在这摊业务没下文了，小米电视也就没啥声量了。
- 因为智慧屏销量只有小米电视销量的零头，花粉和水军们放弃这个阵地了，目前集火的是小米汽车

- 别家今年的高端：4000nit亮度，4000分区背光，量子点广色域，黑耀屏。 
  - 小米今年的高端：看什么看，还没出呢。
- 在等供应链成熟贴牌呢

- 小米今年有些摆烂，半年过去了才出了一个S Mini LED系列。别家都在搞机海了

- 曾经任职于倒闭互联网电视机品牌微鲸。拆过各个竞品互联网品牌，小米怎么说呢。用料属于还行，但是并非最好。
  - 以16年的产品用料来看。当年最好的其实是乐视和微鲸，小米A系列就差了不少，连外框后盖都不舍得配了，直接裸奔上市pptv, 暴风，风行就更糟糕了。
  - 17年，互联网电视品牌出现了问题，钱烧光，传统品牌等着这笔热钱烧完，开始回来收割市场了。这里面雷鸟依靠自己华星光的面板资源和TCL的规模优势，以及软件运营方面直接用TCL系统把研发成本摊平，物流售后方面完全可以共用TCL母品牌的资源。远比小米的成本优势明显。对小米来说，电视业务是补足自己全屋智能的拼板，可以不赚钱，但绝对不会为了这个业务投钱。因此性价比优势也就没有了

- 小米电视主打的还是低价和米家生态，2021年下半年开始，小米电视被雷鸟电视针对，竞争比较激烈
# discuss-screen
- ## 

- ## 

- ## [为什么现在的智能手机不使用半反半透技术的显示屏？ - 知乎](https://www.zhihu.com/question/264049308)
- 半反半透的好处就是保持彩色屏幕和阳光下可读性的同时还能做到省电。不过这种屏幕色彩还原性不是很好，这种屏幕看个简单的图形或者数字文字还行，要是看图片视频了就不舒服了，色彩还原不好。

- 我想是大量生产问题，始终是少众，人们都习惯了背光，背透在彩色显示上差强人意，所以有些時在沒背光下會使用AMBRITE（虎珀）/黑白模式，在晚间或稍暗时是不方便和尴尬的，省了点电但换来不便，现在多使用在少电的穿戴产品。

- [半透反射式TFT液晶屏为何没有流行？ - 知乎](https://www.zhihu.com/question/20807503/answers/updated)
  - 这种屏幕现在除了一些专业的户外器材（例如运动手表啥的）上有用，已经离大众越来越远了，也算是时代的眼泪了。
# discuss-ai/ml-hardware
- ## 

- ## 

- ## 

- ## 

- ## 🍎 [MacBook M4 Max isn't great for LLMs : r/LocalLLaMA _202503](https://www.reddit.com/r/LocalLLaMA/comments/1jn5uto/macbook_m4_max_isnt_great_for_llms/)
- M4 Max is about 50% faster than an Nvidia P40 (both in compute throughput and memory bandwidth). 
  - It is about 2.5x slower than a 3060 in compute¹ throughput (FP16) and 50% faster in memory bandwidth. 
  - Compared to 3090, it is about 7x slower in compute¹ throughput (FP16) and almost 2x slower in memory bandwidth.
- P40s (and generally Pascal) were the last ones without tensor cores (which increase FP16 throughout by 4x).
  - The lack of tensor cores is also the reason Apple M3 Ultra/M4 Max and AMD 395 Max, lag in Prompt Processing throughput compared to Nvidia, even if the M3 Ultra almost matches a 3080/4070 in raster throughput (FP32).
  - Compared to CPU-only inference, P40s are still great value, since they cost $150-300 and are only matched by dual 96-core Epycs with 8-12 channel DDR5 which start from $5000 used.
- Pascal doesn't even have FP16 support, all the operations are done through fp32 units afaik so throughput is effectively halved. It wasn't until Ampere that NVidia had FP16 support.

- Try swapping to serving with LMStudio - then use MLX, and speculative decoding with 0.5b as draft for 14b! Tripled my speed on my M1 Max
  - Speculative decoding really is great. It at least doubled my speeds. In token generation. Prompt processing didn't get and bump though. I'd love to have a 128gb+ RAM machine to also activate KV Cache

- ## [本地部署大模型性价比之王真的是Apple Mac Studio M3 Ultra 192或512吗？ - 知乎 _202503](https://www.zhihu.com/question/14548406514)
- deepseek r1 用mac studio测试
  - ollama: 16 tops
  - lmstudio: 18 tops
  - 512Gb内存还是只能部署4bit量化版本，8bit不行
- 如果按照18.11token/s的输出速度，不考虑其他，全天24小时运行（不考虑prefill等时间）18.11×86400s=156.5万tokens，而官网百万tokens售价才16块，156.5万售价25块钱
  - 而Mac studio 512G内存，1t硬盘版本售价7.3w教育优惠也要6.7w，需要365×24h不停运行8年/7.3年才能回本

- 那要看你怎么定义性价比了，[ktransformers] + [epyc] 现在也已经玩得很强了，苹果胜在上手就能用不用折腾装，在那个价位算一个可行方案，但并非算唯一性价比方案

- ## [MAC mini M4芯片32G+256能跑大模型吗？ - 知乎 _202503](https://www.zhihu.com/question/14795834393)
- 真跑ai只推荐Pro以上的芯片。
  - m4的内存带宽其实和普通核显win机子差不多。而到了Pro，内存带宽就达到256了，达到4060的水准。
  - max和ultra带宽分别是400＋和800＋，基本是显卡级别的带宽，用来跑ai推理很合适。

- 主要是内存大啊，我用一万出头的mac能跑27B的gemma3 8bit量化，如果用显卡的话至少得是个3090级别的

- Mac Mini 当副机可以，统一内存看着香，但很多模型不支持 MPS，或者用 MPS 跑得比 CPU 还慢。

- ## [Apple M5 could ditch unified memory architecture for split CPU and GPU designs | Hacker News _202412](https://news.ycombinator.com/item?id=42552494)
- UMA hurts the GPU too much. Widely parallel processing wants to access memory in bigger chunks than a CPU. If you try to mix access and modification, you lose the benefit of widely parallel processing. 
  - Other GPU designers have considered and eschewed unified memory models, to the tune of hundreds of millions in research dollars.
- I agree that single cache-line fetches are pretty poor for parallel vector units, but supporting the former in an environment designed for the latter doesn't seem to off-putting (the CM-5 did this).

- You can split the CPU and GPU and still have UMA. Splitting CPU/GPU is a packaging and interconnect concern and is not mutually exclusive with UMA.

- ## [求推荐！想组一台256G➕笔记本跑大模型🥹 - 小红书](https://www.xiaohongshu.com/explore/6892017700000000030274de?xsec_token=ABHUpmj6nmLewRxGBOYsEYt2FVRxDHjqOHSnhQfgUJJnc=&xsec_source=pc_search&source=web_explore_feed)
- 普通笔记本不支持256，别异想天开
  - 笔记本内存有是有，但是笔记本不支持，买了也没用，到时候插上去不识别就老实了
- 别想了，笔记本不支持ecc内存，跑时间长容易出错
- 哪个苹果笔记本有512内存 你找出来我看看，我就知道推出过2t内存的mac pro还有512内存的mac studio，mbp最大的就128g内存吧 m4max

- 散热压不住的

- 笔记本目前能本地部署大模型的只有m系芯片的mbp内存拉满（仍然是勉强够用水平）和ryzen ai max+395板载内存拉满128（这个的内存和效率估计不太够，唯一优势x86日常方便），因此主要往itx上面去凑，现有产品也就是我说的这两套即苹果m系和amd ai，因为有统一内存可以用核显来跑ai免去多路gpu的麻烦。

- 如果你需要cpu高性能，那么可以考虑用比较新的服务器平台（因为我估计连hedt都无法满足你的内存需求）和itx主板（当然，华擎不一定还在做这类奇特的产品）。你只需求单卡的话可以勉强塞一套itx，但是各方面都很极限了，包括供电和散热，大概是跑不满的。如果你需求多卡的话，可能得几张卡用扩展卡连接以分着用itx主板仅有的那一两个pcie x16接口，这样做性能肯定会有折损，并且100%需要做分体的两个itx机箱，这种情况你需要自己画设计图去tb之类的平台找工厂定做板材，好处是供电和散热没之前那么极限，坏处是这一套下来估计不比eatx机箱轻便多少。

- ## [选个能本地跑70B大模型的笔记本当主力机试 - 小红书](https://www.xiaohongshu.com/explore/6811b115000000002301de1a?xsec_token=ABZEBEajWMF79jFUPp-RsmTEccFriosXMc79IFdgiGHWo=&xsec_source=pc_search&source=web_explore_feed)
  - 之前一直用灵刃16 2024版的当主力机，跑起来风扇实在是响，开个线上会别人都听不清，而且重量实在无法移动。
  - 最近看到HP 战99 Ultra到货就直接拿下了 128G。用了一天，感觉AMD AI395+跟之前i9-14900hx性能差别不大 不过噪音好了很多，集显8060s的性能虽然不如之前4070，但是跑个本地小模型也没什么压力。
  - 重量上1.6KG稍微重了一点点，跟X1C没法比，跟macbook pro 14差不多，比灵刃强太多了。
  - 触屏的

- pd充电能有原厂充电器几成的性能？
  - 原厂130w的，65w的PD会提示慢速充电器，只有一半不到的速度

- 本地70B速度怎么样？
  - 有个20-30 token/s 凑合用
- 我qwrn32量化8也才5个token，你这个70b 20-30token是怎么来的
  - 70量化4可以的，量化8肯定不行

- ## 🆚 [关于几个桌面级的AI统一内存集成方案的对比 - 知乎 _202503](https://zhuanlan.zhihu.com/p/31599083340)
- 目前桌面级别的AI方案，除了nv的独显外，还有几个统一内存的集成方案
  - 苹果Mac mini和Mac studio
  - AMD AI 395 MAX
  - 英伟达 DGX Spark

- 带宽 ：(❓推理/部署时重要)
  - m4pro 64G 和nv dgx spark 128G都是 273 GB/s
  - amd AI 395 max+128G 是            256 GB/s
  - m3ultra 96G是                     400 GB/s (m3u无128G，256G以上才有800GB/s)
  - m4max 128G 是                     546 GB/s

- AI算力：(❓训练时重要)
  - nv dgx spark是  1000 TOPS (FP4)
  - amd AI395max是  126 TOPS（int4）
  - m3ultra是       72 TOPS(int4)
  - m4max和m4pro都是 38 TOPS(int4)

- 价格：
  - nv dgx spark  3000 美元（估计23000人民币？）
  - amd ai395max  25999 人民币
  - m3ultra 96G   32999 人民币
  - m4max 128G    29249 人民币
  - m4pro 64G+1T  16999 人民币

- 综合看来如果性价比和通用性比较好的选择应该是nv DGX Spark（生图，生视频之类的算力比带宽更重要），
  - 如果单纯为了LLM性能（统一内存带宽比算力更重要）m3ultra 96G 可能是比较好的选择。
- 至于之前有看到的一些用mac mini通过雷电口堆叠的虽然可以低成本做到大显存，但是几乎没啥实用价值，因为雷电口带宽只有15GB/s。。。
  - 雷电堆叠是为了低延迟跑tensor parallelism吧，又不是remote访问内存。PCIE带宽也不如内存，但多卡并行还是有效的

- 现在网上ai max 395的小主机已经卖到14000左右了，这样比下来，感觉ai max 395性价比还不错。

- ## [如何评价售价 18999 元的惠普暗影精灵 MAX 游戏本? 哪些亮点值得关注? - 知乎 _202503](https://www.zhihu.com/question/15023061538/answers/updated)
- 暗影精灵MAX这个新模具就用来取代暗影精灵Plus的，依然是主打一个“一线品牌中的性价比”定位。
- 一线品牌高端游戏本的守门员，原来暗影精灵PLUS的替代者。

- 这代Max整体的升级点：
  - 散热规格升级：采用了VC均热板设计，加上液金散热与4出风口设计，整体可以做到250W+的性能释放，双烤75+175W；
  - 屏幕改为更主流的16寸：2.5K分辨率16:10比例高分屏，500nit亮度240Hz刷新率；
  - 新增大师模式，允许用户手动超频。

- 其他配置只能说中规中矩了：
  - 32GB DDR5-5600内存+1TB硬盘，双硬盘位双内存插槽；
  - 只给了2A2C（2个雷电4）+HDMI+RJ45的接口，在游戏本里面算比较少的了；
  - 给了RGB背光键盘，但目前来看还是四区RGB而非单键RGB，并且方向键依旧为半高；
  - 电池容量83Wh，主流旗舰定位的游戏本都90Wh+了，有的甚至99Wh

- 目前惠普精灵遇到一个比较尴尬的问题，比上没有品牌力，比下没有性价比：
  - 加3000可以上逼格更高、更有氛围感、可玩性更高的且品牌更强的ROG枪神9系列；
  - 预算更低，等二线品牌上了之后，大概率1W4不到就可以拿下低U高显的RTX5080游戏本了，性价比更高。
- 国内游戏本市场目前还是以性价比为主导，就连ROG这两年都变得有性价比起来，所以对于暗影精灵MAX这类的不上不下的主流系列旗舰本，我是谨慎看好的，比上无品牌力，比下无性价比。

- 小米G的目标客户是追求性价比的用户，但这帮用户会因为小米G没有性价比不选择小米G……

- ## 🆚📈 [2025买个RTX 5090笔记本，有什么推荐吗？ - 知乎](https://www.zhihu.com/question/1890528801219405195)

> 不太在意便携，主要是看性能+性价比。神舟性价比太高了，但是又有点害怕翻船。

- 在圈定要RTX5090游戏本的前提下，题主的最佳选择肯定是一线品牌高端游戏本一直以来的性价比扛把子，暗影精灵MAX啊
  - U9-275HX+RTX5090+2.5k 240hz 500nit IPS+32/1T PCIe 5.0的核心配置，250w+的整机性能释放表现中等偏上，拓展性一个5.0 M.2一个4.0 M.2，重量2.75kg，接口是俩雷电4，俩USB-A，HDMI和rj45。
  - 上面这个配置也就22999，国补后才20000出头
  - ROG也完全没必要看枪神9 Plus超竞版吧，捆绑了64G内存后价格直接33999了，实在是太夸张。枪神9 超竞版除了内存硬盘都缩小一半以及尺寸为16吋之外，几乎没啥区别，价格则直接下降到了29999，立省4000.

- ## [有没有24g显存的笔记本电脑推荐？ - 知乎 _202409](https://www.zhihu.com/question/666131987)

> 想要买个新电脑来玩AI。主要还是想考虑笔记本，但是看了一圈，好像都是8g显存。最大的也就16g显存。没有找到有24g显存。

- 目前做AI推荐N卡，N卡24G显存只有4090，4090做成便携式只有这一个方法

- 有三个方案：
- 第一个方案是内置显卡的笔记本电脑，优点是便携性好，缺点是性能差点，也得做好散热。
  - 想要16G显存只能RTX4090的型号，绝大部分RTX4080移动端是12G显存，目前使用RTX4090的笔记本电脑不算多，想要性价比就机械革命耀世16Super，想要更强的整机性能释放可以考虑ROG枪神。
- 第二个方案是拓展坞外接桌面显卡，优点是性能强不用考虑散热，并且后期还能随时无痛升级显卡，缺点是丧失了便携性，并且要注意别没断电就拔显卡。
  - 笔记本有雷电3/4或者USB4接口就行，RTX4080会有性能损失，但是能接受，毕竟怎么都比移动端强
- 第三个方案就是放弃繁文缛节，直接上台式机吧。

- ## [纠结选哪款笔记本电脑？主要用于stable diffusion? - 知乎](https://www.zhihu.com/question/620893866)
- 看到楼下有个好点的建议，雷电接口的笔记本+显卡拓展坞+独立显卡
  - 这个方案的话，拓展坞不做推荐确实不知道怎么选，但显卡4090普遍10000以上了

- ## [AI绘画（Stable Diffusion）用什么显卡比较好？ - 知乎](https://www.zhihu.com/question/638915747)
- 在你能承受的范围内，选显存最大的

- 目前的条件下只有N卡能正常玩AI。
- 想要低价拉满AI。就用RTX TITAN 24GB（不到5000，但需要加水冷压，或者魔改的RTX 2080Ti 22G（不到3000）非涡轮卡的版本。但现在目前看24G的3090性价比最高。

- 推荐一块性价比高的显卡，RTX 2080ti 22g。ai画图性能接近RTX 4090的一半，价格只要五分之一。而且22g大内存，对模型训练也很友好。不过RTX 2080ti 已经上市很多年了，要淘到一块好卡不容易，最好有几年保修的更好

- 跑4K以上稳稳的，显存为32G的显卡一定是首选，不是魔改款，那就只有即将上架的5090了。
  - 跑2K以上的话，12G-16G的卡都可以，不过12G跑某些大模型可能不够用
  - 2K将就用，目前选4060TI 16G的用户多点，不过这款显卡只是预算少的选择，毕竟显存位宽被阉割，GPU性能也一般。
  - 没短板，出图快，首推4070TIS 16G，这款卡，我用下来很满意，缺点就是溢价高。
  - 跑1K以上的话，3060 12G，2060 12G，都已经可以跑了

- 经过不断的优化，现在的Stable Diffusion对显卡要求不算太高，
  - 如果只是跑图，4060Ti 16G就够用，炼丹的话，4090也足够了。

- 至于也是3000多的2080Ti-22G，魔改的有风险，多几G显存对这个软件来说用处不大，有新还是买新。
  - 之后就是7000这一档的，5070Ti，为什么不是4070Tis呢，因为50系显卡可以用4位模型，40系只能8位。

- 10系显卡不支持4bit（其实也不支持8bit、16bit），但是Q4能跑啊，就是慢呗。工作原理是按原位数大小装显存中，跑的时候分段转换成fp32来跑。

- ## [如何评价HP最新发布的搭载AI MAX 300系列处理器的战99 Ultra？ “战 99 Ultra”移动工作站已于3月17号上架京东  - 知乎](https://www.zhihu.com/question/15255805038)
- 今年唯二的Strix Halo笔记本（另一个是幻X），同时可能是唯一的常规形态产品。
  - 这机器在海外的名称是Zbook Ultra G1a，实质上是EliteBook X G1a的复用模具但加厚+增强散热的版本。定位就是旗舰轻薄移动工作站的小尺寸版本，类似ThinkPad P1，但是做了14吋的版本。
  - CPU方面，除了和之前已经上市的幻X一样的AI MAX 390/395（分别对应16C+40CU/12C+32CU）之外，还多了一高一低两个新的配置，更低的AI MAX 385是8C+32CU的规格，同时还有个顶配的商用版AI MAX+ Pro 395，这颗CPU是惠普独占的。
- 其他地方就基本和原版的EliteBook一致了：
  - 2.8k 120hz的OLED触摸屏
  - 74.5wh电池，支持PD 3.1快充
  - 单硬盘位

- 这价格只能说是好家伙了，55w性能释放的常规形态机器，卖的比隔壁幻X的平板形态+80w性能的还贵... 如果一定买考虑，只推荐顶配版本，起码还是有独占CPU的

- 如果主要是冲着Strix Halo这颗CPU来的，那还是更推荐幻X，因为性价比更高，AI MAX+ 395+128/1T的版本也就20999，如果是32G的版本，就只要14999了。

- 为什么STX Halo这颗CPU看起来很好，但实际上无OEM愿意用？个人认为主要原因是两点：
  - 一个是这颗处理器原本应该在2024年和STX Point一起上，却因为种种原因延误到了今年，因此对标的对象也从原来的RTX 4060变成了RTX 5050，这时候STX Halo的核显性能实际上就没有太大的吸引力了
  - 另一点在于STX Halo产生的最大意义在于在空间尺寸受限的平台上做到尽可能高的性能，但现在ROG已经在14.0吋的轻薄平台上做出来BD1的卡了（RTX 5080 on 幻14 Air），幻X的上一代也早已经挑战过在13吋的平板上做H45+BD2显卡
- STX Halo这么个怪物CPU本身存在的意义就已经受到了严重的动摇了。继续往小尺寸做？那散热更完蛋，性能也跟着寄。继续往大尺寸做？做到15吋及以上的平台上，传统的CPU+GPU方案成本低，散热更好做，整体效果还更好
  - 不会有人真的觉得A卡游戏体验好吧，尤其是移动端A卡

- 最大的缺点还是价格。2.5万的价格，如果以他对标的7945HX+RTX 4060的笔记本电脑，都可以买3台了，选择R9000P也就8000多出头。那就看你愿不愿意为了轻薄付出溢价了。

- 惠普战99 Ultra，海外对应型号Zbook Ultra G1a，便携移动工作站定位。常规的配置例如全金属机身、2.8K OLED屏幕、惠普工作站的祖传接口3C+HDMI+1A、74.5Wh电池就不再赘述了。
  - 最大的亮点就是AMD锐龙AI MAX 300系列的处理器。AI MAX+ 395处理器是惠普独占，CPU规格和桌面端9950X相当，只不过受制于笔记本电脑散热不能完全发挥；说是集显，但是性能堪比RTX 4060的独显。
  - 同时另一大好处在于实现类似于苹果一样的128GB统一内存，最多可以分配96GB给显存。128GB内存版本为4通道，内存吞吐速度能够达到200GB/s出头，比常规的双通道100GB/s直接翻倍了
- 14寸的笔记本电脑，重量到了1.6kg，属于是偏重的。性能释放也就在55W，不能发挥出完整性能。作为移动工作站只有单硬盘位。

- 问题是性能释放还不如幻x，这个只有55w。

- ## [ROG幻X 2025对于运行AI应用（如本地大模型）有没有显著优势？能否助力用户提升AI体验？ - 知乎 _202503](https://www.zhihu.com/question/14670046303/answers/updated)
- 属于什么都能干，什么都干不好的富哥玩具。
  - 便携和离电性能比不过几千块的mac air。
  - 游戏性能比不过同价位的4080m（马上就5080m了）
  - 大模型被同价位mac studio m4打爆。

- 这玩意跑大模型的能力就是个3060 12g或者最多4060ti 16g的水平，反正12g～16g显存跑不起来的东西395也没速度了，而只要用显存能跑起来，速度绝对吊打395。
- 按我理解这玩意的意义是具备轻薄本少有的同时具备64g以上内存、不尿崩的续航、足够强的显卡以应付图片和视频编辑。然而在这个场合下，却被MacBook pro全方位爆杀。

- [独家首发AI Max+395处理器 ROG 幻X 2025跑分解禁，是否值得购买？ - 知乎 _202502](https://www.zhihu.com/question/12616419565)
- 最近我看到业内新出现了2种桌面级AI计算/PC类产品，一个是在NVIDIA GTC大会上正式发布的DGX Spark（芯片代号GB10），还有基于AMD Ryzen AI MAX PRO处理器的笔记本/移动工作站/台式机，都宣称能支持70B乃至更高参数的模型。
  - NVIDIA DGX Spark号称“最小的 AI 超级计算机”，它的处理器有点像微缩版的DGX计算系统（参考下图），在GB10单芯片上集成了Grace CPU——20个Arm Core，以及Blackwell架构的GPU。
  - AMD Ryzen AI MAX PRO系列（代号Stirx Halo），更接近传统集成显卡的x86 CPU，但整合GPU的性能却比较强。其默认TDP功耗55W，根据不同系统设计，cTDP可调功耗在45-120W范围。
  - 无论使用CPU还是GPU做AI计算，在LLM推理的Prefill（内容输入理解）阶段的瓶颈是算力；而在Decode输出时的性能（Token/s）则主要受制于内存带宽。
  - 我们看到上面2款产品都使用了256位LPDDR5x-8533内存（AMD的实际运行速率为8000），比传统AI PC的64位双通道内存提高了一倍，相当于4通道。
- 由于Grace ARM CPU只认证了DGX™ OS操作系统，应该只能跑Linux（不兼容Windows），所以DGX Spark主要就是用于计算，图形性能方面不知是否做了优化？
  - DGX Spark的AI性能，与GeForce RTX 5070桌面显卡较为接近。不过有一点，5070的显存带宽高达672GB/s，这一点即使是256bit LPDDR5x内存的集显也忘尘莫及。毕竟一块5070独显就是250W TGP功耗，其空间占用也很难做到Mini机箱/轻薄笔记本里面。

- ## [AI绘画（Stable Diffusion）用什么显卡比较好？ - 知乎](https://www.zhihu.com/question/638915747)

- ## [不计预算，帮我买一台性能超强，外观简约的笔记本电脑？用于本地部署各种大模型，暂定微软，还有别的选吗？ - 知乎](https://www.zhihu.com/question/624402976)
- Windows笔记本这边的性能天花板是 i9-13980HX/R9-7945HX +RTX4090（175W）
  - 这俩CPU性能差不多，7945HS便宜点
  - 推荐你选i9-13980HX，因为Intel对各种生产力工具的兼容性更好。
  - 移动端RTX4090的性能相当于桌面端的4070Ti，但是它有16G显存，比12G显存的4070Ti更适合跑模型。
  - 目前，搭载13980HS和RTX 4090笔记本的价格普遍在22000元以上。比如ROG枪神7和微星GP78HS
  - 同样的价格你可以买到i7 13700K和RTX4090 24G的台式机（惠普暗影精灵9plus）

- 当前笔记本端最强的4090笔记本显卡，规格上持平桌面4080，跑分性能上与桌面4070ti相当
  - 笔记本端次强的4080笔记本显卡，规格上接近于桌面4070ti，跑分性能与桌面3090相当

- 建议还是戴尔，惠普，联想这三家的工作站笔记本吧。工作站配置的独立图形显卡适合的要求的大量模型，再就是工作站的内部结构、配置都是针对处理大型3D模型做了加强、优化的，其工作稳定性是普通笔记本无法比拟的。

- ## [amd发布新的芯片，这次芯片跟苹果的m4一样，将gpu和npu集成到同一块芯片上去，说明了什么？ - 知乎 _202501](https://www.zhihu.com/question/9253691862)
  - AMD 在 CES 2025 上发布了锐龙 AI Max 300“Strix Halo”系列 APU，搭载了最高 40CU 的超强核显，此外集成了 50 TOPS“XDNA 2” NPU。
  - 这种将强力 CPU、GPU、NPU 等集成到一个芯片的做法，看起来有点像苹果在 M 系列芯片中的设计。

- 苏妈看到apple M系列芯片被拿来跑AI大模型推理的时候，也鼓捣了一个Ryzen AI Max 300 系列处理器规格曝光，最高16核心、40CU核显 。最高可以从内存中分配96GB超大显存，结合ROCm（开放计算平台）系统支持，或能变成新一代小型工作站神U

- ## [如何看待英伟达公司发布的桌面级AI超算? - 知乎](https://www.zhihu.com/question/8970511370)
- Project Digits 现在改名叫：NVIDIA DGX™ Spark 。
  - 其定位是：个人桌面端的 AI 超级计算机。
  - 由 GB10 超级芯片驱动
  - 使用 FP4，AI 性能达 1000 TOPS
  - 配备 NVIDIA Blackwell GPU，⽀持第五代 Tensor Core 技术
  - NVIDIA Grace CPU 实现，采用 20-core 高性能 Arm 架构
  - 128 GB 统一寻址系统内存
  - 支持高达 4 TB 的 NVMe 存储
  - 支持高达 200B 参数的大语言模型
  - 通过 NVIDIA Connect-X 网络进行连接，可连接两个 DGX Spark，支持高达 405B 参数的模型

- ## 🚀 [如何评价英伟达新发布的桌面 AI 超级电脑 Project Digits？ - 知乎 _202501](https://www.zhihu.com/question/8953765123)
- 上午还在看AMD strix halo，下午Nvidia突然就放了一个相同定位的...

- 想买的同学注意下这个设备的内存，它是统一内存，即CPU和GPU共享LPDDR5X. 它不是GDDR6，也不是HBM2的。
  - 虽然有 128GB，但是根据 Grace 架构 CPU 的 Product Brief，单 CPU 的内存带宽最大只有512GB/s
  - 所以如果用这个设备来运行大语言模型，瓶颈就会变成这个内存带宽。
  - 简单来讲，大语言模型每生成一个token，就需要将整个模型扫一遍进行计算（实际上比这个描述复杂很多）。这意味着，当浮点算力充裕的时候，扫描的速度就决定了生成文本的速度上限。
  - 目前这个设备的内存带宽水平跟 M4 Max 的 MacBook 没什么区别（Apple MacBook Pro M4 Max 128GB 内存带宽是546GB/s）
- 拿 [Llama-3.3-70b-instruct-4bit] 举例，这个4bit量化模型大小约为40GB，那么扫一遍就意味着GPU要处理40GB的数据，如果想要每秒钟生成10 token，简单计算可得，40GB\*10 = 400GB, 这意味着内存带宽至少有 400GB/s 才能保证每秒钟能生成 10 token.
  - 回到 digits 这个设备，在512GB/s 的情况下，**运行 70b-4bit 规模的模型，生成速度理论最大值是 512/40 = 12.8 token/s**

- nv版的mac mini。当然mac mini有macos，project digits只有linux，操作系统生态上以及桌面级定位上估计会导致拉胯掉，nv虽然有cuda生态，但是在桌面级相比os的生态，还是有点困难的。
- 大模型推理其实是个很微妙的产品需求，大显存容量很重要，memory bound也是事实。
  - 总体来讲，容量比带宽重要，毕竟容量决定了yes/no，带宽决定了token/s的体验。但是体验差到一定程度也是个yes/no的问题。
- 以ai pc今天事实上的超级应用为例ai编程而言，10 token/s以下基本就是玩票，加上ai啰哩啰嗦要分析一大堆，基本要做到可用还是得30～40 token/s
  - 按照激活量算，30～40token/s，如果10GB的激活量就300～400GB/s的内存带宽
  - dense模型10B上下做ai编程几乎没法用，moe可以搏一搏。
  - 目前的模型主流的基本都是70b以下的dense，以及200b以上的moe，70b以下的dense很尴尬，效果上比较难接近200b以上的moe，容量需求小，但带宽需求可是实打实的超级高。比较适配[gddr显存] 的正经游戏卡。

- GB10的芯片，应该是从服务器的GB100当中砍一刀下来用的。CPU是联发科定制的一颗ARM，GPU部分算力达到1个P，fp算力。最大的亮点直接拿了128GB的 LPDDR 5x内存做显存。
  - 很多人其实不知道，现在跑大模型无论是训练还是推理，最大的瓶颈是显存容量不足（Memory bound），而不是算力不足(Compute bound)。
  - 比如一个200B的模型，在fp4或者int 4的前提下，光是显存占用就要有100GB大小。运行起来之后还要有kv cache随着上下文长度占用而增大。一张显卡装不下，就要分布在多张卡上，那么就会产生通信开销从而导致算力无法被充分利用，不得不等待通信完成之后再进行计算。
  - 之前消费级的RTX 4090，最大的显存只有24GB。RTX 5090，也只有32GB显存而已。数据中心卡例如A100有40G和80G，但价格又会显著比消费级显卡贵。
  - 所以现在这个128GB的内存作为统一显存使用，至少解决了显存不够用的问题。3000美元的售价，甚至可以说良心了。

- CPU是联发科定制的一颗ARM，跑Linux玩毛游戏

- 其实前两年AI刚开始起头的时候，local LLM和文生图爱好者就发现多数任务都是memory bound的了，市面上除了比汽车还贵N家推理卡，只有Mac的统一内存能装的下。
- 这个具有可用性，cuda生态与性能是不用担心的，mac跑ai就是行为艺术，速度慢到爆炸，生态也是残缺的
- 只是为了 128G 统一内存现在也不需要买这玩意儿啊.. $4799 的 Mac Studio 或者 $4999 的 MacBook Pro 就行. 当然只是为了 AI 目的的话, 老黄这个盒子确实更有性价比.

- 三千刀，128GB，这个价格其实不比苹果好多少。而且三千刀是starting price

- 经典的72B的Llama模型，8比特精度需要84GB的显存，那就需要2块A100或者4块24GB的4090/3090，这两种方案都要比3000美元多且复杂。
  - 要知道Project digits是一整个机器，72B的经典模型可以直接跑，这样就基本上可以做绝大多数的微调工作。
  - 甚至两台机器，就可以跑4比特精度的200B模型，这么大的模型放到之前基本上只有大的公司或者实验室才有可能跑的起来，而现在6000美元就能完美解决，这对于绝大多数的穷Lab来说都是天大的福音。

- Strix Halo和M4 Max是高规格的消费级产品，搭载Strix Halo的是各种品牌开发的笔记本电脑、SFF主机，甚至是准系统、MoDT主板，它们搭载Windows 11操作系统，也可以安装任意GNU/Linux操作系统，就像一个普通的x86电脑一样
  - Project Digits的CPU，是联发科定制的20核ARM CPU，10大核为Cortex-X925，10中核为Cortex-A725。A725和M4小核大性能接近，而X925则不如M4大核和Zen5。另一方面，ARM Linux的生态并不如x86，这和ARM macOS完全不同。Strix Halo的16核32线程的zen5 CPU，基本上是顶级的CPU配置，其多线程性能是拉满的。
  - Project Digits的内存，虽然官方没有说明，但很大可能也是256位的，此时Project Digits在使用LPDDR5X的8533MT/s的内存时，其速率同样为272GB/s，而这一带宽，仅与Strix Halo/M4 Pro相同，是M4 Max的一半；如果是512位，则强于Strix Halo一倍，并与M4 Max持平。
- halo的npu总共就50tops，8060s也没有硬件wmma，2.5ghz下也就51.2tops，加起来不到gb10的1/4
- 可惜halo不是统一内存架构
  - halo是uma架构，15年前初代apu就已经是uma架构了

- 这个东西3000刀是真的很贵，不过project digits是挑战冯诺依曼架构，CPU 访问内存、硬盘，显卡处理数据需要把数据先传到显存。统一内存架构就是把GPU核心直接与内存相连，弄大内存。
  - 目前除了大公司有钱买几百上千卡跑训练，普通人真跑不起LLM大模型。对于普通人来说，核心算力不重要，问题是怎么在显卡load大模型。而统一内存就是用超高性价比的内存代替显存，不用GDDR7，用DDR5 。

- 
- 
- 

# discuss-gpu
- tips-gpu
  - 主力工具不要用AMD的CPU/GPU, 因为linux需要特殊配置, 部分软件也需要特殊配置如pytorch
  - 显存、带宽、位宽
  - nvlink
  - ai: 支持int4、fp8、fp4，不能用nanchaku加速, 支持flash- attention、bf16、awq、sglang

- nvidia性能对比
  - [大模型GPU算力卡汇总 - 知乎](https://zhuanlan.zhihu.com/p/1904206218748236301)
  - [Sable Diffusion WebUI Benchmark Data: nvidia/amd/torch](https://vladmandic.github.io/sd-extension-system-info/pages/benchmark.html)
  - [Which GPU should I buy for ComfyUI · comfyanonymous/ComfyUI Wiki](https://github.com/comfyanonymous/ComfyUI/wiki/Which-GPU-should-I-buy-for-ComfyUI)
  - https://www.zhihu.com/question/615946801/answer/3156016610

- 🆚🔥 [英伟达热门 GPU 对比：H100、A6000、L40S、A100 - 知乎](https://zhuanlan.zhihu.com/p/5041686924)

- 参数对比
  - gpu-arch: 2020-ampere(a100/a6000), 2022-ada-Lovelace(L20/L40s/6000ada/4090/4090d), 2022-hopper(h100), 2024-blackwell(5090)
  - fp16/tflops
  - 3090是最后一代支持nvlink的消费级显卡，低端专业级显卡如5880/L20也不支持nvlink

```markdown
- GPU,   VRAM,        fp16, v-bandwidth,v-bit, cu-core, power, note
- A100,  40GB HBM2,   312,  2039gb/s,   ?,     ?,       400W, 40g-9w
- A6000, 48GB GDDR6,  77,   768gb/s,    ?,     ?,       300W, 48g-3w3
- 6000ad,48GB GDDR?,  ?,    960/s,      ?,     ?,       ?,    48g-4.8w
- L20,   48GB GDDR6,  119,  854gb/s,    384,   1.02w,   350W, no-nvlink
- L40,   48GB GDDR6,  147,  ?,          ?,     ?,       350W, ee
- L40s,  48GB GDDR6,  731,  864gb/s,    ?,     ?,       350W, 48g-4.4w
- 5880ad,48GB GDDR6,  69,   960/s,      384,   1.28w,   285w, 48g-2.5w,no-nvlink,6000Ad阉割
- 5000ad,32GB GDDR6,  65,   576/s,      256,   1.41w,   250w, no-nvlink
- 5090,  32GB GDDR7,  3352, ?gb/s,      512,   2.18w,   450W, 32g-2.3w, no-nvlink
- 4090,  24GB GDDR6X, 330,  1008gb/s,   384,   1.64w,   450W, 48g-2.4w, no-nvlink,850wP
- 4090d, 24GB GDDR6X, 330,  1008gb/s,   384,   1.46w,   425W, 48g-1.9w,频率锁且不超频
- 3090,  24GB GDDR6X,  ?,   912gb/s,    384,   1.05w,   350W, 24g-8.3k, nvlink-ok,VulkanRT,OpenGL4.6
- 3090ti,24GB GDDR6X,  ?,   ?gb/s,      384,   1.08w,   750W, 24g-8.3k, nvlink-ok
```

- ## 

- ## 

- ## [如何使用intel的gpu和npu跑大模型？ - 知乎](https://www.zhihu.com/question/5293002844)
- 去下载ollama intel版，运行，然后就能调用核显跑模型了，但32g本子核显只能调用20G

- 目前比较适合半小白的办法，就是下载intel的ollama portable zip
  - 以上这俩应该都是基于llama.cpp的sycl后端优化的。
  - 其实在NPU或GPU上运行大语言模型还可以用OpenVINO。但不是很适合小白，OpenVINO更适合有一定开发能力的用户。

- 你需要用openvino，推理的时候指定推理的设备npu，gpu还是cpu，就可以把推理运行到你想要的设备上。你可以到openvino的notebook找到很多例子。

- intel自带的gpu不是普通显卡，不能用gpu这个选项，

- ## [3090 相当于 40 系的什么显卡呢？这款产品的优缺点分别是什么呢？ - 知乎](https://www.zhihu.com/question/681021828)
- 3090资深用户，首发购入一直用到4090首发, 
  - 3090理论跑分性能等于4070tis super。
  - 但是3090显存更大，在ai方面性能更强，可以跑一些量化大模型，4090能跑的3090都能跑。
  - 3090的<能耗比>比4090差很多，因为3090是三星8nm工艺，相对台积电5nm差距非常大。相同功耗下4090性能超3090 60%。
  - 3090功耗上限非常高，最高功耗产品为evga 1000瓦水冷款，从400瓦到1000瓦性能提升10%。由此可见能耗比之差。

- AI算力来说，cude算力表现，跟RTX4070差不多；

- ## [3090 24g和3090ti 24g从哪能买到新的? - 知乎](https://www.zhihu.com/question/585256727)
- 3090/ti基本上不会有新的了，ti还好点，但是货本来也不多，标新的店价格都高，甚至高过4080钙中钙
  - 你的情况，要么4080，要么4090，要么二手3090/ti将就点，4070ti的带宽太低了，显存12G其实也能用。
  - 其实3070、3080/ti也都是可以生产力、渲染的。非特殊场景不会随随便便爆显存的。只是4070ti的显存低、带宽低了不说，cuda核心较3090少了30%

- ## [2x4090 vs 6000 ada vs L20 vs L40s: what is the bottleneck for llm inference/finetuning? : r/LocalLLaMA _202408](https://www.reddit.com/r/LocalLLaMA/comments/1exwc04/2x4090_vs_6000_ada_vs_l20_vs_l40s_what_is_the/)
- a 6000 > 4090, less power, no moving data between PCI bus/CPU/cache to GPUs. 1 48gb will often beat 2 24gb for fine tuning.

- The l40s is essentially the 4090 with more vram. It is exactly the same chip. Nvidia released the l40s because the 4090 chips were available and demand on H100 was too high / H100 production volume too low. The 4090 has transformer engine which boosts fp8 performance. If you want inference speed on fp8 and don't need advance nccl support I would go for the 4090s

- ## [网上传的沸沸扬扬的96GB显存的4090魔改版是真实存在的么？是怎么做到的呢，有人用过么？ - 知乎 _202502](https://www.zhihu.com/question/13164350111)
- 因为有全新L20 48G（可近似当作4090D 48G）在2.5万的价位压着，实际上现在4090的价格已经涨无可涨。
  - 👀 L20不支持nvlink

- 以上这些东西你都解决了，那你准备怎么过VBIOS检测？

- ## [2w左右的预算炼丹，2张3090矿卡还是一张4090? - 知乎](https://www.zhihu.com/question/592038342)
- 两年前帮同学装过双路RTX 3090炼丹炉，个人建议还是用单卡RTX 4090。
  - 双卡RTX 3090矿渣不容易安装，市面上开放式散热的RTX 3090的厚度普遍接近3-slot，至少要预留1-slot的散热空间，也就是说每张显卡要占用4-slot，目前消费级主板常见的PCIe区域宽度是7-slot，安装两张RTX 3090有点困难。而且桥接器NVLink Bridge的常见规格是2-slot或者3-slot，和上面说的4-slot占用空间有矛盾
  - 所以，要组双卡RTX 3090优先考虑涡轮版，一般厚度只有2-slot，体积更小，但是RTX 3090涡轮版矿渣的价格比非公版贵了1000元，再加上NVLink Bridge的价格，即便你捡矿渣，两张涡轮RTX 3090的成本也超过单张全新RTX 4090了。
  - 另外，双卡RTX 3090矿渣需要的额定功率更大。单卡RTX 4090的TDP是450 W，双卡RTX 3090的TDP是700 W，电源成本也是要考虑的，而且大功率电源满载的时候挺吵。

- 两张3090矿卡+nvlink (相对于pcie，大模型DP TP 2-3倍速度提升)
  - 性能对比（gpt2 1.3B 8batch 2TP，测试环境alpa/jax）
  - TP模式：结论带nvlink在148个all reduce的条件下，可以提升200%的速度 12.95s vs 38.53
  - DP模式：结论带nvlink的条件下，可以提升150%的速度 12.03s vs 31.15s

- 2张3090要组建带nvlink的平台比你想像的还要麻烦，和单卡4090比较一下
  - 主板: 双卡3090需要一个至少atx的带双PCIEx16插槽的主板，而且两个显卡插槽距离要是标准的3槽间距才行，而显卡厂商不会给你说这些数据很麻烦，很容易买错，4090就一般的matx就行，主板价格就能便宜几百
  - 电源: 双卡3090一般要买1400w左右的电源，4090一般850w就很够了，价格估计差价300到500左右
  - 显卡: 要组双卡考虑到nvlink一般最大3槽，只能选涡轮版或水冷版，比一般3风扇风冷单卡贵2000以上
  - 机箱: 双卡3090一般要支持atx的大机箱才能保证扇热, 4090一般的matx机箱就行，差价一般不会特别大
- 另外nvlink也要1500左右
  - 价格: 实际上要比单卡4090的价格贵大概4000以上
  - 功耗: 双卡3090烤鸡功耗估计要超过800w要远远大于单卡4090的450w，整机双烤估计要突破1000w
  - 质保: 双卡3090都是矿卡无质保，能用多久看脸，而4090全新带质保
  - 保值:30系默认矿，30系已经臭大街了，以后如果用不上了要出掉，30系不好出手，而40系名声好要比30系保值多了

- 两张3090都没有一张4090贵，一张4090是一张3090的三倍有多。

- 4090没有nvlink，大显存还是选3090ti多卡

- 有无nvlink到底有多大区别
  - 模型大小不超过24g 区别不大。 2块4090一般相当于2倍的batch size, Nvlink解决的主要是——能不能的问题。 比如模型大小超24g时
- nvlink只是增大带宽，并不会增大显存，如果你不人为把模型写到两张卡上，每个iteration两张卡各跑个的，然后梯度回传的时候两张卡要同步梯度，有了nvlink这个过程会更快。如果24g不够，你不人为写到两张卡上，两张卡也跑不了。

- 3090只能双卡下nvlink，没有nvlink的卡或跨两组用nvlink连接的卡会走pcie到cpu进行数据交互。你用的pytorch会用nccl自动选择合适的方式交互。

- 关于“3090只能双卡下nvlink”，这个资料您是从来看到的？
  - 当然所有PCIE GPU应该都受这个限制，唯一例外可能是DGX station上的四块A100
  - 3090只有双卡的bridge

- ## [NVIDIA Tesla V100 SXM2 - 2025年AI本地部署性价比之王！双卡V100！32G显存，低价高能，碾压2080Ti 22G - 知乎](https://zhuanlan.zhihu.com/p/1927666998030078159)
- 年初16GB显存的V100售价1000元，如今已降至600元，远超Mai50成为性价比之王。其算力可与1500元左右的RTX 2080 Ti 22G相媲美。
  - 唯一的门槛在于其接口设计：V100采用服务器专用的SXM2接口，而非常见的PCIe x16金手指。SXM2接口一侧为PCIe，另一侧为NVLink，支持多卡互联。
  - 通过200元左右的转接板和80元的散热器改装，仅需900元即可获得2080 Ti级别的性能。
- 单张V100显卡的显存为16GB，双卡配置可达32GB。目前消费级显卡中仅有RTX 5090具备32GB显存，但价格高达2万元起。相比之下，双V100方案仅需2000余元，使得22G显存的2080Ti瞬间失去性价比优势。

- 测试平台采用华擎B650M主板，因其仅有一个PCIe插槽，需在BIOS中启用通道拆分功能以支持双显卡。安装完成后，我们将对双V100系统进行性能测试。
  - 通过NVIDIA SMI工具检测NVLINK状态，可见GPU0与GPU1的链接状态均显示相同带宽值，表明两片GPU已成功互联且NVLINK功能正常启用。
  - 在参数相同的情况下，2080Ti的每次迭代耗时约为2.17秒，而V100的每次迭代耗时约为1.39秒。

- V100不支持flash- attention、bf16、awq、sglang新版本也不支持v100了，显卡太老了，新的加速策略用不了，速度还不如消费卡呢。
  - 对SD跑图来说，不支持int4、fp8、fp4，不能用nanchaku加速。SD也不能多卡显存叠加。

- 本质上还是单卡16G，没什么卵用，而且很多推理特性不支持，远远没有2080ti好

- ## [主要做生成模型，自用深度学习服务器买双卡3090还是买单卡4090？ - 知乎](https://www.zhihu.com/question/9062530414)

- 对于低算力场景，最大的性能瓶颈永远是浮点性能，因为这会决定你的训练时长。
  - RTX3090的浮点性能（FP32/FP16）35.6TFLOPS，RTX4090则高达82.6TFLOPS，几乎高出了3090一倍，显存带宽也略高，同时TensorCore的版本也更新支持更多数据格式。
  - RTX3090看起来有NV LINK，但只是个阉割版，用户确实可以在代码中将整个模型分配在两张卡上（需要完全手动实现），但是其带宽只有112.5Gbps，不到显存带宽的1/8，训练时会出现严重的性能瓶颈。买2张RTX3090 24GB并使用NVLINK桥连接并不意味着你能将其当作一张48GB显存的卡使用。
  - 另外RTX3090是挖矿重灾区，甚至曾经有一段时间单卡日收入能到120RMB，很容易买到矿卡。

- 双卡算力是逼近单卡的，虽然有代差，熟悉双卡后，对多卡也有了经验，很容易扩展到多机多卡。生成模型的训练离不开多机多卡。

- 3090ti没有性价比，双卡3090加nvlink也不错的记得内存配尽量大。4090不支持nvlink的，训练不推荐。

- 2080ti 22gb也是香的不行。追求价格，就买4张2080ti 22gb的更爽。不过不支持flash attention和bf16数据格式。

- 如果是训练为主，毫无疑问选3090x2。
  - 如果是推理为主，且显存占用超过24G，选3090x2；显存占用小于24G，选4090。

- 双卡吧，怎么也得让自己的代码支持一下ddp，不然以后卡多了还得重新踩坑。

- 去年我给某高校实验室攒机那会儿，恰巧把两套配置都折腾过。
- 先说双3090这茬儿，乍看显存怼到48G挺唬人，但您知道跑Stable Diffusion时显存带宽被PCIE通道卡脖子的滋味吗？
  - 上个月拿双卡跑1280x720图生视频，显存倒是富裕得能养鱼，可实际吞吐量比单卡就多出23%，GPU利用率曲线跟过山车似的…
- 不过您要是搞大语言模型微调，单张4090的24G确实容易把裤子卡到脚脖子。可别听论坛那帮敲锣边儿的瞎忽悠，实测用QLoRA技术能把70亿参数模型压进18G显存，这节骨眼儿上4090的第三代Tensor Core直接让训练速度飞起～
- 前些天给某美院动画系那帮哥们装机器，他们拿双3090跑渲染以为捡着宝，结果电源三天两头跳闸——整机850W电源满载时滋啦作响的动静，跟二踢脚在机箱里开party似的
- 要是铁了心玩分布式训练且预算绷得住电费，双卡能省下17%的迭代时间；可要是就图个痛快跑单卡大模型，4090那9%的FP32性能提升配上Dlss3技术，渲染输出时绝对能让您体验什么叫 原地起飞

- NVLink桥接器可实现相邻两张3090的并联，双向带宽最高600 Gbit/s（约75 GB/s），但仅支持两卡间点对点通信，无法实现多卡全互联（如GPU0与GPU1互联后，GPU1与GPU2仍需通过PCIe通信）；
  - 可买专用NVLink桥接器（如华硕ROG NVLink Bridge）并确保主板支持；同时需在Linux系统中启用TCC模式（关闭显示输出），并依赖第三方显存管理工具（如NVIDIA MPS）。

- ## [已有3090Ti一张，再增加一张卡，是选择增加3090Ti+NVLINK，还是增加4090？ - 知乎](https://www.zhihu.com/question/623563385)
- 3090.nvlink, 提前学习一下双卡怎么用，未来大项目都是多卡，纯粹的单卡做不了什么特别大的项目，纵使H100也是大把人用8卡。

- 炼丹是自娱自乐还是将来想拿来谋生？谋生的话大显存多卡任务协同是必修课，一张卡怎么学？

- 3090Ti的Nvlink和专业版的不一样，带宽减半, 也没有显存真正池化

- ## [4090不支持nvlink，在训练深度学习模型时具体的表现是什么？ - 知乎](https://www.zhihu.com/question/603522002)
- 没有[NVLink] 功能只是不能通过桥接器进行两两互联(即不能通过NVLink两两进行p2p)，但是对于多卡并行训练是支持的，可以通过device to host to device这种走[PCIe链路] 进行数据并行处理.
  - nvlink最高可以做到800GB/S，PCIE只有128GB/S
- pcie慢很多而且受制于主板

- ## 👷 [4090 48G涡轮版深度体验 - 知乎 _202502](https://zhuanlan.zhihu.com/p/22691935175)
  - ComfyUI跑flux fp16模型，图像宽高1000*1000，step20，跑完22秒左右，显存占用36G，大显存就是好。

- 能不能测一下与双3090 NVlink的差距
  - 看拼几块3090吧，你要2块肯定比不过4090 48G，NVLINk拼显卡还是有损耗的

- 现在有4090 48g三风扇版不吵了
- 一直正常用，就是显卡温度一直上90度，暴力风扇转速没法调小

- 改完还能打游戏吗
  - 可以正常打游戏

- 哪有靠谱销售渠道啊？
  - 想玩魔改 哪会有售后啊 不都是自己玩吗

- 性价比最高的是2080ti 22g，不过要换电源

- 这种售后怎么搞呢
  - 我是拿自己的4090去改的，花了5千5， 店家说有三年质保哎

- b站修电脑的张哥能修，只要不是核心坏了都能修

- [魔改的RTX 4090 48G卡值得选吗？ - 知乎](https://zhuanlan.zhihu.com/p/1888965700464406937)
  - 这卡我买了一张用了一个月了，分了540gddr5内存跑了满血版q2半个月了，没啥问题，基本在15到20tokens

- ## [丐卡值不值得买? - 知乎](https://www.zhihu.com/question/596939079)
- 要看具体型号。 举个例子，RTX 40系首发RTX 4090、RTX 4080、RTX 4070 TI三款型号，散热模具都超规格了，即便是丐版型号都用料十足，所以一二线品牌的丐卡是最值得买的
  - 但是，从RTX 4070开始情况发生了变化，“RTX 40系显卡散热过剩”的规律也被打破了。市面上的丐版RTX 4070普遍采用低廉的悬臂式散热方案，这种散热不能完全覆盖供电区域，容易导致VRM的个别地方过热。

- 当时初衷也是想看看丐版究竟够不够用，高阶版本拥有更帅气的外观（材质），更好的散热（风扇、热管的数量等）、更好的超频性能（benchmark可能还能看，具体到游戏帧数只能说：你懂的），但真正影响显卡性能的，是GPU和显存。不过，如果高阶版本溢价可以接受，可以选，比如更好的散热性能带来的是温度的降低，温度的降低更有利于整机的稳定性。

- 微星买万图师。现在万图师比超龙性能低不到3%价格整整多一千。微星万图师和[微星超龙] 差距就是游戏满载温度高13℃。

- 一定要相信老黄和苏妈的刀法，4070你就是芯片体质再好、供电再强、散热再稳，给它超冒烟了最多能刚刚好赶上默频的4070Ti
  - 显卡最重要的是里面的PCB那一小部分，核心、显存等等，外面那3P大空调之类的，对于纯粹的性价比爱好者来说，应该放到最次一级来考虑

- 我只知道第一次买显卡买最便宜的丐图师，直接让我桌子附近温度从春天变成夏天。自此下张显卡的温度是我考虑的因素之一。

- 丐卡再丐，理论性能都超越下级[显卡]，无非是供电和散热做的差点，达不到[功耗墙]没法超频，但是芯片总归还是那颗芯片。
  - 反过来说4070做的再好，再堆用料都不可能超越[4070ti]。只要售后质保能保证，在金额预算里面，买一块高级的丐卡也是可以考虑的。

- 够用就好吧，我买的4070s万图师的卡，感觉价位挺合适的，用着也稳定。

- ## 💡 [为什么50系列显卡出来，性价比没有提升反而40系列显卡涨价了？ - 知乎](https://www.zhihu.com/question/1902322217175463161)
- - 40系涨价是因为商家都在清库存，库存减少。仅剩的40系显卡集中到少数几个商家手中。但是市场的需求没有减少。需求不变，供应减少，价格必然提高。而且这几个商家的最佳策略就是涨价，因为以后肯定是要跌的，趁现在能卖高价必须卖高价。
  - 40系是不可能再大降价了。因为没有巨量的显卡下来击穿商家的库存。现在反而是商家那里没有库存，剩下的显卡只能惜售。

- 以前老黄的产能全部由消费级市场承担，所以每次新卡一发布，就会有海量的新卡砸盘，旧卡必须降价清仓否则会烂手里。
  - 现在可不一样了，老黄8成的产能被AI计算卡吃掉，投放给消费级市场的产能寥寥无几，新卡别说砸盘了，填补市场缺口都不够，所以老卡就有了奇货可居的价值，涨价也是理所当然的了。
- 为什么不增加产能？
  - 老黄是fabless，自己没有工厂，完全依赖代工，主要是找台积电，然而台积电每年的产能是固定的，全球大客户那么多，就算是老黄也做不到产能包圆，所以老黄能分到的产能是有限的，他想增产也做不到。
  - 这也能解释为什么有时候老黄会找代工，最主要的原因是台积电那边分到的产能不足以覆盖产品线。
- 拿着设计图纸多找几家代工厂不就有产能了吗？
  - 芯片这东西，比较特殊，他必须在设计立项的时候就敲定代工厂。
  - 想要找代工厂代工，自己是必须设计到门电路一级的布线，然而不同的代工厂，他的元件布局是不一样的，比如A厂的与非门是2x2布局，那B厂的与非门布局可能就是1x4了，换厂就没法做，因此一款芯片必须在立项的时候就决定好找哪家代工，设计好原理图，然后使用代工厂提供的EDA软件进行布线。
  - 大家想象中的像机加工一样，有了设计图就能随便找个工厂加工，在芯片领域是不存在的，哪怕你拿到了完整的4090布线图，找中芯代工，也是做不了的，除非你愿意重新设计布线，那就要先掏几千万美元的设计费，再掏上亿美元的流片费用，并且有流片失败全部费用打水漂的风险，非常划不来。

- 原则上是这样的，不过换厂也未必就代价很大。8Gen1和8+就是一年内从三星换成了台积电。
  - 早就曝光了，按台积电的生产周期，8gen1找台积电做，高通会有大半年的产品真空期，所以他一开始就立项做两款，三星工艺的8gen1先顶上，半年后再推出8+。台积电的产能预定起码提前2年，发现8gen1不行再改8+你这产能都排到2年以后去了。
  - 好像是细节记不清楚了，刚开始高通就是找了台积电和三星分别做一部分，哪知道三星做的发热量严重，最后不得已订单全给台积电了.
- 苹果6S上的A9处理器直接俩版本，三星和台积电的都有

- 国内还算是有良心的，50系出来以后，40系可以买到，稍涨一点价但还算有性价比。
  - 美国市场自从50系上市以后，正价的40系一夜之间全下架了，只有黄牛的高价卡在卖。
  - 在美国，NV 50系和AMD 9070/9070xt上市以来一直处于缺货状态，都被黄牛用bot买走了，普通人很难买到。比如Amazon上面正常价格的一直缺货，一堆非自营黄牛挂高价。
- 普通商家也不允许卖吗
  - 普通商家的都被黄牛买完了

- 40系出来的时候AI热刚刚兴起，[4090] 之所以价格爆炸，也是因为很多人都拿4090当生产力卡用，炼AI
  - 老黄是看到了40系，尤其是4090卖爆了的情况下，才决定50系挤牙膏，全力押宝计算卡上
  - AI卡卖的比游戏卡贵多了，价格可以说突破天际
  - 人家资本也不是傻子，比起花真金白银买算力卡（还可能用不了几年就被淘汰），还不如卷一卷算力，用便宜卡搞大模型。

- ## [5090D显卡比4090强的话为何没有被禁？ - 知乎](https://www.zhihu.com/question/9802980796)
- 5090d是nvidia创立以来性价比最差的显卡。
  - 5090d和4090d算力一样，但比4090d还差，因为4090d可以魔改48g显存，5090d不仅不能扩显存还禁止多卡互联，跑ai软件3秒锁死，要重启才能继续用，可以说只能玩游戏

- 中国特供版旗舰显卡RTX 5090D，虽然其AI算力削减了约29%，但是游戏性能却几乎并未缩水，价格为16, 499元起（略高于RTX 5090的1999美元，即约14648元的价格），将于1月30日上市。？性能差些，价格还贵些

- ## 🚀 [如何看待新推出的Nvidia推出的4090d？ - 知乎 _202312](https://www.zhihu.com/question/637218617)
  - 12999和4090价格一样。看了cuda规格是完整的ad102的百分80

- 老黄的刀法还是很精准的，这次RTX 4090D刚好卡在3A090出口管制条例的界限上。
  - “数据中心芯片”生效范围比较复杂，但是“非数据中心芯片”一刀切在TPP = 4800上，也就是说对消费级RTX 40显卡，TPP限制是4800上。
  - 而这张RTX 4090 D，该显卡搭载14592个CUDA 核心，加速频率 2.52GHz，该显卡搭载14592个CUDA 核心，加速频率 2.52GHz，显存为 24GB 384bit GDDR6X，显卡总功耗 425W，常规游戏功耗 302W。

- 这玩意有4090九成规格，应该还是在禁售范围内的（所以nv还限制了超频）

- 4090D这张卡本身，流处理器规模是4090的89%，Tensor Core和RT Core也是等比低削减，并未专门缩掉了Tensor Core的规模，显存也未阉割，L2甚至可能不变，估计综合游戏性能可以达到4090的90%-95%吧

- 都2023年了，还能在消费市场上见到大公司减量不减价的操作，只能说垄断还是厉害
  - 技术性垄断总比政策性垄断要好，最起码人家是凭真本事垄断的

- 这小砍一刀无伤大雅，依然有73.54TFLOPs➕CUDA➕24GB GDDR6X，吊打7900XTX跟4080以及新的4080S

- 全球芯片开始转向Risc结构，美国的大部分企业选择arm， 只有NVDIA目前的GPU和谷歌的TPU不是，但谷歌似乎也拥抱arm， 至少是用在其手机部分。 中国大企业却是拥抱RISC-V，这种开源的硬体架构规格，因为不需要给arm专利。英特尔也拥抱RISC-V， 表示与arm竞争。

- ## [魔改版4090 48G显卡性价比大探讨：真的值得入手吗？ - 知乎](https://www.zhihu.com/question/14343647195)
- 40系显卡的主要性能瓶颈是[显存位宽] ，和显存容量关系不大。这一点我们可以从4090和rtx6000ada两张卡得到验证。
  - 这一点我们可以从4090和rtx6000ada两张卡得到验证。
  - 4090和rtx6000ada拥有相同的架构的gpu核心，基本相等的cuda核心数量（一个是16384的cuda核心，一个是18176的cuda核心），基本相同的显存位宽（4090是1008GB/S，rtx6000ada是960GB/S）。
  - 两张卡只有显存容量不同（4090的显存有24g，rtx6000ada显存48g）。经过测试，两张卡无论是游戏性能，ai推理，结果都是差不多的。rtx6000ada并没有因为48g的显存容量而有更加优秀的性能。
  - 同样的结论还可以分析4090和4070得到。4090拥有16384的cuda核心，4070拥有5880个cuda核心。4090的cuda核心数量是4070的将近三倍。按理说，将近三倍的显存容量应该带来三倍的性能，但是4090的实测性能只有4070的将近2倍。4090的位宽384bit，4070的位宽192bit。4090刚好是4070的两倍。

- 粗略计算，每10亿个参数大约需要4G显存来加载，所以48G显存能跑120亿参数的大模型，如果是半精度的最多可以跑240亿参数的模型，显存不够大，模型都加载不进去，48G魔改出来的都是涡轮卡，插机架服务器用的，就不是给游戏玩家折腾出来的

- 我下周去找个工厂做一下测试，魔改的原理就是在[4090主板] 上加[显存粒] ，这个分两种一种是他们买的[3090主板]，换成4090芯片，然后加焊接24G显存粒，加两个。这种俗称消费级，就是需要每天关机一次，要不然估计主板顶不住，毕竟是特么的3090改
  - 另外一种就是基于4090主板，加焊显存粒，这种理论上比较OK，但是还没有实测，准备带上显卡去深圳找人魔改一下，要是能成了，那就我就开辟一个魔改业务，本来南京也有，但是南京没有家里创啊，产业链有点拉。只能招聘那些修手机来干

- ## [导师给30w预算装4-6卡服务器，目前打算上5880ada，要噪音较低、不要液冷，求合适方案？ - 知乎](https://www.zhihu.com/question/1939707476724389292)
- 5880满载功耗仅285w，比3090都低，涡轮也很静音。

- https://zhuanlan.zhihu.com/p/1939741761053364343
  - 之前我分享过，在RTX Pro 6000 上执行ollama与gpt-oss-120b，效率麻麻哋，不过，用它来运行vLLM却是一把好手，特别是主流的32B模型: Qwen3-32B，能达到22 token/s的速度，
  - 对比上一代卡皇5880(6000 ada的小兄弟)怎么样呢？实测过，2x5880也就才24 token/s。

- [英伟达中国特供版RTX 5880发布！性能比旗舰大砍近25%，比RTX 5000只高6% - 知乎 _202401](https://zhuanlan.zhihu.com/p/676491377)
  - 相比于旗舰级RTX 6000，定制版5880在性能方面可谓是大幅降级——CUDA核心少了23%，单精度浮点性能低了24%。
  - 实际上，它的表现更加接近RTX 5000——两项参数分别提升了10%和6%。

- ## [双RTX A6000显卡做深度学习，使用nvlink桥接器能实现显存共享成96G吗？ - 知乎](https://www.zhihu.com/question/455953236)
  - 双RTX A6000（显存是48G）显卡做深度学习，使用nvlink桥接器能实现显存共享成96G吗？插上了A6000的安培架构的桥接器，输入nvidia-smi nvlink -i 0 -s 显示的是速度14GB/S，不是显示的active，然后跑训练，还是只能使用48G的显存。
- NV的桥接器功能其实在宣传上有些问题，加了桥接器其实也完全不可能二卡合一、显存倍增，还是两块完全独立的显卡，桥接器只是让两块显卡之间可以快速交换数据，不用再从CPU那边绕一大圈；至于用了双卡以后提升了多少性能，主要看应用软件本身对多GPU优化的怎样，不同的应用软件的表现完全不一样，可能1+1接近2，也可能1+1≈1.5, 也可能1+1=1，甚至可能1+1<1。
  - 最新一代的Ada Lovelace架构的旗舰卡RTX4090, RTX6000Ada和L40干脆把对NVLink的支持彻底取消了，可见目前这个功能在图形类应用的领域有多拉胯，这个功能现在成了ai计算领域的专有功能了

- 可以直接在显存间传输数据，不需要再经过内存了是吗
  - 理论上是，但是也需要应用软件支持此功能才行，这个要看算法的，实际上多卡的算法没那么简单

- NVLink不是单纯的显存叠加，48G变96G，而是会增加两张显卡之间的显存交互带宽。一般来说，多卡跑深度学习，一般是指数据并行，即每个显卡处理一部分数据。

- ## 🚀 [如何评价Nvidia A6000显卡？ - 知乎 _202010](https://www.zhihu.com/question/424306404)
  - 取消Quadro命名，采用10752 CUDA满血GA102核心，48GB的GDDR6不带X显存，供电接口为新8Pin接口（EPS-12V与传统Pcie-8Pin显卡供电口不兼容）

- 虽然说取消了Quadro卡的命名，但是这东西看起来依旧是和Quadro一脉相传，当然叫他“专业卡”或许更直观，
  - 一直以来，游戏卡和专业卡都有着一道非常明显的区别，那就是OpenGL驱动，专业卡能打，但是游戏卡不能打，虽然老黄有放出过Studio驱动出来，但是依旧是无法取代OpenGL驱动的地位

- A6000采用的还是N卡30系的安培架构，所以注意安装cuda还是需要cuda11.1及以上版本。
  - 一个有意思的点是功率300w，比3090的350w要低，可谓是低功耗高效能了。
  - A6000的48G大显存两倍于3090还是比较适合上大模型的，看过网上评价A6000的性能优势主要体现在transformer双精度推理和分布并卡训练，由于目前炼丹的模型要求real-time比较小，单卡足以

- ## [RTX A6000存在的意义是什么？ 同样的价钱为什么不买两块3090交火呢？ - 知乎](https://www.zhihu.com/question/483799457)
- 英伟达把消费级显卡和专业级显卡区分得还是很开的，游戏卡不支持多路NVENC流、不支持vGPU，不支持ECC自动纠错，openGL性能较差。
  - 如果你有跑科学计算的需求的话，ECC显存是非常重要的，可以说必备，这种情况下你只能用专业图形卡或者计算卡来跑。
  - 多路NVENC也可以很好地用在大型广播控制台内，用于录制推流。这也是游戏卡应用不到的领域。

- RTX A6000是基于NVIDIA Ampere架构的超高端专业显卡，搭载最新一代的 RT Core、Tensor Core 和 CUDA Core
  - 兼具 ECC校验、GPUDirect for Video、多GPU 支持、四重立体缓冲、Mosaic多显示器、Quadro Sync等功能。

- 因为老黄禁止数据中心使用游戏卡

- ## [8w左右的双卡4090或单卡A6000服务器，有什么好的推荐？ - 知乎](https://www.zhihu.com/question/646105848)
- 至强W的T7960塔式工作站，保守最大4*A6000的支持。
  - 上限为56C的W9-3495X；DDR5-4800内存；PCIE 5.0；应该够用的存储空间（可选RAID/NVME等高级选项）
  - W7-3465X+128GB内存+RTX4090*2/一个A6000，咬咬牙也不是搞不定。
- 搭载至强可扩展三代的双路塔式T550服务器，最大两个A6000。
  - 上限就不说了，DDR4-3200; PCIE 4.0；标配独立阵列卡以及150TB+存储空间也相当不错。
  - 这个性价比较低，不是很推荐。
- 主流的机架式解决方案，也就是PE R750服务器，支持最大3*A6000，但是建议尽量控制在两张，
  - 它有个姊妹型号叫做750XA，倒是可以支持到4*A6000，相应的也要稍微贵那么一点点。。。
- A6000优势在于桥接扩容显存，所以还是尽量选择塔式，可能用不上，但是必须要支持对不啦。
  - 所以我认为最优选择还是塔式工作站T7960, 8通道DDR5-4800+PCIE5.0啊，何其先进。

- 7960能只买机架和电源吗, 其它的想自己配
  - 最低最低，得带上处理器。内存硬盘显卡自己配去吧。

- [导师给了10w买深度学习的服务器，只要求2张a6000的卡，其他配置有什么推荐么？ - 知乎](https://www.zhihu.com/question/628269514)
  - 推荐用各个厂家的单路旗舰解决方案直接适配。 也就是基于AMD Threadripper PRO或者全新至强W相关的最新平台。
  - 例如业内非常优秀的戴尔Precision 7960 塔式。 性能上限应该是 56C112T；4TB DDR5内存（16个内存插槽）；满配10个3.5硬盘槽位；满配最大四张A6000, 属实的优秀
  - 或者说7960的小弟5860也不是不行 ，扩展能力稍差，但是支持两张A6000运行，应该也是没啥问题的。
  - 或者上一代Precision 7920也行，虽说是末期稍有涨幅，但是性价比依旧是强无敌，旗舰毕竟是旗舰，虽然说是上一代。不过两张A6000。。。。 肯定行。

- ## [装机配置讨论，单卡A6000or双卡4090？ - 知乎](https://www.zhihu.com/question/599204652)
- 6000ADA太贵，6000感觉太老，4090显存比较紧张，马上5090出来之后，肯定6000和6000ADA会降价，甚至届时5090说不定有32G显存，可能是更合适的选择。很纠结，于是目前拿之前入门时候购买的4060Ti16G在顶着用。

- 据我所知 A6000唯一的优势就是显存大，实际上考虑大显存都是考虑降低多卡并行通信开销的，一张也体现不了大显存优势...

- ## [实验室配置服务器，4090，a100和a800选哪个？ - 知乎](https://www.zhihu.com/question/595107162/answer/4153401353)
- 测试发现，L40速度与4090D相当，表现令人满意。
  - A100, 40GB, 312 TFLOPS, ¥90, 000+, 400W, 
  - A6000, 48GB GDDR6, 79 TFLOPS, 300W, ¥33, 000, 300W
  - 4090, 24GB GDDR6X, 330 TFLOPS, ¥12, 000, 450W
  - L40, 48GB GDDR6, 147 TFLOPS, ¥44, 000+, 350W
  - 厂商解释，由于中美博弈的原因，L40宣传上未定位为训练卡，但实际用于训练完全没问题。
- 虽然L40 的 FP16 性能（约 147 TFLOPS）在理论上优于 A6000（约 78.75 TFLOPS），但在实际训练大型模型时，它并不被广泛推荐，原因如下:
  - 优化与软件支持：深度学习框架（如 TensorFlow 和 PyTorch）通常会针对特定的 GPU 进行深度优化，特别是 A100 和 A6000。NVIDIA 的 Ampere 架构（如 A100 和 A6000）在训练性能上得到了广泛认可，许多训练算法和优化器都针对这些显卡进行了调整。而 L40 的推理优化可能不适合训练任务。
  - 计算架构：尽管 L40 的 FP16 性能较高，其计算架构和硬件设计可能不具备 A6000 的特性，例如 Tensor Cores 的优化使用。Tensor Cores 可以大幅提高训练过程中的计算效率，尤其在大型深度学习模型中。

- L40单卡训练是没问题，最大问题是不支持Nvlink
- a6000不比4090高多少，价格高这么多
  - 显存大

- 4090不支持多卡并联，也就是大模型是根本没法训得，它是单卡性能强，同时性价比高(阉割NVLink了，多卡带宽严重不足)。
  - a800是a100的阉割版，也就是说，有a100选，肯定优先a100。因为是要训练大模型，建议购买sxm版本的a100。

- 要玩stable diffusion，目前的版本4090足够用了，其他大模型先明白搞什么，自己训练还是跑跑lamma，glm6b之类的，自己训练稍微大点的模型基本都不够，先算清楚对显存的需求一般就能有决定了。所以个人建议，不知道跑什么或者只跑stable diffusion先上个4090，反正便宜。明确知道搞什么，根据需要可以测算出来
- 4090从头训练图片生成够用吗？有人实践过吗。这些。
  - 按原版模型原版训练方式从0训不太够，原版是A100X8X32训了15万GPU Hours，每张卡batch size=8，总批次8X256，粗暴点算24g的4090一个批次只能2~3，就算不考虑慢的问题，批次依赖也需要另外解决
- 问题的关键是为什么要从头训练，基础模型上微调耗费很小的资源
  - 有创新的诉求，然后微调不够用(具体面临的问题可能和大神们的不同)

- ## [双a6000和双4090哪个计算更快呢？ - 知乎](https://www.zhihu.com/question/664827604)
- 小规模数据，单卡能跑的情况，显然4090比A6000快的多。
  - 数据规模再大点，超出了双卡的存储空间，4090就跑不了了，毕竟A6000一块就能顶2/4块4090啊。

- [渲染建模，是一个A6000牛逼还是两个4090牛逼? - 知乎](https://www.zhihu.com/question/658932305)
  - 在不溢出显存的情况下渲染单4090比A6000起码牛逼2倍，双4090就是4倍，
  - gpu-z上面有数据，一个4090是一个a6000的140%

- ## [深度学习用什么卡比较给力？ - 知乎](https://www.zhihu.com/question/612568623)
- Nvidia的PC机显卡，分为三个系列，Tesla系列，Quadro系列，Geforce系列。。
  - 原先分别对应专业科学计算，专业图形显卡，个人消费级显卡领域等。
  - 从价格上看，同等算力的价格差不多是4：2：1。
- 在算力差不多的情况下，Tesla和Quadro系列的溢价溢在哪里了呢？
  - 主要是稳定性（加了ECC纠错机制），显存效率更高（HBM2 vs GDDR）, 显存容量更大（一般Geforce卡显存在10G左右，但Quadro和Tesla一般都是24G，甚至48G，还有卡间互联技术NVlink等）。
  - 个人用的话，Geforce就差不多了，如上一代的3090，价格～13000¥，算力也足
  - 可以上A6000，～30000¥，也还不错
- 在CES 2025展览会上，英伟达发布的采用Blackwell架构的显卡是GeForce RTX 50系列，包括RTX 5090、RTX 5080、RTX 5070Ti和RTX 5070等型号，对标40xx的显卡
  - Tesla系列，推出了B200，给数据中心用的，死贵死贵。
  - 目前暂未有Quadro系列的最新架构显卡发布，这个系列国内可用的最高配置是Ada5880, 大概5万块一张吧，次一点可用Ada 5000, 3万多一张吧。。

- 现在行情不好，价格丑陋。别说4090了，就连3090也涨价了不少。干脆搞魔改2080ti吧22G的。改好的一张2500块钱，买3张也就现在（2023.11.4号）一张3090的钱。然后上洋垃圾至强x99平台，服务器内存随便插满128g。电源用矿电源1600w，反正放实验室，不心疼。
  - 我半个月前想买4090，商家不发货。只能退款，当天晚上立马去问rtx a6000能不能发货，当时2w6的价格。那会商家还没反应过来。只是晚上不发货，凉凉。第二天商家已经改价成3w了。

- H100 ￥23.5W, A100 ￥13W，但现在一般人或公司不好买了，已经被禁购了

- ## [有没有便宜点的AI算力显卡? - 知乎](https://www.zhihu.com/question/634145498)
- 2080ti 22G，仅需2000出头
- 3080 20G，3090 24G 便宜且支持bf16

- 要便宜，大显存，L40系列看看。英伟达Ada Lovelace 架构，48GB支持ECC的GDDR6显存，两者的显存带宽都是864GB/S, 
  - L40S作为L40的升级版本，主要在FP32运算能力提示幅度为1.1TFLOPS，在TF32 Tensor Core TFLOPS、FP16 Tensor Core、FP8 Tensor Core、INT8 Tensor Core运算能力均提升 一倍左右。

- 要便宜，大显存，p40最合适。24g显存，价格800左右就可以入手。记得一起买风扇和电源转接线。
  - 900块拿下过p100，感觉已经是平民价里面最好性能的了，还有hmb显存。

- 租云服务呀，能选的专业卡多还能开票让老师走经费

- ## [4090 魔改 48g 显存是怎么做到的？ - 知乎 _202502](https://www.zhihu.com/question/11803840385)
- 4090显卡有两个兄弟，叫做l40s和a6000 ada，都用的ad102内核，这两个兄弟显存都是48g的。
  - 没有a6000 ada，要么是30系的a6000，要么是40系的6000 ada。我之前也搞错过。

- 魔改的4090 48G价格是2万2左右（给料的加工费是5.5k左右），同一代（40系显卡）核心的6000 ada 48G要5万2左右，上一代（30系显卡）核心的A6000 48G是3万2左右

- 3090芯片发售时，显存颗粒最大1GB，24GB显存需要24颗，PCB板正反面都有。
  - 4090芯片发售时，显存颗粒达到2GB，24GB显存只需要12颗，PCB板只有一面有焊盘。
  - 流出的4090 48GB改版显卡bios，正好发现4090针脚定义和3090一样，可以焊在3090PCB上
  - 这样4090芯片+3090PCB+24颗2GB显存+流出魔改显卡bios=4090 48GB显卡。
  - 显卡bios大概率不是x86指令，否则早就有个人魔改版，诱惑太大了。
- 有能力改的，大概率不想得罪英伟达。所以这种只能偷偷搞，没保障

- 它就是个混合体：4090核心+3090的PCB板+24颗2GB显存颗粒，而且还有下面几个巧合，任何一个失效都不成立：
  - 4090的核心和3090的核心针脚一样，所以它可以焊到3090的PCB板子上并被识别；
  - 3090用的是24*1GB的显存颗粒，板子没有限制显存颗粒容量，可以换成2GB的；
  - N厂内部流出了显存驱动、显卡固件居然能完美支持。

- 网上测评显示4090 48G 显卡还可以支持 FP8，甚至这款显卡也已经出走海外，来自加拿大的小哥在平台上晒出了自己在 eBay 上买的 RTX 4090 48G，售价要 3 万人民币起步。

- 不得不佩服皮衣刀客的刀法了。科技是第一生产力，刀客在逆天而行。
  - 皮刀客目标在于赚钱， 发展生产力只是你想法而已，人家才不管你发展狗屁生产力呢

- 和3090同一级别的专业卡是RTX A6000，48G显存，其它参数和3090差不多的，现在的售价仍然是3万元
  - 和4090同一级别的专业卡是RTX 6000ADA，48G显存，Cuda核心比4090多约2000个，售价现在6万元；
  - 略低一个级别的RTX 5880ADA，Cuda核心比4090少约2000个，售价在5万左右； 
  - 所以4090 48G 2.3W的售价，性价比极高

- a100性能远不如4090
  - 4090推理王者

- 驱动？卡的bios才更重要
  - 你说得对

- 其实就是传言流出来那版vbios，没有那版vbios，就没有后续48G。
  - vbios有数字签名会和芯片内的安全芯片作相互校验，因此绕不过去，而在2023年流出来了一个工具，可以把不同品牌的vbios（有数字签名版）互刷，所以拿到48G的vbios就等于有了48G的4090，无非是如何搬板，甚至有能力可以重新设计一张pcb来扩张，换句话说，如果未来有更大显存容量的bios流出，原则上也可以做更大显存的卡。
  - vbios签名是与GPU芯片内安全组件进行校验，校验通过时，GPU才会完全初始化。

- 既然4090 48G是用3090的PCB板魔改的 那为什么市面上都没见到魔改3090 48G的？按理来说3090成本比4090低得多啊
  - 30系没有对位的48g计算卡，bios会卡住点不亮。闲鱼上有很多3090芯片转移到4090pcb上的卡，价格还挺实惠，敢买的人不多。
- 因为3090没有48G的BIOS流出。4090的AD102核心还用于ada6000等专业显卡，出厂显存就是48G，说明AD102是可以兼容48G显存的，

- ## [为什么N卡一定要带cuda? - 知乎](https://www.zhihu.com/question/592464568)
- cuda又不是硬件……toolkit想装就装，不带也不会影响打游戏
  - 对于n卡来说，cuda本来就算是增值服务，对于很多开发者来说提供了好用又高效的开发接口。
  - 我是不认同把n卡和cuda划等号。但是cuda明显已经形成了开发者好开发-使用者体验高-N卡占有率高的良性循环。

- 因为现在的显卡的可编程管线都是通用的。除去光栅器等少数部分，像顶点着色器等等，驱动底层和硬件计算单元和CUDA其实都是共用一套东西。

- 至于说AMD没有CUDA，但是AMD有ROCm和OpenCL啊。只不过因为软件支持差，不好用，用的人少而已。

- ## [是否存在支持cuda的核显轻薄本？ - 知乎](https://www.zhihu.com/question/663409299)
- 不存在。cuda是英伟达独显的，N卡独占，是独显的功能。核显是基于CPU的，而CPU是因特尔和AMD这两家的。
- 不存在。Cuda是英伟达自研的只支持自家显卡的算法。核显是Intel和AMD CPU自带的。英伟达并不生产笔记本的CPU。

- CUDA是英伟达独家，目前核显轻薄本是Intel和AMD，自然现在市面上找不到支持CUDA的核显轻薄本。
  - 现在的Intel、AMD甚至高通主推的AI PC全靠NPU，但是目前应用软件层面能够调用NPU的寥寥无几。
  - 而CUDA支持各个软件应用的支持显然更加广泛。到时候大概率会出现英伟达的核显本才是真正意义上的AI PC。
  - 目前英伟达的GPU一大问题是显存容量较小，比如主流的甜点游戏卡RTX 4060就是8GB显存。现阶段跑本地的LLM、Stable diffusion瓶颈并不在多少多少TOPS的算力，而在于很容易爆显存，你连跑都跑不起来。
  - 未来英伟达自己的核显本，可以共享内存，本地的大模型和AI应用可能才会真正发展起来。

- ## [为什么说CUDA是NVIDIA的护城河? - 知乎](https://www.zhihu.com/question/564812763)
- 英伟达从cuda里学到的最重要的一课，就是软硬件捆绑。
  - 计算界cuda之所以厉害，不仅仅是因为它可以调用GPU计算，而是它可以调用GPU硬件加速。
  - physX也是，N卡限定。 甚至于说，如果需求量够大，英伟达把三维体积的有限差分操作，有限元的检测函数积分操作，全做成“电路板计算”也不是不可以。 同时配合着自己的软件体系一起往外推。
  - 这才是英伟达真正的组合拳。 在这套组合拳体系下，cuda扮演着胶水级核心航母的角色。还有其它护卫舰，而这些护卫舰都绕不开。

- 2007年6月，CUDA发布。在Nvidia的持续精耕细作下，CUDA已经成了科学计算领域的事实标准。
  - 等神经网络算法火了，Nvidia又大力支持，各大AI框架因此优先支持CUDA，形成了正循环。
  - 之后，Nvidia又发力与AI关系紧密的自动驾驶和机器人领域，推出了针对汽车的Drive系列芯片和针对工业机器人的Jetson系列。
  - 这一切，都是以CUDA作为软件切入点，最终，CUDA就成了今天的样子，变成了又深又宽的护城河。

- amd抛弃opencl了，推他自家的rocm

- 用fpga、甚至是更定制化的asic来加速，早就有了，性能超过nvidia的同类产品比比皆是，问题还是生态和总拥有成本。google也做了TPU，在内部用得也不少，生态还是干不过CUDA。性能有时候并不是决定性因素。
# discuss-laptop-win/linux
- tips
  - 选择笔记本的一个重要因素是售后维修，大厂会容易很多如联想、惠普

- ## 

- ## 

- ## 

- ## [惠普暗影精灵10slim对比上一代9slim有什么提升吗？ - 知乎](https://www.zhihu.com/question/661490891)
- 暗影精灵10 Slim 16等于便携、拓展、性能哪一样都想要，但哪一样都没顾上。说到底还是上代的产品思路，在2024年跟不上市场了，毕竟竞品有后发优势。
  - 要性能+拓展，有重量差不多、干到200W性能释放、拓展性更好的ThinkBook 16p
  - 要便携+续航，酷睿Ultra、1.85kg更轻薄、质感更好的ROG幻16 Air

- ## [如何评价惠普发布的轻薄游戏本暗影精灵9 Slim，值得购买吗？ - 知乎](https://www.zhihu.com/question/593557269/answers/updated)
- 优点：轻薄，颜值在线，屏幕顶，超大电池。
- 缺点：单硬盘位，祖传大下巴。
- 自使用独显直连屏蔽核显后，直到现在没有再次出现蓝屏问题。

- Slim版则实现了纤薄便携与性能之间的平衡，更适合注重颜值与移动性的玩家

- ## [有哪些笔记本比较完美地支持ubuntu？ - 知乎](https://www.zhihu.com/question/286150644/answers/updated)
- 如果不打算跑cuda或者其他需要Nvidia显卡的程序的话，我一般没遇到过什么特别大的问题。但如果需要用Nvidia的显卡，那就是问题不断，经常要看运气了。
  - Ubuntu本身经常有Nvidia显卡驱动问题，但换成基于Ubuntu的那些以user friendly为指导思想的发行版本，很可能就不需要自己折腾，完全没问题了。这里，我强烈推荐Linux Mint，在Dell XPS上一扫最基本Ubuntu的各种显卡驱动问题。

- ## [笔记本电脑适合安装哪个Linux？ - 知乎](https://www.zhihu.com/question/520319837)
- 笔记本不建议折腾Linux，老老实实当客户端用吧。笔记本换了没适配过的Linux，电源管理，屏幕亮度，无线驱动都可能是问题。买官方支持的Linux本价格可不低。

- 笔记本来安装Linux，会让你用这个笔记本的初衷迷失在各种研究尝试上。

- ## [求推荐适合linux系统的笔记本? - 知乎](https://www.zhihu.com/question/1100336631)

- 台式机建议用Linus配的那个线程撕裂者主机，b站有配置单。显卡建议换成rx5700xt或者rx6700xt。其他的直接复制粘贴就行。
  - 笔记本电脑，i家选十代酷睿（含十代）及以下的酷睿核显本，a家选zen或ryzen架构的到最新的核显本都可以。十一代以上（含十一代）Intel处理器硬件有bug。
  - 独显一般是n卡，能不用就不用，笔记本电脑上Linux用n卡有点自找难受。

- 大部分主流品牌的都可以。

- 最正确的难道不是随便买一台win本子，虚拟机下面跑Linux吗？

- 如果不能忍受需要折腾，Ubuntu certified laptops 大大方方买就是了，主要以Dell、HP、Lenovo御三家为主

- 这玩意不是取决于你愿不愿意折腾驱动么...
  - 如果不愿意折腾就买个专业的移动工作站这种比较稳定，带驱动支持的，
  - 如果愿意折腾与喜爱，那性价比高的游戏本随便找一个就好，CPU都可以顶满到14900HX...

- ThinkPad太贵了，御三家工作站都没问题，惠普性价比最好

- 能不用笔记本别用笔记本。Linux对硬件性能没有太大限制，所以，你的硬件越强~你得到的就越多。
  - 显卡，如果搞AI的话，只选NVIDIA独立显卡，现在3090二手货也不贵了，千万别信什么N卡驱动难搞，那都是不会英文的原始人才会信的话术。Linux用其他卡才叫灾难，要啥啥没有，只能显示，还不如亮机卡。
# discuss-laptop-macbook
- ## 

- ## 

- ## 

- ## 

- ## 

- ## [苹果产品中的“统一内存（unified memory）“与以往的”内存（memory）“有何不同？ - 知乎](https://www.zhihu.com/question/429727608)
- 统一架构的好处，就是把以前内存和显存（显卡的内存，gpu用的memory）做了统一
  - 这样就减少了cpu和gpu通信时候，在内存和显存之间数据通信时候的拷贝

- 这个统一内存就是把内存、GPU的显存和神经网络处理器的缓存放到一起，通过Fabric和CPU/GPU/神经网络处理器相连。
  - 好处是等于在CPU与GPU间加了个缓存区，它们之间的数据传输更容易；
  - 坏处就是三个公用那么大统一内存（比如有16GB），等于给CPU的内存实际不到16GB，其中有部分不得不分给GPU和神经处理器。
- 换个思路，cpu其实用到了一部分显存

- UMA这东西早八百年用烂了，linux的kernel里有个dma-buf子系统专门用来做这个东西
  - dma-buf可以理解为一个在驱动间共享的可被不同硬件共享的内存，当然这个内存属于device memory，有读写限制，和CPU实现有关，这个子系统至少零几年就有了

- 要说统一内存amd走得更前，索尼在ps4就用上了

- [苹果发布会统一内存是什么意思？ - 知乎](https://www.zhihu.com/question/429767639)
  - 以前cpu有自己的内存，gpu也有自己的内存叫显存，苹果直接统一起来了所以叫统一内存。好处是避免了内存和显存之间的数据搬运，坏处：贵。
  - 贵体现在需要更多的lpddr控制器导致芯片面积大，而且lpddr本身就贵一点，焊接一起的lpddr几乎不能更换。
  - 至于有个回答说什么soc的，现在所有的cpu都是soc，gpu也是soc。soc跟是什么芯片没关系，只要不是单一模块都是soc。现在的cpu也有dsp（视频硬件编解码）这些模块所以都是soc。
- UMA不是什么发明，低端PC/游戏机上早就有了。苹果只是把内存带宽整的比较夸张（通过封装）。

- ## [如何评价苹果 3 月 5 日发布的 MacBook Air M4，相比前代有哪些提升？ - 知乎](https://www.zhihu.com/question/14167413067)
- M4 相较于 M3 有 18～25% 的提升
- 显著影响你的电脑的使用年限的，是硬盘和内存，而不是处理器，还是那句话：慢不慢和能不能是两个概念

- 其实M4的单核提升不太重要，因为M4相比M3单核能效提升很小（3%多一点），多出的那些性能都是拉高频率拿功耗换的。反而多核提升是很重要的，像我写论文一开就是十几个网页+PDF文献+编译器，M4多出的两个小核能极大缓解大核的压力从而提升续航

- M4 的 GPU 性能比 M3 提升约 21%，更适合处理3D图形渲染相关的任务
  - 处理速度提高：单核任务快约 25%，多核任务快约 30%

- ## 👷🏻 [macbook air m4 敲代码是否够用？ - 知乎](https://www.zhihu.com/question/15035632763)
- 在使用 MacBook Air M4 24 + 512 近一个月后，我可以说这已经是我最喜欢的电脑了。我用一周时间，在不关机的情况下用 mactop 对上述工况下的系统使用数据进行采集并进行简单的统计分析，结果如下：
  - 整个系统负载最大的指标是 RAM 和 SWAP。我的内存是 24GB，但是在开启所有常用程序后 SWAP 依旧来到了 8GB 左右，说明其实 32GB 是有必要的（不过当时没有国补所以买了 24GB）。不过即使如此，整个系统依旧丝滑，用起来完全没有卡顿。
  - CPU 和 GPU 的均值不超过 20%，略高于我上次在 M4 Pro 上测试的结果，这是合理的，毕竟差了 2 - 4个核心，但是依旧没有成为性能瓶颈。95% 分位数也在 30% 左右，与上次相差不大。说明 M4 这颗芯片提供的性能其实依旧完全满足了我的日常需求。
  - 日常使用时几乎感受不到发热。
- 我经常需要拿着电脑去会议室开会，每一次从桌上拿起 MacBook Pro 时，侧面的出风口都会给我很强的感知，这一点上 Air 的手感完胜。

- 不能用windows 不能做安卓逆向 淘汰 啥时候回归 windows 再买，现在用2019款装的 win10

- 开了内存泄漏大户zotero和arc游览器之后，24g运存就开始不够了

- 个人测试mac mini m4 16g版本，运行20w行代码的java项目，docker运行 mongo + redis+mysql，开七八个网页，内存压力就已经开始黄色，对我来说这还是轻度测试，我个人工作流四五十个网页都很常见，后台还需要postman，微信，qq等，按我用法得32g以上才够用。。

- 如果只是为了外接设备的话，一个几百块的转接器就搞定了.

- 512GB硬盘必备：Xcode、Android Studio、Docker镜像随便一个都能吃50GB，256GB分分钟爆仓

- 真要散热焦虑，淘宝30块买个笔记本支架，温度还能再降5℃

- ## [是选M4 MacBook Air还是M4 MacBook Pro? - 知乎](https://www.zhihu.com/question/14423191905)
- MacBook Air M4：有2个雷雳4接口、MagSafe充电接口和一个耳机插孔。
- MacBook Pro M4：有3个雷雳4接口，还增加了HDMI接口和SD卡槽

- Pro搭载M4 Pro/M4 Max 芯片，性能核心更多（如 M4 Pro 14核CPU + 20核GPU，M4 Max 16核CPU + 40核GPU），内存带宽高达 512GB/s（M4 Max），适合多轨道视频渲染、复杂特效喝多图层设计。

- Pro，屏和喇叭差不少呢 ，值回差价。

- ## [Mac mini可以将笔记本电脑作为显示器吗？ - 知乎](https://www.zhihu.com/question/11673595878)
- 可以，适用于所有笔记本电脑的方法是，通过网络连接远程桌面---特别是两台电脑都处于同一局域网的情形下，效果非常可以。
- 如果用自带的屏幕共享，Mac自己的客户端连接速度尚可，其他VNC客户端倒是一言难尽。
- 可以用HDMI采集卡。Mac mini从2010款开始都标配了HDMI接口。
  - 采集卡不能共享键盘鼠标
  - 或者KVM over USB的，然后自己用一套鼠标键盘
- 直接连接不太现实，但是可以用屏幕共享工具，把 Mac mini 投屏到笔记本上，就可以相当于使用笔记本的键盘和触控板来控制Mac。但要在笔记本上装支持 VNC 协议的客户端，再通过 IP 地址或 Apple ID来 连接Macmini。但是这个操作非常吃网络稳定性，而且画面延迟有点小高。你不介意的话就可以一试，最好还是直接给 Mac mini 配独立的显示器。

- 笔记本电脑没有视频输入功能，要当显示器也不是不可以，可以去买个采集卡，将就可以用了。

- 不过采集卡，好的还是挺贵的，还不如去买个便携屏幕，方便携带，还能给笔记本电脑用也可以。

- 如果需要携带，有便携屏可以选择，配合Mac mini M4用可以一线通，还是比较省心的。特别是有些有一些支持触控的，可以给macOS触控操作
  - 便携屏的话，我喜欢16英寸的，能携带，看着也舒服。像维辰思这个，4K分辨率，是100% DCI-P3广色域，500尼特亮度，日常够用了。

- ## [Mac mini的显示器推荐：便携显示器能做什么，平板能做屏幕用吗？ - 知乎](https://zhuanlan.zhihu.com/p/31411990698)
- 什么叫一线通？就是Mac mini通过雷雳4接口，和便携屏连接就可以实现给屏幕供电和信号。便携屏不需要另外插电源了。

- 为啥不把平板当显示器用？
  - 各种平板电脑不支持视频输入，只能通过远程桌面，或者推流方式实现。但是这样方案一个是延迟很低，分辨率也只是到1080P而已，更高分辨率挺费钱，没必要。
  - 像iPad，现在安卓平板，都没有视频输入能力。被商家限制了功能，或者不想做。

- [MacBook配件之便携屏选购攻略 - 知乎](https://zhuanlan.zhihu.com/p/628909420)

- ## [Mac mini配可随身带显示器如何，是不是比笔记本还自由？ - 知乎](https://www.zhihu.com/question/51732960)
- 笔记本移动电源（or太阳能电池板）+转接口+耳机+便携式显示器。
- 随身显示器，还要带上随身键盘，还有随身排插。还有随身音响的亲。

- 随身携带的显示器有很多选择，我觉得主要问题是电源，如果能搞一个随身携带电池，我觉得让 Mac mini 变成笔记本就不难了。

- ## [入门macOS系统，选air还是pro? - 知乎](https://www.zhihu.com/question/1895920692941263011)
- Pro多出来的性能，普通人根本用不上，就像你买个跑车但天天堵在三环

- air还有个好处，年头久了也不用清灰，省事。

- MacBook Air M4芯片和Mac mini，以及MacBook Pro有区别，它的CPU是10核心，但是GPU是8核心的，比那两个核心数少了两个。在图形秘籍的因公，比如一些游戏，会有一些影响。

- ## [Macbook Air M4 24+512还是 Macbook Pro M4 Pro 24+512? - 知乎](https://www.zhihu.com/question/1893050996537668535)
- 有条件还是尽量选pro，pro的接口和屏幕更适合生产力，
  - 它的mini led屏在写代码时，120Hz Promotion带来的跟手感是用了就回不去的。
  - 而且pro默认支持同时外接2台6K显示器，air需开盖才能外接双屏，pro对于多窗口工作更灵活。
  - 像你如果经常同时进行多任务，比如后台跑Stata+开PyCharm+Chrome多标签，需要外接多屏或高速接口，那必须是pro

- Air 和 pro 我觉得体验上的最大差异是屏幕观感，如果你需要高亮度，高对比度，高刷新率，那无疑只有 pro 满足，如果对这些没要求，那就图 Air 的轻薄方便携带吧；

- 作为维修人员来说，PRO的故障率比AIR高很多，10台坏掉的机器7成是PRO，AIR故障率非常低，苹果历代的AIR都是这样的，苹果的AIR用个几年，顶多电池扛不住了换个电池就好了，PRO就不一样，主板故障率对比AIR高太多了

- ## 🆚️ [MacBook Air 与 MacBook Pro 差别多大？ - 知乎](https://www.zhihu.com/question/20385806)
- MacBook Pro 与 MacBook Air差别有多大，要大可以很大，要小也就个风扇的差距。

- Air没有配风扇，大型软件只能轻度使用。外接显示器超过一定时间发热处理器就会降频。
  - Pro有风扇，大型软件耗电较大。但Pro的性能除Mac pro和studio外最强！

- 同配置的M1 芯片 MacBook Air 和 M1 芯片 MacBook Pro，差距就在于MacBook Pro有风扇，MacBook Air没有风扇，导致MacBook Pro在持续高性能工作下表现更优异。

- [现在适合入手Macbook吗？Pro和Air怎么选？冲M3还是等M4？ - 知乎](https://www.zhihu.com/question/655713407)
- macbook 我只推荐 pro: air 并不轻，不是叫 air 就轻，air 还有很多问题，散热差，屏幕差，而且没法接多个显示器，只能同时点亮两个屏幕，意思就是你接了两个屏幕的情况，air 本体的屏幕就没显示了，我的 macbook pro 上面接了 3 个屏幕，本体屏幕也正常使用 

- Air无风扇设计：适合短时间高负载任务（如轻度视频剪辑、编程编译），但持续高负载（如长时间渲染、3D建模）可能导致降频，性能下降。

- Pro配备主动散热风扇：可维持长时间高性能输出，更适合专业级工作流（如4K/8K视频剪辑、复杂建模）。

- 我写代码以前是iOS开发为主，现在是小程序开发。之前用的是MacBook Pro，现在用的是Air，以后应该都会用Air了。既然选了笔记本，就是为了轻便去的。 我现在用的是16G+1T。 真正考验性能的可能就是视频剪辑类的了，写代码Pro与Air都能对付的。

- pro版多了一个HDMI接口，如果你需要外接显示器或者投影仪之类的东西，这个接口会方便很多，如果不需要的话，那还是建议省下一千块。
# discuss-pc-mini/diy
- tips
  - 不推荐买整机工作站，购买单独的算力卡即可

- ## 

- ## 

- ## 

- ## 

- ## [英特尔怎么可能一年之间就没落了？ - 知乎 _202410](https://www.zhihu.com/question/2005473234)
- pc端只是表象，真正打断intel骨头的是服务器端。zen刚推出的时候，16~32核线程撕裂者，平均每核成本和售价比志强低，线程撕裂者一推出就收到市场好评，28核以下的志强市场立刻遭受线程撕裂者的瓜分。
  - 后续zen2架构下，推出最高64核心128线程的霄龙服务器，志强平台一个能打的都没有，论性能，拼不过，论价格拼不过，论能耗，拼不过，唯一可以拿出手说话的就是志强的内存延迟更低。
  - 到了zen3时期，霄龙服务器缓存进一步增大，延迟相比志强甚至略有优势，IPC也比志强好，功耗也更低，一颗64核心128线程的霄龙U，价格一万多美元，而Intel这边迟迟推不出新一代志强，还是28核心56线程的志强当道，价格也要1万多美元，你是商家，你选谁？
  - zen4时期，霄龙继续领先，志强还是被压着打，只能吃吃老本，掏不出什么让人满意的新U。
- 市场统计，志强份额还是领先于霄龙，但是那是历史，没什么卵用，新的大订单基本是霄龙吃下了，志强只能吃吃老本的更新换代，根本不解渴。
- Intel的困局本质上是性能更高的志强平台已经很久没更新技术，技术下放更是无从谈起。PC端的缝缝补补还能和amd打得有来有回，混个28开、46开、55开，服务器端真的是一败涂地。

- 不知道的以为英特尔还在挤牙膏，其实是英特尔肚里真没货。

- 服务端求稳，，路径依赖给Intel吃老本了两年，zen2的服务器我就测过了，真是性价比吊打Intel，而且为了好迁移程序AMD经常是单路对双路

- 旧的超算中心都是iU，稍微新的就是AU了；当然国产U也有，用过国产海光X86
  - 华为的前阶段国家还有补贴，对于小微企业还是有相当吸引力，毕竟云主机能用价格低就是王道。

- 就国内市场而言，我觉得是被海光打败的，我司已经2年没采购intel的服务器了，全是海光和鲲鹏。
- 海光就是zen1架构

- 性能强的的有amd，低功耗的有arm的。被挤了。

- intel技术出现了什么问题了？
  - 一切源自10nm难产……工艺上不去很难堆核…堆核了发热和功耗倍增对dc成本不划算……
  - 堆不了核，架构升级不了

- epyc 对于企业来说省的远不止是 cpu 差价的钱，整台服务器除了 cpu 外的其他硬件、机柜、电力等，用 epyc 一台能顶至强好几台，省下的钱可不是个小数字

- PC DIY市场对于厂家而言是最鸡肋的，利润不高但音量很大。商用、专业领域甚至游戏主机都是更优质的市场。但是对于一个产品导向的公司来说，他不会随意丢弃某个市场，只是支持力度的问题。PC DIY市场地位在目前基本就和讨饭的差不远

- 有没有可能，从十年前就开始没落了。intel7（10nm）这个工艺应该在2016年就出来的，结果到2024年了还在缩肛。

- intel岂止是在cpu上拉胯了，这几年砍了多少方向了？砍了，FPGA拆分了，放弃。说是要把工作重心放在cpu上，可是工艺早就被台积电甩开。最重要的服务器领域甚至拿不出和AMD旗舰型号对标的产品。要我说现在这个衰退速度还算慢的，要不是有使用惯性，intel应该更垮一些。

- ## [线程撕裂者这种核心超多的CPU主要能用来做什么，来使用掉绝大部分核心？ - 知乎](https://www.zhihu.com/question/500819181/answers/updated)
- 对于普通家用电脑来说，别说8核心，4核心基本就能满足许多需求了，这是因为大部分的常用软件并没有对多核心处理器进行优化，即使你的CPU核心数量再多也用不到，相当于浪费，但是像[线程撕裂者]这样的超多核心CPU可以在专业领域方面发挥很大的作用。
  - 3D图形渲染、数据中心和视频处理这些工作都可以非常好的利用多核心处理器的性能，更多的核心就能起到更多的作用
- 另外，CPU [X86架构] 经过多年的发展，如今想要大幅度提升单核性能已经很难了，所以英特尔和[AMD] 都在想方设法增加CPU核心数量，通过多核协同工作来提升CPU性能，未来还会有越来越多的软件和游戏对多核处理器进行优化，所谓的“一核有难，八核围观”的尴尬场景会越来越少

- 强计算生产力用途包括3D渲染，影视制作渲染，CG动画，有限元分析CFD，[Fluent]，SAS，Python，量化交易，[股票量化策略]，回测，高频交易，深度学习和机器学习，自动标记，训练，推理，平面美工，游戏程序开发，能赚钱的游戏直播主播，游戏工作室等等

- 工作站，服务器，多开虚拟机。

- 编译 ~ 比如chromium，虚幻引擎 100核也不多…

- ## [高端显卡买哪个 4090-48g vs 5090-32g - 小红书](https://www.xiaohongshu.com/explore/685fdabf000000002400c5fb?xsec_token=ABXvcJCtj5SgpnxaAuvQTSjGIPWgAdou5ozGSko5ifxSI=&xsec_source=pc_search&source=web_explore_feed)
  - 48GB版本4090是涡轮版魔改的，性能比4090主机版低20%性能。并且被改的卡不一定是一手卡，也没有官方质保。店家会保一年。
  - 5090目前的适配并不完善，要求新驱动。对少数深度学习项目有兼容性问题。

- 我其实不太理解为啥5090才给32g
  - 刀法，给多了影响算力卡出售。后续的卡可能会卖不动。
  - GTX定位不是跑模型，按最初的设想，算力卡才是跑模型的。这样就能通过Nvlink技术共享显存。
- 人家定位就是游戏显卡，什么游戏能用爆32G显存？跑推理训练去买pro6000啊

- 5090说不定能改64GB，说不定之后会有人改
  - 很难，没有bios

- 目前用 8 张 4090-48 挺稳定的
- 涡轮卡吗？
  - 我听说改48GB的基本上是涡轮版，因为这样利润最大。
  - 不但是利润，涡轮卡是双槽，一个机箱内可以塞更多的卡

- 48GB魔改版可以多张卡叠加显存嘛
  - 可以张量并行部署更大的模型
- 稳定的话应该没问题，组里有十几张都没啥问题
- 不能，多卡叠加显存必须去买老黄的专业ai计算卡

- 搞RTX pro 6000，一张就96G显存了
  - 8万多可以搞四张了
  - 现在价格6w5左右

- 还没买，我比较保守，怕48GB的有问题，倾向于5090。
  - 存在兼容性差的问题，同课题组有人买了5070，他说要求更版本的pytorch（因为支持的cuda版本必须高），所以低版本的pytorch项目跑不起来。
  - 12.8等高版本的pytorch不支持很多项目项目的

- 打游戏就老老实实买5090，ai都是伪需求，没几个用得上的，真正有需求的会去买ai卡
  - 跑模型为啥要买Geforce，买telsa的H200，H100不香么，再次点Quadro这种专业卡都有Pro 6000，跑ai完全吊打5090，真的有需求的人买不起也会去租的

- 5090配环境还是麻烦，干活的现在用4090一年后再考虑5090

- ## [8K配的工作站加4090 48G 成功跑起Deepseek - 小红书 _202504](https://www.xiaohongshu.com/explore/67fa372d000000001e00ba5a?xsec_token=ABufSAS9QghohUw1fzyX0iVOG5KQLPpvxE2fkT2okUTlk=&xsec_source=pc_search&source=web_explore_feed)
  - 运行的是ikawrakow/ik_llama.cpp/这个库，他用 AVX2 指令集做了许多优化
  - 运行的是 Q2 的版本的 deepseek v3，占用内存 222G，显存 20G，所以普通 4090 也能跑起来
  - 输入 41 t/s, 输出 8 t/s
  - 我用的是联想 P620准系统+256 内存 8K 多点的价格
  - 这个 P620 准系统也不差 5945ws 线程撕裂者 联想锁机 U 可以跑到 4.5G 十分便宜 5 6 百左右吧
  - PCIE 插槽多 128通道，每个插槽都可以拆分，以后扩展比较方便
  - 8 通道 DDR4 3200内存，不比 DDR5 慢，一条 32G 200 左右
  - 唯一缺点，主板的1000w 电源没法更大了，主板插槽也不支持两个高功率显卡，所以想在这个系统上插双 4090 是没戏，但可以插 2 个 A6000。
  - 同价位的 PC 是完全没法比的。虽然我这些都是二手，但几百块的 cpu 就是坏了换一个也没啥心疼
  - 我调查过其他的工作站服务器，epyc 志强，我觉得都不如线程撕裂者，平时当 AI 服务器，偶尔还可以剪剪片子性能也很好。

- 我买的带cpu的准系统，这个cpu锁联想的主板，所以便宜

- 问下这个机器的电源怎么接，机器本身电源只有两根显卡电源接口的线，4090至少要三根
  - 两根8pin转 4090 16pin的就可以了

- 这种魔改的显存官方驱动支持吗
  - 支持

- ## [我的RTX 4090 48G深度体验报告 - 小红书 _202503](https://www.xiaohongshu.com/explore/67ca95ca000000000d015047?xsec_token=ABqsyDIYHWnZyXfQUxpaLc8ZkBUCid6Z7dPfToCAZBfTA=&xsec_source=pc_search&source=web_explore_feed)
  - 用4K OLED电视测了《赛博朋克：往日之影》，路径光追全开+DLSS 3.5插帧，画面毛发反光真实到离谱…帧数居然稳在98！以前3080直接掉到40的酒吧霓虹灯场景，现在丝滑到想哭
  - 用Blender渲染公司新项目场景，32GB显存直接吃满！如果换成老显卡估计要崩…但4090 48G居然能边渲染边开着AE做特效预览，这才是真正的“生产力解放”
  - 偷偷试了本地部署70亿参数AI模型，48G显存跑图+训练同时进行
  - 电源建议1000W金牌起步！我旧电源带不动疯狂闪退
  - 机箱尺寸必须量好，这张卡比iPhone 15还长2cm
  - 非刚需慎入！除非你是8K剪辑/AI训练/富哥

- 适合笔记本吗？
  - 这是桌面级核弹！笔记本请认准4090移动版（完全不是一个东西）

- 跑游戏和普通4090无任何区别。甚至在没爆显存的基础上，跑AI也和普通4090速度是一样的，不要幻想有了48G就会更快。需要指出的是，跑70b模型确实能发挥48G的优势，不再是一个字一个字蹦。最后，涡轮风扇噪音极大，部分用户可能无法接受。

- ## [同预算，我发现了比4090 48g更优的卡 - 小红书](https://www.xiaohongshu.com/explore/68933df200000000250232c0?xsec_token=ABJcKpAiG7_wvbIBshcL_hTstuY3ZuJRr7DRybbzYqQno=&xsec_source=pc_search&source=web_explore_feed)
  - 公布结果：5880 ada 48g显卡，
  - 按照nvidia官方发布的datasheet，算力差距在20%。毕竟这个价位。考虑稳定性，和大显存，这卡还是比较好的选择
- a6000为啥比5880ada还贵？
  - a6000有两个版本，一个是a6000 一个是6000ada，你说的贵的，是ada版本，属于是4090一代产品，5880是6000ada的阉割版

- 4090的显存bandwidth太低了
  - 小作坊感觉也够用了，毕竟老师们的经费也不见得能买h100这类。

- 这个价格我只能想到是L20了，差不多的价格，显存比4090 48G大，关键是可以上NVLink联合显存，性价比真的高。

- ## [4090 48G真爽，给女儿的人工智能实验成功 - 小红书](https://www.xiaohongshu.com/explore/67de13d1000000000b0151d1?xsec_token=ABYgeab4C5E3b9gpHBDeBL8cszeX4XJpIaX3RvHVudVRc=&xsec_source=pc_search&source=web_explore_feed)
  - 很多朋友关心这块4090 48g。我的配置也说一下，我是联想P620 5945w的线程撕裂者加256内存，这一套系统大概8K，比起PC级的配置，经济实惠，主要是PCIE扩展可以有很多，内存通道也多，内存便宜。
  - 跑大模型，32b并发16能到400多t, 训练时，满精度只能跑1.5b, 如果是lora就无所谓了，32b也可以跑。

- 小模型参数不够推不出来怎么办？感觉有好多不确定性
  - 只要想办法让它通过思考输出和agent任务相关的token, 执行任务成功率就会很高，以前靠长cot是没法在小模型做的，通过RL训练解决了这个任务，如果只训练特定领域成本也不高
- 个人认为小模型推不出来反而是确定性太强，过于依赖提示词，用起来语言模型像文生图似的
  - 其实你这样想，学会从大量工具中挑选对的，以及写对参数，这些是不需要大量知识的，只需要输出符合逻辑的token作为上下文，它就能完成任务。RL+GRPO给了一种解决小模型提升干活能力的思路

- ## [如何评价 Framework 笔记本？ - 知乎](https://www.zhihu.com/question/475249794/answers/updated)
- 喜欢接口多惊鸿14就有3A2C，HKC，机械革命这些才是真的懂平民产品该什么样子的厂家。
  - framework? 产量和销量上不去，又没有日系的溢价的情况下根本没法做好品控，那就只能根据现有的模具改一改。

- 要模块化没问题，首先先把显卡可换，内存，网卡，硬盘，CPU，全部可换，你得去说服intel让它别改针脚，不然你这改个C口就模块化了？
  - 是啊，对于真的用笔记本的人来说，模块化应该是像00-10年代主流笔记本一样，起码能自行更换cpu吧。framework的伪模块化只是对外接口模块化罢了。

- framework要做的该是笔记本的pc架构标准，这不是一个公司可以做到的，而且还需要时间去拓展硬件生态

- cpu、显卡与主板绑定，更换直接换整个主板，所谓的模块化显卡就是接显卡坞之前还得再加个模块转换接口么？？大概了解了一下这个产品的现有信息，我只能说，眼前一黑。为了模块化而模块化的产品，请不要打diy的幌子噶韭菜了。

- 总结一下上述回答：轻薄和模块化是不可兼得的鱼和熊掌。目前很难在完全轻薄和最大程度模块化中间找到一个能让很多人满意的“度”。

- ## 🛝 [有没有前期将就用后期可以升级扩展到顶级的电脑配置？ - 知乎](https://www.zhihu.com/question/15227206505)
- 你想有钱了再搞扩展，最关键的就是主板一定要买好的，大板是必须的，而且是近期出的
  - 如果主板买的老、旧、丐版，那后期没法升级，只能全换
  - 其他CPU、显卡、内存、硬盘、电源都可以升级

- 不存在。我现在的配置是2070S，想升级，计划保留电源，硬盘和内存。结果发现ddr5的物理接口都改了，想要释放新显卡，就必须连内存一起换了。
  - 所以你要是用久了再升级，会发现当前零件全过时了。而短时间之后就升到顶配，那不如再等等直接入手顶配，毕竟电子产品，二手价格是腰斩的。
- 一般电脑升级，就是除了硬盘，电源可以保留，其他全换。

- 先买一个联想的P620准系统，它自带了机箱、80PLUS铂金电源、主板、CPU散热器以及内存散热器，这个是最贵的，大概是5000元左右，其他的我们都买丐中丐
  - CPU先用一颗最低端的线程撕裂者5945WX，联想锁的大概700-800元，区区12核24线程的低端CPU
  - 内存先简单来4条32G的 [三星DDR4 2R] x4 2666MHz的ECC内存，凑一个128G的内存容量，大概700元左右
  - 硬盘如果囊中羞涩，可以先来一根[西数的SN7100] 1T过渡一下，不过服务器主板有非常丰富的PCIE插槽，直接插PCIE固态或者用U2固态也是非常好的选择，如果需要素材比较多可以考虑上一个机械硬盘
  - 显卡我们可以挑一个亮机卡，比如[P1000]，这就只要200元了，UG、CAD并不是特别吃显卡的软件，买P1000这种低端的专业图形卡即可
  - 这样子一台简简单单的建模工作站就OK了
  - 日后想升级很简单，CPU换成5995WX，这是64核128线程的真 线程撕裂者，内存简简单单扩展到256G，硬盘往死里加就OK
- 这机箱真漂亮。玩装机，玩到最后就是机箱。

- 这种准系统工作站一个很容易忽略的问题是就是显卡无法安装游戏的显卡，机箱空间有限装不了，而且这种机箱设计本身就是面对工作站方向设计的，而且只能装那种工作站专用的涡轮显卡，那个声音很酸爽有够你受的。
  - 后来我用外接显卡方式解决了游戏显卡不能装工作站的问题，实现了能用大内存又能用高性能游戏显卡。
  - 现在游戏显卡基本上都是设计很高，而工作站对显卡高度是有限制的，里面空间也很小也不利于散热，所以如果可以重新选择我以后会倾向于用游戏主机来做设计。

- 这问题不是就给AM5定制的吗？
  - 主板：B850M带WiFi，1200左右，考虑后期升级一定要弄块好点的板子，要不然升级供电带不起来。
  - CPU：凑合用9600X或者7500F，前者1200后者800，未来可以升9800X3D或者9950X3D，游戏生产力都可以兼顾。或者搞块8500G用核显，连亮机卡都可以省。
  - 内存：16G×2 6000MHz或者6400Mhz，AMD不用上高频内存，6000频率同频用还省钱，后期ddr5普及之后可以升级32G×2 8000MHz分频用。
  - 显卡：凑合用随便淘张亮机卡就行，升级主板支持pcie5.0，别说5090，将来6090都能跑的满。
  - 硬盘：先买块4.0的固态用着，将来可以换pcie5.0的固态。
  - 电源：二手比较划算300块可以淘到海韵750W，大牌稳定可靠还安静，升级显卡也没什么瓶颈，不带90级别显卡都没什么压力。
  - 机箱：正常尺寸机箱，看个人喜好。

- ## [迄今为止，你用过的最好用的数码产品是什么？夸一夸? - 知乎](https://www.zhihu.com/question/14769217934)
- 联想P620工作站，最便宜的线撕工作站，同时各种拓展给够，有万兆、雷电、u2、nvme，还有四槽想咋拆分就咋拆分的PCIe4.0x16，也不会像t7960那样各种不认盘，继承老板们的锁平台线撕CPU还能再省一比马内，
  - 除了上不了机架和电源瓦数偏低之外没有任何缺点，当然你放到机柜最底下的托盘也不是不行
  - 想起来没得bmc用，这确实是最大的槽点，不过要是拿来当homelab的话那其实用不太到，不如小米智能插座

- [服务器里的基版管理控制器（BMC）是哪个？ - 知乎](https://www.zhihu.com/question/54716507)
  - BMC是一个独立于服务器系统的小型操作系统，作用是方便服务器远程管理、监控、安装、重启等操作。BMC接通电源即启动运行，由于独立于业务程序不受影响，避免了因死机或者重新安装系统而进入机房。
  - BMC只是一个集成在主板上的芯片（也有通过PCIE等各种形式插在主板上），对外表现形式只有一个标准RJ45网口，拥有独立IP。普通维护只需使用浏览器访问IP: PORT登录管理页面，服务器集群一般使用BMC指令进行大规模无人值守操作。
  - 一般服务器BMC网口是独立的，仔细看印有BMC字样。但是也有小型服务器BMC网口和通信网口是二合一的。
  - 当然也有不叫BMC的，只要遵守IPMI协议，都是类似的。

- ## [漫步者G1500BRA音响测评 - 小红书](https://www.xiaohongshu.com/explore/66d12cf8000000001f038e03?xsec_token=AB38kMIt8DJB5wbhI53QOtqHIYVOHf_3EnOAptaC3-TWM=&xsec_source=pc_search&source=web_search_result_notes)
  - 性价比高、7.1环绕的音效、有线输入和插电是USB二合一、内置声卡可调节等
  - 整体非常简约，包装里有音响本体、说明书、品牌贴纸、可插拔麦克风，线是一直在上面的
  - 虽然有两种连接方式，蓝牙和有线，但它还是比较倾向于有线，除非你手机或者其他不能插USB的设备使用，可以插在插座上，开启蓝牙模式，但我买回来主要是给电脑用
  - 如果是电脑有线使用，还可以去官网下载声卡软件，声卡软件里的功能非常多，虽然它默认的音效已经很完美了哈哈，但是可以自定义音效，适合不同人的需求
  - 7.1环绕音我一开始是不了解的，直到我用了这款音响以后，声音就像包裹了你的耳朵一样，非常有沉浸感
  - 音响有三种模式，音乐模式就是低音会强一些，游戏模式延迟低，声音大，电影模式声音要小一些 沉浸感强
  - 麦克风离远点就差劲了，放在显示器下面，离嘴巴太远，别买了

- 不适配ps5真的很无语
  - 但是他适配switch

- 感觉我的外放声音好小
  - 游戏模式会大一些

- 开关机的声音只需要按4 G 和5 音量加 两秒就能关掉了

- ## [为什么现在的音响大都是蓝牙音响？ - 知乎](https://www.zhihu.com/question/658012042)
- 一般好点的那些，都叫《音箱》，而叫《音响》的，都是只有玩得不多的人才会搜索的。

- 几乎所有的有源音箱都是有有线连接的，一般标注为：AUX接口，

- 一个新选择——Wi-Fi音箱。传输音频的方式，只能用蓝牙吗？是不是有其他方式？唉，那就对了！“Wi-Fi就是其一。”Wi-Fi音箱其实已经推出市场很久，只是在国内少有人知道。

- [为什么有线音箱少了？ - 知乎](https://www.zhihu.com/question/514579467)】
  - 没有少，只是有线音响（一般指有源音箱）。好点的都带蓝牙功能，方便手机平板无线连接

- ## [联想推出扬天 M4000q 台式机，i5-12400 + 16GB 内存，该款产品是否值得入手？ - 知乎](https://www.zhihu.com/question/518095107)
- DIY玩家来说肯定是看不上的，没有3080，没有16个PCIe通道。但是你把他看作一个办公主机，我觉得是非常香的。这个办公机不比那些采购用的臭鱼烂虾什么6代i5良心多了。
  - 配置上看起来和联想的家用天逸510s 比较类似，也都是7L小机箱

- ## [从笔记本转用台式机屏幕分辨率都是2k，但从16寸到27寸按理说会变糊，不会不适应吗？ - 知乎](https://www.zhihu.com/question/662562760)
- 不会，因为台式机和笔记本有个最大的区别，就是视距。
  - 笔记本是没办法的，你手是要放到键盘上的，视距几乎和臂长差不多，必须离近了看，所以ppi不够的话，颗粒感就会让人很难受
  - 台式机分辨率2k就已经够用了，只要你不是近视眼贴着屏幕看，4k和2k体验差距并不大

- 为了能让27寸显示器看起来能有一个舒适的视野范围，题主自己，不由自主地就会在更远些位置来使用
  - 无论是16寸还是27寸，为了得到更好地视觉体验，眼睛与屏幕的距离是不同的

- ## [惠普战99台式机值得买不？ - 知乎](https://www.zhihu.com/question/588726682)
- 这是有史以来性价比最高的品牌机了这个机器我也用了4个月了，给南桥、固态硬盘加了散热器和添加同型号内存条，改装电源并扩展了一张AMD W6400显卡，解决了主板过热问题，在2k环境下流畅运行。所以只能说，这个机器对得起这个价格。

- 我买的战99款式是14500集显款，也拆机研究了内部，我来说一下他几个缺点吧：
  - 1. 主机噪音过大
  - 2. 内存条是单通道 我因为是核显，想追求双通道加了600元从16g升级到32g, 其实这本身已经溢价了，但没想到这不是两根16g, 而是一根32g
  - 3. 开机按钮太细 因为按钮是窝在机器里，靠指腹根本按不下去，得用指甲掐。很不方便。

- DDR5 单根也是双通道

- ## [现在有政府20%补贴，同样配置买台式机整机是否比自己散装要更划算呢？ - 知乎](https://www.zhihu.com/question/666757762)
- 打八折后整机确实有一定优势，尤其是懒得动手或者不太懂DIY的用户，本来DIY还有价格优势，现在这波八折价格优势几乎被抹平了。
- 看了一圈电脑的，补贴主要针对的品牌整机笔记本一体机这类，单独配件不能单独补贴吧，也就是好像不能自己攒机器领补贴吧

- 即使是有20%政府补贴后依旧没看到性价比很高的整机，如果有，麻烦踢我一脚。

- 想买惠普暗影精灵10+显示器套装14代i5+4060ti+27寸2k显示器打折后6500这个价位，有点买主机送显示器的感觉

- 我也看了，确实没有。而且补贴的都是高价整机，他那个价格，你能自己挑配置攒一个更好的。

- 你如果去京东淘宝买那几个销量最高的主机应该是比自己组装更划算的，哪怕不需要补贴

- ## [为什么台式 PC 还处在组装（DIY）阶段？ - 知乎](https://www.zhihu.com/question/1899923881755678262)
- PC平台的DIY优势，使得它的每一个细节都专门化、专业化，因为它开放

- 我觉得所有消费电子产品都应该模块化, PC是唯一走在前面的

- 所谓的台式机DIY，说难听点，不过是一块大板各种插，再拧进一个足够大的箱子里。
  - 我的观点很简单，手机发展不出DIY市场，本质上是因为普通人都是手残，厂商能放心把一堆小东西扔给你自己装？

- 
- 
- 

# discuss-os-linux/win/macos
- ## 

- ## 💡 [时至今日 win本阵营有能对标MacBook的产品嘛? - 知乎](https://www.zhihu.com/question/630359957)
- MacBook在换用了自家的M系列芯片之后，能耗比带来的续航问题完全不是一个量级的。
  - Windows本只能主打通用性，开放的系统环境和MacBook的封闭系统上不一样。
  - MacBook的工艺和品控也是最强的，CNC一体成型的工艺、苹果高成本转轴方案，大多数Windows本都无法匹敌。

- 幻 13，对标 MacBook air。屏幕和MacBook air同样尺寸同样画质，而且是视网膜高刷屏，强mac一手，续航大概有 Mac的80%，13性寸给了 75w大电池。
  - 插电后开启独显直连，性能强 mac 一大截，富哥们还可以插 4090 显卡坞，办公本瞬间变成台式机性能。
  - 槽点就是液金偏移和 16g 内存，不过不要保修的话 16g 内存可以 tb 升级到 32，或者买海外 4070款。
  - 性能，屏幕，续航三者都考虑的话，这款机子同尺寸没有对手，如果考虑触屏的话只有这一款可以考虑。

- 实质上是对标苹果的是小米，4000块的笔记本电脑都用CNC顶级工艺。。。只不过市场表现比较惨淡。
- 还有一些对标的，出师未捷身先死。例如ThinkPad X1 Nano，2024年就要没有了。戴尔XPS系列也一直试图对标，但是相去甚远，几乎没有对得上。

- 小米的还是做不到那么薄，毕竟是组装，cpu主板什么的不像mac的

- 华为有几款，粗看还可以，但是翻过来看到底部满是散热孔，感觉就不怎么舒服了。

- Microsoft Surface Laptop：这本来应该能成为像MacBook一样软硬结合的典范，无奈Windows Phone不给力早早被放弃，这款当初的Windows轻薄本标杆由于5年没换模具，现在已经相当落伍了。

- 因为利润在cpu和系统，做硬件的就那么多利润，外观好自然别的地方就得省

- 个人认为，相比于Windows笔记本，MacBook最好用的地方，在于触控板的体验。截至目前，应该还没有Windows笔记本的触控板能达到MacBook触控板的体验。

- 雷蛇啊，灵刃15，江湖人送措号黑苹果。

- 
- 
- 

- ## [国产系统大致比较和分析（优麒麟、开放麒麟、深度deepin、统信UOS、银河麒麟、中标麒麟） - 知乎](https://zhuanlan.zhihu.com/p/661508663)

### 桌面级系统

- 优麒麟是 Ubuntu 官方衍生版，得到来自Debian、Ubuntu、LUPA及各地Linux用户组等国内外众多社区爱好者的广泛参与和热情支持。
  - 针对中国市场加入大量本地优化功能。比如支持中文输入法、农历、天气插件
  - 优麒麟的桌面环境采用UKUI软件。UKUI 是一款轻量级的 Linux 桌面环境，基于 GTK 和 QT 进行开发。

- openKylin开放麒麟是中国首个桌面操作系统开发者平台由国家工业安全发展研究中心等单位联合成立，将打造具有自主创新技术的开源桌面操作系统，定位于桌面操作系统根社区 。

- 开放麒麟和银河麒麟桌面操作系统的关系类似于深度deepin和统信UOS。前者为根社区版本，后者是上游商业版本。社区版本更注重功能也更激进，商业版本则更注重稳定。

- deepin是由武汉深之度科技有限公司在Debian基础上开发的Linux操作系统，其前身是Hiweed Linux操作系统。
  - deepin操作系统内部集成了DDE（Deepin Desktop Environment）深度桌面环境），并支持deepin store、deepin Music、deepin Movie等第一方应用软件，定位于桌面操作系统根社区 。

- 统信UOS 由深度（deepin）为基础，经过定制而来的产品。
  - UOS 拥有 家庭版、专业版、服务器版 三个分支。

### 服务器级系统

- 银河麒麟高级服务器操作系统V10是针对企业级关键业务，适应虚拟化、云计算、大数据、工业互联网时代对主机系统可靠性、安全性、性能、扩展性和实时性等需求
  - 银河麒麟高级服务器操作系统汲取最新的云和容器开源技术，融合云计算、大数据、人工智能技术，助力企业上云
  - 产品同源支持飞腾、鲲鹏、龙芯、申威、海光、兆芯等自主平台，并针对不同平台在内核层优化增强。

- 基于RHEL系统开发

- 中标麒麟高级服务器操作系统软件V7.0是在多年Linux研制经验基础上，适应虚拟化、云计算、大数据，满足业务对性能、扩展性、安全等要求

### 👥

- 官方主要是麒麟。deepin原来是民间的，但是反而口碑最好，所以就转正，商业化成uos了。要是说开放性和前途，我站uos

- 还有连接打印机不好用

- 中标和银河还属于不同公司，中标一直是红帽系的，银河最早以FreeBSD为主的四核融合，后来难度太大，便倒向了红帽系。
  - 深度则是从一开始就是基于ubuntu，后来改成了基于Debian，再后来阿里、华为分庭抗礼，就又搞出来a版和e版，但主力开发的还是d版
- 其实deepin一开始就是基于Debian不稳定版，后来改为了基于ubuntu，再后来就改成了基于Debian稳定版，现在又改成了直接基于linux内核但是，由于过于激进，于是在玲珑生态起来之前，也兼容了Debian生态，类似于鸿蒙现在的路线。鸿蒙也是在自家生态起来之前先兼容安卓生态

- 真是扯淡，一个硬件厂家一套固件一套软件。你让开发者怎么做适配，

- ## [统信UOS何时被鸿蒙HarmonyOS替代？ - 知乎](https://www.zhihu.com/question/644762431)
- 统信UOS可以说是目前最好的信创操作系统，适配x86、arm、loongarch、+sw等指令集的国产CPU，包括海光、兆芯、鲲鹏、飞腾、龙芯、申威等 

- openHarmony和Harmony NEXT的生态是互通的吧；NEXT本身就基于openHarmony；
  - UOS已经发布了基于openHarmony的版本，你可以理解为UOS就是一套类似MIUI的东西，底层原来是Linux，现在换成openHarmony，

- 鸿蒙PC版和手机版生态是互通的，这意味着随着手机版的发行推广，未来推出的PC版一出生就有海量的应用，这种想象空间是巨大的

- 你们上次也是这么说openeuler的，现在快一统国内市场了

- 不需要替代，uos服务器版本来就有基于openeuler的版本，uos桌面版弄个openharmony版就行了。

- 本来谷歌华为是打算一块搞fuchsia的，目标是把chrome os和安卓全换这玩意，然后众所周知的原因fuchsia黄了，华为单干的就是现在的鸿蒙了

- ## [如何评价国产统信UOS系统？ - 知乎](https://www.zhihu.com/question/594635253)
- 统信这破系统完美地放弃了Linux类似物的所有优点，学习了封闭式系统的所有缺点：一台机器的一年授权费几百块，激活码过期后专门禁用微信和wps，不能更新下载软件，微信wps官网的linux版本安装包全部不能用，第三方安装包通通报错不兼容，只能从自带商店下载应用。要说卡脖子还是自己人最在行

- 从开发者的角度来看，这系统非常逆天。
  - 首先UOS专业版是收费系统，700元，不同架构的价格还不一样，不确定是否通用。如果不购买授权，试用期3个月，过了试用期就不能再更新和安装软件了。过了试用期不给root权限。

- 听说家庭版不用花钱，但是不开放下载，需要先提交申请。还有就是家庭版系统得绑定UOS账户，1个账户最多激活5台机器，多了就得解绑

- UOS把自己的软件生态搞得如此封闭，对于不太懂计算机的用户来说，基本上只能从他自家的应用商店安装应用软件，简直比苹果还霸道。

- 中标麒麟已经被银河麒麟合并了，现在主要是银河麒麟与统信两家。

- ## [银河麒麟和统信哪个好? - 知乎](https://www.zhihu.com/question/581675808)
- 银河麒麟不激活可以无限制使用全部功能，只是没有技术支持。
  - UOS不激活不能访问软件源，不能启用开发者模式。
- 银河麒麟跨SP的大版本升级需要收取额外的费用才能激活，UOS似乎不需要。

- 银河麒麟软件安装和权限管理和其他deb系Linux比较一致。
  - UOS权限过于封闭，不启用开发者模式不能获取root权限，不允许安装非商店包，且软件源的包使用deepin-elf-verify包阻止在其他Debian系系统上安装。而且对root权限的限制不仅针对用户也针对开发者。程序不能直接用sudo请求输入root密码提权而需要通过Dbus授权。

- 统信是给纯小白用的，怕给玩儿坏了，所以不给root权限，跟安卓一样。开发者大概也不会放着deepin不用去用统信。

- UOS对打印机驱动的支持比麒麟完善，因为它自己做了对Windows的打印驱动支持。

- 我司信创软件售后95%25以上问题的都是统信环境出的，甚至需要单独出包给统信签名，麒麟基本没啥售后除非sudoers文件被故意改过 

- 从开放性上来说，UOS统信更好一点，原因是UOS使用的DDE桌面开放性更好，提炼出了一套DTK套件，基于QT，这点感觉有发展前途，也是一个很好的思路，希望在这条开源的道路上更进一步，形成自己的特色。
  - 银河麒麟不知道怎么说，也有自己的桌面UKUI，但是个人感觉开放性不好，藏着掖着，只能让人觉得做的不好！

- 银河面向服务器，统信面向办公，面向家庭娱乐，各司其职，多好。

- ## 🆚 [带您了解星光麒麟和银河麒麟的差别 - 知乎](https://zhuanlan.zhihu.com/p/14101203674)
- 星光麒麟采用微内核设计，通过将非核心功能移到内核之外，大大提升了系统的安全性，在面临外部恶意攻击时，微内核的攻击面更小，能够有效抵御病毒和黑客的入侵。
  - 主要面向科研与超算领域，能够精准地处理复杂的数据模型，但其局限性在于对消费级硬件的适配性较差，普通电脑可能无法发挥其优势，且在软件生态支持上相对薄弱。

- 银河麒麟系统
  - 拥有强大的多任务处理能力，图形界面友好，操作便捷，对于普通用户和专业人员都能提供良好的使用体验，
  - 同时，对多种网络协议有着广泛的支持，保障了在不同网络环境下的稳定通信。
  - 多层次的安全访问控制机制，严格限制不同用户的权限，保障系统安全稳定运行。
  - 星光麒麟的软件生态相对小众，集中于科研等特定领域，银河麒麟则在民用和工业等多领域构建了较为丰富的软件生态，与众多第三方软件有良好的兼容性。
# discuss
- ## 

- ## 

- ## 🤔 [国内品牌笔记本电脑近年来市场占有率越来越高，背后有哪些方面的因素？ - 知乎](https://www.zhihu.com/question/663854470)
- 笔记本早就已经是一国两岸的品牌统治全球市场了
  - 澳洲市场甚至都是国产品牌通吃，大陆的联想，对岸的微星华硕，基本把苹果以外的高端吃满了，惠普只能吃点低端市场

- 我想说内地销量排行里HP和Dell常年前五（联想稳定第一），ASUS虽然销量也不小但常年others，MSI这种只做游戏本还死撑溢价的那就是others中的others了
  - 惠普戴尔纯属被企业采购撑起来的，离开企业采购啥也不是

- 每年英特尔和 AMD 的新CPU发布都是周期性的，以前是1年为单位，现在差不多是三个季度为单位。
- 英伟达近来都是2年一个周期，30系，40系，50系显卡。
- 需要在一个发布周期里，尽快地卡在3月开学季，6月618大促，9月开学季，双11，这四个节点，完成研发，调试，制造，备货，渠道出货，同时营销团队也要给力做好宣传，最后赶在双12清库存，准备迎接下一波的新一代全新处理器。
  - 说白了，就一个字，卷。

- 如果是国内市场的话，国外的品牌主要就苹果、惠普和戴尔。国产厂商份额的提升，主要那就与戴尔这两年的操作有关
  - 前两年戴尔突然被自己人“卡脖子”了（不让用中国的元器件还是啥的），于是要逐渐退出中国市场

- 如果有一天，国产笔记本品牌不仅屏幕是京东方、华星光电，硬盘也都是长存，显卡也都是摩尔线程了，整个国产供应链“一条龙服务”，那戴尔、惠普之流还能有什么竞争力可言？

- 华为手机、小米手机在互联网时代的背书，大家对国产电脑的认知也在一点点发生变化，当然产品也确实做的越来越好

- 不光是国内整机品牌的占有率高，而且你看现在买电脑是不是大部分配件都是国产的，内存硬盘屏幕电池基本都是国产了

- 国产笔记本水平现在比国外某些老牌卷得多

- ## 万能的推，目前我的网络结构是这样：（光猫桥接模式）
- https://twitter.com/haozes/status/1728252250114715882
  - 1. 光猫->软路由->小米路由，手机电脑是连小米的 wifi 。但此时设备无法通过 IPV6 连接测试。
  - 2. 我试过，如果去除软路由。仅光猫-小米路由，用小米 PPOP 拨号，设备连小米WIFI 是能通过 ipv6 测试的。
  - 怎么解决方案1下的ipv6  ？
- 已经都解决。现在用软路由直接拨号，小米路由当AP有两个坑：
  1. openclash 插件会有点冲突，得先关掉，测试ipv6的连通性
  2. openclash  取消“ipv6”流量代理，“允许ipv6 dns 解析”两个设置，避免它影响。另外可以用国内站点测试，避免它直接走了clash：
- openwrt啥都有啊，翻墙都是辅助功能。
- 新一点的类似的openwrt无线路由器 接到猫上硬件一站式免折腾。折腾软件就可以了。

- ## 三年前我搬新家，配置了一套精妙无比的米家智能家居生态系统。 星罗棋布的隐藏传感器，让我体验丝滑无缝。 
- https://twitter.com/XDash/status/1690655450927112193
  - 三年过去了，Zigbee 和 Mesh 协议的传感器，也该更换纽扣电池了。 
  - 星罗棋布的隐藏传感器，害我找遍每个地缝。
- 我也差不多三年前弄的全屋智能系统，现在使用率也就20%
- 想想剩下的电改造的钱，三年一换真香。
- 所以要接线
