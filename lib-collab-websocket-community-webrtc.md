---
title: lib-collab-websocket-community-webrtc
tags: [collaboration, community, webrtc, websocket]
created: 2022-10-11T08:56:11.457Z
modified: 2023-12-12T08:45:31.670Z
---

# lib-collab-websocket-community-webrtc

# guide
- feathersæ¡†æ¶ä¸ºå®æ—¶ç±»åº”ç”¨è€Œè®¾è®¡ï¼Œä»£ç é‡å¾ˆå°‘
# discuss-stars
- ## 
- ## 
- ## just intercepting a direct Undici request and handling it on the socket level in Node.js. Is this... socket-level interception, at last? _202508
- https://x.com/kettanaito/status/1952733757037007059
  - Doesn't patch Undici; 
  - Doesn't re-configure Undici; 
  - Doesn't patch "node:http"
  - Works on the "node:net" level.
- ğŸ‘€ There's a price though. The interceptor now has to be imported before the client code. Previously, it was less sensitive to import order. "node:net" is way down low and as such gets subjected to import order issues.
  - Which means that if we are to pursue this, you'd have to set up MSW as a part of your test environment. Some request clients, like XHR in JSDOM, come from environment and would have to be imported after the interceptor for the things to work.
  - For "node:http"-based requests, all that you have to do is place the interceptor import before the client import. That's usually enough.
- the biggest change here is that interceptors themselves will be able to switch to being protocol-first! Things like HttpRequestInterceptor vs ClientRequestInterceptor. This is huge.
- Undici has really great tooling for mocking on its own, too! They've got MockAgent and mockDispatcher, IIRC, and they handle Undici-initiated requests really well. 
- ## The repeating 2 and 3 messages in Chrome DevTools are Socket. IO heartbeat packets used to keep the connection alive. 
- 2: A ping packet sent by the server to check if the client is alive.
  - 3: A pong packet sent by the client in response to a ping.
- By default, the server sends a ping every 25 seconds (pingInterval).
  - The client must respond with a pong within 5 seconds (pingTimeout).
- Server as the "Source of Truth" for Connection Health
  - Centralized Timing Control: The server can tune pingInterval and pingTimeout globally based on its own load and infrastructure needs. Client-driven pings would require synchronization across diverse clients, complicating scaling.
  - Burst Avoidance: If all clients sent pings independently, the server could face traffic spikes. Server-side scheduling spreads out pings evenly.
- Why Not Client-Initiated Pings?
  - Unpredictable Client Behavior: Clients might use varying intervals, go to sleep (mobile apps), or disconnect abruptly without notifying the server.
  - State Synchronization Overhead: The server would need to track each clientâ€™s last ping time, increasing complexity and memory usage.
  - Risk of False Positives: A client might fail to send a ping due to temporary CPU load or throttling, but the connection itself could still be alive.
- Efficient Resource Usage & Rate Control
  - Think of the server as â€œpollingâ€ each client at a fixed cadence it chooses (e.g. every 25â€¯s). It can throttle that down in lowâ€‘traffic scenarios or speed it up when clients seem flaky.
  - If the client were free to ping first, misbehaving or buggy clients could hammer the server, driving CPU/network usage up and potentially leading to DDOSâ€‘like scenarios. Serverâ€‘initiated pings let the server gate the heartbeat frequency.
- The core reason boils down to efficient and reliable detection of client-side disconnections from the server's perspective, prioritizing server resource management.
  - Server-initiated pings guarantee that traffic flows at regular, predictable intervals configured by the server.
  - It allows the server to rapidly detect and clean up resources for unexpectedly disconnected clients using a dedicated timeout mechanism (pingTimeout). 
- ## [websocket - Is there a limit (practical or otherwise) to the number of web sockets a page opens? - Stack Overflow](https://stackoverflow.com/questions/26003756/is-there-a-limit-practical-or-otherwise-to-the-number-of-web-sockets-a-page-op)
- It seems that the maximum number of possible open Websockets is defined by the browser implementation, and it is being difficult to find numbers.
  - In the Chromium source code (Google Chrome for Linux), I can see a max of 30 per host, 256 overall.
  - In the Firefox configuration, (go to about:config and search for network.websocket) I can see a max of 6 persistent connections per host and 200 overall, but apparently the persistent conection limit does not affect WebSocket connections, so only the 200 limit applies.
- ## [Custom event naming convention Â· Issue #1571 Â· socketio/socket.io](https://github.com/socketio/socket.io/issues/1571)
- I have seen examples with 1) lower case and underscore and 2) camelcase, Altso, should I use present tense or past?
- ## [Sharing websocket across browser tabs? - Stack Overflow](https://stackoverflow.com/questions/9554896/sharing-websocket-across-browser-tabs)
- 
- 
- [How does websockets deal with for two tabs of the same browser - Stack Overflow](https://stackoverflow.com/questions/23300615/how-does-websockets-deal-with-for-two-tabs-of-the-same-browser)
- There's a separate websocket for each tab.
  - You don't need to create a separate cookie per tab because the websocket itself already serves as the unique id for each tab.
- [proper way to share a single WebSocket connection across multiple tabs - Stack Overflow](https://stackoverflow.com/questions/72081821/best-proper-way-to-share-a-single-websocket-connection-across-multiple-tabs)
- Unfortunately is not a straightforward task. But because many browsers are limiting the number of connections to the same origin it is an issue I faced a few times.
- Assuming you are forced to share the connection and other options are not feasible, these are the possibilities:
  - SharedWorker (33.17% support). Allows you to share the connection as you already discovered.
  - BroadcastChannel (91.23% support). Allows you to communicate between tabs.
  - SessionStorage (97.25%). Allows you to communicate between tabs. This is a bit of a hack see but worked well for me.
- 
- 
- 
- ## ğŸ§­ Blink: Intent to Ship: WebSocketStream. Someone should do a benchmark comparing message throughput versus WebSocket.
- https://twitter.com/jarredsumner/status/1755136727415681407
  - If this becomes adopted by other browsers, it is inevitable that Bun and Node will end up supporting it eventually
- isn't it already addressed by webtransport?
- Iâ€™m a benchmark guy for Redis Enterpise, write benchmarks for CPUs, Fpgas, ASICS, Embedded platforms. Opposite of fake geek bench . Specify what exactly you would like to benchmark in a real life use case.
- ## [websocketä¸€èˆ¬ä¼šç”¨åœ¨ä»€ä¹ˆå®é™…çš„åœºåˆï¼Ÿ](https://www.zhihu.com/question/269060103/answer/2399818045)
1. å³æ—¶é€šä¿¡ã€ç¤¾äº¤è®¢é˜…
2. å¤šç©å®¶æ¸¸æˆ
3. ç¼–ç¨‹
4. æ”¶é›†ç‚¹å‡»æµæ•°æ®
5. è‚¡ç¥¨åŸºé‡‘æŠ¥ä»·
6. ä½“è‚²å®å†µæ›´æ–°
7. å¤šåª’ä½“èŠå¤©
8. åŸºäºä½ç½®çš„åº”ç”¨
9. åœ¨çº¿æ•™è‚²
- å¼¹å¹•
- é€‚åˆéœ€è¦é¢‘ç¹ä¼ è¾“æ•°æ®ä»¥åŠæœåŠ¡ç«¯ä¸»æ¨æ•°æ®ç­‰åœºåˆ
  - éœ€è¦ä»æœåŠ¡å™¨é«˜é¢‘ç‡æ›´æ–°æ•°æ®çš„åº”ç”¨åœºæ™¯ï¼Œå¦‚æ¸¸æˆã€ç¤¾äº¤é€šè®¯ã€å®æ—¶æŠ•ç¥¨ã€æ‹å–ã€åœ°å›¾å®šä½å¯¼èˆªç­‰
  - åä½œåº”ç”¨ï¼Œå¦‚ç™½æ¿åº”ç”¨ã€å¤šäººæ–‡æ¡£ã€ä¼šè®®ç­‰
  - éœ€è¦é€šçŸ¥çš„åº”ç”¨ï¼Œå¦‚é‚®ä»¶ã€å®æ—¶æ¨é€ã€è¿œç¨‹æ§åˆ¶ã€èŠå¤©ç­‰ã€‚
- ## [æ‰‹å†™Socks5é€šä¿¡ - HadYang](https://hadyang.github.io/2019/03/socks-proxy/)
- Socks åè®®æœ¬èº«æ˜¯åŸºäº TCP çš„åè®®ï¼Œä½äºåº”ç”¨å±‚ä¸ä¼ è¾“å±‚ä¹‹é—´çš„ä¼šè¯å±‚ï¼Œå°†åº”ç”¨å±‚çš„æ•°æ®é€æ˜çš„ä¼ è¾“åˆ° TCP å±‚
- Socks5 åè®®åœ¨è¿›è¡Œä»£ç†é€šä¿¡æ—¶ï¼Œé¦–å…ˆéœ€è¦è¿›è¡Œè¿æ¥ã€è®¤è¯ç­‰æ­¥éª¤ã€‚
- ## [WebSocket ç›¸æ¯”æ™®é€šçš„ TCP é•¿è¿æ¥æœ‰ä»€ä¹ˆä¼˜åŠ¿ï¼Ÿ - çŸ¥ä¹](https://www.zhihu.com/question/303724564)
- WebSocket æ˜¯åº”ç”¨å±‚åè®®ï¼Œtcp æ˜¯ä¼ è¾“å±‚åè®®ã€‚
  - websocket æœ¬èº«æ˜¯åŸºäº tcp å®ç°çš„ã€‚
  - tcp æœ¬èº«æ— æ‰€è°“é•¿çŸ­è¿æ¥ï¼Œç†æƒ³çŠ¶æ€ä¸‹åªè¦ä¸ closeï¼Œtcp è¿æ¥å°±ä¸€ç›´å­˜åœ¨ï¼ˆæ³¨æ„æ˜¯ç†æƒ³ï¼‰ã€‚
  - æ‰€è°“çš„é•¿è¿æ¥æœ¬èº«æ˜¯ä¸€æ¡è™šæ‹Ÿé“¾è·¯ã€‚
- TCPï¼šæ˜¯å®¢æˆ·ç«¯ä¸æœåŠ¡ç«¯ï¼Œå¦‚ä½•å»ºç«‹æ¡æ‰‹åŠè¿æ¥çš„ä¸€ç§åè®®æ–¹å¼ï¼Œ
  - ä¸€èˆ¬ä½¿ç”¨Socketçš„æœåŠ¡ï¼Œå°±æ˜¯åŸºäºTCPåè®®è¿æ¥å¥½åï¼Œä½ è¦è‡ªå·±å®šä¹‰å®¢æˆ·ç«¯ä¸æœåŠ¡ç«¯å¦‚ä½•ä¼ è¾“æ•°æ®ï¼Œä¸»è¦è€ƒè™‘çš„æ˜¯å¦‚ä½•ç¡®è®¤æœåŠ¡ç«¯æ˜¯å®Œæ•´çš„æ”¶åˆ°äº†å®¢æˆ·è¯·æ±‚çš„æŠ¥æ–‡ã€‚ 
  - websocketå…¶å®ä¹Ÿæ˜¯ä¸ºäº†è§£å†³å¯ä»¥å®Œæ•´æ¥æ”¶æŠ¥æ–‡è€Œè¡ç”Ÿå‡ºæ¥çš„ã€‚
- WebSocketï¼š æ˜¯æ ¹æ®TCPå»ºç«‹äº†è¿æ¥åï¼Œå¦‚ä½•å®šä¹‰æ•°æ®çš„ä¼ è¾“çš„æ–¹å¼ï¼Œå¦‚ä¼ è¾“çš„æ•°æ®çš„é•¿åº¦ï¼Œç”¨å‡ ä¸ªå­—èŠ‚è¡¨ç¤ºï¼Œå†…å®¹å¯¹åº”çš„å­—èŠ‚ï¼Œåœ¨å“ªä¸ªä½ç½®è¡¨ç¤ºï¼Œ
  - ç›®å‰websocketå·²ç»è¢«å¾ˆå¤šè¯­è¨€æ”¯æŒï¼Œä¸€èˆ¬å»ºè®®ç”¨WebSocketçš„æ–¹å¼å†™æˆæœåŠ¡ï¼Œå®ç°é•¿è¿æ¥çš„é€šè®¯ã€‚
- WebSocket æ—¢æ˜¯ä¸€ç§æŠ€æœ¯ï¼Œæ›´æ˜¯ä¸€ä¸ª Socket çš„åº”ç”¨å±‚åè®®ï¼Œå®ƒè§„å®šäº†ä¸¤ç«¯ä¹‹é—´æ•°æ®ä¼ è¾“çš„ç¼–ç å’Œè§£ç æ–¹æ¡ˆ
  - æµè§ˆå™¨é‚£ä¸ª WebSocket å¯¹è±¡ï¼Œå°±æ˜¯ä¸€ä¸ª WebSocket åè®®çš„å®ç°ï¼Œä½¿ç”¨è€…åªéœ€è¦è°ƒç”¨å®ƒçš„ API å°±å¯ä»¥ä½¿ç”¨ WebSocket åè®®è¿›è¡Œé€šè®¯ã€‚WebSocket ä¸æ­¢å¯ä»¥åœ¨æµè§ˆå™¨ä¸Šä½¿ç”¨ï¼Œåœ¨æœåŠ¡å™¨æˆ–è€…å…¶ä»–ç±»å‹çš„å®¢æˆ·ç«¯ä¹ŸåŒæ ·å¯ä»¥ä½¿ç”¨ï¼Œåªè¦æœ‰å®ç°çš„è½¯ä»¶åŒ…å³å¯ã€‚
- ## [ä¸ºä»€ä¹ˆå½“ä»ŠWebåº”ç”¨ä¸éƒ½é‡‡ç”¨WebSocketå½¢å¼è¿›è¡Œæ•°æ®äº¤äº’ï¼Ÿ](https://www.zhihu.com/question/417163973)
  - ä¸ºä»€ä¹ˆä¸èƒ½ç»Ÿä¸€ä¸€ä¸‹å‰åç«¯çš„äº¤äº’ï¼Œè®©ç»å¤§éƒ¨åˆ†é€šä¿¡éƒ½ä½¿ç”¨websocketï¼Ÿ
- åˆ†ææ€è·¯
  - å ç”¨æœåŠ¡å™¨cpuã€å†…å­˜
    - é•¿è¿æ¥æœ‰ç»´æŠ¤çš„å¼€é”€ï¼ŒçŸ­è¿æ¥ä¼šå¾ˆå¿«é‡Šæ”¾
  - æ¶ˆè€—å¸¦å®½èµ„æºï¼Œå¦‚ä¼ è¾“é¢å¤–æ•°æ®
  - åœºæ™¯é€šç”¨æ€§ï¼Œå¯¹ç§»åŠ¨ç«¯çš„æ”¯æŒ
  - æ°´å¹³æ‰©å±•æ€§
- è‡´å‘½ç¼ºé™·å°±æ˜¯æ— æ³•è´Ÿè½½å‡è¡¡ï¼Œç»´æŒè¿æ¥å ç”¨èµ„æº
  - è´Ÿè½½å‡è¡¡å¯ä»¥åšï¼Œç»´æŒè¿æ¥å ç”¨èµ„æºæ‰æ˜¯å¤§å¤´
  - å¯ä»¥è´Ÿè½½å‡è¡¡ï¼Œå®¢æˆ·ç«¯å‘è´Ÿè½½å‡è¡¡æœåŠ¡å™¨å‘èµ·æ–°å»ºè¿æ¥è¯·æ±‚ï¼Œè´Ÿè½½å‡è¡¡æœåŠ¡å™¨æ ¹æ®è´Ÿè½½å‡è¡¡æŠŠåº”ç”¨æœåŠ¡å™¨websocketåœ°å€å‘ç»™å®¢æˆ·ç«¯ï¼Œå®¢æˆ·ç«¯å†å‘èµ·å…·ä½“çš„è¿æ¥è¯·æ±‚
- å®¢æˆ·ç«¯è½®è¯¢ä¹Ÿä¼šå ç”¨æœåŠ¡å™¨èµ„æº
- websocketå‡ºæ¥ä»¥åï¼ŒæŒ‰è¯´è§£å†³äº†æ•°æ®äº¤äº’çš„é—®é¢˜ï¼Œå¦‚æœæ¯ä¸ªæ¥å£éƒ½åšæˆwebsocketæ¨¡å¼ï¼Œå²‚ä¸æ˜¯ä¸å­˜åœ¨æ•°æ®ä¸åˆ·æ–°ï¼Œéƒ½æ˜¯å®æ—¶æ˜¾ç¤ºçš„äº†ï¼Œ
  - ä¸ºä»€ä¹ˆhttpè¿˜æ²¡æœ‰è¢«æ·˜æ±°å‘¢ï¼ŒåŸå› å°±åœ¨äºï¼Œæ—¢ç„¶ä»–è¿æ¥äº†ä¸ä¼šæ–­å¼€ï¼Œå¿…ç„¶æ˜¯åç«¯é‚£è¾¹ç”¨äº†æŸç§æ–¹æ³•æ¥å®ç°ï¼Œè€Œè¿™ä¸ªæ–¹æ³•è‚¯å®šæ˜¯éœ€è¦å ç”¨æœåŠ¡å™¨çš„ï¼ŒwebsocketåŸºäºtcpå®ç°
  - å¦‚æœä½¿ç”¨äººå‘˜ä¸€å¤šï¼ŒåŒæ—¶å»ºç«‹å¤šä¸ªwebsocketé“¾æ¥ï¼Œè‹¥æ˜¯ä¸€ä¸ªæ•°æ®æ”¹å˜ï¼Œå¯èƒ½ä¼šå‘å¾ˆå¤šç”¨æˆ·å‘é€ä¸€æ¬¡æ•°æ®ï¼Œè¿™ä¸ªæ•°æ®é‡æ˜¯åºå¤§çš„ï¼ŒåŒæ ·æµªè´¹å¸¦å®½æµé‡è€Œä¸”è€—è´¹æœåŠ¡å™¨
  - é•¿è¿æ¥æœ‰ç»´æŠ¤çš„å¼€é”€ï¼ŒçŸ­é“¾æ¥HTTPè¯·æ±‚è¯·æ±‚å®Œå°±æ–­å¼€äº†ï¼Œå³ä½¿æœ‰keep-aliveä¹Ÿæ˜¯è¯·æ±‚å®Œå¾ˆå¿«ä¼šé‡Šæ”¾ã€‚è€Œé•¿è¿æ¥é¢å¯¹æµ·é‡ç”¨æˆ·çš„æ—¶å€™ï¼Œå¼€é”€æ¯”çŸ­é“¾æ¥ä¼šå¤§å¾ˆå¤šï¼Œé™¤éä½ æ˜¯WEBIMæœåŠ¡ã€‚
- åœ¨ä¸­å›½é•¿è¿æ¥è¿«äºæŸäº›éšç§˜çš„æ”¿ç­–ï¼Œä½¿ç”¨èµ·æ¥éå¸¸çš„è´¹åŠ²å’Œå°´å°¬ï¼Œå³ä½¿ä½¿ç”¨äº‘æœåŠ¡å•†çš„CDNæ¡¥æ¥éƒ½ç‹ ä¸ç†æƒ³ï¼Œå¯èƒ½è¦åŠ ä¸€äº›éå¸¸ç‰¹æ®Šçš„è¿è¥å•†çº§åˆ«ç™½åå•æ‰å¯ä»¥ï¼Œè¿™å…¶å®æ‰æ˜¯ä¸»è¦åŸå› ã€‚
- https://www.zhihu.com/question/417163973/answer/2951435706
- è¯´è¯´webSocketç¼ºç‚¹å§
- å®ç°æˆæœ¬é«˜ï¼šWebSocketéœ€è¦åœ¨æœåŠ¡å™¨ç«¯å’Œå®¢æˆ·ç«¯éƒ½è¿›è¡Œç›¸åº”çš„ç¼–ç¨‹ï¼Œéœ€è¦ä¸€å®šçš„å­¦ä¹ æˆæœ¬å’Œç¼–ç¨‹æˆæœ¬ã€‚å¯¹äºä¸€äº›å°å‹çš„Webåº”ç”¨æˆ–è€…åªéœ€è¦å¶å°”è¿›è¡Œå®æ—¶é€šä¿¡çš„åº”ç”¨ï¼Œä½¿ç”¨WebSocketå¯èƒ½ä¸åˆ’ç®—ã€‚
- å…¼å®¹æ€§é—®é¢˜ï¼šè™½ç„¶ç°åœ¨å¤§å¤šæ•°ç°ä»£æµè§ˆå™¨éƒ½æ”¯æŒWebSocketï¼Œä½†æ˜¯ä¸€äº›è€æ—§çš„æµè§ˆå™¨ä¸æ”¯æŒWebSocketã€‚å¦‚æœåº”ç”¨éœ€è¦å…¼å®¹è€æ—§æµè§ˆå™¨ï¼Œé‚£ä¹ˆä½¿ç”¨WebSocketå¯èƒ½ä¼šå­˜åœ¨å…¼å®¹æ€§é—®é¢˜ã€‚
- é˜²ç«å¢™é™åˆ¶ï¼šæœ‰äº›ç½‘ç»œç¯å¢ƒä¸‹ï¼Œé˜²ç«å¢™å¯èƒ½ä¼šé™åˆ¶WebSocketçš„è¿æ¥ï¼Œè¿™æ ·å°±æ— æ³•ä½¿ç”¨WebSocketè¿›è¡Œæ•°æ®äº¤äº’ã€‚æ­¤æ—¶ï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨HTTPé•¿è½®è¯¢ã€æœåŠ¡å™¨å‘é€äº‹ä»¶ï¼ˆServer-Sent Eventsï¼‰ç­‰å…¶ä»–æŠ€æœ¯è¿›è¡Œæ•°æ®äº¤äº’ã€‚
- æ•°æ®é‡å°ï¼šå¦‚æœWebåº”ç”¨åªéœ€è¦è¿›è¡Œå°é‡çš„æ•°æ®äº¤äº’ï¼Œé‚£ä¹ˆä½¿ç”¨WebSocketå¯èƒ½ä¼šè¿‡äºå¤æ‚ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä½¿ç”¨ç®€å•çš„AjaxæŠ€æœ¯ä¹Ÿå¯ä»¥æ»¡è¶³éœ€æ±‚ã€‚
- å®‰å…¨é—®é¢˜ï¼šç”±äºWebSocketå…è®¸åœ¨å®¢æˆ·ç«¯å’ŒæœåŠ¡å™¨ä¹‹é—´å»ºç«‹é•¿ä¹…çš„è¿æ¥ï¼Œå¦‚æœä¸å¦¥å–„å¤„ç†å®‰å…¨é—®é¢˜ï¼Œå¯èƒ½ä¼šå¯¼è‡´ä¸€äº›å®‰å…¨éšæ‚£ã€‚ä¸ºäº†é¿å…è¿™ç§é—®é¢˜ï¼Œéœ€è¦åœ¨åº”ç”¨ä¸­åŠ å…¥ç›¸åº”çš„å®‰å…¨æªæ–½ï¼Œå¢åŠ äº†å¼€å‘çš„éš¾åº¦ã€‚
- https://www.zhihu.com/question/27745845/answer/2302967079
- websocketåœ¨æŠ€æœ¯ä¸Šï¼Œä¸å¤Ÿé€šç”¨ï¼›å¤šç§å®¢æˆ·ç«¯è®¿é—®æŠ€æœ¯ï¼Œè­¬å¦‚ç§»åŠ¨ç«¯ï¼Œè‡ªå·±å¼€å‘çš„sdkï¼›ç”¨httpåè®®ï¼Œä¼šå¾ˆé€šç”¨è€Œç®€å•ï¼›
- å¹¶å‘ï¼Œhttpæ˜¯çŸ­è¿æ¥ï¼Œè€Œwebsocketä¼šä¿æŒé•¿è¿æ¥ï¼Œå½“äº¤äº’å¹¶ä¸é¢‘ç¹çš„æ—¶å€™ï¼Œè¿æ¥æ˜¯è¢«å¤§é‡æµªè´¹çš„ï¼Œå› æ­¤æœåŠ¡å™¨çš„è¿æ¥å®¹é‡ä¼šå¤§å¤§å¤šäºhttpï¼›
- è´Ÿè½½ï¼Œhttpåè®®ï¼Œå¯ä»¥å¾ˆå®¹æ˜“çš„è¿›è¡Œwebè¯·æ±‚è½¬å‘æ¥æ‰©å®¹ï¼Œåœ¨æ­å»ºlbsæ¥å…¥å±‚çš„æ—¶å€™ï¼Œå¾ˆç®€å•å’Œç¨³å®šï¼›è€Œwebsocketåè®®ï¼Œè™½ç„¶nginxä¹Ÿå¯ä»¥è½¬å‘ï¼Œä½†æ˜¯æ¯•ç«Ÿæ˜¯æ–°æŠ€æœ¯ï¼Œç¨³å®šæ€§æœªçŸ¥ï¼›
- ç®€å•ï¼šåœ¨é—®é¢˜è¯Šæ–­çš„æ—¶å€™ï¼Œå¯ä»¥ç›´æ¥é¢å‘httpåè®®è¿›è¡Œåˆ‡ç‰‡ä»è€Œç›‘è§†åŸå§‹æ•°æ®ï¼Œå·¥å…·ä¹Ÿå¾ˆå¤šï¼›è€Œwebsocketï¼Œéœ€è¦æ›´å¤šé¢å‘tcpåè®®çš„å·¥å…·ï¼Œå¤æ‚åº¦å’Œéš¾åº¦ä¼šå¢åŠ ä¸å°‘ï¼›
- ä¹‹å‰æˆ‘ä»¬ä¹Ÿç”¨ WebSocket åšå¯¹è¯å’Œæ¨é€ï¼Œåæ¥å…¨æ”¹ç”¨ SSE (Server-Send Events, Event-Stream, EventSource)ã€‚
  - å³ä¾¿ä»¥å‰ç”¨ WebSocket åšå¯¹è¯ï¼Œå‘é€æ¶ˆæ¯ä¹Ÿæ”¹æˆäº† POSTã€‚
  - ä¸€æ¥å…¼å®¹æ€§æ›´å¥½ï¼Œä¸€ä¸ªæ¥å£å¤šç«¯éƒ½èƒ½ç”¨ï¼›
  - äºŒæ¥å‘å›¾ç‰‡ã€æ–‡ä»¶å¤„ç†èµ·æ¥æ›´é¡ºæ‰‹ï¼Œå°±æ˜¯æ™®é€šçš„ HTTP ä¸Šä¼ å˜›ã€‚
  - æ—¢ç„¶å¦‚æ­¤ï¼ŒWebSocket å…¨åŒåŠŸå°±æ˜¾å¾—æ²¡å¤šå°‘æ„ä¹‰äº†ã€‚POST è´Ÿè´£å‘ï¼ŒSSE è´Ÿè´£æ”¶ï¼Œä¸€æ ·çš„å…¨åŒå·¥äº’ä¸å¹²æ‰°ã€‚
- SSE ä¹Ÿæœ‰ä¸ªç¼ºç‚¹ï¼Œç»ˆç«¯æ–­è¿åœ¨æœåŠ¡ç«¯ä¸èƒ½åŠæ—¶å‘ç°ã€‚WebSocket æµ‹è¯•æ–­è¿ç«‹é©¬èƒ½è§¦å‘æœåŠ¡ç«¯çš„ oncloseï¼Œè€Œ SSE æ–­è¿åï¼Œè¾“å‡ºå¹¶ä¸ä¼šç«‹å³äº§ç”Ÿå¼‚å¸¸ï¼ˆjava servlet ç¯å¢ƒï¼‰ï¼Œè¦ç­‰ä¸€æ®µæ—¶é—´æ‰è¡Œï¼Œè¿™ä¸ªæ—¶é—´è²Œä¼¼è·Ÿè¶…æ—¶è®¾ç½®ç›¸å…³ã€‚ä¸»åŠ¨è°ƒæ¥å£é€šçŸ¥ä¸­æ–­è™½ç„¶èƒ½é€‚ç”¨ç‰¹å®šåº”ç”¨åœºæ™¯ï¼Œå³ä¾¿å…³çª—å£ä¹Ÿèƒ½åœ¨å¯¹åº”äº‹ä»¶é‡Œè°ƒï¼Œä½†èµ·ç å¦‚æœèƒ½åŠæ—¶çŸ¥é“æ–­è¿ä¹Ÿå¥½æ¸…ç†æ‰è¿™ä¸ªæ²¡ç”¨çš„è¿æ¥ã€‚å¦‚æœæ‚¨çŸ¥é“ä»€ä¹ˆå¥½çš„ã€ç®€å•çš„åŠæ³•ï¼Œè¯·è¯„è®ºç»™æˆ‘ï¼Œä¸‡åˆ†æ„Ÿè°¢ã€‚
  - å¾®ä¿¡å°ç¨‹åºè¿˜æ²¡å°è£… EventSourceï¼Œè™½ç„¶æ”¯æŒ HTTP æµå¼æ•°æ®ï¼Œä½†å¾—è‡ªè¡Œå¤„ç†æ•°æ®å’Œé‡è¿ã€‚ç¿»å¾®ä¿¡å¼€å‘è€…è®ºå›å‘ç°è¿™ä¸ªé—®é¢˜è‡³å°‘è¢«æ 3 å¹´äº†ã€‚ä¸çŸ¥é“å°†æ¥ä»–ä»¬ä¼šä¸ä¼šå°è£…ä¸€ä¸ª
- æœåŠ¡ç«¯ä¸ºä»€ä¹ˆçŸ¥é“å®¢æˆ·ç«¯æ–­äº†ï¼Œä¸éƒ½æ˜¯é å¿ƒè·³å—ï¼Ÿ
  - å¯ä»¥é é“¾æ¥
- æˆ‘åè€Œä¸æ˜¯å¾ˆèƒ½ç†è§£ä½ ä¸ºä»€ä¹ˆè¦åœ¨æ–­è¿æ—¶ä¸­æ­¢ä»»åŠ¡ï¼Œä½ æŠŠä»»åŠ¡å’Œäº‹ä»¶æµåˆ†å¼€å¤„ç†å°±ä¸æ€•æ–­è¿äº†ï¼Œåˆ›å»ºä»»åŠ¡ä»¥åå•ç‹¬åˆ›å»ºä¸€ä¸ªå¸¦ç¼“å­˜çš„æ¶ˆæ¯é˜Ÿåˆ—ï¼Œä»»åŠ¡å¾€é˜Ÿåˆ—é‡Œå†™ï¼ŒSSEä»é˜Ÿåˆ—é‡Œè¯»ï¼ŒSSEæœ¬èº«æœ‰é€šè¿‡last idè‡ªåŠ¨é‡è¿çš„æœºåˆ¶çš„
- sseæ˜¯å•æ¥æ”¶ï¼Œæ— æ³•å‘é€æ•°æ®ï¼Œè¦å®ç°å¿ƒè·³åªèƒ½ä¸æ–­postå¦å¤–ä¸€ä¸ªæ¥å£ï¼Œè¿˜ä¸å¥½å¤„ç†çŠ¶æ€ï¼Œç”¨å¿ƒè·³å°±æœ‰ç‚¹æ‰¯äº†ã€‚
  - é‚£æˆ‘è§‰å¾—ä¸ºäº†è¿™ä¸ªéœ€æ±‚ä»æ— çŠ¶æ€å˜æˆæœ‰çŠ¶æ€ä¼¼ä¹ä¸åˆç®—
- sseå®¢æˆ·ç«¯æ–­è¿ç¡®å®ä¸ä¼šé€šçŸ¥æœåŠ¡ç«¯ï¼Œéœ€è¦æœåŠ¡ç«¯å®šæ—¶å‘é€ç©ºåŒ…æ£€æµ‹è¿æ¥çŠ¶æ€ï¼ˆæŠ›å¼‚å¸¸å°±æ˜¯æ–­äº†ï¼‰, ä»¥ä¸Šæ˜¯åŸºäºJava springbootæ¡†æ¶çš„æµ‹è¯•ç»“æœ
  - è€Œä¸”å¦‚æœè®¾ç½®äº†è¿æ¥æ—¶é—´ï¼Œå³ä½¿å®¢æˆ·ç«¯sseè¿æ¥æ­£å¸¸ï¼Œå¦‚æœè¿æ¥æ—¶é—´è¶…è¿‡é…ç½®ï¼Œåˆ™ä¼šè‡ªåŠ¨æ–­è¿ï¼›å¦‚ä½•è¿æ¥æ—¶é—´è®¾ç½®çš„æ°¸ä¹…ï¼ˆ-1ï¼‰ï¼Œå®¢æˆ·ç«¯æ–­è¿ä¹‹åï¼ŒæœåŠ¡å™¨è¿˜ä¼šç»§ç»­ç»´æŒsseè¿æ¥ï¼Œéœ€è¦å®šæ—¶ä»»åŠ¡æ£€æŸ¥è¿æ¥çŠ¶æ€ï¼ŒåŠæ—¶ç§»é™¤å·²æ–­å¼€çš„èµ„æºï¼Œå¦åˆ™è¿æ¥æ± ä¼šè¶Šç§¯è¶Šå¤š
- æ²¡å•¥ç‰¹æ®Šçš„åº“ï¼Œæˆ‘æœåŠ¡ç«¯ç”¨çš„nodejsï¼Œsseåœ¨æœåŠ¡å®šä½å™¨æ³¨å†Œå…¨å±€å”¯ä¸€å®ä¾‹ï¼Œå®¢æˆ·ç«¯ç”¨çš„pythonçš„aiohttp_sse_clientï¼Œä»–çš„å®ç°é€»è¾‘ä¹Ÿä¸å¤æ‚ä½ å¯ä»¥çœ‹çœ‹ä»–çš„ä»£ç ï¼Œæ ¸å¿ƒæ€è·¯ä¹Ÿæ˜¯è¿­ä»£å™¨åˆ¤æ–­æµï¼Œsessionç®¡ç†ç”Ÿå‘½å‘¨æœŸï¼Œç½‘ç»œå¼‚å¸¸ç»Ÿä¸€å¾ªç¯é‡è¿ã€‚
  - ç›®å‰å¥½åƒé™¤äº†pythonæœ‰ä¸ªåˆ«äººå°è£…å¥½çš„sseè¿æ¥åº“ï¼Œå…¶ä»–çš„è¯­è¨€éƒ½æ²¡æœ‰ï¼Œé˜¿é‡Œäº‘ä¹Ÿæ˜¯é‡‡ç”¨å¤šçº§åˆ¤æ–­åšçš„è¿æ¥ç®¡ç†
- ä¸ºä»€ä¹ˆæ”¾å¼ƒwebsocketå‘¢ï¼Ÿ
  - ws è¦é¢å¤–é…ç½® Ningx çš„ Upgradeï¼Œè¿™è¿˜å¥½ã€‚å¦å¤–ï¼Œéœ€è¦é¢å¤–çš„åè®®æ”¯æŒåŒ…ï¼Œæ¯”å¦‚ jetty é‡Œè¦ç”¨åˆ° javax.websocket-api, websocket-servlet, javax-websocket-server-impl åŠç›¸å…³ä¾èµ–ç­‰ï¼Œæˆ‘æœ‰ä»£ç æ´ç™–
- è¿˜æœ‰ä¸ªé—®é¢˜æ˜¯ websocket ä¸å¥½è¿‡ CDNã€‚
- 500å¹¶å‘çš„è¯ï¼Œç”¨ä¸Šwebsocketï¼Œå¯èƒ½å°±åªå‰©ä¸‹30å¹¶å‘äº†
- WebSocketåœ¨æµè§ˆå™¨ç«¯çš„å¹¿æ³›å®ç°ä¼¼ä¹åªæ˜¯ä¸€ä¸ªæ—¶é—´é—®é¢˜ï¼Œå€¼å¾—æ³¨æ„çš„æ˜¯æœåŠ¡å™¨ç«¯æ²¡æœ‰æ ‡å‡†çš„APIï¼Œå„ä¸ªå®ç°éƒ½æœ‰è‡ªå·±çš„ä¸€å¥—APIï¼Œå¹¶ä¸”JCPä¹Ÿæ²¡æœ‰ç±»ä¼¼çš„ææ¡ˆï¼Œæ‰€ä»¥ä½¿ç”¨WebSocketå¼€å‘æœåŠ¡å™¨ç«¯æœ‰ä¸€å®šçš„é£é™©ï¼Œå¯èƒ½ä¼šè¢«é”å®šåœ¨æŸä¸ªå¹³å°ä¸Šæˆ–è€…è¢«è¿«é™çº§ã€‚
- websocketä¸httpä¸åŒçš„ä¹‹å¤„åœ¨äºï¼Œhttpå‘çš„è¯·æ±‚æ˜¯åŒæ­¥çš„(tcpåè®®ä¼šç­‰å¾…å“åº”)ï¼Œæµè§ˆå™¨å‘èµ·è¯·æ±‚ä¼šåŒæ­¥ç­‰å¾…æœåŠ¡å™¨è¿”å›ï¼Œè€Œsocketæ˜¯å‘é€å®Œäº†å°±ç»“æŸäº†ï¼Œä¸ç®¡æœåŠ¡å™¨åˆæ²¡è¿”å›ï¼Œè€Œä¸”å…ˆå‘åœ°æ•°æ®ä¸ä¸€å®šå…ˆæ”¶åˆ°ï¼Œä¸æŒ‰é¡ºåºè¿”å›ï¼Œ éš¾ç‚¹å°±åœ¨äºå‘é€æ•°æ®åœ¨ws.sendå‡½æ•°é‡Œï¼Œè€Œæ¥æ”¶æ•°æ®åœ¨ws.onmessageé‡Œï¼Œæ•°æ®ä¸èƒ½äº’é€š
- å¾ˆå¤šå…¬å¸å†…éƒ¨http proxyä¸é…ç½®ä»£ç†websocketï¼Œå¯¹äºtoBä¸šåŠ¡æ˜¯ä¸ªå¾ˆå¤§çš„éšœç¢
- wsæœ‰å¾ˆå¤šç¼ºç‚¹ï¼Œä¼ æ•°æ®ä¸æ˜¯æ ‡å‡†çš„ï¼Œå› ä¸ºä¸æ˜¯æ ‡å‡†çš„ï¼Œä¸­é—´ä»¶çœ‹ä¸åˆ°ä½ åšäº†ä»€ä¹ˆï¼Œwafæ— æ³•æ­£å¸¸æ£€æµ‹ï¼Œcc å…¥ä¾µé˜²ä¸èƒœé˜²
- æ•°æ®å¤„ç†å¤ªéšæ„ï¼Œæ— æ³•å‡†ç¡®è´Ÿè½½å‡è¡¡ï¼Œå¯èƒ½aæœºå™¨ç´¯æ­»äº†bæœºå™¨åœ¨å›´è§‚
- çŠ¶æ€æ¢å¤éœ€è¦æ›´å¤šçš„ç¡®è®¤æªæ–½ï¼Œå¦åˆ™å­˜åœ¨å®‰å…¨é£é™©
# discuss-sse
- ## 

- ## 

- ## 

- ## [How to implement EventSource and SSE in your Frontend and Backend - DEV Community](https://dev.to/lagoni/how-to-implement-eventsource-and-sse-in-your-frontend-and-backend-18co)
- When you send data back to the client, it is important to tell the client what to expect from the response. We do this by separating our response by newlines in our stream of data. 
- Single newline \n: Used to separate different fields within a single event. For example, event type (event:), data (data:), id (id:), and retry (retry:) can be separated by single newlines within an event.
- Double newline \n\n: Used to indicate the end of a single server-sent event. After the server sends a double newline, the client knows that the current event has been fully received and can start processing it. The server can start sending a new event at this point.
- An example of utilizing this could be the payment status given earlier:
  - It will wait until the data stream has been sent since we added the double newline in the response.

```JS
res.write('event: PaymentStatus \n')
res.write('data: JSON.stringify({error: null, data: '
  PaymentCaptured '}) \n\n')
```

- [Understanding Server-Sent Events (SSE) with Node.js ](https://itsfuad.medium.com/understanding-server-sent-events-sse-with-node-js-3e881c533081)
  - The server responds with a `text/event-stream` content type, and data is sent in the following format:
  - Data: Each message can contain multiple data fields, with each field separated by a newline (`\n`). The event must end with two newlines (`\n\n`).

- ## [The line break problem when using Server Sent Events (SSE) _202406](https://medium.com/@thiagosalvatore/the-line-break-problem-when-using-server-sent-events-sse-1159632d09a0)
- imagine our backend needs to stream the literal `\n` . The event would look like this: `"event: eventName\ndata: \n\n\n"` .
  - The question arises: how will the SSE library parse this?
  - According to the documented logic, we would receive the following events: `{"event": "eventName", "data": ""} {"data": ""}` .
  - Hereâ€™s why this happens: `\n` serves as an end-of-line identifier, so the parser treats everything up to the first `\n` as one block (event) and the subsequent `\n` as another block with empty data. When the frontend parses this, it essentially ignores the second event and appends an empty string to the existing text. Consequently, the line break is ignored, potentially disrupting the entire markdown rendering.
- After evaluating various approaches, we found the best solution was to serialize the data as a JSON object rather than as a raw string.
  - This method offers more flexibility in the types of data we can return and prevents issues like the one we encountered.

- ## âš–ï¸ [Newlines in SSE data Â· Issue Â· bigskysoftware/htmx _202402](https://github.com/bigskysoftware/htmx/issues/2292)
- [HTML Standard](https://html.spec.whatwg.org/multipage/server-sent-events.html#parsing-an-event-stream)

- Have a look at html.spec.whatwg.org/multipage/server-sent-events.html. Two newlines are treated as end of event. One newline as end of line. That's the protocol. SSE has no other encoding.

- SSE spec lets you do what you want with `<pre>`. Just append `data:`  to each line

- you could also base64 encode, or in my case, replace `\n` with `<br>`. Not sure what the "right" way is tho.

- ## ğŸ§© [Server-Sent Events (SSE) Are Underrated | Hacker News _202412](https://news.ycombinator.com/item?id=42511318)
- A while ago I created Mercure: an open pub-sub protocol built on top of SSE that is a replacement for WebSockets-based solutions such as Pusher. Mercure is now used by hundreds of apps in production.
  - At the core of Mercure is the hub. It is a standalone component that maintains persistent SSE (HTTP) connections to the clients, and it exposes a very simple HTTP API that server apps and clients can use to publish. POSTed updates are broadcasted to all connected clients using SSE. This makes SSE usable even with technologies not able to maintain persistent connections such as PHP and many serverless providers.
  - Mercure also adds nice features to SSE such as a JWT-based authorization mechanism, the ability to subscribe to several topics using a single connection, events history, automatic state reconciliation in case of network issueâ€¦

- I used a similar solution called Centrifugo for a while. It allows you to choose which transport to use (ws, sse, others)
  - ğŸ‘· I'm the author of Centrifugo. Let me share a bit more about Centrifugo transport choices. 
  - Itâ€™s not just about supporting multiple transports â€” developers can also choose between bidirectional and unidirectional communication models, depending on their needs.
  - For scenarios where stable subscriptions are required without sending data from the client to the server, Centrifugo seamlessly supports unidirectional transports like SSE, HTTP-streaming, unidirectional gRPC streams, and even unidirectional WebSockets (this may sound kinda funny for many I guess). This means integration is possible without relying on client-side SDKs.
  - However, Centrifugo truly shines in its bidirectional communication capabilities. Its primary transport is WebSocket â€“ with JSON or Protobuf protocols, with SSE/HTTP-streaming fallbacks that are also bidirectional â€” an approach reminiscent of SockJS, but with more efficient implementation and no mandatory sticky sessions. Sticky sessions is an optimization in Centrifugo, not a requirement. 
  - It's worth noting that SSE only supports JSON format, since binary is not possible with it. This is where HTTP-streaming in conjuction with ReadableStream browser API can make much more sense!
  - I believe Centrifugo gives developers the flexibility to choose the transport and communication style that best fits their application's needs. And it scales good out of the box to many nodes â€“ with the help of Redis or Nats brokers. Of course this all comes with limitations every abstraction brings.

- SSE/Mercure (as WebSockets) is much battery-efficient than polling (push vs poll, less bandwidth used).
  - on controlled environnements, SSE can use a Â« push proxy Â» to wake up the device only when necessary

- ğŸ› It doesnâ€™t mention the big drawback of SSE as spelled out in the MDN docs: â€œWarning: When not used over HTTP/2, SSE suffers from a limitation to the maximum number of open connections, which can be especially painful when opening multiple tabs, as the limit is per browser and is set to a very low number (6).â€
  - One of my company's APIs uses SSE, and it's been a big support headache for us, because many people are being corporate firewalls that don't do HTTP/2 or HTTP/3, and people often open many tabs at the same time. It's unfortunately not possible to detect client-side whether the limit has been reached.
  - Another drawback of SSE is lack of authorization header support. There are a few polyfills (like this one) that simulate SSE over fetch/XHR, but it would be nice to not need to add the bloat.
- ğŸ’¡ I hate to suggest a solution before testing it myself so apologies in advance but I have a hunch that `BroadcastChannel` API can help you detect browser tab opens on client side. New tabs won't connect to event source and instead listen for localStorage updates that the first loaded tab makes.
  - The problem in this case is how to handle the first tab closing and re-assign which tab then becomes the new "first" tab that connects to the event source but it may be a LOE to solve.
- Rather than Broadcast Channel, you can use the Web Locks API 
  - This handles the leader election pretty seamlessly because all tabs try to become the leader and only one actually can.
  - This library (https://github.com/pubkey/broadcast-channel) from the fantastic RxDB javascript DB library uses WebLocks with a fallback to `BroadcastChannel`. But, WebLocks are supported on 96% of browsers, so probably safe to just use it exclusively now
- This sounds like a good use case for using a service worker. All tabs talk to the service worker and the worker is the single instance that talks to the backend and can use only one connection. Maybe there are some trade offs for using SSE in web workers, I'm not sure.
  - `BroadcastChannel` is a better solution for a couple of reasons. Service Workers are better at intercepting network requests and returning items from a cache, thereâ€™s some amount of additional effort to do work outside of that. 
  - The other thing is theyâ€™re a little more difficult to set up. A broadcast channel can be handled in a couple lines of code, easily debuggable as they run on the main thread, and theyâ€™re more suited to the purpose.
- agreed. Workers was one of my first thoughts but I think BroadcastChannel delivers with much lower LOE
- I disagree. You can just `postMessage` to communicate with the service worker and therefore I imagine the code using broadcast channel to be actually quite similar. About debugging, service workers are easily debuggable, though not on the main thread as you already mentioned.

- caniuse Shared Web Workers 45%
  - caniuse BroadcastChannel 96%
  - the issue with SharedWorkers is that Android Chromium doesn't support it yet

- Supposedly websockets (the protocol) support authorization headers, but often there are no APIs for that in websocket libraries, so people just abuse the subprotocols header in the handshake.
  - I don't think the problem is libraries. Browsers don't support this.

- websockets are great until you have to load balance them. And then you learn why they arenâ€™t so great.

- browser connection limitaions: Does anyone know why it is so low?
  - Historical reasons. The HTTP/1.1 spec actually recommends limited to 2 connections per domain. That said, I'm not sure why it's still so low. I would guess mostly to avoid unintended side effects of changing it.

- Because you're supposed to use a single connection with HTTP Pipelining for all your ressources
  - When index.html loads 4 CSS and 5 JS : 10 ressources in HTTP 1.0 needed 10 connections, with 10 TLS negociations (unless one ressource loaded fast and you could reuse it's released connection)
  - With HTTP1.1 Pipelining you open only one connection, including a single TLS nego, and ask 10 ressources.
  - Why not only 1 per domain so ? IIRC it's because the 1st ressource index.html may take a lot of Time to complete and well race conditions suggest you use another one that the 'main thread' more or less. So basically 2 are sufficient.

- There is little reason to not use HTTP/2 these days unless you are not doing TLS.
  - Corporate proxy servers often downgrade connections to HTTP 1.1 because inertia and lazy vendors.

- nginx can't reverse proxy http/2 or higher, so you end up with very weird functionality, essentially you can't use nginx with SSE.

- For my use cases, the main limitations of SSE are:
  - 1. Text-only, so if you want to do binary you need to do something like base64
  - 2. Browser connection limits for HTTP/1.1, ie you can only have ~6 connections per domain
- Connection limits aren't a problem as long as you use HTTP/2+.
  - Even so, I don't think I would reach for SSE these days. For less latency-sensitive and data-use sensitive applications, I would just use long polling.
- For things that are more performance-sensitive, I would probably use fetch with `ReadableStream` body responses. On the server side I would prefix each message with a 32bit integer (or maybe a variable length int of some sort) that gives the size of the message. This is far more flexible (by allowing binary data), and has less overhead compared to SSE, which requires 7 bytes (`"data:" + "\n\n"`) of overhead for each message.
- `ReadableStream` appears to be SSE without any defined standards for chunk separation. In practice, how is it any different from using SSE? It appears to use the same concept.
  - Presumably,  `ReadableStream` does not auto-reconnect.

- One thing I dislike regards to SSE, which is not its fault but probably a side effect of the perceived simplicity: lots of developers do not actually use proper implementations and instead just parse the data chunks with regex, or something of the sorts! This is bad because SSE, for example, supports comments (`": text"`) in streams, which most of those hand-rolled implementations don't support.
  - For example, my friend used an LLM proxy that sends keepalive/queue data as SSE comments (just for debugging mainly), but it didn't work for Gemini, because someone at Google decided to parse SSE with a regex. if the regex doesn't match the complete line, the library will just throw an error

- https://data-star.dev is a hypermedia-oriented front end library built entirely around the idea of streaming hypermedia responses via SSE.
  - It was developed using Go & NATS as backend technologies, but works with any SSE implementation.

- The part where it says: > SSE works seamlessly with existing HTTP infrastructure.
  - I'd be careful with that assumption. I have tried using SSE through some 3rd party load balancer at my work and it doesn't work that well. Because SSE is long-lived and doesn't normally close immediately, this load balancer will keep collecting and collecting bytes from the server and not forward it until server closes the connection, effectively making SSEs useless.
  - I had to use WebSockets instead to get around this limitation with the load balancer.
- I had a similar issue at one point but if I remember correctly I just had to have my webserver send the header section without closing the connection. Usually things would just get streamed through but for some reason until the full header was sent the proxy didn't forward and didn't acknowledge the connection.
  - Not entirely. If a load balancer is set to buffer say 4kb of data all the time, your SSE is stuck until you close the connection.
  - I think there is a HTTP/2 flush instruction, but no load balancer is obligated to handle it and your SSE library might not be flushing anyway.

- OpenAI's own documentation makes note of how difficult it is to work with SSE and to just use their library instead. My team wrote our own parser for these streaming events from an OpenAI compatible LLM server. The streaming format is awful. The double newline block separator also shows up in a bunch of our text, making parsing a nightmare. The "data:" signifier is slightly better, but when working with scientific software, it still occurs too often. Instead we've had to rely on the totally-not-reliable fact that the server returns each as a separate packet and the receiving end can be set up to return each packet in the stream.
  - The suggestions I've found online for how to deal with the newline issue are to fold together consecutive newlines, but this loses formatting of some documents and otherwise means there is no way to transmit data verbatim. That might be fine for HTML or other text formats where newlines are pretty much optional, but it sucks for other data types.
  - I'm happy to have something like SSE but the protocol needs more time to cook.
- SSE has been part of the WHATWG standard for almost 20 years. Every protocol requires some sort of data encoding. 
  - For SSE you need to either restrict yourself to payloads that can never conflict with the message structure (e.g. an enumeration of short strings to indicate different sorts of events), or you need to encode the data.
  - It sounds like you are trying to send raw, unencoded data and are surprised that it sometimes conflicts with the message structure. Well of course it does! You canâ€™t blame the protocol for that.
- Every other protocol I've used has a standard way to encode arbitrary data, but especially text data, usually using some kind of escape sequence. SSE does not. Just because it has been around for a long time does not mean it is well thought out or complete.

- > SSE works seamlessly with existing HTTP infrastructure
  - This is false. SSE is not supported on many proxies, and isn't even supported on some common local proxy tooling.

- SSE is not underrated. In fact it's being used by Open AI for streaming completions. It's just not always needed unlike the very obvious use cases for normal REST APIs and Websockets.

- Iâ€™ve never understood the use of SSE over ndjson.
  - Manually streaming a XHR and parsing the messages is significantly more work, and you lose the built-in browser API. But if you use a fetch ReadableStream with TLV messages I'm sold.

- Does anyone have a good trick for figuring out when the client side connection is closed? I just kill the connection on the server every N minutes and force the client to reconnect, but it's not exactly graceful.
  - The socket closes. Most languages bubble this back up to you with a connection closed exception. In python async world, it would be a cancelled error.

- I'm curious as to how everyone deals with HTTP/2 requirements between the backend servers and the load balancer? By default, HTTP/2 requires TLS which means either no SSL termination at the load balancer or a SSL cert generated per server with a different one for the front end load balancer. This all seems very inefficient.
  - You don't need http2 on the actual backend. All limitations for SSE/http1 are browser level. Just downgrade to http1 from the LB to backend, even without SSL. As long as LB to browser is http2 you should be fine.

- http streaming is even more underrated.

- ### [Server-sent events, WebSockets, and HTTP | Hacker News _202202](https://news.ycombinator.com/item?id=30403438)
- I've used the Broadcast channel API in conjunction with SSE to have only one tab handle the SSE connection, and broadcast incoming SSEs to the other tabs which also reduces the number of connections to the server to one.
  - On the server it's also a PITA because not all instances/pods have the subscribers list. The way I've found to solve this is with clustering the instances with Hazelcast or Redis or a MQ.
- Also, when using an nginx reverse proxy, including `X-Accel-Buffering: no` in the HTTP header of the server response may be required to keep events from being buffered.

- These are all potential issues with plain sse, but are pretty easily solved in a few lines of code.
  - Granted the benefits of sse: no additional port to open, no dependencies - just slip your logic into your routing at /events. Of course this may not be important for some. Websockets are a good choice as well. I tend to id clients on ip address not connections however, depends on the specific app.

- The best way to do pub/sub on the web with a standard protocol is MQTT
  - Strong disagree. MQTT has no place in a world with WebSockets. MQTT knowledge is so esoteric in comparison. Maybe it's the Haskell of transport protocols: really friggin smart, but not if you're trying to be useful to society at large.
- MQTT is neither "esoteric" or "not useful to society at large" nor is WebSockets vs MQTT even a useful contrast, since WebSockets to a large degree addresses a different level of the stack (and indeed "MQTT over WebSockets" is a common way of deploying it).

- Can Web Push Notifications not also be considered as an alternative?
  - Technically it would fit nicely. Unfortunately, it requires the user to explicitly give permissions to show notifications to the website, even if you don't show any notifications. This is a blocker for its usage in many cases.

- ## [http - Stop server-sent events by server - Stack Overflow](https://stackoverflow.com/questions/36669100/stop-server-sent-events-by-server)
- The server-sent events is yet another streaming technique which is one of ways of Comet. To stop streaming data, just close the connection in server. 

- According to html5doctor.com/server-sent-events/#properties) "if the connection drops, the EventSource fires an `error` event and automatically tries to `reconnect`. The server can also control the timeout before the client tries to reconnect."

- ## [How do I close a Server-Send Events connection in Flask? - Stack Overflow](https://stackoverflow.com/questions/11597367/how-do-i-close-a-server-send-events-connection-in-flask)
- It seems the author of Flask does not have a plan to support that yet. For "Server-Sent Events", it is better to use an event-driven architecture like NodeJS.

- It is important to note you need to close the connection on the client as well, otherwise it will try and reopen the connection after a `retry` timeout.
  - my preferred solution was to close the connection from the server by yielding an expected data message.
  - flask: `yield "data: finished\n\n"`

- ## [How to close a "Server-Sent Events"-connection on the server? - Stack Overflow](https://stackoverflow.com/questions/6534572/how-to-close-a-server-sent-events-connection-on-the-server)
- By default, if the connection between the client and server closes, the connection is restarted. 
  - The connection is terminated with the `.close()` method: `evtSource.close()` ; 

- According to the specification:
  - Clients will reconnect if the connection is closed; it is possible to tell a client to stop reconnecting using HTTP response code `204` No Content.

- your client has to close the connection. That leaves two options. The first, is to simply assume any error from the server should close the EventSource.
  - We are assuming that a network error is a graceful shutdown, this may not be the case. There may also be some scenarios where we do want the reconnect behavior.
  - So instead, why don't we just ask the client to gracefully shutdown itself! We have a way to send messages to the client from the server, so all we need to do is send a message from the server that says "shut me down".

```JS
const sse = new EventSource('/events')
sse.onmessage = m => console.log(m.data)
sse.onerror = () => sse.close()
```

- Caution: If you use a package to manage server-sent events in node.js, making a direct call to `response.end()` may cause the package to send additional data after `response.end()`, and this will crash the server with a "WRITE after close" error.
  - Instead of directly calling `response.end()`, my workaround was to call `response.emit('close')`, which allowed the package to handle the close.

- [Node. JS Server Sent Events: Route continues to run after res.end() resulting in ERR_STREAM_WRITE_AFTER_END error - Stack Overflow](https://stackoverflow.com/questions/59797523/node-js-server-sent-events-route-continues-to-run-after-res-end-resulting-in/59798626?noredirect=1#comment105739184_59798626)
  - This seems like the right way to do it. It's a good use of an `eventEmitter` because your routes are not coupled to the actual data source at all, just listening for an event and you can change the data source implementation at any time without having to change the routes at all.

- ## [Comparison of data before and after using Streamable HTTP | by Higress_ai | Medium _202504](https://medium.com/@higress_ai/comparison-of-data-before-and-after-using-streamable-http-b094db8b414e)
- Recently, the MCP repositoryâ€™s PR #206 introduced a brand new Streamable HTTP transport layer to replace the original HTTP+SSE transport layer. 
- The two protocols are simply compared as follows:
  - HTTP+SSE: The client sends requests via HTTP POST, and the server pushes responses through a separate SSE (Server-Sent Events) endpoint, requiring the maintenance of two separate connections.
  - Streamable HTTP: It uses a single HTTP endpoint to handle requests and responses uniformly, allowing the server to choose between returning standard HTTP responses or enabling SSE streaming as needed.
- Streamable HTTP offers better stability compared to HTTP + SSE, performing better under high concurrency scenarios.
  - In terms of performance, Streamable HTTP has clear advantages over HTTP + SSE, with shorter and more stable response times.
  - The client implementation of Streamable HTTP is simpler than HTTP + SSE, requiring less code and lower maintenance costs.
- Problems with HTTP + SSE
  - The server must maintain long connections, which can lead to significant resource consumption under high concurrency.
  - Server messages can only be transmitted via SSE, which creates unnecessary complexity and overhead.
  - Infrastructure compatibility: Many existing network infrastructures may not correctly handle long-term SSE connections. Enterprise firewalls may forcefully terminate timed-out connections, making the service unreliable.
- Improvements in Streamable HTTP
  - Streamable HTTP removes the dedicated /sse endpoint for establishing connections, integrating all communication into a single endpoint
  - The server can flexibly choose to return standard HTTP responses or stream them via SSE based on the type and content of the request
  - Powerful Session Management: Supports the Last-Event-ID mechanism to ensure that messages not received after a disconnection can be recovered.
- ## ğŸ†š [SSE vs. Streamable HTTP - which will be the standard for remote servers? : r/mcp _202505](https://www.reddit.com/r/mcp/comments/1kdyse2/sse_vs_streamable_http_which_will_be_the_standard/)
- SSE is effectively legacy now and is basically unworkable for truly distributed MCP anyway. The new world (when the SDKs catch up) will be Streamable HTTP. Of course, how many of the 8000 odd servers that already exist will be updated is debatable.
- Sse is not the problem. The Problem is the stateful connection mcp mandates.
  - The new approach still uses `text/event-stream` , but stateless.
- Exactly. SSE was never the problem. People are complaining about SSE servers being stateful.
  - SSE (i.e. stateful) servers are not going anywhere. There is space for streamable servers, but I don't see them as comparable or functionally equivalent to SSE servers.
- Why did MCP go SSE and then http streaming instead of just starting with something like websockets
  - "We ultimately decided not to pursue WS right now because:
  - Wanting to use MCP in an "RPC-like" way (e.g., a stateless MCP server that just exposes basic tools) would incur a lot of unnecessary operational and network overhead if a WebSocket is required for each call.
  - From a browser, there is no way to attach headers (like Authorization), and unlike SSE, third-party libraries cannot reimplement WebSocket from scratch in the browser.
  - Only GET requests can be transparently upgraded to WebSocket (other HTTP methods are not supported for upgrading), meaning that some kind of two-step upgrade process would be required on a POST endpoint, introducing complexity and latency."
- ## ğŸŒ° did you know that there is another technologie, simpler, native and that use HTTP you can use to do real-time?
- https://twitter.com/soubiran_/status/1773634287918608804
- SSE is great. A lot of apps just don't need bi-directional communication that WS provide.
  - However, currently browsers limits a website to have a maximum of 6 SSE streams. So if someone opens a 7th tab, the SSE connection will fail.
- Do technologies like Firebase auth use SSE to observe auth changes on the client? Any idea?
  - ğŸŒ° i recommend @supabase realtime event subscription instead, easier to implement, especially when deploying on Serverless platform (where SSE is crippled).
- what is the server load for SSEs? If the HTTP connection stays always open, that means that the server needs to more resources?
  - Yes and that's exactly the same for WebSocket. Once the client disconnect, the connection ends.
- ## æœ‰åœ¨å®é™…é¡¹ç›®ä¸­ç”¨è¿‡ SSE(Server Sent Events) çš„å—ã€‚æœ‰å•¥å‘æ²¡
- https://twitter.com/_a_wing/status/1739901379953787028
- iOS ä¸æ”¯æŒ
  - å’Œä½ çš„æƒ³æ³•ä¸€æ ·ï¼Œä½†æœ€åiOSè¿˜æ˜¯ç”¨äº†web sockets
- åŸç”Ÿ event source æ²¡æ³•ç”¨ï¼Œæ¯”å¦‚ ä¸èƒ½å¸¦ headers ã€æµè§ˆå™¨ä¸Šåªæ”¯æŒ GETï¼Œæ‰¾ä¸ªç¬¬ä¸‰æ–¹çš„å°±è¡Œ
- æ‰‹æœºä¸Šæµè§ˆå™¨åˆ‡åå°ç§’æ–­
- æ—©çŸ¥é“ï¼Œè¿˜æ˜¯è½®è¯¢
- å…¶å®ä½ ç”¨ fetch+ReadableStream æŒç»­æ‹‰ä¸€è·¯ http ä¹Ÿæ˜¯ä¸€æ ·çš„æ•ˆæœã€‚ 2015å¹´åº•ç”¨åˆ°ç°åœ¨äº†ï¼Œç°åœ¨è¿Safariå’ŒFireFoxéƒ½æœ‰
  - ReadableStream æ¯•ç«Ÿæ˜¯æ–°å‡ºæ¥çš„ä¸œè¥¿ã€‚
- SSE æ–­çº¿äº†çš„å¯ä»¥è‡ªåŠ¨é‡è¿ï¼Œå¯ä»¥æ¥ç€æ¥ç€ä¹‹å‰æ®µçš„åœ°æ–¹ç»­ä¼ ã€‚å½“ç„¶ fetch + ReadableStream ä¹Ÿå¯ä»¥è‡ªå·±å®ç°è¿™ä¸€å¥—æœºåˆ¶å°±æ˜¯äº†ã€‚
- å‰ç«¯è°ƒåŒ…ï¼Œç›¸æ¯” ws å°‘å†™ä¸€ç‚¹ä»£ç ï¼Œï¼Œåç«¯å¦‚æœè¦åšåˆ†å¸ƒå¼ï¼Œè·¯ç”±ä¼šæ¯”è¾ƒéº»çƒ¦ï¼Œ
  - å’Œ ws ä¸€æ ·åç«¯éƒ½å¸¦çŠ¶æ€ï¼Œéœ€è¦æœ‰ user session å’Œ node è·¯ç”±æœºåˆ¶ï¼Œç”¨ redis channel å»å®ç°æ¯”è¾ƒç®€å•ã€‚
- æ²¡å•¥å‘ï¼Œå¦‚æœæ˜¯å‰é¢æœ‰ä¸ªnginxï¼Œéœ€è¦æ³¨æ„ä¸‹æœ‰è®¾ç½®ä¸€ä¸ªheaderï¼Œå…·ä½“è®°ä¸æ¸…äº†ã€‚ä¸ç„¶å‰ç«¯æ”¶ä¸åˆ°ã€‚
- å”¯ä¸€ä¸€å‘ï¼Œå¦‚æœå‘ç°ä¼¼ä¹è¢« buffer/cache ä½äº†ä¸€æ‰¹å€¼ï¼Œæ£€æŸ¥ä¸€è·¯ä¸Šçš„æ‰€æœ‰åä»£ï¼ˆåŒ…æ‹¬ cloudflareï¼Œå¦‚æœç”¨äº†çš„è¯ï¼‰çš„é…ç½®
- æœ‰ä¸€ä¸ªå‘ï¼Œ ï¼Œæœ‰ç½‘å…³çš„æƒ…å†µä¸‹è®°å¾—çœ‹çœ‹ç½‘å…³é…ç½®æ˜¯å¦å¼€å¯äº†å¯¹ SSE çš„æ”¯æŒï¼Œä¸ç„¶åˆå¾—æ’æŸ¥åŠå¤©
- uber æœ‰ä¸€ç¯‡ä»‹ç»ä»–ä»¬åœ¨åå°ä½¿ç”¨sseçš„åšå®¢ï¼Œè¿˜æœ‰å…·ä½“çš„ä»£ç ï¼Œå¯ä»¥å‚è€ƒä¸€ä¸‹
- ## æŠ€æœ¯å•Šï¼Œè¿˜æ˜¯è¦çœ‹å¤©æ—¶ã€‚SSEå¾ˆæ—©å°±å‡ºæ¥äº†ï¼ŒåŸºæœ¬æ²¡äººç”¨ã€‚
- https://twitter.com/NalaGinrut/status/1673676930036514816
  - 2015å¹´é‚£ä¼šå„¿æˆ‘è¯´åœ¨æ¡†æ¶é‡Œå®ç°ä¸€ä¸‹ï¼Œç»“æœä¸€å¸®å¹´è½»äººéƒ½è¯´ç°åœ¨æ˜¯websocketçš„å¹´å¤´ï¼Œäºæ˜¯å°±å®ç°äº†websocketï¼Œè€ŒæŠŠSSEæ”¾åˆ°äº†todoé‡Œã€‚
  - è¿™ä¹ˆå¤šå¹´è¿‡å»äº†SSEåˆå€Ÿç€chatgpt steamæ­»ç°å¤ç‡ƒäº†
- æ˜¯å•Šï¼Œç°åœ¨èƒ½æˆä¸º ChatGPT/LLM ç­‰çš„åŸºç¡€æŠ€æœ¯æˆ–è½¯ä»¶éƒ½ä¼šå†èµ·é£
- è¿˜æ˜¯æœ‰ä¸å°‘å…¬å¸ä¸šåŠ¡åœ¨ç”¨ SSE çš„ï¼Œç”µå•† feeds, sku å¤šçš„åœºæ™¯éƒ½æŒºé€‚åˆçš„

# discuss-ssh/tunnel
- ## 
- ## 
- ## 
- ## [What os difference websocket vs ssh-tunnel? - Stack Overflow](https://stackoverflow.com/questions/55685980/what-os-difference-websocket-vs-ssh-tunnel)
- WebSocket is a protocol designed for 2-way real-time communication between browsers and servers to replace hacky solutions like long polling and XHR streaming.
- SSH is a protocol designed for operating network services securely over an insecure network. 
  - Usually it's used for remote logins, file transfers, however it can be used for any protocol, however a few modifications need to be made.
- The difference between them is, well, WebSocket is designed to be used for the browser and has support there. 
  - However, SSH is a more general protocol and can be used for more however it is not supported by browsers directly, but through proxies which bridge WebSocket to SSH.
- ## [what is more secure -- Data transfer using socket programming OR SSH/SCP/FTP - Stack Overflow](https://stackoverflow.com/questions/2642808/what-is-more-secure-data-transfer-using-socket-programming-or-ssh-scp-ftp)
- Just using sockets doesn't give you any security at all. The right choice depends on the application, the systems you're using
- SSH/SFTP/SCP all makes use of sockets under socket programming. Unless you have a better algorithm (for security) than what SSH provides, use a SSH module for Perl.
- Out of the box sockets aren't secure. The data is transmitted in raw form from point A to point B. 
  - Adding SSL adds security. Many protocols support SSL. In particular several flavors of FTP and HTTP support SSL.
- If I were to start from scratch on such a system I would use FTPS.
- SSH is a remote shell protocol and itself it is not used for file transfer (like FTP). 
- SCP file transfer protocol was part of SSH1 but as SSH1 is outdated and flawed, SCP is not recommended for use. 
  - In SSH2 (used in all modern systems) SFTP (SSH File Transfer Protocol) is used.
- FTP (RFC 959) by itself doesn't provide any security. There exist extensions that let you run FTP over SSL/TLS (either implicitly, over pre-encrypted channel, or explicitly, via TLS as a part of FTP protocol). FTP over SSL is called FTPS (don't mix it with SFTP).
- FTPS (FTP over SSL/TLS) - it's equivalent of HTTPS which in simple terms means it's encrypted version of the ordinary FTP protocol. 
  - I think it's great for downloading over the Internet from remote and possibly public machines. It offers superior authentication mechanism in the form of X.509 certificates. 
  - There is some trouble with firewalls because it uses, as FTP does, two connections. 
  - If your goal is to prevent anyone from seeing what you're downloading this is IMHO perfect solution. I tend to use this protocol to access machines that I don't control.
- SFTP (SSH FTP) - it's good protocol, maybe bit superior to the FTPS, but in my opinion it's better suited for controlled environment. 
  - I will use this protocol when I want to download a file from my account on one machine to another. Or when I want to upload new script to a server. 
  - It's for me remote equivalent of me going to the machine with flash drive and logging on the machine.
- VPN - if those machines are fixed so to speak - you are always connecting to the same machines - I would consider using VPN to deliver the security. 
  - The transmissions are protected from outsiders, the server behaves like it's in the same network and I can use any protocol I want.

# discuss
- ## 
- ## 
- ## 
- ## TIL (and painful reminder): You need to close WebSocket connections with a code for a Node process/thread to properly exit.
- https://x.com/schickling/status/1869081922846220583
- MDN claims it to be automatically set to 1000?
- Every TinyBase documentation snippet doubles up as a unit test. This is why they all include cleanup!
- nodejs - not even once.
- ## Iâ€™m increasingly thinking that every client-server connection should be default realtime using websockets, unless you have a very good reason for not doing that.
- https://x.com/jamonholmgren/status/1852568079223681525
  - And most server-server connections too.
  - and SSE is a great way to scale up if you really mainly need one-way realtime (which is common).
- Avoid web protocols entirely. Especially within a backend where you have full control over whatâ€™s being used. Real-time is good but Websockets are not that. Build on top of UDP.
  - Why not? Zoom and Slack both offer WebSocket APIs, and you can get events streamed in that way.
- the request / response model is simple, effective and not only scales very well but has decades of infrastructure built explicitly to support it. unless youâ€™re explicitly building a realtime web app (chat, multiplayer) itâ€™s overkill & you will likely get it wrong
- Keeping connections alive with WebSockets can drive up CPU usage and hit connection limits fast, often needing a lot of tweaking at the kernel level to manage. Iâ€™d stick to using WebSockets mainly for event-driven apps where real-time updates are key.
  - Thatâ€™s why Elixir/Phoenix is amazing. Millions on a single server, and easy horizontal scaling
- That mentality is a good way to make your app buggy or completely unusable during network issues.
- donâ€™t think most apps need it. Optimistic updating client-side keeps state snappy on front end and in sync with server. Itâ€™s a nice middle ground 
- The websocket overhead is greater than a tcp+tls handshake (on a healthy network) If using http3 you can have 0-RTT for itempodent reqs which basically makes connecting again free (+ UDP benefits on unhealthy networks if some packets get lost)
- This makes caching (of all sorts: BF, CDNs, basic HTTP caching) more difficult, SEO more difficult, debugging more annoying, scaling is horrific (when are connections terminated? How many can a server handle?)
- Request/response over http3 is more than adequate.  Why on earth do you need more than that for simple data hydration?
- Websockets have tons of issues, esp around public internet connections that might block them.
- ## ğŸ¤” how are you doing websockets? assume you have multiple application servers running and broadcasts need to work to clients across all
- https://x.com/thdxr/status/1851038633014198392
- DB backed events, polling works in most cases.. you can make a simple observable event type abstraction. it depends. Iâ€™ve never done anything too resource intensive.
- I wrote https://npmjs.com/package/mqemitter before @nodejs had promises, and I never had to reach for something else. Use the Redis/Valkey pubsub adapter.
  - Works well up to several hundred thousands messages per second (depends on the size of message).
- In the past I reached for ZMQ. I keep hearing good things about NATs from GoLang devs.  A lot of times it's Redis TBH. (Or any of the MQ services)
- Use go, Nats or Centrifuge
- we use just a simple socketio like ws wrapper on our api instance, all behind a load balancer on AWS
  - use a few different ways of throwing info from one side of our stack to another, but mainly designed around http://NATS.io, basically a pub-sub model, each user gets an ephemeral channel
  - we ingest data from webhooks often from multiple third party services, so getting it from say, instance A, over to instance B where a client is connected (and even multiple instances) works nicely via this method
- ## ä½œä¸º RTC çš„ä»ä¸šè€…è¯´ä¸€ä¸‹ OpenAI åœ¨å‘å¸ƒrealtime api çš„æ—¶å€™ä¸ºå•¥ä¼šæ‹‰ä¸Š livekit ä»¥åŠ agoraï¼š
- https://x.com/leeoxiang/status/1841737253024137687
  1ã€RTC çš„æ¥å…¥æˆæœ¬è¿œæ¯”http è¦é«˜å¾ˆå¤šå€ï¼Œç®€å•çš„åœºæ™¯æŒ‰ç…§è¦æŒ‰ç…§å‘¨ç®—ï¼Œå¤æ‚çš„åœºæ™¯è¦æŒ‰ç…§æœˆç®—ã€‚
  2ã€RealtimeAI  30 å¤šä¸ªä¿¡ä»¤ï¼Œæ¶‰åŠåˆ°é•¿è¿æ¥çš„é‡è¿ï¼Œå¤æ‚çŠ¶æ€å¤„ç†ï¼ŒæŠ€æœ¯ä¸å¥½çš„å¼€å‘è€…å·²ç»å¾ˆéš¾ hold ä½äº†ã€‚
  3ã€é™¤äº†åè®®ä¹‹å¤–ï¼ŒéŸ³é¢‘çš„å‰åå¤„ç†ï¼ˆé™å™ªã€äººå£°åˆ†å‰²ç­‰ç­‰ï¼‰ä»¥åŠå„ç§ç¡¬ä»¶è®¾å¤‡çš„é€‚é…ä¹Ÿéœ€è¦éå¸¸ä¸“ä¸šçš„å›¢é˜Ÿæ¥å¤„ç†ã€‚
  - è¿™å…¶ä¸­å¤§é‡çš„æ¥å…¥å·¥ä½œopenai æœ¬èº«æ˜¯æ”¯æŒä¸äº†çš„ï¼Œä¹Ÿä¸æ˜¯ openai æ“…é•¿çš„ã€‚
- rtcæ˜¯éå¸¸æˆç†Ÿçš„é€šä¿¡è§£å†³æ–¹æ¡ˆäº†ï¼Œ4å¹´å‰å°±å¾ˆæˆç†Ÿäº†ï¼Œç–«æƒ…æœŸé—´rtcå€Ÿç€è§†é¢‘ä¼šè®®åˆç«äº†ä¸€æ³¢ï¼Œopenaiæ²¡å¿…è¦è‡ªå·±å»ºè®¾rtcç½‘ç»œï¼Œè¿™æ–¹é¢å…¶å®ƒrtcä¾›åº”å•†æ—©åšå¥½äº†ã€‚
- ## Web trivia: Chrome has its own IPC protocol called Mojo that's also used in part by Firefox and is similar in design to how MessageChannels work in JS user land, which are implemented on top of it.
- https://x.com/qwtel/status/1813126057073254690
- ## [Where to hold my socket in my redux store? - Stack Overflow](https://stackoverflow.com/questions/65940957/where-to-hold-my-socket-in-my-redux-store)
- Websockets should typically go in a Redux middleware, where they have access to dispatch and getState
- ## [Socket.io-client on recieving event running useEffect two times - Stack Overflow](https://stackoverflow.com/questions/75250544/socket-io-client-on-recieving-event-running-useeffect-two-times)
- the problem is that you are removing the wrong listener--you have to pass the exact same function that you want to remove (because you can have two listeners on an event). 
- ## ğŸ«§ [address horizontal scalability in documentation Â· Issue Â· ueberdosis/hocuspocus _202304](https://github.com/ueberdosis/hocuspocus/issues/575)
- It's not clear to me the guarantees hocuspocus tries to achieve around horizontal scaling. #178 and #279 both talk about horizontal scaling, but I'm hoping for something explicit in the code that yes, hocuspocus supports multiple instances behind a load balancer, if all features (eg stateless messaging) are expected to work, etc. I think the answer is yes, but I'd love more explicit confirmation somewhere!
- [Redis Scaling  Â· ueberdosis/hocuspocus](https://github.com/ueberdosis/hocuspocus/issues/178)
- ## [Web Sockets are not efficient and hard to scale, change my view. : r/reactjs _202312](https://www.reddit.com/r/reactjs/comments/18ogc0o/web_sockets_are_not_efficient_and_hard_to_scale/)
- Socket.io internally uses ws library as one of their transport options. socket.io provides a lot of options like retries, polling, disconnection detection, multiplexing, retry options etc etc lot of configurations which you may need in real applications sooner or later . You can also check by providing ws as first option as socket.io transports . Better check socket.io performance tuning guide.
- I saw it mentioned in another comment, but definitely look into Server-Sent Events (SSE) using something like Event Source.
- We use websocket for chats and notifications and we can dynamically scale up and down because backend is containerized and we are storing the socket sessionâ€™s on redis
  - Socket.io has documentation on how to scale the app you can follow that. Or just store the socket session when client join the app thats it
- Web sockets just use TCP. It's pretty lightweight, you can have a metric shit-ton of active TCP connections with no issues.
- ## [The WebSocket Handbook | Hacker News _202201](https://news.ycombinator.com/item?id=29893242)
- We use WebSockets in two regards: handling live page updates via Phoenix Live View for users (eg: real time chat messages, viewer count, etc) and as a transport medium for our real time API. The former is very easy to handle because for the most part users are navigating around pages which can terminate the ws connection and creates a new one (though most of the times not). The advantages Live View provides us is not having to write duplicated logic in the client & server, and instead just push data to users and their browser automatically reflects the changes.
- ## [Proper way of using React hooks + WebSockets - Stack Overflow](https://stackoverflow.com/questions/60152922/proper-way-of-using-react-hooks-websockets)
- As you are only setting the web socket once, I think a better approach is to use a ref instead of a state
- What is the right way to handle authentication over web sockets?
  - As with REST APIs, you'd want to be able to authenticate to a websocket-based API using either basic auth, or a bearer token-based auth scheme. Unfortunately, the browser websocket API doesn't allow you to specify arbitrary headers in the websocket request, so it's typical instead to have credentials supplied via a query param (such as "accessToken" for a bearer token) in the wss request.
- It's the same thing as HTTP. Websocket starts off as an HTTP request with cookies, headers etc. Use those just like HTTP to authenticate, and your Websocket server should pass the user data to the websocket object
- Best solution might be to generate a short-lived one-time-use ticket and pass it in the querystring.
- HTTP servers have already solved traffic management, load balancing, scaling up and down, zero downtime deployments, A/B tests and experimentation and lots more to such a degree that we don't have to even think about them anymore. All of these problems come to the forefront again when you have to scale websocket connections beyond a single server.
  - There's a (relatively) easy trick for this: Redis pubsub. When a message comes into an instance, you push it to Redis and have all of your other instances subscribed to it. Messages sync in real-time and the experience is transparent.
- To be a bit clearer, you don't want to push websocket messages per se; eg auth negotiation or info requests. You do want to pubsub out conditioned messages that are generated by any given instance for the purpose of broadcast; eg "userX connected" or "userX said Y".
- If you want something simpler for real-time communication you can use comet-stream. It goes through all firewalls and scales better than most single threaded websocket servers: https://github.com/tinspin/rupy/wiki/Comet-Stream
- 
- 
- ## [Ask HN: WebSocket data architecture strategies: idempodent vs. incremental data? | Hacker News _202104](https://news.ycombinator.com/item?id=26963959)
- I think you could find some inspiration in cryptocurrency exchanges. Most of them expose public websockets for prices, order books, trades, etc. They're high volume with lots of subscribers.
- If I understand the question: you donâ€™t have to choose between idempotence and efficient incremental updates if you can give your application data a revision number. Send your incremental update(delta) with a reference to the app dataâ€™s last revision. Increment the revision number after applying each delta and reject any delta that doesnâ€™t reference the current version on the server, theyâ€™ll only be applied at most once, so theyâ€™re idempotent. There are fancier versions of this scheme that can be devised based on the business rules for your application.
- ## [Ask HN: How do you scale WebSocket? | Hacker News _202206](https://news.ycombinator.com/item?id=31925145)
- Socket.io has a great article on how you can setup your architecture to scale Web Socket servers: https://socket.io/docs/v4/using-multiple-nodes/
- it sounds like the immediate question is how do you route an external event (webhook) to the right websocket.
  - You need to include information that comes back in the event that identifies the websocket, either directly (server id + an id the server would understand) or indirectly (something that you can look up in a table/hash to get direct information).
- 
- 
- ## ğŸ’¥ [Millions of active WebSockets with Node.js | Hacker News _202302](https://news.ycombinator.com/item?id=34876935)
- > The theoretical limit is 65k connections per IP address but the actual limit is often more like 20k, so we use multiple addresses to connect 20k to each (50 * 20k = 1 mil).
  - The 65k limit is because of the port limit. WebSocket is using the â€œtrickâ€ of opening a port without answering before the server have any news to give, this way the messages are more push-like.
- We did this with Node.js and uWebSockets and it scaled easily to a few million web sockets on ~10 machines so I can confirm the stack works in practice
- ## [Show HN: DriftDB â€“ an open source WebSocket backend for real-time apps | Hacker News _202302](https://news.ycombinator.com/item?id=34639728)
- have you come across NATS? https://nats.io. The server natively supports WebSockets. There are many clients including Deno, Node, WebSockets, Rust, Go, C, Python, etc. In addition to stateless messaging, it supports durable streams, and optimized API layers on top like key-value, and object storage. The server also natively supports MQTT 3.1.1.
  - Nats is not something I see as a competitor for external clients (browsers, mobile apps), primarily because it doesn't handle reconnections / message delivery / quality-of-service / at-least-once or exactly-once delivery (except for MQTT).
  - Therefore, I don't see what it adds here. It seems designed for service communication, not client-server. They also don't list browsers as a use case https://docs.nats.io/nats-concepts/overview#use-cases. (though it is of course possible, it's just not ideal IMHO.)
- Even with NATS jetstream, NATS has a focus on service communication.
- what's the relationship between driftdb and plane? Can they be used together? Does one depend on another?
  - The idea for DriftDB came from seeing people try to use Plane for things that it wasnâ€™t intended for (e.g. simple WebSocket backends). DriftDB doesnâ€™t depend on Plane if itâ€™s hosted on Cloudflare. For deploying on your own infrastructure, Plane could be useful, but there are a few pieces missing to do the integration.
- ğŸ”€ This is really cool! But how are conflicts handled?
  - As far as the server itself is concerned, itâ€™s just a broadcast channel with replay and compaction capabilities, so itâ€™s not directly concerned with conflict resolution. You could use it as a broadcast channel for CRDTs if you wanted to.
  - The useSharedState react hook is more opinionated, it uses last-write-wins semantics in the case of a conflict. The useSharedReducer hookâ€™s behavior on conflict is up to the reducer provided.
- ## [Woe be unto you for using a WebSocket | Hacker News _202112](https://news.ycombinator.com/item?id=29651447)
- I think this conflates a very specific paradigm for using WebSockets (state synchronization with a stateful "server") with WebSockets as a technology.
  - WebSockets are just, well, sockets, with a goofy HTTP "upgrade" handshake and some framing on top of them. You could implement the exact same request/response model as in an HTTP based service over a WebSocket if you wanted to.
  - Stateful services are a tradeoff whether you use a WebSocket or not.
- Websockets work great for message passing but it struggles with data structures more complicated than what JSON can represent. Jsynchronous syncs any javascript object or array with arbitrarily deep nesting and full support for circular data structures.
- I am the author of Centrifugo server (https://github.com/centrifugal/centrifugo) - where the main protocol is WebSocket. Agree with many points in post â€“ and if there is a chance to build sth without replacing stateless HTTP to persistent WebSocket (or EventSource, HTTP-streaming, raw TCP etc) â€“ then definitely better to go without persistent connections.
- ğŸ’¡ My advice:
  â€¢ Make push updates optional. If no push connection can be established, fall back to polling. You can start by implementing polling only and add push later.
  â€¢ Use websockets only for server-to-client communication. Messages from the client are sent via regular HTTP requests.
  â€¢ Keep no meaningful state on the server. That includes TCP connection state. You should be able to kill all your ec2 instances and re-spawn them without interrupting service.
  â€¢ Use request/response for all logic on the server. All your code should be able to run in an AWS lambda.
  â€¢ Use a channel/subscription paradigm so client can connect to streams they're interested in
  â€¢ Instead of rolling your own websocket server, use a hosted service like pusher.com or ably.com. They do all the heavy lifting for you (like keeping thousands of TCP connections open) and provide a request/response style interface for your server to send messages to connected clients
- I work at MSFT and on the fluid framework.
  - We use websockets and solve a lot of the state management problem called out here by keeping very little state on the server itself. The primary thing on server is a monotonically increasing integer we use to stamp messages, this gives us total order broadcast which we then build upon
  - The main server logic is in the Alfred and Deli lambdas. Alfred sits on the socket and dumps message into Kafka. Deli sits on the Kafka queue, stamps messages, the puts them on another queue for Alfredâ€™s to broadcast
- come to phoenix/elixir land. Channels are amazing and the new views system allows you to seamlessly sync state to a frontend using websockets with almost no javascript
- Worth looking at Elixir Phoenix Channels if youâ€™re wanting to use sockets. Handle a lot of the messy stuff for you.
- The answer is simple: Abstraction, or the lack thereof. Building real-time web applications are difficult. But the difficulty is accidental complexity that could be abstracted away. However, most of the tech stacks are not there yet - mainly because the request-response model is good enough for most of the sites, so the industry wouldn't push it forward wholeheartedly. Maybe the situation would start to change after WASM take off, or maybe not.
  - The best bet is to work on platforms that already have great WebSocket support. PHP might not be a great choice. Node.js is okayish but not great. Blazor sounds interesting but I'm not sure about the performance. Elixir/Phoenix is probably the best bet for now. It has nice, abstracted APIs, it's performant, and it can form clusters either by itself or with Redis.
  - It's very hard to scale WebSocket because of its stateful nature, so please look for platforms already solved this problem.
- You can turn websockets into a flawless request/response with async/await included on like 20 lines of JavaScript. I do it all the time. Generate an ID, make a request, store the promise resolve/reject in a map (js object). Your onmessage handler looks up the promise based on the ID and resolves the promise.
- The biggest challenge when migrating from HTTP to any kind of stream is the loss of callback on response, because there is no request/response. There is only push. That means your messaging and message handling becomes far more complex to compensate.
- ## ğŸ¹ [Deepstream 5.0: Resurrected using MIT license | Hacker News _201910](https://news.ycombinator.com/item?id=21371658)
- Generally deepstream is an alternative to using firebase, socket.io, featherJS and meteor. However rather than putting the logic within the server you instead run them as microservices and allow deepstream to handle load-balancing for you.
- The two main things deepstream offers are: 
  - Events: pubsub mechanism
  - Records: Records is events with persistence. They are more heavy weight objects that persist their content in a cache + db and across all connected devices without the user/developer having to actually do anything. The also support offline support if you want to be able to get/set data while offline.
- It's a real-time pub/sub messaging system (competitive to NATS), with built in messaging patterns like request/response.
  - Also supports persistence of data records (JSON docs) and syncing changes to those docs (competitive to Firebase, etc), backed by Redis.
  - Works with different protocols (websocket, MQTT, HTTP) and has client libraries for popular languages.
- The biggest pain point I've experienced with these pubsub services is how to negotiate client connections so that all the subscribers to a topic are directly connected to the same machine. 
  - In other words, clients' messages do not have to ever be relayed at the networking level. 
  - This means providing some reconnecting or connection-info data for the client, and it's why I think most of these frameworks fail to improve on home cooked solutions: you have to touch the message to help squeeze out efficiency.
  - A non-IP based routing mechanism requires some kind of header/parsing/deserialization of the message being passed. In application level code this is quite slow, you have to query some kind of map synchronized about cluster nodes. This is especially shitty if message addresses are ephemeral, especially per RPC call (which is the default behaviour in most cluster-based RPC frameworks), because then your near cache of the cluster map is never populated. Alternatively you can just broadcast to everyone (skip the cluster map) but then why cluster?
  - It would be great if we just had IPv6 adoption though. Then you could just uh, route. The DNS based routing in stuff like Kubernetes is close but not for external Internet facing clients. The whole point is to avoid a bastion host.
- I totally agree. Having a single point of entry gives us some small benefits like a single connection/simplified deployments but it isn't efficient to have a provider connected on one node in a cluster and have to forward data to subscribers on another just because of how they were distributed by a load-balancer. Theres actually an action in the handshake protocol which allows a node in a cluster to redirect a connection to a different/more optimal node. It was used for multi-tenancy clusters previously. In theory you can run multiple isolated clusters (or individual nodes) and have multiple connections from the client, routed based on which subscription lives where. It's a pattern I have been talking about with a couple of users but it hasn't been required by anyone yet. It isn't as efficient as doing it on a network layer but it at least reduced intercluster traffic dramatically.
- I used to be really concerned about this, but one day I sat down and did the math and realized that the worst case scenario is that I'd have no more than two times as many messages, which means this isn't a scalability issue: if a topic has N subscribers, at bare minimum you are going to have N+1 messages to send a given event (one to receive it into the cluster, and N to dispatch it to the subscribers); if everyone is connected to some random machine, then you need to take the incoming event and send it to the right internal machine that is storing that topic (which is one extra message) and then that machine will need to indirectly send the message to the connecting computers of the subscribers (which is one extra message per subscriber), so you end up with 2N+2 messages. The alternative, where users cluster themselves based on topic with their entry connections, is that these individual end users have to maintain a ton of separate connections for inbound messages for each of the topics they are interested in, which is often going to work out to be much worse for everyone involved.
- 
- 
- 
- 
- 
- 
- ## After working with WebSockets for a while I'm wondering why devs don't use them more.
- https://x.com/jamonholmgren/status/1798803384541302814
- Great technology but I always opt for SSE + a good API kind of achieves everything you need, easier to maintain and feels cleaner
- Market data providers like @AlpacaHQ use websockets, thereâ€™s no other way 
  - http://HawkAlpha.com uses websockets to stream and place trades in real time
- Elixir/Phoenix/LiveView is the on true way.
- Compensating for data loss on disconnect / reconnect
- typical cookie based Authentication isn't as straightforward with web sockets because cookies only get sent once on initial connect
- Scaling tends to be much harder with web  sockets due to no caching and more resources
- To me the big two things are:
  - 1) Event-driven architecture is unfamiliar to most and generally harder to reason about 
  - 2) scaling/deployment requires extra work
- ## ğŸ†šï¸ Server-sent events, WebSocket, and Webhooks. How do they differ?
- https://twitter.com/Franc0Fernand0/status/1777675213729136987
- WebSocket 
  - They provide a bidirectional communication channel over a single TCP connection.
  - The client and server can both send messages through the channel in real-time.
  - To use WebSocket, the client must include specific fields in the HTTP header to tell the server to switch to the WebSocket protocol.
  - Once the server replies, a WebSocket connection is set up.
- Server-sent events 
  - A bidirectional channel is overkill in scenarios where the data flow is unidirectional.
  - SSE addresses this problem and allows the server to push messages to a client over HTTP.
  - The client sends a GET request to the server, specifying itâ€™s waiting for an event stream.
  - This will start an open connection that the server can use to send messages to the client.
- WebHooks 
  - While SSE is usually used to get updates to the front end, Webhooks generally get updates to the back end.
  - They work like a callback informing the client of new updates. The server set up a clear API endpoint to receive updates from outside.
- ## ğŸŒ° ChatGPTç½‘é¡µç‰ˆä»SSEæ”¹æˆWebsocketäº† _20240202
- https://twitter.com/wong2_x/status/1753351893211037994
- https://twitter.com/wong2_x/status/1759403801394794789
  - æ›´æ–°ï¼šåˆå…¨éƒ¨æ”¹å›SSEäº† _20240219
- 1. å¯¹ç»ˆç«¯ç”¨æˆ·æ¥è¯´ä½¿ç”¨æ„Ÿè§‰åŸºæœ¬æ²¡æœ‰å˜åŒ–ã€‚
  - 2. ä½†ä»æŠ€æœ¯è§’åº¦çœ‹, ChatGPTæ”¹ç”¨WebsocketæŠ€æœ¯ä¸æœåŠ¡å™¨ç«¯é€šä¿¡å¯ä»¥æå‡é€šä¿¡æ•ˆç‡, é™ä½å»¶è¿Ÿ, ä¸”æ”¯æŒæ€§æ›´å¥½ã€‚
- http://pplx.ai ä¹Ÿæ”¹æˆäº† Websocket.
- è¯´æ˜ç”Ÿæˆå’Œè®¡ç®—é€Ÿåº¦æ›´å¿«äº†ï¼Œä¹Ÿæ‰©å®¹äº†ã€‚
- æ„Ÿè§‰æ²¡ä»€ä¹ˆå¿…è¦ï¼Œé™¤éäº¤äº’å½¢å¼ä¸å†éœ€è¦é—®ä¸€å¥ç­”ä¸€å¥ï¼Œè€Œæ˜¯æ”¯æŒè¿ç»­æé—®æˆ–è€…å¤šäººç¾¤èŠ
- ä»ç”Ÿå‘½å‘¨æœŸæ¥çœ‹ Websocket ç®¡ç†èµ·æ¥æ›´éº»çƒ¦ä¸€äº›, ä½†çš„ç¡®å»ºç«‹è¿æ¥æ¬¡æ•°ä¼šé™ï¼Œä¹Ÿç®—ä¸€ä¸ªä¼˜åŒ–å§ã€‚å·¥ç¨‹ä¸Šæå‡å¤æ‚åº¦ï¼Œæ€§èƒ½ä¸Šæ‹¿åˆ°æ”¶ç›Šã€‚
- æƒ³é—®ä¸‹æ€ä¹ˆåˆ¤æ–­çš„
  - æµè§ˆå™¨çœ‹ä¸‹Network
- æ˜¯ä¸¤ç§éƒ½åœ¨ç”¨ æˆ‘ä»Šå¤©è¿˜æ˜¯wss
- AB Testæµ‹è¯•åå›æ»šï¼Ÿ
  - åº”è¯¥æ˜¯çš„
- å¯¹äºè¿™ç§åªéœ€è¦responseæµå¼è¿”å›çš„åœºæ™¯ï¼Œsseå°±è¶³å¤Ÿäº†è€Œä¸”æ¶æ„è¶³å¤Ÿç®€å•ï¼ŒæœåŠ¡ç«¯ä¸éœ€è¦åšä»€ä¹ˆç‰¹æ®Šè®¾ç½®ï¼ˆè®¾ç½®ä¸€äº›content-typeï¼‰å°±å¯ä»¥äº†ï¼Œç›¸åwebsocketåœ¨chatgptè¿™ç§åœºæ™¯ä¸‹æœ‰ç‚¹æ€é¸¡ç”¨ç‰›åˆ€äº†ã€‚
- æ˜¯çš„ï¼Œwsæœ‰çŠ¶æ€ï¼Œç»´æŠ¤èµ·æ¥è¿˜æ˜¯éº»çƒ¦
- Gradio 4.0 ä¹Ÿä»wsæ”¹æˆäº†SSE
- wsçš„åç«¯æŠŠä¸Šä¸‹è¡Œæ‹§åœ¨äº†ä¸€ä¸ªè¿æ¥ä¸Šï¼Œå¢åŠ å¤æ‚åº¦ï¼Œä¸æ˜“è§£è€¦ã€‚
  - å¯¹äºå‰ç«¯æ¥è¯´sseè¿˜æ˜¯wså…¶å®æ— æ‰€è°“ã€‚
- å¯¹è¿™æ ·çš„åœºæ™¯æ¥è¯´ï¼Œwebsocket å¤ªå¤æ‚äº†ã€‚
- ## ğŸ†šï¸ You can use two ways to let web apps talk to each other: polling and webhooks.
- https://twitter.com/Franc0Fernand0/status/1748620224767701040
- In API Polling, your app continuously requests updates to the email-sending server to know if the mail has been sent. 
- this method is simple and easy to use, it does have  some drawbacks:
  - It requires a lot of resources
  - It doesn't give real-time updates
  - The 3rd party service service talks to your app directly, which makes it less secure.
- Webhooks, on the other hand, work like a callback or a direct phone call informing your app of new updates. 
- This push-based approach has many advantages:
  - Ensure real-time data updates
  - Reduce the number of API calls and resources you use
  - Guarantee better scalability and system decoupling
- there are also some things to think about when setting up Webhooks.
  - First, it is necessary to set up a clear API endpoint to send updates from outside services.
  - Second, it is important to set up security measures for webhook requests and failure handling measures for when the webhook doesn't get an answer
- Over the years, I've seen webhooks become dominant while integrating with 3rd party APIs.
- One failure-handling measure in webhook is using a message broker like RabbitMQ to ensure that updates are delivered again until your server acknowledges them.
- How do you deal with webhook failure?
  - You can implement a retry policy for failed delivery but limit the number of retries to prevent endless attempts. 
  - As a fallback strategy, you can consider an alternative communication channel.
- How do we implement robust failure handling in both Webhook and Polling scenarios?
  - Retry strategies are at the base of failure handling in both cases. With polling, you can consider adaptive polling to adjust the frequency based on the system load.
- ## ğŸ†šï¸ Polling vs Webhooks
- https://twitter.com/ProgressiveCod2/status/1734474112670822904
  - In polling, a client repeatedly requests data from a server at predefined intervals.
  - Webhooks are like having a built-in notification system. Data is pushed to you as soon as itâ€™s available.
- The choice depends on how realtime the client needs data. Webhooks have drawbacks too
  - server needs to keep inventory of clients
  - server should be resilient to network partitions 
- Notification backed by scalable APIs could be another approach.
- ## [åœ¨å¤šåª’ä½“é€šä¿¡ä¸­ï¼Œä¿¡ä»¤æœåŠ¡å™¨å’Œæµåª’ä½“æœåŠ¡å™¨å„å……å½“ä»€ä¹ˆè§’è‰²ï¼Ÿå„è‡ªçš„ä¸»è¦åŠŸèƒ½æ˜¯ä»€ä¹ˆï¼Ÿ - çŸ¥ä¹](https://www.zhihu.com/question/281716536)
- ä¿¡ä»¤æ˜¯åè°ƒé€šä¿¡çš„è¿‡ç¨‹ã€‚ä¸ºäº†ä½¿WebRTCåº”ç”¨ç¨‹åºèƒ½å¤Ÿå»ºç«‹ä¸€ä¸ªâ€œé€šè¯â€ï¼Œå…¶å®¢æˆ·éœ€è¦äº¤æ¢ä»¥ä¸‹ä¿¡æ¯ï¼š
  - ä¼šè¯æ§åˆ¶æ¶ˆæ¯ç”¨äºæ‰“å¼€æˆ–å…³é—­é€šä¿¡
  - é”™è¯¯æ¶ˆæ¯
  - åª’ä½“å…ƒæ•°æ®ï¼Œå¦‚ç¼–è§£ç å™¨å’Œç¼–è§£ç å™¨è®¾ç½®ï¼Œå¸¦å®½å’Œåª’ä½“ç±»å‹
  - å¯†é’¥æ•°æ®ï¼Œç”¨äºå»ºç«‹å®‰å…¨çš„è¿æ¥
  - ç½‘ç»œæ•°æ®ï¼Œå¦‚å¤–ç•Œç¼©å‡çš„ä¸»æœºIPåœ°å€å’Œç«¯å£
- è¿™ä¸ªä¿¡ä»¤è¿‡ç¨‹éœ€è¦ä¸€ä¸ªæ–¹å¼ä½¿å®¢æˆ·æ¥å›åœ°è¿›è¡Œæ¶ˆæ¯ä¼ é€’ã€‚
- æ²¡æœ‰ä¿¡ä»¤æœåŠ¡å™¨ï¼Œå„ä¸ªWebRTCä¹‹é—´æ˜¯æ²¡åŠæ³•é€šä¿¡çš„ã€‚ä¼ é€’åª’ä½“æ•°æ®æœ‰ä¸¤ä¸ªä¿¡æ¯ï¼Œå¿…é¡»ç»è¿‡ä¿¡ä»¤æœåŠ¡å™¨è¿›è¡Œäº¤æ¢ã€‚
- æˆ‘ä»¬è¦å®ç°p2pç›´æ¥çš„é€šä¿¡ï¼Œéœ€è¦äº¤æ¢å‡ ä¸ªä¿¡æ¯ï¼šåª’ä½“ä¿¡æ¯ï¼Œç½‘ç»œä¿¡æ¯ï¼Œå…·ä½“ä¸šåŠ¡ã€‚
- åª’ä½“ä¿¡æ¯
  - é€šè¿‡SDPæ¥è¡¨ç¤ºï¼Œå¦‚ç¼–è§£ç å™¨æ˜¯ä»€ä¹ˆï¼Ÿæ˜¯å¦æ”¯æŒéŸ³é¢‘è§†é¢‘ï¼Ÿç¼–ç æ–¹å¼æ˜¯ä»€ä¹ˆï¼Ÿç­‰
  - è¿™äº›ä¿¡æ¯æ˜¯é€šè¿‡SDPåè®®æè¿°å‡ºæ¥ï¼Œé€šè¿‡ä¿¡ä»¤æœåŠ¡å™¨ä¸­è½¬çš„
- ç½‘ç»œä¿¡æ¯
  - ä¸¤ä¸ªWebRTCå®¢æˆ·ç«¯ä¼šå°½å¯èƒ½é€‰æ‹©P2Pè¿›è¡Œè¿æ¥ï¼Œé‚£ä¹ˆè¿›è¡Œè¿æ¥å‰æ˜¯å¦‚ä½•å‘ç°å¯¹æ–¹çš„ï¼Ÿå°±æ˜¯é€šè¿‡ä¿¡ä»¤æœåŠ¡å™¨ã€‚
  - é¦–å…ˆå°†ä½ æ‰€æœ‰ç½‘ç»œç›¸å…³ä¿¡æ¯ä¼ åˆ°ä¿¡ä»¤æœåŠ¡å™¨ï¼ŒæœåŠ¡å™¨å¸®ä½ äº¤æ¢åˆ°å¯¹ç«¯ï¼Œå¯¹ç«¯æ‹¿åˆ°ä½ çš„ä¿¡æ¯åï¼Œ
  - è‹¥åœ¨åŒä¸€å±€åŸŸç½‘å†…ï¼Œç›´æ¥é€šè¿‡P2Pä¼ è¾“ï¼›è‹¥ä¸åœ¨ï¼Œé¦–å…ˆè¿›è¡ŒP2Pç©¿è¶Šï¼Œçœ‹æ˜¯å¦èƒ½æ‰“é€šï¼Œæ‰“é€šåˆ™ä¼ è¾“ï¼Œæ‰“ä¸é€šåˆ™ä¸­è½¬ç­‰ã€‚
- å…·ä½“ä¸šåŠ¡
  - è¿˜æœ‰ä¸€ç‚¹ä¹Ÿéœ€è¦ä¿¡ä»¤æœåŠ¡å™¨è¿›è¡Œä¼ è¾“ï¼Œæ¯”å¦‚åŠ å…¥æˆ¿é—´ï¼Œç¦»å¼€æˆ¿é—´ï¼Œç¦è¨€ç­‰åŠŸèƒ½
- ## [[è¯‘] WebSockets ä¸é•¿è½®è¯¢çš„è¾ƒé‡ - çŸ¥ä¹](https://zhuanlan.zhihu.com/p/69950157)
- é•¿è½®è¯¢-pros
  - å‡ ä¹å¾—åˆ°äº†è®¾å¤‡çš„æ™®éæ”¯æŒ
  - å¯ä»¥ä½¿ç”¨ XMLHttpRequest æˆ–é€šè¿‡ JSONP åˆ©ç”¨ç®€å•çš„ HTML è„šæœ¬æ ‡ç­¾ã€‚
- é•¿è½®è¯¢-cons
  - å¤§é‡å æ®æœåŠ¡å™¨èµ„æºã€‚
  - å¯é çš„æ¶ˆæ¯æ’åº å¯èƒ½æ˜¯é•¿è½®è¯¢çš„ä¸€ä¸ªé—®é¢˜ï¼Œå› ä¸ºæ¥è‡ªåŒä¸€ä¸ªå®¢æˆ·ç«¯çš„å¤šä¸ª HTTP è¯·æ±‚å¯èƒ½åŒæ—¶è¿è¡Œ
  - æ ¹æ®æœåŠ¡ç«¯å®ç°çš„ä¸åŒï¼Œä¸€ä¸ªå®¢æˆ·ç«¯å¯¹æ¶ˆæ¯çš„ç¡®è®¤æ¥æ”¶ä¹Ÿå¯èƒ½å¯¼è‡´å¦ä¸€ä¸ªå®¢æˆ·ç«¯æ ¹æœ¬ä¸ä¼šæ”¶åˆ°é¢„æœŸçš„æ¶ˆæ¯
- websocket-pros
  - ä¿æŒä¸€ä¸ªå”¯ä¸€çš„è¿æ¥æ‰“å¼€ï¼ŒåŒæ—¶æ¶ˆé™¤é•¿è½®è¯¢çš„å»¶è¿Ÿé—®é¢˜
  - æ— éœ€å‘é€å¤´éƒ¨æ•°æ®ã€‚åè¿‡æ¥è¯´ï¼Œè¿™åˆå‡å°‘äº†æ•°æ®å‘é€åˆ°æœåŠ¡å™¨æ—¶éœ€è¦ä»˜å‡ºçš„é«˜æ˜‚çš„æ•°æ®è´Ÿè½½ä»£ä»·ã€‚
- websocket-cons
  - å½“è¿æ¥ç»ˆæ­¢æ—¶ï¼ŒWebSockets æ— æ³•è‡ªåŠ¨æ¢å¤è¿æ¥ â€”â€” è¿™æ˜¯éœ€è¦ä½ è‡ªå·±å®ç°çš„éƒ¨åˆ†ï¼Œä¹Ÿæ˜¯å¯¼è‡´å­˜åœ¨è®¸å¤š å®¢æˆ·ç«¯åº“ çš„åŸå› ã€‚
  - æ—©äº 2011 å¹´çš„æµè§ˆå™¨æ— æ³•æ”¯æŒ WebSocket è¿æ¥
- ## [Webé€šä¿¡ä¸­ä½¿ç”¨é•¿è½®è¯¢ï¼ˆlong pollingï¼‰Holdä½è¿æ¥çš„æ—¶é—´åº”è¯¥è®¾ç½®ä¸ºå¤šä¹…å¥½å‘¢ï¼Ÿ - çŸ¥ä¹](https://www.zhihu.com/question/31593363)
- long pollè¦æ–­æ‰æ˜¯å› ä¸ºè€ƒè™‘åˆ°é“¾è·¯ä¸­é—´çš„ç»„ä»¶ï¼ˆæ¯”å¦‚Proxyï¼‰å¯èƒ½ä¼šå¼ºè¡Œæ–­å¼€é€ æˆé—®é¢˜ï¼Œä¸å¦‚ä¸»åŠ¨æ–­å¼€é‡è¿ã€‚
  - å„ç§ç»„ä»¶é…ç½®çš„è¶…æ—¶é€šå¸¸å¯èƒ½æ˜¯60ç§’æˆ–30ç§’ã€‚æ‰€ä»¥è¿‡å»ä¸€èˆ¬ä¿å®ˆè®¾ç½®ä¸º30ç§’ã€‚
  - ç™¾åº¦è´´å§è®¾ä¸º60ç§’ä¹Ÿè®¸æ˜¯è€ƒå¯Ÿè¿‡é“¾è·¯çš„æƒ…å†µï¼Œä¹Ÿå¯èƒ½å°±æ˜¯éšæ‰‹ä¸€è®¾ã€‚å…·ä½“è¦æ‰¾å¼€å‘äººå‘˜é—®äº†ã€‚
- ## ğŸ†šï¸ [WebRTCå’ŒWebSocketæœ‰ä»€ä¹ˆå…³ç³»å’ŒåŒºåˆ«ï¼Ÿ](https://www.zhihu.com/question/424264607)
- è¿™ä¸¤ç§æŠ€æœ¯æœ¬è´¨ä¸ŠåŠæ¯›é’±å…³ç³»éƒ½æ²¡æœ‰ï¼Œé™¤äº†å®ƒä»¬éƒ½å¯ä»¥åœ¨webä¸­ç”¨ä¹‹å¤–ã€‚
  - socket å’Œ rtc æœ‰å¤šå¤§åŒºåˆ«ï¼Œè¿™ä¸¤ç§æŠ€æœ¯å°±æœ‰å¤šå¤§åŒºåˆ«ã€‚
- websocketå°±æ˜¯å€ŸåŠ©äºhttpå»ºç«‹ä¸€ä¸ªtcpçš„è¿æ¥ï¼Œç„¶ååœ¨è¿™ä¸ªtcpè¿æ¥ä¸­ä¼ è¾“websocketè¿™ç§ç‰¹å®šåè®®å¯¹åº”æ ¼å¼çš„äºŒè¿›åˆ¶åˆ†å¸§æ•°æ®ã€‚
  - ç®€å•ç‚¹è¯´ï¼Œwebsocket å°±æ˜¯å°è£…äº† tcp æ¥ç»™ web çš„ JavaScript ç”¨ã€‚
- webrtcåˆ™ä¸»è¦æ˜¯ç»™rtcå°è£…äº†ä¸ªwebç«¯çš„jsæ¥å£ã€‚
  - åº•å±‚webrtcçš„åº“éœ€è¦å®Œæˆå…¨éƒ¨ rtc ç›¸å…³çš„é€»è¾‘ï¼ŒåŒ…æ‹¬ p2pè¿æ¥ï¼ŒéŸ³è§†é¢‘çš„ï¼Œé‡‡é›†ï¼Œå¤„ç†ï¼Œç¼–ç ï¼Œè§£ç ï¼Œä¼ è¾“ï¼Œæ‹¥å¡æ§åˆ¶ç­‰ç­‰ç­‰ä¸€å¤§å †ä¸œè¥¿ã€‚
  - å¦å¤–ï¼Œä¼ è¾“å±‚åè®®ï¼Œwebrtcä¸»è¦åœ¨ç”¨udpï¼Œè€Œä¸æ˜¯websocketçš„ tcpã€‚
- ä½†è¯´å®ƒä»¬ä¸€ç‚¹å…³ç³»ä¹Ÿæ²¡æœ‰ï¼Œå…¶å®ä¹Ÿä¸ä¸€å®šã€‚
  - æœ‰äº› webrtc çš„éƒ¨ç½²æ–¹æ¡ˆä¸­ï¼Œä¼šæŠŠ websocket ç”¨ä½œä¿¡ä»¤åè®®çš„ä¼ è¾“é€šé“ã€‚

### [WebRTC(Web Real-Time Communication)å®æ—¶é€šä¿¡æŠ€æœ¯ä»‹ç»](https://www.zhihu.com/question/424264607/answer/2394172608)

- https://github.com/caiya/webrtc-p2p
  - åœ¨ä¸¤ä¸ªæµè§ˆå™¨ä¸­è¿›è¡Œå®æ—¶è§†é¢‘é€šè¯
- https://github.com/caiya/webrtc-p2p-datachannel
  - p2pè§†é¢‘èŠå¤©ï¼ŒåŠ å…¥datachannelè¿›è¡Œç®€å•çš„æ¶ˆæ¯å‘é€
- https://github.com/hughfenghen/rtc-live-show
  - åŸºäºWEB RTC + rrwebå®ç°çš„é¡µé¢â€œç›´æ’­â€demo
- WebRTCç›®çš„æ˜¯æ— æ’ä»¶å®ç°webç«¯çš„å®æ—¶é€šä¿¡çš„èƒ½åŠ›ã€‚
- WebRTCæä¾›äº†è§†é¢‘ä¼šè®®çš„æ ¸å¿ƒæŠ€æœ¯ï¼ŒåŒ…æ‹¬éŸ³è§†é¢‘çš„é‡‡é›†ã€ç¼–è§£ç ã€ç½‘ç»œä¼ è¾“ã€å±•ç¤ºç­‰åŠŸèƒ½ï¼Œå¹¶ä¸”è¿˜æ”¯æŒè·¨å¹³å°ï¼ŒåŒ…æ‹¬linuxã€windowsã€macã€androidç­‰ã€‚
- ğŸ‘‰ğŸ» å»ºç«‹WebRTCè¿æ¥éœ€è¦å¦‚ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š
- è·å–æœ¬åœ°åª’ä½“ï¼ˆgetUserMedia()ï¼ŒMediaStream APIï¼‰
- åœ¨æµè§ˆå™¨å’Œå¯¹ç­‰ç«¯ï¼ˆå…¶å®ƒæµè§ˆå™¨æˆ–ç»ˆç«¯ï¼‰ä¹‹é—´å»ºç«‹å¯¹ç­‰è¿æ¥ï¼ˆRTCPeerConnection APIï¼‰
- å°†åª’ä½“å’Œæ•°æ®é€šé“å…³è”è‡³è¯¥è¿æ¥
- äº¤æ¢ä¼šè¯æè¿°ï¼ˆRTCSessionDescriptionï¼‰
- åœ¨WebRTCä¸­ï¼Œä¿¡ä»¤èµ·ç€ä¸¾è¶³è½»é‡çš„ä½œç”¨ã€‚ä½†å®ç°æ²¡æœ‰æ ‡å‡†åŒ–ï¼Œæ¯”å¦‚httpã€websocketã€xmppç­‰ã€‚
- ä¿¡ä»¤å°±æ˜¯åè°ƒé€šè®¯çš„è¿‡ç¨‹ï¼Œä¸€æ—¦ä¿¡ä»¤æœåŠ¡å»ºç«‹å¥½äº†ï¼Œä¸¤ä¸ªå®¢æˆ·ç«¯ä¹‹é—´å»ºç«‹äº†è¿æ¥ï¼Œç†è®ºä¸Šå®ƒä»¬å°±å¯ä»¥è¿›è¡Œç‚¹å¯¹ç‚¹é€šè®¯äº†ã€‚
  - åå•†åª’ä½“åŠŸèƒ½å’Œè®¾ç½®
  - æ ‡è¯†å’ŒéªŒè¯ä¼šè¯å‚ä¸è€…çš„èº«ä»½ï¼ˆäº¤æ¢SDPå¯¹è±¡ä¸­çš„ä¿¡æ¯ï¼šåª’ä½“ç±»å‹ã€ç¼–è§£ç å™¨ã€å¸¦å®½ç­‰å…ƒæ•°æ®ï¼‰
  - æ§åˆ¶åª’ä½“ä¼šè¯ã€æŒ‡ç¤ºè¿›åº¦ã€æ›´æ”¹ä¼šè¯ã€ç»ˆæ­¢ä¼šè¯
  - åŒå ç”¨åˆ†è§£
- WebRTCè¦æ±‚åœ¨ä¸¤ä¸ªå¯¹ç­‰ç«¯å»ºç«‹åŒå‘çš„ä¿¡ä»¤é€šé“ï¼Œé€šå¸¸æœ‰ä¸‰ç§æ–¹å¼æ¥ä¼ è¾“WebRTCä¿¡ä»¤ï¼šhttpã€websocketã€æ•°æ®é€šé“
- WebRTCæä¾›äº†æµè§ˆå™¨ç«¯çš„P2Pé€šä¿¡ï¼Œä½†å¹¶ä¸æ„å‘³ç€WebRTCä¸éœ€è¦æœåŠ¡å™¨ã€‚
- æ’‡å¼€åº”ç”¨æœåŠ¡å™¨ä¸è¯´ï¼Œè‡³å°‘ä»¥ä¸‹ä¸¤ç§æœåŠ¡å™¨æ˜¯å¿…é¡»çš„ï¼š
  - æµè§ˆå™¨ä¹‹é—´å»ºç«‹é€šä¿¡å‰äº¤æ¢å„ç§å…ƒæ•°æ®ï¼ˆä¿¡ä»¤ï¼‰çš„æœåŠ¡å™¨ï¼ˆä¿¡ä»¤æœåŠ¡ï¼‰
  - ç©¿è¶ŠNATå’Œé˜²ç«å¢™çš„æœåŠ¡å™¨ï¼ˆstunã€turnã€rsipç­‰ï¼‰
- å…ƒæ•°æ®æ˜¯é€šè¿‡ä¿¡ä»¤æœåŠ¡å™¨ä¸­è½¬å‘ç»™å¦ä¸€ä¸ªå®¢æˆ·ç«¯ï¼Œä½†æ˜¯å¯¹äºæµåª’ä½“æ•°æ®ï¼Œä¸€æ—¦ä¼šè¯å»ºç«‹ï¼Œé¦–å…ˆå°è¯•ä½¿ç”¨ç‚¹å¯¹ç‚¹è¿æ¥ã€‚
  - ç®€å•ä¸€ç‚¹è¯´å°±æ˜¯ï¼šæ¯ä¸ªå®¢æˆ·ç«¯éƒ½æœ‰ä¸€ä¸ªå”¯ä¸€çš„åœ°å€ï¼Œä»–èƒ½ç”¨æ¥å’Œå…¶ä»–å®¢æˆ·ç«¯è¿›è¡Œé€šè®¯å’Œæ•°æ®äº¤æ¢ã€‚
- WebRTCä½¿ç”¨RTCPeerConnectionå»ºç«‹è¿æ¥ä¼ é€æµæ•°æ®ï¼Œåœ¨å»ºç«‹RTCPeerConnectionå®ä¾‹ä¹‹åï¼Œæƒ³è¦å»ºç«‹ç‚¹å¯¹ç‚¹çš„ä¿¡é“ï¼Œéœ€è¦åšä¸¤ä»¶äº‹ï¼š
  - ç¡®å®šæœ¬æœºä¸Šçš„åª’ä½“æµçš„ç‰¹æ€§ï¼Œæ¯”å¦‚åˆ†è¾¨ç‡ã€ç¼–è§£ç èƒ½åŠ›å•¥çš„ï¼ˆSDPæè¿°ç¬¦ï¼‰
  - è¿æ¥ä¸¤ç«¯çš„ä¸»æœºçš„ç½‘ç»œåœ°å€ï¼ˆICE Candidateï¼‰
- WebRTCå®šä¹‰äº†ä¸¤ç»„ä¸»è¦çš„åŠŸèƒ½ï¼Œåˆ†åˆ«æ˜¯ï¼šåª’ä½“æ•è·ï¼ˆgetUserMedia()ï¼‰ã€åª’ä½“ä¼ è¾“ã€‚
  - å¯¹ç­‰è¿æ¥å’Œæè®®/åº”ç­”åå•†çš„æ¦‚å¿µæ˜¯åª’ä½“ä¼ è¾“çš„æ ¸å¿ƒã€‚
- RTCPeerConnectionæ¥å£æ˜¯WebRTCçš„ä¸»è¦APIï¼Œç”¨æ¥åœ¨P2Pç«¯å»ºç«‹åª’ä½“è¿æ¥åŠæ•°æ®è¿æ¥è·¯å¾„ã€‚
- RTCDataChannelï¼Œæ•°æ®é€šé“æ˜¯æµè§ˆå™¨ä¹‹é—´å»ºç«‹çš„éåª’ä½“çš„äº¤äº’è¿æ¥ã€‚
  - å³ä¸ä¼ é€’åª’ä½“æ¶ˆæ¯ï¼Œç»•è¿‡æœåŠ¡å™¨ç›´æ¥ä¼ é€’æ•°æ®ã€‚
  - ç›¸æ¯”WebSocketã€httpæ¶ˆæ¯ï¼Œæ•°æ®é€šé“æ”¯æŒæµé‡å¤§ã€å»¶è¿Ÿä½ã€‚
- å•ä¸ªå¯¹ç­‰è¿æ¥ä¸­çš„å¤šä¸ªæ•°æ®é€šé“åº•å±‚å…±äº«ä¸€ä¸ªæµï¼Œæ‰€ä»¥åªéœ€ä¸€æ¬¡offerã€answerå³å¯å»ºç«‹é¦–ä¸ªæ•°æ®é€šé“ã€‚ä¹‹åå†å»ºç«‹æ•°æ®é€šé“æ— éœ€å†æ¬¡è¿›è¡Œofferã€answeräº¤æ¢ã€‚
- ## [åˆ°åº•ä»€ä¹ˆæ˜¯WebRTCæœåŠ¡å™¨ï¼Œä»¥åŠå®ƒæ˜¯å¦‚ä½•è”æ¥é€šè¯çš„](https://webrtc.org.cn/webrtc-server/)
- WebRTCå¹¶ä¸æ˜¯çœŸæ­£æ„å‘³ç€ä½ ä¸éœ€è¦æœåŠ¡å™¨æ¥åå•†å’Œè”æ¥é€šè¯ã€‚å®ƒåªæ„å‘³ç€ï¼Œåœ¨å¤šæ•°æƒ…å†µä¸­ï¼Œä½ å¯ä»¥ç›´æ¥åœ°åœ¨æµè§ˆå™¨ä¹‹é—´è¿›è¡Œé€šä¿¡ã€‚
- è¦æƒ³è®©ä»»ä½•WebRTCæœåŠ¡æ­£å¸¸çš„å·¥ä½œï¼Œä½ éœ€è¦å¦‚ä¸‹2ä¸ªåç«¯æœåŠ¡å™¨
- ä¿¡ä»¤æœåŠ¡å™¨
  - å¯¹äºæµè§ˆå™¨çš„å¯¹è¯æ¥è¯´ï¼Œæœ€é‡è¦çš„å°±æ˜¯æŸç§ä¸­ä»‹å™¨â€”ä¸€ä¸ªäº†è§£é€šè¯åŒæ–¹ç«¯ç‚¹çš„æœåŠ¡å™¨ã€‚
  - è¿™å°±æ˜¯ä¿¡ä»¤æœåŠ¡å™¨ï¼Œè´Ÿè´£åå•†ä¼šè¯ï¼Œè€Œä¸”å¯èƒ½æ˜¯æœ€æ¥è¿‘WebRTCæœåŠ¡å™¨çš„ä¸œè¥¿äº†ã€‚
  - é€šå¸¸ï¼Œè¿™ä¸ªæœåŠ¡å™¨ä¹Ÿä¼šç©¿è¿‡ä¼šè¯å‘é€ç›¸å…³æ•°æ®ã€‚
  - ä¿¡ä»¤æœåŠ¡å™¨å¯ä»¥å®æ–½åƒSIPæˆ–XMPPçš„æ ‡å‡†åŒ–åè®®ï¼Œæˆ–è€…ç§æœ‰åè®®ã€‚
  - æœ‰æ—¶ï¼Œä¿¡ä»¤å†…å®¹ä¹Ÿä¼šä½œä¸ºWebæœåŠ¡å™¨çš„ä¸€éƒ¨åˆ†æ¥æ“ä½œç½‘é¡µã€‚å…¶ä»–æƒ…å†µä¸­ï¼Œä¿¡ä»¤æœåŠ¡å™¨å°±ä¸“é—¨ç”¨æ¥å¤„ç†ä¿¡ä»¤äº†ã€‚
- TURNå’ŒSTUNæœåŠ¡å™¨
  - å½“é€šè¯ä¸¤ç«¯ç«¯ç‚¹éƒ½æ£€æµ‹åˆ°äº†å¯¹æ–¹çš„æ—¶å€™ï¼Œä»–ä»¬ä¼šå°è¯•ç€åœ¨å…¶ä¹‹é—´å»ºç«‹ç›´æ¥è”æ¥â€”æœ‰æ—¶å€™ä¼šæœ‰ç”¨ï¼Œä½†ä¹Ÿæœ‰ä¸èµ·ä½œç”¨çš„æ—¶å€™ã€‚
  - å½“æ²¡æœ‰ç”¨çš„æ—¶å€™ï¼Œæ˜¯å› ä¸ºåœ¨é€šä¿¡é€šé“ä¸Šçš„ç½‘ç»œåœ°å€è½¬æ¢æˆ–è€…é˜²ç«å¢™æœºåˆ¶ï¼Œè¦ä¹ˆæ©ç›–äº†æµè§ˆå™¨çš„åœ°å€ï¼Œå°†å…¶ä»ç§äººIPåœ°å€è½¬æ¢åˆ°å…¬å…±åœ°å€ï¼Œè¦ä¹ˆå®ƒä»¬è®¤ä¸ºè¿™ä¸ªä¼šè¯æ˜¯ä¸å®‰å…¨çš„ï¼Œä»¥è‡³äºå®ƒä»¬ä¼šé˜»æ‹¦æµå…¥çš„æ•°æ®æµå¹¶ä¸”ä¸å…è®¸é€šè¯çš„è¿›è¡Œ
  - ä¸ºäº†å…‹æœè¿™äº›é—®é¢˜ï¼ŒWebRTCä½¿ç”¨äº†STUNå’ŒTURNï¼Œå®ƒä»¬æ˜¯è¦æ±‚æœåŠ¡å™¨æ„ä»¶æ¥ååŠ©åå•†åª’ä½“ä¼ è¾“çš„åè®®ï¼Œè€Œä¸”æœ‰æ—¶å°†æ‰€æœ‰çš„åª’ä½“éƒ½ä¸­ç»§ç»™TURNæœåŠ¡å™¨ã€‚
- åª’ä½“æœåŠ¡å™¨
  - ç”šè‡³åœ¨åå•†ä¿¡ä»¤ä»¥åŠè”é€šåª’ä½“ä¹‹åï¼Œæˆ‘ä»¬å¯èƒ½è¿˜æƒ³è¦åœ¨æœåŠ¡ç«¯å¤„ç†åª’ä½“ã€‚
  - è¿™ç§åŠŸèƒ½æ˜¯éœ€è¦æœ‰çš„ï¼Œå› ä¸ºè¿™æ ·ç”¨æˆ·å°±å¯ä»¥å®æ–½ä¸€ä¸ªæœ‰ç€å¤§é‡å‚ä¸è€…çš„ä¼šè¯ï¼Œå¹¶ä¸”è®°å½•å­˜æ¡£ä¼šè¯æˆ–ä¼šè¯åˆ°å…¶ä»–ç±»å‹çš„ç½‘ç»œåè®®çš„ç½‘å…³ã€‚
  - åœ¨è¿™äº›æƒ…å†µä¸­ï¼Œæˆ‘ä»¬å°±ä¼šç”¨åˆ°åç«¯çš„åª’ä½“æœåŠ¡å™¨ã€‚
