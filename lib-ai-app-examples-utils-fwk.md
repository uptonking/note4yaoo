---
title: lib-ai-app-examples-utils-fwk
tags: [ai, examples, utils]
created: 2025-02-21T18:20:28.621Z
modified: 2025-02-21T18:20:42.624Z
---

# lib-ai-app-examples-utils-fwk

# guide

# popular
- https://github.com/microsoft/mcp-for-beginners /MIT/202507/python/ts
  - This open-source curriculum introduces the fundamentals of Model Context Protocol (MCP) through real-world, cross-language examples in . NET, Java, TypeScript, JavaScript, and Python.

- https://github.com/langgenius/dify /82.5kStar/apache2/202503/python
  - https://dify.ai/
  - Dify is an open-source LLM app development platform
  - combines AI workflow, RAG pipeline, agent capabilities, model management, observability features and more
  - ä¾èµ–flask-sqlalchemyã€beautifulsoup4ã€celeryã€gunicornã€langfuseã€langsmithã€numpyã€pandasã€pydanticã€starletteã€unstructuredã€python-docxã€boto3
  - å‰ç«¯ä¾èµ– @dagrejs/dagreã€elkjsã€elkjs@lexical/reactã€@next/mdxã€zustandã€swrã€tanstack-query5ã€ahooksã€echarts-for-reactã€immerã€mermaidã€react-markdownã€react-windowã€remark-gfmã€sortablejs
  - license ğŸ’°
    - Unless explicitly authorized by Dify in writing, you may not use the Dify source code to operate a multi-tenant environment.
    - In the process of using Dify's frontend, you may not remove or modify the LOGO or copyright information in the Dify console or applications. 
  - https://github.com/YFGaia/dify-plus /dify-lic
    - Dify-Plus æ˜¯ Dify çš„ä¼ä¸šçº§å¢å¼ºç‰ˆï¼Œé›†æˆäº†åŸºäº gin-vue-admin çš„ç®¡ç†ä¸­å¿ƒï¼Œå¹¶é’ˆå¯¹ä¼ä¸šåœºæ™¯è¿›è¡Œäº†åŠŸèƒ½ä¼˜åŒ–ã€‚
    - Dify-Plus = ç®¡ç†ä¸­å¿ƒ + Dify äºŒå¼€ 
    - åœ¨åŸæœ‰ Dify çš„åŸºç¡€ä¸­ï¼Œè¯¥é¡¹ç›®åšäº†ä¸€äº›äºŒå¼€ä»¥åŠæ–°å¢äº†ç®¡ç†ä¸­å¿ƒçš„åŠŸèƒ½ï¼ŒåŸå…ˆè¿™äº›åŠŸèƒ½åªæ˜¯åœ¨æˆ‘ä»¬ä¼ä¸šå†…éƒ¨ä½¿ç”¨ï¼Œå¯¹å¤–äº¤æµåå‘ç°å¾ˆå¤šä¼™ä¼´ä¹Ÿé‡åˆ°æˆ‘ä»¬ç›¸åŒä¸€äº›ç—›ç‚¹ï¼Œæ•…å°†æˆ‘ä»¬çš„äºŒå¼€å†…å®¹è¿›è¡Œå¼€æº
    - æ–°å¢ï¼šç”¨æˆ·é¢åº¦
    - æ–°å¢ï¼šå¯†é’¥é¢åº¦è®¾ç½®
    - æ–°å¢ ï¼šWeb å…¬å¼€é¡µç™»å½•é‰´æƒ
    - æ–°å¢ï¼šåå°åˆ›å»ºç”¨æˆ·ï¼Œè‡ªåŠ¨é‚€è¯·è¿›ç®¡ç†å‘˜ç©ºé—´
    - æ–°å¢ï¼šsandbox-fullï¼Œä»¥æ”¾å¼€ä»£ç æ‰§è¡ŒèŠ‚ç‚¹å‡½æ•°é™åˆ¶
  - ğŸ› [Token Limit for full Document (10000 Token cut) _202506](https://github.com/langgenius/dify/issues/20604)
    - Dify's Retrieval-Augmented Generation (RAG) module, especially when utilizing the Parent-Child mode with a full document, appears to have a rigid limitation of 10,000 tokens per document. This constraint means that any content exceeding this token count is effectively ignored or truncated before it enters the retrieval process.
    - There is currently no apparent configuration option (for example, in the .env file) that allows users to adjust this maximum token length for RAG processing. 
    - there is no configurable option (neither in .env nor in the UI) to increase the 10,000-token limit in Parent-Child mode.
  - [Helpï¼š How to deal with the Doc Extractor output is too big in Knowledge template ](https://github.com/langgenius/dify/discussions/28889)
    - If the pdf file content is too large and it exceed the max context length of LLM. How to deal with it? 

- https://github.com/cloudflare/agents /MIT/202502/ts
  - https://developers.cloudflare.com/agents/
  - Build and deploy AI Agents on Cloudflare
  - https://x.com/threepointone/status/1895097050439593993
    - an event bus for ai agents

- https://github.com/mozilla-ai/any-agent /1kStar/apache2/202511/python
  - https://mozilla-ai.github.io/any-agent/
  - A single interface to use and evaluate different agent frameworks.
  - Multi-agent can be implemented using Agents-As-Tools.
# agent-framework/backend
- https://github.com/langchain-ai/langchain /113kStar/MIT/202508/python
  - https://python.langchain.com/
  - https://python.langchain.com/docs/introduction/
  - LangChain is a framework for building LLM-powered applications. 
  - langchain-core: Base abstractions for chat models and other components.
  - langchain: Chains, agents, and retrieval strategies that make up an application's cognitive architecture.
  - langgraph: Orchestration framework for combining LangChain components into production-ready applications with persistence, streaming, and other key features
  - LangSmith: Trace and evaluate your language model applications and intelligent agents

- https://github.com/langchain-ai/langchainjs /15.4kStar/MIT/202508/ts
  - https://js.langchain.com/docs/
  - a framework for developing applications powered by language models
  - can be used in: nodejs, Browser, Cloudflare Workers, Deno, VERCEL
  - [Is LangChainJS possible without NodeJS? Â· langchain-ai/langchainjs _202504](https://github.com/langchain-ai/langchainjs/discussions/4494)
    - æ”¯æŒåœ¨æµè§ˆå™¨çº¯å‰ç«¯è¿è¡Œ

- https://github.com/langchain-ai/langgraph /17.1kStar/MIT/202508/python
  - https://langchain-ai.github.io/langgraph/
  - a low-level orchestration framework for building, managing, and deploying long-running, stateful agents.
  - LangGraph does not abstract prompts or architecture
  - Durable execution: Build agents that persist through failures and can run for extended periods, automatically resuming from exactly where they left off.
  - Human-in-the-loop: Seamlessly incorporate human oversight by inspecting and modifying agent state at any point during execution.
  - both short-term working memory for ongoing reasoning and long-term persistent memory across sessions.
  - [Feature request: Source code? Â· Issue Â· langchain-ai/langgraph-studio _202410](https://github.com/langchain-ai/langgraph-studio/issues/154)
    - we're currently not considering open-sourcing the project, as it depends on some parts of LangSmith.
  - [[Docs] Add LangGraph integration examples to JS/TS documentation _202507](https://github.com/orgs/langfuse/discussions/7709)
    - Currently, the Langfuse JS/TS documentation lacks guidance on integrating with LangGraph. 

- https://github.com/langchain-ai/langgraphjs /1.9kStar/MIT/202508/ts
  - https://langchain-ai.github.io/langgraphjs/
  - LangGraph library enables agent orchestration â€” offering customizable architectures, long-term memory, and human-in-the-loop to reliably handle complex tasks.
  - JavaScript port of LangGraph. The architecture is the same conceptually â€” a durable graph of tasks/agents
  - Reliability and controllability. LangGraph persists context for long-running workflows, keeping your agents on course.
  - Low-level and extensible. Build custom agents with fully descriptive, low-level primitives 
  - First-class streaming support. With token-by-token streaming and streaming of intermediate steps, LangGraph gives users clear visibility into agent reasoning and actions as they unfold in real time
  - LangGraph is inspired by Pregel and Apache Beam. The public interface draws inspiration from NetworkX.

- https://github.com/langfuse/langfuse /14.8kStar/MIT+EE/202508/ts
  - https://langfuse.com/docs
  - Langfuse is an open source LLM engineering platform. 
  - It helps teams collaboratively develop, monitor, evaluate, and debug AI applications. 
  - ç³»ç»Ÿå…ƒæ•°æ®å­˜å‚¨åœ¨pg, è§‚æµ‹æ•°æ®å­˜å‚¨åœ¨clickhouseï¼Œé™„ä»¶å­˜å‚¨åœ¨s3
  - Observability: tracking LLM calls and other relevant logic in your app such as retrieval, embedding, or agent actions
  - Prompt Management 
  - Evaluations: supports LLM-as-a-judge, user feedback collection
  - Datasets enable test sets and benchmarks for evaluating your LLM applications
  - LLM Playground is a tool for testing and iterating on your prompts and model configurations
  - [All Langfuse Product Features now Free Open-Source : r/LangChain _202506](https://www.reddit.com/r/LangChain/comments/1l36tte/all_langfuse_product_features_now_free_opensource/)
    - ğŸ’¡ Langfuse is an open-source LangSmith alternative that helps teams collaboratively build, debug, and improve their LLM applications
  - [Self-host Langfuse (Open Source LLM Observability)](https://langfuse.com/self-hosting)

- https://github.com/K-Mistele/swarm /GPLv3/202501/ts/inactive
  - Model-agnostic typescript implementation of OpenAI's Swarm framework with the Vercel AI SDK
  - model-agnostic library for creating and managing multi-agent AI systems
  - This package is loosely based off of OpenAI Swarm, but please note that APIs are not identical, and they are not intended to be. 
  - This package is intended to provide the same functionality, but with better patterns
- https://github.com/joshmu/ts-swarm /MIT/202507/ts/deprecated
  - Minimal agentic library mixing the simplicity of OpenAI Swarm with the flexibility of the Vercel AI SDK
  - Option to run locally with the ollama-ai-provider.

- https://github.com/microsoft/autogen /48.5kStar/MIT/202508/python
  - https://microsoft.github.io/autogen/
  - a framework for creating multi-agent AI applications that can act autonomously or work alongside humans.
  - æœªä¸»æ‰“workflow
  - The framework uses a layered and extensible design.
  - Core API implements message passing, event-driven agents, and local and distributed runtime for flexibility and power. 
  - AgentChat API implements a simpler but opinionated API for rapid prototyping. 
  - Extensions API enables first- and third-party extensions continuously expanding framework capabilities.
  - AutoGen Studio provides a no-code GUI for building multi-agent applications.
  - AutoGen Bench provides a benchmarking suite for evaluating agent performance.

- https://github.com/crewAIInc/crewAI /35.5kStar/MIT/202508/python
  - https://crewai.com/
  - a lean, lightning-fast Python framework built entirely from scratchâ€”completely independent of LangChain or other agent frameworks.
  - CrewAI's Advantage: CrewAI combines autonomous agent intelligence with precise workflow control through its unique Crews and Flows architecture. 
  - CrewAI Crews: Teams of AI agents with true autonomy and agency, working together to accomplish complex tasks through role-based collaboration
  - CrewAI Flows: Enable granular, event-driven control, single LLM calls for precise task orchestration and supports Crews natively
  - Flexible Low Level Customization: Complete freedom to customize at both high and low levels - from overall workflows and system architecture to granular agent behaviors, internal prompts, and execution logic.
  - Ideal for Every Use Case
  - ğŸ†š How CrewAI Compares
    - While LangGraph provides a foundation for building agent workflows, its approach requires significant boilerplate code and complex state management patterns. The framework's tight coupling with LangChain can limit flexibility when implementing custom agent behaviors or integrating with external systems.
    - Autogen: While Autogen excels at creating conversational agents capable of working together, it lacks an inherent concept of process.
    - ChatDev: ChatDev introduced the idea of processes into the realm of AI agents, but its implementation is quite rigid. Customizations in ChatDev are limited

- https://github.com/mastra-ai/mastra /15.8kStar/apache2/202508/ts
  - https://mastra.ai/
  - ğŸ’« https://mastra.ai/en/docs/server-db/local-dev-playground
  - an opinionated TypeScript framework that helps you build AI applications and features quickly.
  - It gives you the set of primitives you need: workflows, agents, RAG, integrations and evals.
  - ä¸ä¾èµ–langchain/langflow
  - You can run Mastra on your local machine, or deploy to a serverless cloud.
  - Mastra uses the Vercel AI SDK for model routing, providing a unified interface to interact with any LLM provider including OpenAI, Anthropic, and Google Gemini. 
  - Agents are systems where the language model chooses a sequence of actions. 
  - Tools are typed functions that can be executed by agents or workflows, with built-in integration access and parameter validation. 
  - Workflows are durable graph-based state machines. They have loops, branching, wait for human input, embed other workflows
  - RAG lets you construct a knowledge base for agents
  - Evals are automated tests that evaluate LLM outputs using model-graded, rule-based, and statistical methods.
  - https://github.com/mastra-ai/mastra/blob/main/examples/crypto-chatbot/lib/editor/diff.js
    - ä½¿ç”¨diff_match_patchè®¡ç®—å·®å¼‚
  - https://x.com/dingyi/status/1893329741060489438
    - ä»¥å‰éå¸¸å–œæ¬¢ä¸”æ·±åº¦ä½¿ç”¨çš„ Gatsbyï¼Œä»–ä»¬å›¢é˜ŸåŸç­äººé©¬åšçš„æ–°äº§å“ï¼ŒThe TypeScript Agent Framework
  - ğŸ¯ [The next evolution of Mastra streaming _202509](https://mastra.ai/blog/mastra-streaming)
    - When we first built Mastra, we relied entirely on Vercel's AI SDK for streaming. It was a pragmatic choice that let us focus on what made Mastra unique: the orchestration layer that sits above language models.
    - But as developers started building more complex apps with Mastra, we kept hitting the same limitations. What happens when an agent calls another agent? How do you stream results from a workflow that contains multiple agents? 
    - Our old implementation worked beautifully for single model calls, but Mastra needed something more.
    - So we built our own streaming layer.
    - The new `format` option we're introducing (like `format: 'aisdk'`) establishes a pattern where Mastra can output streams in whatever format your frontend needs. Today it's AI SDK v5. Tomorrow it could be `copilotkit`, assistant-ui, or a format we haven't even imagined yet.
    - We've written before about nested streaming, but it bears repeating: modern AI applications are compositional. Agents call other agents. Workflows orchestrate multiple models. Tools can be entire applications themselves. Our custom streaming protocol makes these patterns not just possible but elegant.

- https://github.com/MotiaDev/motia /5.8kStar/MIT/202508/ts
  - https://motia.dev/
  - Modern Backend Framework that unifies APIs, background jobs, workflows, and AI agents into a single cohesive system with built-in observability and state management.
  - a modern backend framework for building event-driven applications with built-in observability and state management.
  - Motia gives you full, code-first control of your agents and automations with the simplicity of a visual interface, letting you focus on what truly matters: your business logic
  - ä¸ä¾èµ–langchain/langflow
  - æ‰§è¡Œæ—¶è¿›åº¦åŠ¨ç”»æ˜¾ç¤ºåœ¨ä»»åŠ¡ç”»å¸ƒä¸‹æ–¹çš„æ°´å¹³æ¡å½¢å›¾ï¼Œuxè®¾è®¡ä¸ç¬¦åˆä¸»æµ
    - ä½†æ”¯æŒåœ¨æ°´å¹³æ¡å½¢å›¾æ˜¾ç¤ºå„èŠ‚ç‚¹çš„æ‰§è¡Œæ—¶é—´ï¼Œæ•°æ®æ›´å…·ä½“
  - Use any LLM, vector store, or reasoning pattern without restrictions.
  - Zero Infrastructure Headaches - No Kubernetes expertise required. Deploy agents with a single command
  - Code-First Development - Write agent logic in familiar languages, not proprietary DSLs.
  - Composable Steps with Runtime Validation - Build agents from modular, reusable components with automatic input/output validation.
  - Built-in Observability - Debug agent behavior with visual execution graphs and real-time logging.
  - Instant APIs & Webhooks - Expose agent functionality via HTTP endpoints without extra code.
  - https://github.com/MotiaDev/motia-examples /æ•°æ®æµåŠ¨ç”»
    - Intelligent Q&A from PDFs with Docling's smart chunking, Weaviate's sca lable vector DB, and OpenAI embeddings & text generation. 
    - Built with TypeScript & Python.

- https://github.com/gensx-inc/gensx /507Star/apache2/202508/ts
  - https://gensx.com/
  - The TypeScript framework for agents & workflows with react-like components.
  - GenSX takes a lot of inspiration from React, but the programming model is very different - itâ€™s a Node.js framework designed for data flow.
  - ä¸ä¾èµ–langchain/langflow
  - Pure Functions: Components are pure TypeScript functions that are easily testable, reusable, and sharable
  - Parallel by Default: Components execute in parallel when possible while maintaining dependencies
  - Full TypeScript support with no DSLs or special syntax - just standard language features
  - Streaming Built-in: Stream responses with a single prop change, no refactoring needed
  - https://x.com/_Evan_Boyle/status/1892590845485895730
    - GenSX components are reusable by default and are easy to consume and share. 

- https://github.com/google-gemini/gemini-fullstack-langgraph-quickstart /apache2/202506/python/ts
  - Get started with building Fullstack Agents using Gemini 2.5 and LangGraph
  - https://x.com/JvShah124/status/1933016336113791159
    - Gemini 2.5 + LangGraph = Build Research Agents That AUTONOMOUSLY Crawl the Web, Cite Sources & Solve Complex Queries.
    - Backend: Python (FastAPI) + LangGraph for orchestrating multi-step workflows
    - Pluggable AI: Gemini 2.5 by default, but swap in Claude/Mistral via API keys
    - Tools: Google Search API + room to add LlamaIndex, custom APIs, etc.

- https://github.com/huggingface/smolagents /22.5kStar/apache2/202509/python
  - https://huggingface.co/docs/smolagents
  - smolagents is a library that enables you to run powerful agents in a few lines of code.  
  - Simplicity: the logic for agents fits in ~1, 000 lines of code (see agents.py). We kept abstractions to their minimal shape above raw code
  - First-class support for Code Agents. Our CodeAgent writes its actions in code. we support executing in sandboxed environments via E2B, Modal, Docker, or Pyodide+Deno WebAssembly sandbox.
  - Hub integrations: you can share/pull tools or agents to/from the Hub for instant sharing o
  - Model-agnostic: smolagents supports any LLM. It can be a local transformers or ollama model
  - support text, vision, video, even audio inputs
  - Tool-agnostic: you can use tools from any MCP server, from LangChain, you can even use a Hub Space as a tool.

- https://github.com/apocas/restai /431Star/apache2/202508/python
  - https://apocas.github.io/restai/
  - an AIaaS (AI as a Service) open-source platform. 
  - Built on top of LlamaIndex & Langchain. langchainä»…ç”¨äºdalle_image_generator, LlamaIndexç”¨å¾—å¤š
  - Supports any public LLM supported by LlamaIndex and any local LLM supported by Ollama/vLLM/etc
  - Built-in image generation (Dall-E, SD, Flux) and dynamic loading generators.
  - Image Generation: Supports local and remote image generators. 
    - Local image generators are run in a separate process. 
    - New generators are easily added and loaded dynamically.
    - æœ¬åœ°çš„å›¾ç‰‡ç”ŸæˆåŸºäºdiffuserså®ç°ï¼Œ å¦‚ `from diffusers import DiffusionPipeline`;
  - Proxy: Allows management of an OpenAI compatible proxy. LiteLLM is supported out of the box.
  - Projects: There are multiple project types, each with its own features. (rag, ragsql, inference, vision, router, agent)
  - The API is a first-class citizen of RestAI. All endpoints are documented using Swagger.
  - There are two vectorstores supported: ChromaDB and RedisVL
  - https://github.com/apocas/restai-frontend /202505/js/inactive
    - ä¾èµ–mui.v5ã€@reduxjs/toolkitã€echartsã€mui-datatablesã€react-d3-treeã€recharts

- https://github.com/The-Pocket/PocketFlow /8.2kStar/MIT/202508/python
  - https://the-pocket.github.io/PocketFlow/
  - Pocket Flow is a 100-line minimalist LLM framework
  - Lightweight: Just 100 lines. Zero bloat, zero dependencies, zero vendor lock-in.
  - Expressive: Everything you loveâ€”(Multi-)Agents, Workflow, RAG, and more.
  - Agentic Coding: Let AI Agents (e.g., Cursor AI) build Agentsâ€”10x productivity boost!
  - https://github.com/The-Pocket/PocketFlow-Typescript
  - https://github.com/The-Pocket/PocketFlow-Go
  - [I Built Pocket Flow, an LLM Framework in just 100 Lines â€” Here is Why _202503](https://medium.com/@zh2408/i-built-an-llm-framework-in-just-100-lines-83ff1968014b)
  - [Streaming LLM Responses â€” Tutorial For Dummies (Using PocketFlow!) _202505](https://medium.com/@zh2408/streaming-llm-responses-tutorial-for-dummies-using-pocketflow-417ad920c102)

- https://github.com/Osly-AI/Pocket-Flow-Framework /664Star/MIT/202502/ts/inactive
  - https://Osly-AI.github.io/Pocket-Flow-Framework
  - Enabling nonâ€‘developers to create custom AI workflows with natural language.
  - The original core abstraction behind the Pocketflow Platform
  - This repo contains the original Pocketflow Frameworkâ€”the Nested Directed Graph engine that underpins oneâ€‘shot workflow generation on Pocketflow. Workflows on the platform wrap around this framework, providing a consistent execution model and state management layer.
  - Nested Directed Graph: Breaks complex tasks into reusable nodes with branching and recursion.
  - Oneâ€‘Shot Assembly: Core abstraction powering promptâ€‘based workflow creation.
  - Modular Nodes: Each node is an independent processing unit.
  - Vendorâ€‘Agnostic: Integrate any LLM or API without extra wrappers.
  - Debug-Friendly: Inspect state and trace execution paths easily.

## deep-research

- https://github.com/bytedance/deer-flow /16.1kStar/MIT/202508/python/ts
  - https://deerflow.tech/
  - community-driven Deep Research framework, combining language models with tools like web search, crawling, and Python execution
  - DeerFlow implements a modular multi-agent system architecture designed for automated research and code analysis. 
  - The system is built on LangGraph, enabling a flexible state-based workflow where components communicate through a well-defined message passing system.
  - DeerFlow uses LangGraph for its workflow architecture. You can use LangGraph Studio to debug and visualize the workflow in real-time.
  - DeerFlow now includes a Text-to-Speech (TTS) feature that allows you to convert research reports to speech.

- https://github.com/langchain-ai/local-deep-researcher /8kStar/MIT/202508/python
  - a fully local web research assistant that uses any LLM hosted by Ollama or LMStudio.
  - By default, it will use DuckDuckGo for web search, which does not require an API key. But you can also use SearXNG, Tavily or Perplexity by adding their API keys to the environment file
  - [Building a fully local research assistant from scratch with Ollama - YouTube _202412](https://www.youtube.com/watch?v=XGuTzHoqlj8)

- https://github.com/langchain-ai/open_deep_research /7.4kStar/MIT/202508/python
  - a simple, configurable, fully open source deep research agent that works across many model providers, search tools, and MCP servers.
  - By default it uses the Tavily search API.
  - [Local Open Deep Research with Offline Wikipedia Search Source : r/LocalLLaMA _202510](https://www.reddit.com/r/LocalLLaMA/comments/1nx5w8m/local_open_deep_research_with_offline_wikipedia/)
    - I created my own branch of the deep research repo and added functionality to enable fully offline Wikipedia search to decrease the per-report cost even further
    - [Wikipedia Deep Research](https://publish.obsidian.md/neutron/Published/Projects/10-03-25+Wikipedia+Deep+Research)

- https://github.com/assafelovic/gpt-researcher /24.1kStar/apache2/202511/python/ts
  - https://gptr.dev/
  - An LLM agent that conducts deep research (local and web) on any given topic and generates a long report with citations.

## router/gateway

- https://github.com/Egham-7/adaptive-ai-provider /202510/ts
  - https://llmadaptive.uk/
  - The Adaptive AI Provider for the AI SDK contains language model support for adaptive provider selection across multiple AI services
  - Intelligent Model Selection - Automatically picks optimal models
  - Multi-Provider - OpenAI, Anthropic, Google, DeepSeek, Groq, etc.
  - [Adaptive AI Provider for the Vercel AI SDK â€” real-time model routing using UniRoute (Google Research) : r/vercel _202510](https://www.reddit.com/r/vercel/comments/1o5itci/adaptive_ai_provider_for_the_vercel_ai_sdk/)
    - Itâ€™s based on UniRoute, Google Researchâ€™s new framework for universal model routing across unseen LLMs.
    - Adaptive automatically chooses which LLM to use for every request based on prompt complexity and live model performance.
    - It runs automated evals continuously in the background, clusters prompts by domain, and routes each query to the smallest feasible model that maintains quality.
    - it performs live eval-based routing using UniRouteâ€™s cluster-based generalization method, which can handle unseen LLMs without retraining.
    - Typical savings: 60â€“90% lower inference cost.
    - Routing overhead: ~10 ms.

- https://github.com/maximhq/bifrost /718Star/apache2/202510/go/ts
  - https://www.getmaxim.ai/bifrost
  - Fastest LLM gateway (50x faster than LiteLLM) with adaptive load balancer, cluster mode, guardrails, 1000+ models support & <100 Âµs overhead at 5k RPS.
  - Bifrost is a high-performance AI gateway that unifies access to 12+ providers (OpenAI, Anthropic, AWS Bedrock, Google Vertex, and more) through a single OpenAI-compatible API.
  - Multi-Provider Support - OpenAI, Anthropic, AWS Bedrock, Google Vertex, Azure, Cohere, Mistral, Ollama, Groq, and more
  - Automatic Fallbacks - Seamless failover between providers and models with zero downtime
  - Multimodal Support - Support for text, images, audio, and streaming, all behind a common interface.

- https://github.com/Dominic-Shirazi/ConductorAPI /MIT/202512/python/js
  - a powerful organization layer for your local AI API traffic. 
  - A single OpenAI-compatible endpoint that routes AI API requests and spins local models up or down to manage VRAM
  - Run Multiple Automation Tasks: Execute coding agents, chat bots, and summarizers simultaneously without conflict. The orchestrator queues them and switches models instantly.
  - Resource Management: Only one VRAM-heavy model runs at a time. The system automatically unloads idle models and loads the next one required.
  - Route Aliases: Use stable names like route:coding or route:chat. If your primary model is down or overloaded, the system can automatically fall back to another model (local or cloud).
  - Extensibility: Add any OpenAI-compatible provider (Groq, weak-to-strong-generalization rigs, custom RAG APIs) just by dropping a YAML file in the providers/ folder.
  - [Local AI: Managing VRAM by dynamically swapping models via API : r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/comments/1pm36fl/local_ai_managing_vram_by_dynamically_swapping/)
    - Dynamically loads and unloads models on demand (easy to add additional runtimes)
      - Runs one request at a time using a queue to avoid VRAM contention, and groups requests for the same model together to reduce reload overhead
      - The next step is intelligently running more than one model concurrently when VRAM allows.
      - The core idea is treating models as on-demand workloads rather than long-running processes.
    - ğŸ¤” This is now natively supported by llama.cpp.
      - llama.cpp can run image generation, video generation, audio generation and text generation?
    - I'd want to 'set' the limit to be 92GB so I still have VRAM for the system, and for it to close down applications. I've been thinking how to make it more efficient.
      - This is where I'm looking for either V2 or V3 to go. Although my system is much lighter, that assigned to this with concurrency and VRAM monitoring insight.

- https://huggingface.co/katanemo/Arch-Router-1.5B /LlamaLic/qwen2
  - [I built the HuggingChat Omni Router : r/ollama _202510](https://www.reddit.com/r/ollama/comments/1odn14n/i_built_the_huggingchat_omni_router/)
  - HuggingFace relaunched their chat app called Omni with support for 115+ LLMs.
  - The critical unlock in Omni is the use of a policy-based approach to model selection. I built that policy-based router: https://huggingface.co/katanemo/Arch-Router-1.5B
  - The core insight behind our policy-based router was that it gives developers the constructs to achieve automatic behavior, grounded in their own evals of which LLMs are best for specific coding tasks like debugging, reviews, architecture, design or code gen
  - Essentially, the idea behind this work was to decouple task identification (e.g., code generation, image editing, q/a) from LLM assignment.
  - The model is also integrated as a first-class primitive in archgw: a models-native proxy server for agents. 
  - https://github.com/katanemo/archgw /4.2kStar/apache2/202510/rust/python
    - https://archgw.com/
    - Arch is a models-native proxy server that handles the plumbing work in AI: agent routing & hand off, guardrails, end-to-end logs and traces, unified access to LLMs from OpenAI, Anthropic, Ollama, etc.
    - Arch handles the pesky plumbing work in building AI agents â€” like applying guardrails, routing prompts to the right agent, generating hyper-rich information traces for RL, and unifying access to any LLM.
    - Arch runs alongside app servers as a containerized process, and builds on top of `Envoy`'s proven HTTP management and scalability features to handle ingress and egress traffic related to prompts and LLMs.
    - Arch was built by the contributors of Envoy Proxy with the belief that: Prompts are nuanced and opaque user requests, which require the same capabilities as traditional HTTP requests including secure handling, intelligent routing, robust observability, and integration with backend (API) systems to improve speed and accuracy for common agentic scenarios â€“ all outside core application logic.

- https://github.com/songquanpeng/one-api /27.7kStar/MIT/202502/go/js/inactive
  - LLM API ç®¡ç† & åˆ†å‘ç³»ç»Ÿï¼Œæ”¯æŒ OpenAIã€Azureã€Anthropic Claudeã€Google Geminiã€DeepSeekã€å­—èŠ‚è±†åŒ…
  - æ”¯æŒé…ç½®é•œåƒä»¥åŠä¼—å¤šç¬¬ä¸‰æ–¹ä»£ç†æœåŠ¡ã€‚
  - æ”¯æŒä»¤ç‰Œç®¡ç†ï¼Œè®¾ç½®ä»¤ç‰Œçš„è¿‡æœŸæ—¶é—´ã€é¢åº¦ã€å…è®¸çš„ IP èŒƒå›´ä»¥åŠå…è®¸çš„æ¨¡å‹è®¿é—®ã€‚
  - ğŸ´ forks
  - https://github.com/MartialBE/one-hub /apache2/202510/go/js
    - https://one-hub.xiao5.info/
    - OpenAI æ¥å£ç®¡ç† & åˆ†å‘ç³»ç»Ÿï¼Œæ”¹è‡ªsongquanpeng/one-apiã€‚æ”¯æŒæ›´å¤šæ¨¡å‹ï¼ŒåŠ å…¥ç»Ÿè®¡é¡µé¢ï¼Œå®Œå–„éopenaiæ¨¡å‹çš„å‡½æ•°è°ƒç”¨ã€‚
- https://github.com/QuantumNous/new-api /11.7kStar/AGPL+LOGO/202510/go/js
  - https://www.newapi.ai/
  - AIæ¨¡å‹èšåˆç®¡ç†ä¸­è½¬åˆ†å‘ç³»ç»Ÿï¼Œæ”¯æŒå°†å¤šç§å¤§æ¨¡å‹è½¬ä¸ºç»Ÿä¸€æ ¼å¼è°ƒç”¨ï¼Œæ”¯æŒOpenAIã€Claudeã€Geminiç­‰æ ¼å¼ï¼Œå¯ä¾›ä¸ªäººæˆ–è€…ä¼ä¸šå†…éƒ¨ç®¡ç†ä¸åˆ†å‘æ¸ é“ä½¿ç”¨
  - æ–°ä¸€ä»£å¤§æ¨¡å‹ç½‘å…³ä¸AIèµ„äº§ç®¡ç†ç³»ç»Ÿ
  - åœ¨One APIçš„åŸºç¡€ä¸Šè¿›è¡ŒäºŒæ¬¡å¼€å‘
  - [æœ‰æ²¡æœ‰ä»€ä¹ˆèƒ½å¤Ÿèšåˆä¸­è½¬ç«™apiçš„é¡¹ç›®å‘¢ï¼Ÿ - å¼€å‘è°ƒä¼˜ - LINUX DO](https://linux.do/t/topic/1172062)
  - https://github.com/Veloera/Veloera /GPL/202510/go/js
    - ä¼˜ç§€çš„ AI API ç½‘å…³ç³»ç»Ÿ
    - åŸæ±åŸå‘³çš„ New API ä½“éªŒ, å¯¹ç•Œé¢æ— å¤§æ”¹åŠ¨, éµå¾ª GPL 3.0 åè®®, æ— å•†ç”¨é™åˆ¶
    - æ”¯æŒç¤¼å“ç , å…¨å±€æ¯ç”¨æˆ·ä¸€æ¬¡, å¯æ§åˆ¶æ€»ä½¿ç”¨æ¬¡æ•°
    - æ¸ é“ Key ä¸å†åŠ å¯†, å‘é€åˆ°å‰ç«¯æ˜¾ç¤º
    - æœ¬ç¨‹åºåŸºäº new-api äºŒå¼€, æ•°æ®åº“ç»“æ„åŸºæœ¬å…¼å®¹, ä¼šè‡ªåŠ¨è¿è¡Œè¿ç§».

- https://github.com/deanxv/done-hub /apache2/202510/go/js
  - åŸºäºone-hubäºŒæ¬¡å¼€å‘è€Œæ¥çš„
  - [åŸºäº One-Hub çš„äºŒå¼€é¡¹ç›® Done-Hub ](https://linux.do/t/topic/712560)
    - æ”¯æŒ /gemini åŸç”Ÿç”Ÿå›¾è¯·æ±‚çš„é¢å¤–å‚æ•°é€ä¼ 
    - æ”¯æŒ gemini-2.0-flash-preview-image-generation æ–‡ç”Ÿå›¾ / å›¾ç”Ÿå›¾ï¼Œå¹¶å…¼å®¹ OpenAI å¯¹è¯æ¥å£

- https://github.com/tbphp/gpt-load /5.4kStar/MIT/202510/go/ts/vue
  - https://www.gpt-load.com/
  - æ™ºèƒ½å¯†é’¥è½®è¯¢çš„å¤šæ¸ é“ AI ä»£ç†

- https://github.com/qixing-jk/all-api-hub /MIT/202510/ts
  - https://qixing-jk.github.io/all-api-hub/
  - ä¸€ä¸ªå¼€æºçš„æµè§ˆå™¨æ’ä»¶ï¼Œèšåˆç®¡ç†æ‰€æœ‰ä¸­è½¬ç«™è´¦å·çš„ä½™é¢ã€æ¨¡å‹å’Œå¯†é’¥ï¼Œå‘Šåˆ«ç¹çç™»å½•ã€‚
  - æœ¬é¡¹ç›®ä¸ºå¼€æºé¡¹ç›®ï¼Œåœ¨One API Hubçš„åŸºç¡€ä¸Šè¿›è¡ŒäºŒæ¬¡å¼€å‘
  - https://github.com/fxaxg/one-api-hub /MIT

- https://github.com/eraycc/API-Gateway-Manager /202511/ts
  - åŸºäº Next.js çš„ AI API ä¸­è½¬ç«™ç®¡ç†ç³»ç»Ÿ
  - æ”¯æŒå¤šç”¨æˆ·ã€API ç«™ç‚¹ç®¡ç†ã€æ¨¡å‹æµ‹è¯•ä¸ç»Ÿä¸€è®¤è¯
  - åŒç³»ç»Ÿç™»å½•ï¼šç”¨æˆ·ç³»ç»Ÿ + ç®¡ç†å‘˜ç³»ç»Ÿ, ç®¡ç†å‘˜å¯æ— ç¼åˆ‡æ¢ç”¨æˆ·/ç®¡ç†ç³»ç»Ÿ
  - å¤šç«™ç‚¹æ”¯æŒï¼šç®¡ç†å¤šä¸ª AI API ä¸­è½¬ç«™
  - é¢åº¦æŸ¥è¯¢ï¼šå®æ—¶æŸ¥è¯¢ API ä½¿ç”¨é¢åº¦ï¼ˆç›®å‰ä»…é™ newapiï¼‰

## agent-fwk-vendors

- https://github.com/firebase/genkit /5.2kStar/apache2/202512/ts
  - https://genkit.dev/
  - open-source framework for building full-stack AI-powered applications, built and used in production by Google's Firebase
  - It provides SDKs for js/python/go
  - It offers a unified interface for integrating AI models from providers like Google, OpenAI, Anthropic, Ollama, and more. 
# ai-api

# browser-use
- https://github.com/browser-use/browser-use /57.9kStar/MIT/202504/python/js
  - https://browser-use.com/
  - Enable AI to control your browser
  - [Pack æ‹†è§£ browser-use é¡¹ç›® ](https://quaily.com/silico-anatomy/packs/110)
- https://github.com/browser-use/web-ui /MIT/202504/python
  - This project builds upon the foundation of the browser-use, which is designed to make websites accessible for AI agents.
  - WebUI: is built on Gradio and supports most of browser-use functionalities.
  - support for various Large Language Models (LLMs), including: Google, OpenAI, Azure OpenAI, Anthropic, DeepSeek, Ollama etc. 
  - You can choose to keep the browser window open between AI tasks, allowing you to see the complete history and state of AI interactions.

- https://github.com/microsoft/playwright-mcp /apache2/202503/ts
  - A Model Context Protocol (MCP) server that provides browser automation capabilities using Playwright. 
  - This server enables LLMs to interact with web pages through structured accessibility snapshots, bypassing the need for screenshots or visually-tuned models.
  - https://x.com/playwrightweb/status/1904265499422409047
    - we went ahead and built an MCP server for Playwright. Ours is snapshot-based, which makes it faster and more reliable! You can opt into the visual mode too.

- https://github.com/Skyvern-AI/skyvern /AGPL/202506/python/ts
  - https://www.skyvern.com/
  - Skyvern automates browser-based workflows using LLMs and computer vision. 
  - It provides a simple API endpoint to fully automate manual workflows on a large number of websites
  - Instead of only relying on code-defined XPath interactions, Skyvern relies on Vision LLMs to interact with the websites.
  - Skyvern Cloud is a managed cloud version of Skyvern that allows you to run Skyvern without worrying about the infrastructure
    - It allows you to run multiple Skyvern instances in parallel and comes bundled with anti-bot detection mechanisms, proxy network, and CAPTCHA solvers.
  - Skyvern starts running the task in a browser that pops up and closes it when the task is done
  - Skyvern was inspired by the Task-Driven autonomous agent design popularized by BabyAGI and AutoGPT -- with one major bonus: we give Skyvern the ability to interact with websites using browser automation libraries like Playwright.

- https://github.com/browserbase/stagehand /11.3kStar/MIT/202504/ts
  - https://stagehand.dev/
  - An AI web browsing framework focused on simplicity and extensibility.
  - Stagehand is the easiest way to build browser automations. It is fully compatible with Playwright, offering three simple AI APIs on top of the base Playwright `Page` class
  - It works best when your code is a sequence of atomic actions.
  - Stagehand allows you to write durable, self-healing, and repeatable web automation workflows that actually work.
  - https://github.com/browserbase/mcp-server-browserbase
  - https://github.com/browserbase/sdk-node

- https://github.com/browserless/browserless /10kStar/SSPL-NC/202504/ts
  - https://browserless.io/
  - Browserless allows remote clients to connect and execute headless work, all inside of docker. 
  - It supports the standard, unforked Puppeteer and Playwright libraries, as well offering REST-based APIs for common actions like data collection, PDF generation and more.
  - Parallelism and request-queueing are built-in + configurable.
  - Works with unforked Puppeteer and Playwright.
  - An interactive puppeteer debugger, so you can see what the headless browser is doing and use its DevTools.
  - Support for running and development on Apple's M1 machines
  - ğŸ’° If you want to use Browserless to build commercial sites, applications, or in a continuous-integration system that's closed-source, then you'll need to purchase a commercial license.
  - ğŸ’¡ Browserless listens for both incoming websocket requests, generally issued by most libraries, as well as pre-build REST APIs to do common functions (PDF generation, images and so on). When a websocket connects to Browserless it starts Chrome and proxies your request into it. 
    - Once the session is done then it closes and awaits for more connections. 
    - Some libraries use Chrome's HTTP endpoints, like /json to inspect debug-able targets, which Browserless also supports.

- https://github.com/rebrowser/rebrowser-patches /202506/js
  - Collection of patches for puppeteer and playwright to avoid automation detection and leaks. 
  - Helps to avoid Cloudflare and DataDome CAPTCHA pages. 
  - Easy to patch/unpatch, can be enabled/disabled on demand.
# computer/container-use
- https://github.com/bytedance/UI-TARS-desktop /9.6kStar/apache2/202503/ts
  - https://agent-tars.com/
  - A GUI Agent application based on UI-TARS(Vision-Language Model) that allows you to control your computer using natural language.
  - â“ agent-tarsä¼¼ä¹æ”¯æŒreplayï¼Œui-tarsæ˜¯å¦æ”¯æŒreplay
  - https://x.com/Nin19536/status/1905975354227040314
    - ä» TARS çš„å¼€æº repo å­¦åˆ°çš„ä¸¤ä¸ªæ¶æ„ç‰¹ç‚¹
    - 1ï¸âƒ£mcp ç»Ÿä¸€å·¥å…·åè®®: å¯æ’æ‹”ï¼Œå¯æ‰©å±•éå¸¸å…³é”®ï¼Œä¸” tool å®šä¹‰å’Œ tool æ‰§è¡Œå¯¹å¤–åªæš´éœ²æ¥å£ï¼Œagent ç«¯ä¸å…³å¿ƒå®ç°ã€‚
    - 2ï¸âƒ£äº‹ä»¶ç®¡ç†: ç®¡ç†å¥½æ‰€æœ‰æµå¼è¾“å‡ºã€ä»»ä½•å·¥å…· updateï¼Œéƒ½éœ€è¦è€ƒè™‘åˆ°å‰ç«¯å±•ç¤º event çš„æ–¹å¼ï¼Œæä¾›æ›´å¥½äº¤äº’ã€‚è€Œä¸”äº‹ä»¶ç®¡ç†æœ‰åˆ©äºæ¨¡å‹ç»Ÿä¸€ç®¡ç†ä¸Šä¸‹æ–‡ã€‚ä»¥äº‹ä»¶æ—¶é—´æˆ³æ°¸è¿œè‡ªå¢ï¼Œä¾¿äºæ—¶é—´å›æº¯å’Œç”¨æˆ·è§‚æµ‹ã€‚
  - [2025-03-18] We released a technical preview version of a new desktop app - Agent TARS, a multimodal AI agent that leverages browser operations by visually interpreting web pages and seamlessly integrating with command lines and file systems.
    - Comprehensive Tool Support: Integrates with search, file editing, command line, and Model Context Protocol (MCP) tools to handle complex workflows.
  - https://github.com/bytedance/UI-TARS /apache2
    - UI-TARS is a next-generation native GUI agent model designed to interact seamlessly with graphical user interfaces (GUIs) using human-like perception, reasoning, and action capabilities. 
    - Unlike traditional modular frameworks, UI-TARS integrates all key componentsâ€”perception, reasoning, grounding, and memoryâ€”within a single vision-language model (VLM), enabling end-to-end task automation without predefined workflows or manual rules.
    - This project builds upon and extends the capabilities of Qwen2-VL, a powerful vision-language model, which serves as the foundational architecture for UI-TARS. 
  - https://github.com/web-infra-dev/Midscene /MIT/ts
    - open-source web automation SDK that has supported UI-TARS model. 
    - Midscene.js lets AI be your browser operator. Just describe what you want to do in natural language, and it will help you operate web pages, validate content, and extract data. 
    - Besides the default model GPT-4o, we have added two new recommended open-source models to Midscene.js: UI-TARS and Qwen2.5-VL. (Yes, Open Source !) 
    - Supports Puppeteer and Playwright integration, allowing you to combine AI capabilities with these powerful automation tools
    - Visual Reports for Debugging ğŸï¸: Through our test reports and Playground, you can easily understand, replay and debug the entire process.
    - [Midscene.js - Joyful Automation by AI - Midscene.js](https://midscenejs.com/index.html#visualized-report)  
      - Midscene wants to provide a way to make automation more stable and easier to debug, so we provide a visual report after each run. With this report, you can review the animated replay and view the details of each step in the process.

- https://github.com/e2b-dev/open-computer-use /apache2/202503/python
  - A secure cloud Linux computer powered by E2B Desktop Sandbox and controlled by open-source LLMs.
  - Uses E2B for secure Desktop Sandbox
  - Operates the computer via the keyboard, mouse, and shell commands
  - Supports 10+ LLMs, OS-Atlas/ShowUI and any other models you want
  - Live streams the display of the sandbox on the client computer
  - User can pause and prompt the agent at any time
  - Uses Ubuntu, but designed to work with any operating system
  - [How I taught an AI to use a computer _202501](https://blog.jamesmurdza.com/how-i-taught-an-ai-to-use-a-computer)

- https://github.com/Aident-AI/open-cuak /apache2/202503/ts
  - https://aident.ai/
  - Open CUA Kit (Computer Use Agent), is THE platform for teaching, hiring and managing automation agents at scale â€” starting with browsers.
  - Open-CUAK is designed to run and manage thousands of automation agents, ensuring each one is reliable.
  - Run Operator-like automation workflows locally, ensuring full privacy

- https://github.com/bytebot-ai/bytebot /MIT/202505/ts
  - Bytebot is the container for desktop agents.
  - Bytebot spins up a containerized Linux desktop you can drive programmatically or via VNCâ€”perfect for automation, scraping, CI tasks, and remote work.
  - https://x.com/zhangjintao9020/status/1911379146665603542
    - å®é™…ä¸Šæ˜¯ä¸€ä¸ª xface æ¡Œé¢ç¯å¢ƒçš„ Ubuntuï¼Œé€šè¿‡ VNC æˆ–æµè§ˆå™¨æ¥ç®¡ç†è®¿é—®
    - ç»“åˆ CF å³å°†åˆ°æ¥çš„æ— çŠ¶æ€å®¹å™¨åŒ–ï¼
# acp/agent-client-protocol
- https://github.com/RAIT-09/obsidian-agent-client /127Star/apache2/202512/ts
  - Bring AI agents into Obsidian via Agent Client Protocol (ACP), such as Claude Code, Codex and Gemini CLI.
  - This plugin lets you chat with Claude Code, Codex, Gemini CLI, and other AI agents right from your vault.
  - Multi-Agent Support: Switch between Claude Code, Codex, Gemini CLI, and custom agents
  - Note Mention Support: @notename to reference specific notes
  - Use / commands to browse and trigger actions provided by your current agent
  - Permission Management: Fine-grained control over agent actions

- https://github.com/marimo-team/use-acp /apache2/202510/ts
  - https://marimo-team.github.io/use-acp/
  - React hooks for Agent Client Protocol (ACP) over WebSockets.
  - Reactive state management
# mcp
- https://github.com/upstash/context7 /34kStar/MIT/202510/ts
  - https://context7.com/
  - Context7 MCP - Up-to-date Code Docs For Any Prompt
  - Context7 MCP pulls up-to-date, version-specific documentation and code examples straight from the source â€” and places them directly into your prompt.
  - require Context7 API Key (Optional) for higher rate limits and private repositories 
  - [Feature Request: Option to Self-Host Documentation Backend _202504](https://github.com/upstash/context7/issues/59)
    - interesting idea. I will think about this. the biggest obstacle would be licensing. we aim to make this service free for developers and open source projects. but we want to commercialize if a company like cursor needs it.
    - but we can keep parser private and web backend open.
    - maybe you can store all the docs in a public database, that way anyone can self-host.
    - Another option is to allow companies to host their documentation on context7's servers privately, and support authentication.

- https://github.com/jlowin/fastmcp /MIT/202503/python
  - https://github.com/modelcontextprotocol/python-sdk
  - The fast, Pythonic way to build Model Context Protocol servers
  - ä¾èµ–pydantic2ã€httpx
  - You can now find FastMCP as part of the official Model Context Protocol Python SDK
    - this repository is no longer maintained.

- https://github.com/AIDC-AI/Pixelle-MCP /271Star/MIT/202508/python
  - https://pixelle.ai/
  - Open-Source Multimodal AIGC Solution based on ComfyUI + MCP + LLM
  - An AIGC solution based on the MCP protocol, seamlessly converting ComfyUI workflows into MCP tools
  - Server-side is built on ComfyUI, inheriting all capabilities from the open ComfyUI ecosystem
  - MCP Server provides functionality based on the MCP protocol, supporting integration with any MCP client (including but not limited to Cursor, Claude Desktop, etc.)
  - MCP Client is developed based on the `Chainlit` framework, inheriting Chainlit's UI controls
  - Integrated the LiteLLM framework, adding multi-model support for Gemini, DeepSeek, Claude, Qwen, and more
  - Flexible Deployment: Supports standalone deployment of Server-side only as MCP Server, or standalone deployment of Client-side only as MCP Client, or combined deployment
  - Unified Configuration: Uses YAML configuration scheme, one config file manages all services
  - https://github.com/Chainlit/chainlit /10.5kStar/apache2/202508/python/ts
    - https://docs.chainlit.io/
    - Build python production-ready conversational AI applications in minutes
    - As of May 1st 2025, the original Chainlit team has stepped back from active development.
    - ä¾èµ–langchainã€LlamaIndexã€ChromaDB

- https://github.com/mark3labs/mcp-filesystem-server /go
  - Go server implementing Model Context Protocol (MCP) for filesystem operations.
  - é€šè¿‡è¿™ä¸ªMCPå°±å¯ä»¥æ“ä½œæœ¬åœ°æ–‡ä»¶ç³»ç»Ÿäº†ï¼Œç”±äºè¿™ä¸ªæ˜¯goç¼–å†™çš„ï¼Œgoèƒ½äº¤å‰ç¼–è¯‘çš„æ¶æ„ç‰¹åˆ«å¤šï¼Œæ‰€ä»¥ç†è®ºä¸Šå¤§éƒ¨åˆ†ç³»ç»Ÿéƒ½èƒ½è¿è¡Œè¿™ä¸ªMCP Serverã€‚

- https://github.com/mcpc-tech/mcpc /MIT/202510/ts
  - https://mcpc.tech/
  - MCPC is the SDK for building agentic MCP (Model Context Protocol) Servers.
  - Build Multi-Agent Systems: By defining each agent as a MCP tool, you can compose and orchestrate them to construct sophisticated, collaborative multi-agent systems
  - Compose MCP servers as building blocks, select and customize tools, or modify their descriptions and parameters
  - Logging and tracing: Built-in MCP logging and OpenTelemetry tracing support
  - https://github.com/mcpc-tech/ai-elements-remix-template /MIT/202510/ts
    - https://ai-elements-remix-template.pages.dev/
    - A modern chat interface template built with AI SDK and customizable UI components.
    - React Router V7 - Full-stack React framework
    - ACP Support - Connect to any Agent Client Protocol compatible agent like Gemini CLI, Claude Code, or Codex CLI
    - Uses AI SDK with `acp-ai-provider` to enable seamless integration with ACP-compatible AI agents on the web platform using `streamText` and `useChat`
# protocols-ai
- https://github.com/agentclientprotocol/agent-client-protocol /871Star/apache2/202510/rust/ts
  - https://github.com/zed-industries/agent-client-protocol
  - https://agentclientprotocol.com/
  - A protocol for connecting any editor to any agent
  - [Bring Your Own Agent to Zed â€” Featuring Gemini CLI â€” Zed's Blog _202508](https://zed.dev/blog/bring-your-own-agent-to-zed)
# crawler-ai
- https://github.com/mendableai/firecrawl /AGPLv3/202502/python/rust/ts
  - https://firecrawl.dev/
  - Turn entire websites into LLM-ready markdown or structured data. 
  - Scrape, crawl and extract with a single API.
  - The hard stuff: proxies, anti-bot mechanisms, dynamic content (js-rendered), output parsing, orchestration
  - Batching (New): scrape thousands of URLs at the same time with a new async endpoint.
  - open-version: scrape, extract, map, formats, sdk
  - cloud-version: anti-bot, dashboard, actions, browserless, enterprise
  - This project is primarily licensed under AGPLv3
    - However, certain components of this project are licensed under the MIT 
    - The SDKs and some UI components are licensed under the MIT License. 

- https://github.com/getmaxun/maxun /AGPL/202503/ts
  - https://www.maxun.dev/
  - Open-source no-code web data extraction platform. 
  - Maxun lets you create custom robots which emulate user actions and extract data. A robot can perform any of the actions: Capture List, Capture Text or Capture Screenshot. Once a robot is created, it will keep extracting data for you without manual intervention

- https://github.com/dylan-sutton-chavez/llm-web-crawler /202510/python
  - A horizontally scalable web crawling engine designed for structured content extraction. 
  - It performs URL normalization, HTML parsing, Markdown conversion, and LLM post-processing (using xai_sdk with grok). 
  - Output is serialized in line-delimited JSON (`.jsonl`).
  - A crawler functions similarly to how a graph works. Basically, each web page behaves like a node, where a single node can point to n number of websites, and multiple nodes can point to the same website. The navigation of a crawler is based on the same principle as a graph traversal; in this case, I will base it on a breadth-first search (`BFS`) model.
  - The Crawler module implements a horizontal-scalable architecture, where you can create one Crawler module with hundreds of nodes (sharing the same memmory, but managing hundreds of asynchronous processes).
  - ä¾èµ– requestsã€html-to-markdownã€jsonlinesã€xai_sdk
# github-repo
- https://github.com/ahmedkhaleel2004/gitdiagram /MIT/202503/python/ts
  - https://gitdiagram.com/
  - Turn any GitHub repository into an interactive diagram for visualization in seconds.
  - Powered by Claude 3.5 Sonnet for quick and accurate diagrams
  - Public API available for integration (WIP)
  - Frontend: Next.js, TypeScript, Tailwind CSS, ShadCN
  - Backend: FastAPI, Python, Server Actions
  - Database: PostgreSQL (with Drizzle ORM)
  - Deployment: Vercel (Frontend), EC2 (Backend)
  - Analytics: PostHog, Api-Analytics
# perf/large
- https://github.com/MoonshotAI/MoBA /MIT/202502/python
  - Mixture of Block Attention for Long-Context LLMs
  - https://x.com/tuturetom/status/1892753818028216717
    - å¯ä»¥å®ç°è¿‘ä¹æ— é™çš„ä¸Šä¸‹æ–‡çª—å£ï¼Œå°†ä¸€æ•´æœ¬ä¹¦æˆ–ä¸€æ•´ä¸ªä»£ç åº“æ‰”è¿›å»æé—®
# utils
- https://github.com/Olow304/memvid /MIT/202506/python
  - https://pypi.org/project/memvid/
  - Video-based AI memory library. 
  - Store millions of text chunks in MP4 files with lightning-fast semantic search. No database needed.
  - Memvid revolutionizes AI memory management by encoding text data into videos, enabling lightning-fast semantic search across millions of text chunks with sub-second retrieval times. 
  - Unlike traditional vector databases that consume massive amounts of RAM and storage, Memvid compresses your knowledge base into compact video files while maintaining instant access to any piece of information.
  - Video-as-Database: Store millions of text chunks in a single MP4 file
  - Efficient Storage: 10x compression compared to traditional databases
  - PDF Support: Direct import and indexing of PDF documents
  - Built-in Chat: Conversational interface with context-aware responses
  - Pluggable LLMs: Works with OpenAI, Anthropic, or local models
  - Offline-First: No internet required after video generation

## streaming-llm

- https://github.com/globalaiplatform/langdiff /225Star/apache2/202509/python/ts
  - https://langdiff.readthedocs.io/en/latest/
  - https://globalaiplatform.github.io/langdiff/
  - LangDiff is a Python library that solves the hard problems of streaming structured LLM outputs to frontends
  - LangDiff provides intelligent partial parsing with granular, type-safe events as JSON structures build token by token, plus automatic JSON Patch generation for efficient frontend synchronization.
  - Streaming Parsing
    - Define schemas for streaming structured outputs using Pydantic-style models.
    - Receive granular, type-safe callbacks (on_append, on_update, on_complete) as tokens stream in.
    - Derive Pydantic models from LangDiff models for seamless interop with existing libraries and SDKs like OpenAI SDK.
  - Change Tracking
    - Track mutations without changing your code patterns by instrumenting existing Pydantic models, or plain Python dict/list/objects.
    - Generate JSON Patch diffs automatically for efficient state synchronization between frontend and backend.
  - The Problem with Traditional Streaming Approaches
    - Even partial JSON parsing libraries that "repair" incomplete JSON don't fully solve the issues
  - The Coupling Problem
    - tightly coupling frontend UIs to LLM output schemas.
  - âœ¨ LangDiff solves these problems through two key innovations:
    - Intelligent Streaming Parsing: Define schemas that understand the streaming nature of LLM outputs. Get type-safe callbacks for partial updates, complete fields, and new array items as they arrive.
    - Change-Based Synchronization: Instead of streaming raw JSON, track mutations on your application objects and send lightweight JSON Patch diffs to frontends. This decouples UI state from LLM output format.

- [Smooth a stream of LLM tokens into a stream of characters while reducing jitter by stabilising output timing. Explorations of different approaches.](https://gist.github.com/sebinsua/76fc5eb6fc498636bc637b9f10b7e6bf)
  - This approach slows the stream down a little and does generally reduce the jitter (such as pauses and bursts in the token stream). The approach was made based on educated guess-work about what might work and evaluated by eye-balling it instead of in a systematic manner. It is not perfect and sometimes the queue is exhausted only to find that we are waiting on a token. 
  - Another approach might be to extend the function that calculates the delay length by looking at the rate of increase/decrease of the queue size, as this would allow the algorithm to consider 'the future' in its decisions.
  - I experimented trying to put this on the back-end using ai in a Next.js app and a client-side React library on the UI. In order to do so, I had to transform to and from AsyncIterator and ReadableStream
# proxy
- https://github.com/lymanzhao/Ollama-serve /202503/python
  - ä¸€ä¸ª Ollamaè½¬å‘ä»£ç†ï¼Œç”¨äºä¸ºåŸç”Ÿ Ollama æœåŠ¡æ·»åŠ  API å¯†é’¥è®¤è¯åŠŸèƒ½ã€‚
  - è¯¥é¡¹ç›®è§£å†³äº† Ollama å®˜æ–¹ä¸æä¾› API å¯†é’¥éªŒè¯çš„é—®é¢˜ï¼Œä½¿æ‚¨å¯ä»¥æ›´å®‰å…¨åœ°éƒ¨ç½² Ollama æœåŠ¡å¹¶é˜²æ­¢æœªæˆæƒè®¿é—®
# more
- https://github.com/beuaaa/pywinauto_recorder /MIT/202411/python
  - https://pywinauto-recorder.readthedocs.io/
  - A record-replay tool to automate GUI via pywinauto
  - records user interface actions and saves them in a Python script. The saved Python script can be run to replay the user interface actions previously recorded.
  - "Pywinauto recorder" is a unique inspect/record/replay tool in the open source field because it generates reliable scripts without hard-coded coordinates thanks to Pywinauto.
  - The functions of the generated Python script return Pywinauto wrappers so it can be enhanced with Pywinauto methods.
