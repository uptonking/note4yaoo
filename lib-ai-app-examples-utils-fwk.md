---
title: lib-ai-app-examples-utils-fwk
tags: [ai, examples, utils]
created: 2025-02-21T18:20:28.621Z
modified: 2025-02-21T18:20:42.624Z
---

# lib-ai-app-examples-utils-fwk

# guide

# popular
- https://github.com/microsoft/mcp-for-beginners /MIT/202507/python/ts
  - This open-source curriculum introduces the fundamentals of Model Context Protocol (MCP) through real-world, cross-language examples in . NET, Java, TypeScript, JavaScript, and Python.

- https://github.com/langgenius/dify /82.5kStar/apache2/202503/python
  - https://dify.ai/
  - Dify is an open-source LLM app development platform
  - combines AI workflow, RAG pipeline, agent capabilities, model management, observability features and more
  - ä¾èµ–flask-sqlalchemyã€beautifulsoup4ã€celeryã€gunicornã€langfuseã€langsmithã€numpyã€pandasã€pydanticã€starletteã€unstructuredã€python-docxã€boto3
  - å‰ç«¯ä¾èµ– @dagrejs/dagreã€elkjsã€elkjs@lexical/reactã€@next/mdxã€zustandã€swrã€tanstack-query5ã€ahooksã€echarts-for-reactã€immerã€mermaidã€react-markdownã€react-windowã€remark-gfmã€sortablejs
  - license ğŸ’°
    - Unless explicitly authorized by Dify in writing, you may not use the Dify source code to operate a multi-tenant environment.
    - In the process of using Dify's frontend, you may not remove or modify the LOGO or copyright information in the Dify console or applications. 
  - https://github.com/YFGaia/dify-plus /dify-lic
    - Dify-Plus æ˜¯ Dify çš„ä¼ä¸šçº§å¢å¼ºç‰ˆï¼Œé›†æˆäº†åŸºäº gin-vue-admin çš„ç®¡ç†ä¸­å¿ƒï¼Œå¹¶é’ˆå¯¹ä¼ä¸šåœºæ™¯è¿›è¡Œäº†åŠŸèƒ½ä¼˜åŒ–ã€‚
    - Dify-Plus = ç®¡ç†ä¸­å¿ƒ + Dify äºŒå¼€ 
    - åœ¨åŸæœ‰ Dify çš„åŸºç¡€ä¸­ï¼Œè¯¥é¡¹ç›®åšäº†ä¸€äº›äºŒå¼€ä»¥åŠæ–°å¢äº†ç®¡ç†ä¸­å¿ƒçš„åŠŸèƒ½ï¼ŒåŸå…ˆè¿™äº›åŠŸèƒ½åªæ˜¯åœ¨æˆ‘ä»¬ä¼ä¸šå†…éƒ¨ä½¿ç”¨ï¼Œå¯¹å¤–äº¤æµåå‘ç°å¾ˆå¤šä¼™ä¼´ä¹Ÿé‡åˆ°æˆ‘ä»¬ç›¸åŒä¸€äº›ç—›ç‚¹ï¼Œæ•…å°†æˆ‘ä»¬çš„äºŒå¼€å†…å®¹è¿›è¡Œå¼€æº
    - æ–°å¢ï¼šç”¨æˆ·é¢åº¦
    - æ–°å¢ï¼šå¯†é’¥é¢åº¦è®¾ç½®
    - æ–°å¢ ï¼šWeb å…¬å¼€é¡µç™»å½•é‰´æƒ
    - æ–°å¢ï¼šåå°åˆ›å»ºç”¨æˆ·ï¼Œè‡ªåŠ¨é‚€è¯·è¿›ç®¡ç†å‘˜ç©ºé—´
    - æ–°å¢ï¼šsandbox-fullï¼Œä»¥æ”¾å¼€ä»£ç æ‰§è¡ŒèŠ‚ç‚¹å‡½æ•°é™åˆ¶
  - ğŸ› [Token Limit for full Document (10000 Token cut) _202506](https://github.com/langgenius/dify/issues/20604)
    - Dify's Retrieval-Augmented Generation (RAG) module, especially when utilizing the Parent-Child mode with a full document, appears to have a rigid limitation of 10,000 tokens per document. This constraint means that any content exceeding this token count is effectively ignored or truncated before it enters the retrieval process.
    - There is currently no apparent configuration option (for example, in the .env file) that allows users to adjust this maximum token length for RAG processing. 
    - there is no configurable option (neither in .env nor in the UI) to increase the 10,000-token limit in Parent-Child mode.
  - [Helpï¼š How to deal with the Doc Extractor output is too big in Knowledge template ](https://github.com/langgenius/dify/discussions/28889)
    - If the pdf file content is too large and it exceed the max context length of LLM. How to deal with it? 

- https://github.com/cloudflare/agents /MIT/202502/ts
  - https://developers.cloudflare.com/agents/
  - Build and deploy AI Agents on Cloudflare
  - https://x.com/threepointone/status/1895097050439593993
    - an event bus for ai agents

- https://github.com/mozilla-ai/any-agent /1kStar/apache2/202511/python
  - https://mozilla-ai.github.io/any-agent/
  - A single interface to use and evaluate different agent frameworks.
  - Multi-agent can be implemented using Agents-As-Tools.
# agent-framework/backend
- https://github.com/langchain-ai/langchain /113kStar/MIT/202508/python
  - https://python.langchain.com/
  - https://python.langchain.com/docs/introduction/
  - LangChain is a framework for building LLM-powered applications. 
  - langchain-core: Base abstractions for chat models and other components.
  - langchain: Chains, agents, and retrieval strategies that make up an application's cognitive architecture.
  - langgraph: Orchestration framework for combining LangChain components into production-ready applications with persistence, streaming, and other key features
  - LangSmith: Trace and evaluate your language model applications and intelligent agents

- https://github.com/langchain-ai/langchainjs /15.4kStar/MIT/202508/ts
  - https://js.langchain.com/docs/
  - a framework for developing applications powered by language models
  - can be used in: nodejs, Browser, Cloudflare Workers, Deno, VERCEL
  - [Is LangChainJS possible without NodeJS? Â· langchain-ai/langchainjs _202504](https://github.com/langchain-ai/langchainjs/discussions/4494)
    - æ”¯æŒåœ¨æµè§ˆå™¨çº¯å‰ç«¯è¿è¡Œ

- https://github.com/langchain-ai/langgraph /17.1kStar/MIT/202508/python
  - https://langchain-ai.github.io/langgraph/
  - a low-level orchestration framework for building, managing, and deploying long-running, stateful agents.
  - LangGraph does not abstract prompts or architecture
  - Durable execution: Build agents that persist through failures and can run for extended periods, automatically resuming from exactly where they left off.
  - Human-in-the-loop: Seamlessly incorporate human oversight by inspecting and modifying agent state at any point during execution.
  - both short-term working memory for ongoing reasoning and long-term persistent memory across sessions.
  - [Feature request: Source code? Â· Issue Â· langchain-ai/langgraph-studio _202410](https://github.com/langchain-ai/langgraph-studio/issues/154)
    - we're currently not considering open-sourcing the project, as it depends on some parts of LangSmith.
  - [[Docs] Add LangGraph integration examples to JS/TS documentation _202507](https://github.com/orgs/langfuse/discussions/7709)
    - Currently, the Langfuse JS/TS documentation lacks guidance on integrating with LangGraph. 

- https://github.com/langchain-ai/langgraphjs /1.9kStar/MIT/202508/ts
  - https://langchain-ai.github.io/langgraphjs/
  - LangGraph library enables agent orchestration â€” offering customizable architectures, long-term memory, and human-in-the-loop to reliably handle complex tasks.
  - JavaScript port of LangGraph. The architecture is the same conceptually â€” a durable graph of tasks/agents
  - Reliability and controllability. LangGraph persists context for long-running workflows, keeping your agents on course.
  - Low-level and extensible. Build custom agents with fully descriptive, low-level primitives 
  - First-class streaming support. With token-by-token streaming and streaming of intermediate steps, LangGraph gives users clear visibility into agent reasoning and actions as they unfold in real time
  - LangGraph is inspired by Pregel and Apache Beam. The public interface draws inspiration from NetworkX.

- https://github.com/langfuse/langfuse /14.8kStar/MIT+EE/202508/ts
  - https://langfuse.com/docs
  - Langfuse is an open source LLM engineering platform. 
  - It helps teams collaboratively develop, monitor, evaluate, and debug AI applications. 
  - ç³»ç»Ÿå…ƒæ•°æ®å­˜å‚¨åœ¨pg, è§‚æµ‹æ•°æ®å­˜å‚¨åœ¨clickhouseï¼Œé™„ä»¶å­˜å‚¨åœ¨s3
  - Observability: tracking LLM calls and other relevant logic in your app such as retrieval, embedding, or agent actions
  - Prompt Management 
  - Evaluations: supports LLM-as-a-judge, user feedback collection
  - Datasets enable test sets and benchmarks for evaluating your LLM applications
  - LLM Playground is a tool for testing and iterating on your prompts and model configurations
  - [All Langfuse Product Features now Free Open-Source : r/LangChain _202506](https://www.reddit.com/r/LangChain/comments/1l36tte/all_langfuse_product_features_now_free_opensource/)
    - ğŸ’¡ Langfuse is an open-source LangSmith alternative that helps teams collaboratively build, debug, and improve their LLM applications
  - [Self-host Langfuse (Open Source LLM Observability)](https://langfuse.com/self-hosting)

- https://github.com/github/copilot-sdk /5.9kStar/MIT/202601/ts
  - Embed Copilot's agentic workflows in your applicationâ€”now available in Technical preview as a programmable SDK for Python, TypeScript, Go, and . NET.
  - The GitHub Copilot SDK exposes the same engine behind Copilot CLI: a production-tested agent runtime you can invoke programmatically. No need to build your own orchestrationâ€”you define agent behavior, Copilot handles planning, tool invocation, file edits, and more.
  - All SDKs communicate with the Copilot CLI server via JSON-RPC
  - a GitHub Copilot subscription is required to use the GitHub Copilot SDK. 
  - [GitHub introduces Copilot SDK (open source) â€“ anyone can now build Copilot-style agents : r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/comments/1qoa9h5/github_introduces_copilot_sdk_open_source_anyone/)

- https://github.com/K-Mistele/swarm /GPLv3/202501/ts/inactive
  - Model-agnostic typescript implementation of OpenAI's Swarm framework with the Vercel AI SDK
  - model-agnostic library for creating and managing multi-agent AI systems
  - This package is loosely based off of OpenAI Swarm, but please note that APIs are not identical, and they are not intended to be. 
  - This package is intended to provide the same functionality, but with better patterns
- https://github.com/joshmu/ts-swarm /MIT/202507/ts/deprecated
  - Minimal agentic library mixing the simplicity of OpenAI Swarm with the flexibility of the Vercel AI SDK
  - Option to run locally with the ollama-ai-provider.

- https://github.com/microsoft/autogen /48.5kStar/MIT/202508/python
  - https://microsoft.github.io/autogen/
  - a framework for creating multi-agent AI applications that can act autonomously or work alongside humans.
  - æœªä¸»æ‰“workflow
  - The framework uses a layered and extensible design.
  - Core API implements message passing, event-driven agents, and local and distributed runtime for flexibility and power. 
  - AgentChat API implements a simpler but opinionated API for rapid prototyping. 
  - Extensions API enables first- and third-party extensions continuously expanding framework capabilities.
  - AutoGen Studio provides a no-code GUI for building multi-agent applications.
  - AutoGen Bench provides a benchmarking suite for evaluating agent performance.

- https://github.com/crewAIInc/crewAI /35.5kStar/MIT/202508/python
  - https://crewai.com/
  - a lean, lightning-fast Python framework built entirely from scratchâ€”completely independent of LangChain or other agent frameworks.
  - CrewAI's Advantage: CrewAI combines autonomous agent intelligence with precise workflow control through its unique Crews and Flows architecture. 
  - CrewAI Crews: Teams of AI agents with true autonomy and agency, working together to accomplish complex tasks through role-based collaboration
  - CrewAI Flows: Enable granular, event-driven control, single LLM calls for precise task orchestration and supports Crews natively
  - Flexible Low Level Customization: Complete freedom to customize at both high and low levels - from overall workflows and system architecture to granular agent behaviors, internal prompts, and execution logic.
  - Ideal for Every Use Case
  - ğŸ†š How CrewAI Compares
    - While LangGraph provides a foundation for building agent workflows, its approach requires significant boilerplate code and complex state management patterns. The framework's tight coupling with LangChain can limit flexibility when implementing custom agent behaviors or integrating with external systems.
    - Autogen: While Autogen excels at creating conversational agents capable of working together, it lacks an inherent concept of process.
    - ChatDev: ChatDev introduced the idea of processes into the realm of AI agents, but its implementation is quite rigid. Customizations in ChatDev are limited

- https://github.com/mastra-ai/mastra /15.8kStar/apache2/202508/ts
  - https://mastra.ai/
  - ğŸ’« https://mastra.ai/en/docs/server-db/local-dev-playground
  - an opinionated TypeScript framework that helps you build AI applications and features quickly.
  - It gives you the set of primitives you need: workflows, agents, RAG, integrations and evals.
  - ä¸ä¾èµ–langchain/langflow
  - You can run Mastra on your local machine, or deploy to a serverless cloud.
  - Mastra uses the Vercel AI SDK for model routing, providing a unified interface to interact with any LLM provider including OpenAI, Anthropic, and Google Gemini. 
  - Agents are systems where the language model chooses a sequence of actions. 
  - Tools are typed functions that can be executed by agents or workflows, with built-in integration access and parameter validation. 
  - Workflows are durable graph-based state machines. They have loops, branching, wait for human input, embed other workflows
  - RAG lets you construct a knowledge base for agents
  - Evals are automated tests that evaluate LLM outputs using model-graded, rule-based, and statistical methods.
  - https://github.com/mastra-ai/mastra/blob/main/examples/crypto-chatbot/lib/editor/diff.js
    - ä½¿ç”¨diff_match_patchè®¡ç®—å·®å¼‚
  - https://x.com/dingyi/status/1893329741060489438
    - ä»¥å‰éå¸¸å–œæ¬¢ä¸”æ·±åº¦ä½¿ç”¨çš„ Gatsbyï¼Œä»–ä»¬å›¢é˜ŸåŸç­äººé©¬åšçš„æ–°äº§å“ï¼ŒThe TypeScript Agent Framework
  - ğŸ¯ [The next evolution of Mastra streaming _202509](https://mastra.ai/blog/mastra-streaming)
    - When we first built Mastra, we relied entirely on Vercel's AI SDK for streaming. It was a pragmatic choice that let us focus on what made Mastra unique: the orchestration layer that sits above language models.
    - But as developers started building more complex apps with Mastra, we kept hitting the same limitations. What happens when an agent calls another agent? How do you stream results from a workflow that contains multiple agents? 
    - Our old implementation worked beautifully for single model calls, but Mastra needed something more.
    - So we built our own streaming layer.
    - The new `format` option we're introducing (like `format: 'aisdk'`) establishes a pattern where Mastra can output streams in whatever format your frontend needs. Today it's AI SDK v5. Tomorrow it could be `copilotkit`, assistant-ui, or a format we haven't even imagined yet.
    - We've written before about nested streaming, but it bears repeating: modern AI applications are compositional. Agents call other agents. Workflows orchestrate multiple models. Tools can be entire applications themselves. Our custom streaming protocol makes these patterns not just possible but elegant.
  - [streaming v2  _202507](https://github.com/mastra-ai/mastra/pull/5965)
    - A new streaming protocol that allows us to stream all mastra primitives, agent, tools, workflows. (soon networks). Our old protocol was based on Vercel's AI sdk datatprtocol which works great for agents but not for workflows, networks and the future of Mastra.
    - The new protocol allows us to nest streams and calculate usage values of all primitives.

- https://github.com/MotiaDev/motia /5.8kStar/MIT/202508/ts
  - https://motia.dev/
  - Modern Backend Framework that unifies APIs, background jobs, workflows, and AI agents into a single cohesive system with built-in observability and state management.
  - a modern backend framework for building event-driven applications with built-in observability and state management.
  - Motia gives you full, code-first control of your agents and automations with the simplicity of a visual interface, letting you focus on what truly matters: your business logic
  - ä¸ä¾èµ–langchain/langflow
  - æ‰§è¡Œæ—¶è¿›åº¦åŠ¨ç”»æ˜¾ç¤ºåœ¨ä»»åŠ¡ç”»å¸ƒä¸‹æ–¹çš„æ°´å¹³æ¡å½¢å›¾ï¼Œuxè®¾è®¡ä¸ç¬¦åˆä¸»æµ
    - ä½†æ”¯æŒåœ¨æ°´å¹³æ¡å½¢å›¾æ˜¾ç¤ºå„èŠ‚ç‚¹çš„æ‰§è¡Œæ—¶é—´ï¼Œæ•°æ®æ›´å…·ä½“
  - Use any LLM, vector store, or reasoning pattern without restrictions.
  - Zero Infrastructure Headaches - No Kubernetes expertise required. Deploy agents with a single command
  - Code-First Development - Write agent logic in familiar languages, not proprietary DSLs.
  - Composable Steps with Runtime Validation - Build agents from modular, reusable components with automatic input/output validation.
  - Built-in Observability - Debug agent behavior with visual execution graphs and real-time logging.
  - Instant APIs & Webhooks - Expose agent functionality via HTTP endpoints without extra code.
  - https://github.com/MotiaDev/motia-examples /æ•°æ®æµåŠ¨ç”»
    - Intelligent Q&A from PDFs with Docling's smart chunking, Weaviate's sca lable vector DB, and OpenAI embeddings & text generation. 
    - Built with TypeScript & Python.

- https://github.com/gensx-inc/gensx /507Star/apache2/202508/ts
  - https://gensx.com/
  - The TypeScript framework for agents & workflows with react-like components.
  - GenSX takes a lot of inspiration from React, but the programming model is very different - itâ€™s a Node.js framework designed for data flow.
  - ä¸ä¾èµ–langchain/langflow
  - Pure Functions: Components are pure TypeScript functions that are easily testable, reusable, and sharable
  - Parallel by Default: Components execute in parallel when possible while maintaining dependencies
  - Full TypeScript support with no DSLs or special syntax - just standard language features
  - Streaming Built-in: Stream responses with a single prop change, no refactoring needed
  - https://x.com/_Evan_Boyle/status/1892590845485895730
    - GenSX components are reusable by default and are easy to consume and share. 

- https://github.com/google-gemini/gemini-fullstack-langgraph-quickstart /apache2/202506/python/ts
  - Get started with building Fullstack Agents using Gemini 2.5 and LangGraph
  - https://x.com/JvShah124/status/1933016336113791159
    - Gemini 2.5 + LangGraph = Build Research Agents That AUTONOMOUSLY Crawl the Web, Cite Sources & Solve Complex Queries.
    - Backend: Python (FastAPI) + LangGraph for orchestrating multi-step workflows
    - Pluggable AI: Gemini 2.5 by default, but swap in Claude/Mistral via API keys
    - Tools: Google Search API + room to add LlamaIndex, custom APIs, etc.

- https://github.com/huggingface/smolagents /22.5kStar/apache2/202509/python
  - https://huggingface.co/docs/smolagents
  - smolagents is a library that enables you to run powerful agents in a few lines of code.  
  - Simplicity: the logic for agents fits in ~1, 000 lines of code (see agents.py). We kept abstractions to their minimal shape above raw code
  - First-class support for Code Agents. Our CodeAgent writes its actions in code. we support executing in sandboxed environments via E2B, Modal, Docker, or Pyodide+Deno WebAssembly sandbox.
  - Hub integrations: you can share/pull tools or agents to/from the Hub for instant sharing o
  - Model-agnostic: smolagents supports any LLM. It can be a local transformers or ollama model
  - support text, vision, video, even audio inputs
  - Tool-agnostic: you can use tools from any MCP server, from LangChain, you can even use a Hub Space as a tool.

- https://github.com/apocas/restai /431Star/apache2/202508/python
  - https://apocas.github.io/restai/
  - an AIaaS (AI as a Service) open-source platform. 
  - Built on top of LlamaIndex & Langchain. langchainä»…ç”¨äºdalle_image_generator, LlamaIndexç”¨å¾—å¤š
  - Supports any public LLM supported by LlamaIndex and any local LLM supported by Ollama/vLLM/etc
  - Built-in image generation (Dall-E, SD, Flux) and dynamic loading generators.
  - Image Generation: Supports local and remote image generators. 
    - Local image generators are run in a separate process. 
    - New generators are easily added and loaded dynamically.
    - æœ¬åœ°çš„å›¾ç‰‡ç”ŸæˆåŸºäºdiffuserså®ç°ï¼Œ å¦‚ `from diffusers import DiffusionPipeline`;
  - Proxy: Allows management of an OpenAI compatible proxy. LiteLLM is supported out of the box.
  - Projects: There are multiple project types, each with its own features. (rag, ragsql, inference, vision, router, agent)
  - The API is a first-class citizen of RestAI. All endpoints are documented using Swagger.
  - There are two vectorstores supported: ChromaDB and RedisVL
  - https://github.com/apocas/restai-frontend /202505/js/inactive
    - ä¾èµ–mui.v5ã€@reduxjs/toolkitã€echartsã€mui-datatablesã€react-d3-treeã€recharts

- https://github.com/The-Pocket/PocketFlow /8.2kStar/MIT/202508/python
  - https://the-pocket.github.io/PocketFlow/
  - Pocket Flow is a 100-line minimalist LLM framework
  - Lightweight: Just 100 lines. Zero bloat, zero dependencies, zero vendor lock-in.
  - Expressive: Everything you loveâ€”(Multi-)Agents, Workflow, RAG, and more.
  - Agentic Coding: Let AI Agents (e.g., Cursor AI) build Agentsâ€”10x productivity boost!
  - https://github.com/The-Pocket/PocketFlow-Typescript
  - https://github.com/The-Pocket/PocketFlow-Go
  - [I Built Pocket Flow, an LLM Framework in just 100 Lines â€” Here is Why _202503](https://medium.com/@zh2408/i-built-an-llm-framework-in-just-100-lines-83ff1968014b)
  - [Streaming LLM Responses â€” Tutorial For Dummies (Using PocketFlow!) _202505](https://medium.com/@zh2408/streaming-llm-responses-tutorial-for-dummies-using-pocketflow-417ad920c102)

- https://github.com/Osly-AI/Pocket-Flow-Framework /664Star/MIT/202502/ts/inactive
  - https://Osly-AI.github.io/Pocket-Flow-Framework
  - Enabling nonâ€‘developers to create custom AI workflows with natural language.
  - The original core abstraction behind the Pocketflow Platform
  - This repo contains the original Pocketflow Frameworkâ€”the Nested Directed Graph engine that underpins oneâ€‘shot workflow generation on Pocketflow. Workflows on the platform wrap around this framework, providing a consistent execution model and state management layer.
  - Nested Directed Graph: Breaks complex tasks into reusable nodes with branching and recursion.
  - Oneâ€‘Shot Assembly: Core abstraction powering promptâ€‘based workflow creation.
  - Modular Nodes: Each node is an independent processing unit.
  - Vendorâ€‘Agnostic: Integrate any LLM or API without extra wrappers.
  - Debug-Friendly: Inspect state and trace execution paths easily.

- https://github.com/strands-agents/sdk-python /5kStar/apache2/202601/python
  - https://strandsagents.com/
  - A model-driven approach to building AI agents in just a few lines of code.
  - Strands Agents is a simple yet powerful SDK that takes a model-driven approach to building and running AI agents
  - Lightweight & Flexible: Simple agent loop that just works and is fully customizable
  - Model Agnostic: Support for Amazon Bedrock, Anthropic, Gemini, LiteLLM, Llama, Ollama, OpenAI, Writer, and custom providers
  - Advanced Capabilities: Multi-agent systems, autonomous agents, and streaming support
  - Built-in MCP: Native support for Model Context Protocol (MCP) servers, enabling access to thousands of pre-built tools

- https://github.com/badlogic/pi-mono /4.5kStar/MIT/202602/ts
  - AI agent toolkit: coding agent CLI, unified LLM API, TUI & web UI libraries, Slack bot, vLLM pods
  - [Pi: The Minimal Agent Within OpenClaw | Armin Ronacher's Thoughts and Writings _202601](https://lucumr.pocoo.org/2026/1/31/pi/)
  - https://x.com/shao__meng/status/2017745045156467003
    - Pi å¯èƒ½æ˜¯å½“ä»Šç³»ç»Ÿæç¤ºè¯æœ€çŸ­çš„ç¼–ç¨‹ Agentâ€”â€”åªæœ‰ Readã€Writeã€Editã€Bash å››ä¸ªå·¥å…·ï¼Œä½†å®ƒæ”¯æ’‘äº†æœ¬å‘¨äº’è”ç½‘ä¸Šæœ€ç«çš„é¡¹ç›® @openclaw
  - https://x.com/mitsuhiko/status/2017604638137012335
    - Self-extending agents are exciting, but the moment they can rewrite their own tools you need change control like a real system: pinned versions, eval gates, and a rollback path. Otherwise â€œit got betterâ€ turns into â€œit drifted.â€

## deep-research

- https://github.com/666ghj/BettaFish /34.1kStar/GPL/202601/python
  - https://deepwiki.com/666ghj/BettaFish
  - å¾®èˆ†ï¼šäººäººå¯ç”¨çš„å¤šAgentèˆ†æƒ…åˆ†æåŠ©æ‰‹ï¼Œæ‰“ç ´ä¿¡æ¯èŒ§æˆ¿ï¼Œè¿˜åŸèˆ†æƒ…åŸè²Œ
  - æ„å»ºäº†ä» BettaFishï¼ˆæ•°æ®æ”¶é›†ä¸åˆ†æï¼‰åˆ° MiroFishï¼ˆå…¨æ™¯é¢„æµ‹ï¼‰çš„å®Œæ•´é“¾è·¯
  - ğŸ’¡ ä¸ä¸€å®šè¦åšé€šç”¨research, ç»†åˆ†åœºæ™¯çš„äº§å“ä¹Ÿæœ‰ä¼˜ç‚¹

- https://github.com/bytedance/deer-flow /16.1kStar/MIT/202508/python/ts
  - https://deerflow.tech/
  - community-driven Deep Research framework, combining language models with tools like web search, crawling, and Python execution
  - DeerFlow implements a modular multi-agent system architecture designed for automated research and code analysis. 
  - The system is built on LangGraph, enabling a flexible state-based workflow where components communicate through a well-defined message passing system.
  - DeerFlow uses LangGraph for its workflow architecture. You can use LangGraph Studio to debug and visualize the workflow in real-time.
  - DeerFlow now includes a Text-to-Speech (TTS) feature that allows you to convert research reports to speech.

- https://github.com/langchain-ai/local-deep-researcher /8kStar/MIT/202508/python
  - a fully local web research assistant that uses any LLM hosted by Ollama or LMStudio.
  - By default, it will use DuckDuckGo for web search, which does not require an API key. But you can also use SearXNG, Tavily or Perplexity by adding their API keys to the environment file
  - [Building a fully local research assistant from scratch with Ollama - YouTube _202412](https://www.youtube.com/watch?v=XGuTzHoqlj8)

- https://github.com/langchain-ai/open_deep_research /7.4kStar/MIT/202508/python
  - a simple, configurable, fully open source deep research agent that works across many model providers, search tools, and MCP servers.
  - By default it uses the Tavily search API.
  - [Local Open Deep Research with Offline Wikipedia Search Source : r/LocalLLaMA _202510](https://www.reddit.com/r/LocalLLaMA/comments/1nx5w8m/local_open_deep_research_with_offline_wikipedia/)
    - I created my own branch of the deep research repo and added functionality to enable fully offline Wikipedia search to decrease the per-report cost even further
    - [Wikipedia Deep Research](https://publish.obsidian.md/neutron/Published/Projects/10-03-25+Wikipedia+Deep+Research)

- https://github.com/assafelovic/gpt-researcher /24.1kStar/apache2/202511/python/ts
  - https://gptr.dev/
  - An LLM agent that conducts deep research (local and web) on any given topic and generates a long report with citations.

## agent-fwk-vendors

- https://github.com/cuga-project/cuga-agent /341Star/apache2/202512/python/ts/ibm
  - https://huggingface.co/spaces/ibm-research/cuga-agent/tree/main
  - https://cuga.dev/
  - CUGA is an open-source generalist agent for the enterprise, supporting complex task execution on web and APIs, OpenAPI/MCP integrations, composable architecture, reasoning modes, and policy-aware features.
  - High-performing generalist agent â€” Benchmarked on complex web and API tasks. 
  - integrate tools via OpenAPI specs, MCP servers, and Langchain, enabling rapid connection to REST APIs, custom protocols, and Python functions
  - Integrates with Langflow â€” Low-code visual build experience for designing and deploying agent workflows
  - composable â€” Built with modularity in mind, CUGA itself can be exposed as a tool to other agents, enabling nested reasoning and multi-agent collaboration
  - Configurable policy and human-in-the-loop instructions (Experimental)
  - Save-and-reuse capabilities (Experimental) â€” Capture and reuse successful execution paths (plans, code, and trajectories) for faster and consistent behavior across repeated tasks
  - Cuga supports isolated code execution using Docker/Podman containers for enhanced security.
  - [CUGA on Hugging Face: Democratizing Configurable AI Agents _202512](https://huggingface.co/blog/ibm-research/cuga-on-hugging-face)

- https://github.com/firebase/genkit /5.2kStar/apache2/202512/ts
  - https://genkit.dev/
  - open-source framework for building full-stack AI-powered applications, built and used in production by Google's Firebase
  - It provides SDKs for js/python/go
  - It offers a unified interface for integrating AI models from providers like Google, OpenAI, Anthropic, Ollama, and more. 
# router/gateway
- https://github.com/BerriAI/litellm /34kStar/MIT+EE/202601/python/ts
  - https://docs.litellm.ai/docs/
  - Python SDK, Proxy Server (LLM Gateway) to call 100+ LLM APIs in OpenAI format - [Bedrock, Azure, OpenAI, VertexAI, Cohere, Anthropic, Sagemaker, HuggingFace, Replicate, Groq]
  - Translate inputs to provider's completion, embedding, and image_generation endpoints
  - Consistent output, text responses will always be available at ['choices'][0]['message']['content']
  - Set Budgets & Rate limits per project, api key, model

- https://github.com/ssrsgaga/API-Check /MIT/202601/ts
  - https://api-check-beta.vercel.app/
  - å¿«é€Ÿçš„å¤§æ¨¡å‹ API è¿é€šæ€§æµ‹è¯•å·¥å…·ã€‚çº¯å‰ç«¯è¿è¡Œï¼Œæ”¯æŒ OpenAI æ ¼å¼ï¼Œæ•°æ®ä»…åœ¨æœ¬åœ°å­˜å‚¨ã€‚
  - [API Checkå¤§æ¨¡å‹æ‰¹é‡æµ‹æ´»åŠ©æ‰‹ã€å¤šåŠŸèƒ½å…è´¹å¼€æº/Vercelä¸€é”®éƒ¨ç½²/çº¯å‰ç«¯ _202601](https://linux.do/t/topic/1384242)

- https://github.com/maximhq/bifrost /718Star/apache2/202510/go/ts
  - https://www.getmaxim.ai/bifrost
  - Fastest LLM gateway (50x faster than LiteLLM) with adaptive load balancer, cluster mode, guardrails, 1000+ models support & <100 Âµs overhead at 5k RPS.
  - Bifrost is a high-performance AI gateway that unifies access to 12+ providers (OpenAI, Anthropic, AWS Bedrock, Google Vertex, and more) through a single OpenAI-compatible API.
  - Multi-Provider Support - OpenAI, Anthropic, AWS Bedrock, Google Vertex, Azure, Cohere, Mistral, Ollama, Groq, and more
  - Automatic Fallbacks - Seamless failover between providers and models with zero downtime
  - Multimodal Support - Support for text, images, audio, and streaming, all behind a common interface.

- https://github.com/Dominic-Shirazi/ConductorAPI /MIT/202512/python/js
  - a powerful organization layer for your local AI API traffic. 
  - A single OpenAI-compatible endpoint that routes AI API requests and spins local models up or down to manage VRAM
  - Run Multiple Automation Tasks: Execute coding agents, chat bots, and summarizers simultaneously without conflict. The orchestrator queues them and switches models instantly.
  - Resource Management: Only one VRAM-heavy model runs at a time. The system automatically unloads idle models and loads the next one required.
  - Route Aliases: Use stable names like route:coding or route:chat. If your primary model is down or overloaded, the system can automatically fall back to another model (local or cloud).
  - Extensibility: Add any OpenAI-compatible provider (Groq, weak-to-strong-generalization rigs, custom RAG APIs) just by dropping a YAML file in the providers/ folder.
  - [Local AI: Managing VRAM by dynamically swapping models via API : r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/comments/1pm36fl/local_ai_managing_vram_by_dynamically_swapping/)
    - Dynamically loads and unloads models on demand (easy to add additional runtimes)
      - Runs one request at a time using a queue to avoid VRAM contention, and groups requests for the same model together to reduce reload overhead
      - The next step is intelligently running more than one model concurrently when VRAM allows.
      - The core idea is treating models as on-demand workloads rather than long-running processes.
    - ğŸ¤” This is now natively supported by llama.cpp.
      - llama.cpp can run image generation, video generation, audio generation and text generation?
    - I'd want to 'set' the limit to be 92GB so I still have VRAM for the system, and for it to close down applications. I've been thinking how to make it more efficient.
      - This is where I'm looking for either V2 or V3 to go. Although my system is much lighter, that assigned to this with concurrency and VRAM monitoring insight.

- https://github.com/songquanpeng/one-api /27.7kStar/MIT/202502/go/js/inactive
  - LLM API ç®¡ç† & åˆ†å‘ç³»ç»Ÿï¼Œæ”¯æŒ OpenAIã€Azureã€Anthropic Claudeã€Google Geminiã€DeepSeekã€å­—èŠ‚è±†åŒ…
  - æ”¯æŒé…ç½®é•œåƒä»¥åŠä¼—å¤šç¬¬ä¸‰æ–¹ä»£ç†æœåŠ¡ã€‚
  - æ”¯æŒä»¤ç‰Œç®¡ç†ï¼Œè®¾ç½®ä»¤ç‰Œçš„è¿‡æœŸæ—¶é—´ã€é¢åº¦ã€å…è®¸çš„ IP èŒƒå›´ä»¥åŠå…è®¸çš„æ¨¡å‹è®¿é—®ã€‚
  - ğŸ´ forks
  - https://github.com/MartialBE/one-hub /2.6kStar/apache2/202601/go/js
    - https://one-hub-doc.vercel.app/
    - https://one-hub.xiao5.info/  /demo
    - OpenAI æ¥å£ç®¡ç† & åˆ†å‘ç³»ç»Ÿï¼Œæ”¹è‡ªsongquanpeng/one-apiã€‚æ”¯æŒæ›´å¤šæ¨¡å‹ï¼ŒåŠ å…¥ç»Ÿè®¡é¡µé¢ï¼Œå®Œå–„éopenaiæ¨¡å‹çš„å‡½æ•°è°ƒç”¨ã€‚
- https://github.com/QuantumNous/new-api /11.7kStar/AGPL+LOGO/202510/go/js
  - https://www.newapi.ai/
  - AIæ¨¡å‹èšåˆç®¡ç†ä¸­è½¬åˆ†å‘ç³»ç»Ÿï¼Œæ”¯æŒå°†å¤šç§å¤§æ¨¡å‹è½¬ä¸ºç»Ÿä¸€æ ¼å¼è°ƒç”¨ï¼Œæ”¯æŒOpenAIã€Claudeã€Geminiç­‰æ ¼å¼ï¼Œå¯ä¾›ä¸ªäººæˆ–è€…ä¼ä¸šå†…éƒ¨ç®¡ç†ä¸åˆ†å‘æ¸ é“ä½¿ç”¨
  - æ–°ä¸€ä»£å¤§æ¨¡å‹ç½‘å…³ä¸AIèµ„äº§ç®¡ç†ç³»ç»Ÿ
  - åœ¨One APIçš„åŸºç¡€ä¸Šè¿›è¡ŒäºŒæ¬¡å¼€å‘
  - [æœ‰æ²¡æœ‰ä»€ä¹ˆèƒ½å¤Ÿèšåˆä¸­è½¬ç«™apiçš„é¡¹ç›®å‘¢ï¼Ÿ - å¼€å‘è°ƒä¼˜ - LINUX DO](https://linux.do/t/topic/1172062)
  - https://github.com/Veloera/Veloera /GPL/202510/go/js
    - ä¼˜ç§€çš„ AI API ç½‘å…³ç³»ç»Ÿ
    - åŸæ±åŸå‘³çš„ New API ä½“éªŒ, å¯¹ç•Œé¢æ— å¤§æ”¹åŠ¨, éµå¾ª GPL 3.0 åè®®, æ— å•†ç”¨é™åˆ¶
    - æ”¯æŒç¤¼å“ç , å…¨å±€æ¯ç”¨æˆ·ä¸€æ¬¡, å¯æ§åˆ¶æ€»ä½¿ç”¨æ¬¡æ•°
    - æ¸ é“ Key ä¸å†åŠ å¯†, å‘é€åˆ°å‰ç«¯æ˜¾ç¤º
    - æœ¬ç¨‹åºåŸºäº new-api äºŒå¼€, æ•°æ®åº“ç»“æ„åŸºæœ¬å…¼å®¹, ä¼šè‡ªåŠ¨è¿è¡Œè¿ç§».

- https://github.com/deanxv/done-hub /574Star/apache2/202601/go/js
  - https://github.com/MartialBE/one-hub/wiki/Deployment
  - åŸºäºone-hubäºŒæ¬¡å¼€å‘è€Œæ¥çš„
  - ä¼˜å…ˆçº§å¤§çš„ä¼˜å…ˆè°ƒç”¨ï¼ŒåŒä¼˜å…ˆçº§ï¼ŒåŸºäºæƒé‡è½®è¯¢ï¼› æƒ³è¦è½®è¯¢çš„è¯è¿˜æ˜¯åŒä¼˜å…ˆçº§è®¾ç½®æƒé‡
  - ç›®å‰ä¸åŸç‰ˆ(æœ€æ–°é•œåƒ)çš„åŒºåˆ«
    - æ”¯æŒåä»£æ¸ é“
    - æ”¯æŒæ‰¹é‡åˆ é™¤æ¸ é“
    - æ”¯æŒè‡ªå®šä¹‰æ¸ é“ä½¿ç”¨ClaudeåŸç”Ÿè·¯ç”± - æ¥å…¥ClaudeCode
    - æ–°å¢é‚€è¯·ç è®¾ç½®æ¨¡å—
  - [åŸºäº One-Hub çš„äºŒå¼€é¡¹ç›® Done-Hub ](https://linux.do/t/topic/712560)
    - æ”¯æŒ /gemini åŸç”Ÿç”Ÿå›¾è¯·æ±‚çš„é¢å¤–å‚æ•°é€ä¼ 
    - æ”¯æŒ gemini-2.0-flash-preview-image-generation æ–‡ç”Ÿå›¾ / å›¾ç”Ÿå›¾ï¼Œå¹¶å…¼å®¹ OpenAI å¯¹è¯æ¥å£
  - [åŒæ¸ é“å¤šAPIè½®è¯¢åŠŸèƒ½ ](https://github.com/MartialBE/one-hub/issues/791)
    - ç”¨tagå°±è¡Œäº†
    - åœ¨ä¸€ä¸ªtagä¸‹çš„æ¸ é“ï¼Œæ˜¯éšæœºè¿˜æ˜¯è½®è¯¢ï¼Ÿ
    - éšæœºï¼Œä½†æ˜¯ç‰¹å®šæ¡ä»¶å¤±è´¥çš„æ¸ é“å›å†»ç»“ä¸€å®šæ—¶é—´å¹¶åˆ‡æ¢æ¸ é“
  - [feat(openai)ï¼šé€‚é…ä¸€äº›å…¼å®¹openaiæ¥å£çš„urlï¼Œä½†æ˜¯ç‰ˆæœ¬å·ä¸æ˜¯v1çš„  Â· Pull Request Â· MartialBE/one-hub](https://github.com/MartialBE/one-hub/pull/546)
  - [å·²æœ‰æ¸ é“çš„æ¨¡å‹æ˜ å°„æ— æ³•æ­£åˆ æ”¹æŸ¥ï¼Œæ•´ä¸ªå‘ˆç°ç°è‰² Â· Issue Â· MartialBE/one-hub](https://github.com/MartialBE/one-hub/issues/380)
    - æ˜¯ä¸æ˜¯å¡«å†™äº† æ ‡ç­¾ã€‚ æŠŠæ ‡ç­¾åˆ äº†
    - è¿™æ˜¯ç”¨äºæ‰¹é‡ç®¡ç†çš„ã€‚ ä½ æ·»åŠ åè¦å» æ¸ é“æ ‡ç­¾ ä¿®æ”¹
  - [æœ‰æ¥å…¥è±†åŒ…çš„è®¡åˆ’å—?  ](https://github.com/MartialBE/one-hub/issues/323)
    - ç›´æ¥ç”¨ openai + æ¨¡å‹æ˜ å°„å°±å¯ä»¥äº†
    - æ¸ é“APIåœ°å€ Base URL å¡«å…¥ https://ark.cn-beijing.volces.com
    - ChatCompletionsåœ°å€ å¡«å…¥ /api/v3/chat/completions
  - [new-apiã€one-apiã€chatnioå¯¹æ¯”ä»¥åŠä»¤ç‰Œé™åˆ¶å¯ç”¨æ¨¡å‹ ](https://github.com/MartialBE/one-hub/issues/332)
  - [é€šè¿‡OneHubæ¥å…¥å­—èŠ‚ç«å±±å¼•æ“æ•™ç¨‹ ](https://linux.do/t/topic/412857)
  - [[Bug] æ— æ³•å¯¹ç›¸åŒæ¨¡å‹ä¸åŒåç§°(deepseek-r1å’Œdeepseek-ai/deepseek-r1)çš„æ¨¡å‹è´Ÿè½½å‡è¡¡è°ƒç”¨ ](https://github.com/songquanpeng/one-api/issues/2170)
  - [å¸Œæœ›æ—¥å¿—åŒæ—¶è®°å½•â€œç”¨æˆ·è¯·æ±‚æ¨¡å‹â€å’Œâ€œå®é™…è½¬å‘æ¨¡å‹â€ ](https://github.com/MartialBE/one-hub/issues/581)
    - é…ç½®æ˜ å°„çš„æ—¶å€™åœ¨å®é™…æ¨¡å‹åå­—å‰é¢æ·»åŠ ï¼‹å·logå°±è®°å½•çš„è¯·æ±‚åç§°
  - [ä¸€ç«™å¼å¤šæ¨¡å‹ç®¡ç†ï¼šOne APIå®ç”¨æŒ‡å—](https://gameapp.club/post/2024-06-10-oneapi-and-models-tips/)
  - [ä¸åŒæ¨¡å‹å‚å•†, åŒä¸€æ¨¡å‹åç§° çš„å¤„ç† ](https://github.com/MartialBE/one-hub/issues/562)
    - 202503: ä¸åŒæ¨¡å‹å‚å•†, åŒä¸€æ¨¡å‹åç§° è¿™ä¸ªä¸è¡Œï¼Œ å› ä¸ºè¯·æ±‚çš„æ—¶å€™ æ˜¯é€šè¿‡æ¨¡å‹åç§°æ¥æŸ¥æ‰¾æ¸ é“çš„ï¼Œ ç”¨æˆ·ä¸èƒ½æŒ‡å®š ä¾›åº”å•†ï¼Œæˆ–è®¸å¯ä»¥ç”¨åˆ†ç»„æ¥è§£å†³
  - [è¯·æ•™oneapiè´Ÿè½½å‡è¡¡é—®é¢˜ ](https://linux.do/t/topic/108049)
    - æ¥¼ä¸»æƒ³è¦çš„æ˜¯ä¸€ä¸ªæ¸ é“é‡Œå¤šä¸ª key è´Ÿè½½å‡è¡¡ï¼Œæ‰¹é‡åˆ›å»ºå®Œæ˜¯åˆ†æˆå¤šä¸ªæ¸ é“
  - [one-apiè´Ÿè½½å‡è¡¡ç–‘é—® ](https://linux.do/t/topic/210397)
  - [ç™¾åº¦æ–‡å¿ƒæ¨¡å‹è°ƒç”¨å¼‚å¸¸ ](https://github.com/MartialBE/one-hub/issues/208)
    - failed to get token encoder for model ERNIE-Speed: no encoding for model ERNIE-Speed, using encoder for gpt-3.5-turbo è¿™ä¸ªæŠ¥é”™æ˜¯åªæ²¡æœ‰æ‰¾åˆ°è¿™ä¸ªæ¨¡å‹çš„tokensè®¡ç®—ï¼Œå¯ä»¥æ— è§†

- https://github.com/james-6-23/new_api_tools /202512/python/ts
  - NewAPI-Tool æ˜¯ä¸€ä¸ªä¸“ä¸º NewAPI (One API åˆ†æ”¯) è®¾è®¡çš„ç°ä»£åŒ–å¢å¼ºç®¡ç†ä¸­é—´ä»¶ã€‚
  - å®ƒé€šè¿‡ç›´è§‚çš„ Web ç•Œé¢ï¼Œè¡¥å…¨äº†åŸç‰ˆç³»ç»Ÿåœ¨æ•°æ®å¯è§†åŒ–ã€å……å€¼è®°å½•å®¡è®¡ã€æ‰¹é‡å…‘æ¢ç ç®¡ç†ç­‰æ–¹é¢çš„åŠŸèƒ½ï¼Œå¸®åŠ©ç®¡ç†å‘˜æ›´é«˜æ•ˆåœ°è¿ç»´ç³»ç»Ÿ
  - å®æ—¶æ¦‚è§ˆï¼šç”¨æˆ·æ•°ã€Tokenã€æ¸ é“ã€æ¨¡å‹ã€å…‘æ¢ç ç­‰å…³é”®æŒ‡æ ‡ä¸€ç›®äº†ç„¶ã€‚
  - å…‘æ¢ç å¢å¼ºç®¡ç†
  - å……å€¼è®°å½•å®¡è®¡
  - ç‹¬ç«‹è®¤è¯ï¼šæ‹¥æœ‰ç‹¬ç«‹çš„ç®¡ç†åå°ç™»å½•æœºåˆ¶ï¼Œæ”¯æŒ JWT Sessionã€‚
  - å¤šæ•°æ®åº“æ”¯æŒï¼šå®Œç¾æ”¯æŒ MySQL å’Œ PostgreSQLã€‚

- https://github.com/tbphp/gpt-load /5.4kStar/MIT/202510/go/ts/vue
  - https://www.gpt-load.com/
  - æ™ºèƒ½å¯†é’¥è½®è¯¢çš„å¤šæ¸ é“ AI ä»£ç†

- https://github.com/eraycc/API-Gateway-Manager /202511/ts
  - åŸºäº Next.js çš„ AI API ä¸­è½¬ç«™ç®¡ç†ç³»ç»Ÿ
  - æ”¯æŒå¤šç”¨æˆ·ã€API ç«™ç‚¹ç®¡ç†ã€æ¨¡å‹æµ‹è¯•ä¸ç»Ÿä¸€è®¤è¯
  - åŒç³»ç»Ÿç™»å½•ï¼šç”¨æˆ·ç³»ç»Ÿ + ç®¡ç†å‘˜ç³»ç»Ÿ, ç®¡ç†å‘˜å¯æ— ç¼åˆ‡æ¢ç”¨æˆ·/ç®¡ç†ç³»ç»Ÿ
  - å¤šç«™ç‚¹æ”¯æŒï¼šç®¡ç†å¤šä¸ª AI API ä¸­è½¬ç«™
  - é¢åº¦æŸ¥è¯¢ï¼šå®æ—¶æŸ¥è¯¢ API ä½¿ç”¨é¢åº¦ï¼ˆç›®å‰ä»…é™ newapiï¼‰

- https://github.com/fruitbars/simple-one-api /2.3kStar/MIT/202506/go/js
  - OpenAI æ¥å£æ¥å…¥é€‚é…ï¼Œæ”¯æŒåƒå¸†å¤§æ¨¡å‹å¹³å°ã€è®¯é£æ˜Ÿç«å¤§æ¨¡å‹ã€è…¾è®¯æ··å…ƒä»¥åŠMiniMaxã€Deep-Seekï¼Œç­‰å…¼å®¹OpenAIæ¥å£ï¼Œä»…å•å¯æ‰§è¡Œæ–‡ä»¶ï¼Œé…ç½®è¶…çº§ç®€å•ï¼Œä¸€é”®éƒ¨ç½²ï¼Œå¼€ç®±å³ç”¨
  - ç›®å‰å¸‚é¢ä¸Šå…è´¹çš„ä½¿ç”¨å›½äº§çš„å…è´¹å¤§æ¨¡å‹è¶Šæ¥è¶Šå¤šï¼Œone-apiå¯¹äºä¸ªäººç”¨èµ·æ¥è¿˜æ˜¯æœ‰ç‚¹éº»çƒ¦ï¼Œå°±æƒ³è¦ä¸€ä¸ªä¸è¦ç»Ÿè®¡ã€æµé‡ã€è®¡è´¹ç­‰ç­‰çš„é€‚é…ç¨‹åºå³å¯ã€‚
  - å³ä½¿æœ‰äº›å‚å•†è¯´å…¼å®¹openaiçš„æ¥å£ï¼Œä½†æ˜¯å®é™…ä¸Šè¿˜æ˜¯å­˜åœ¨äº›è®¸å·®å¼‚çš„
  - simple-one-apiä¸»è¦æ˜¯è§£å†³ä»¥ä¸Š2ç‚¹ï¼Œæ—¨åœ¨å…¼å®¹å¤šç§å¤§æ¨¡å‹æ¥å£ï¼Œå¹¶ç»Ÿä¸€å¯¹å¤–æä¾› OpenAI æ¥å£ã€‚

- https://github.com/looplj/axonhub /1.3kStar/LGPL+apache2/202601/go/ts
  - https://axonhub.onrender.com/
  - AI gateway system that provides a unified OpenAI ( Chat Completion, Responses), Anthropic, Gemini and AI SDK compatible API
  - åç«¯ï¼šGo + ent + gqlgen
  - å‰ç«¯ï¼šReact + TypeScript + Shadcn + Graphql
  - æœ¬é¡¹ç›®å’Œ new-api ç­‰é¡¹ç›®çš„ä¸åŒï¼Œæœ¬é¡¹ç›®ç›®æ ‡ç”¨æˆ·æ˜¯ AI äº§å“å¼€å‘è€…ï¼Œä¸æ˜¯ä¸­è½¬æœåŠ¡å•†ï¼Œæ‰€ä»¥ä¼šæœ‰æ›´å¤šå¼€å‘ç›‘æ§ç›¸å…³èƒ½åŠ›ï¼Œæ¯”å¦‚ Traceã€‚
  - [åˆ†äº«è‡ªå·±å¼€æºçš„ä¸€ä¸ªè‚äº†ä¸€æ®µæ—¶é—´çš„ AI ç½‘å…³é¡¹ç›® _202511](https://linux.do/t/topic/1153975)
    - OpenAI/Anthropic è¯·æ±‚æ ¼å¼äº’è½¬
    - æ¸ é“ç®¡ç†ï¼Œé¡¹ç›®ç®¡ç†ï¼Œæƒé™æ§åˆ¶ï¼Œç”¨æˆ·ç®¡ç†ï¼ŒAPI Key ç®¡ç†
    - ä½ä¾µå…¥ LLM API Trace ï¼Œæ”¯æŒä¸éœ€è¦ SDK å°±å¯ä»¥ trace ä¸€æ¬¡å¯¹è¯çš„å¤šä¸ª requestï¼Œä»¥åŠä¿å­˜ Request å’Œ Response å†…å®¹ï¼Œæ–¹ä¾¿æ’æŸ¥é—®é¢˜

- https://github.com/jwy87/SimpleHub /MIT/202601/js
  - å¤šç«™ç‚¹ç®¡ç†ï¼šç»Ÿä¸€ç®¡ç†å¤šä¸ª AI ä¸­è½¬ç«™ï¼Œæ”¯æŒ NewAPIã€Veloeraã€DoneHubã€VOAPI ç­‰ä¸»æµå¹³å°
  - æ¨¡å‹å˜æ›´æ£€æµ‹ï¼šè‡ªåŠ¨è¿½è¸ªæ¨¡å‹åˆ—è¡¨çš„å¢åˆ æ”¹ï¼Œç²¾ç¡®è®°å½•æ¯æ¬¡å˜åŒ–
  - æ™ºèƒ½ç­¾åˆ°ï¼šæ”¯æŒ NewAPIã€Veloera å¹³å°è‡ªåŠ¨ç­¾åˆ°ï¼Œæ¯æ—¥è‡ªåŠ¨é¢†å–å¥–åŠ±
  - [[å¼€æº]å°ç™½æ“äº†ä¸€ä¸ªAPIèšåˆç®¡ç†ç«™ï¼ˆå«è‡ªåŠ¨ç­¾åˆ°ï¼‰ ](https://linux.do/t/topic/1095754)

- https://github.com/qixing-jk/all-api-hub /722Star/AGPL/202601/ts
  - http://all-api-hub.qixing1217.top/
  - å¼€æºæµè§ˆå™¨æ’ä»¶ï¼Œç»Ÿä¸€ç®¡ç†ç¬¬ä¸‰æ–¹ AI èšåˆä¸­è½¬ç«™ä¸è‡ªå»º New APIï¼šè‡ªåŠ¨è¯†åˆ«è´¦å·ã€æŸ¥çœ‹ä½™é¢ã€åŒæ­¥æ¨¡å‹ã€ç®¡ç†å¯†é’¥ï¼Œå…¨å¹³å°ä¸äº‘ç«¯å¤‡ä»½
  - ç«™ç‚¹ä¿¡æ¯ç®¡ç† - å¤šæ–¹å¼è·å–çœŸå®ç«™ç‚¹åç§°ï¼Œæ”¯æŒç­¾åˆ°çŠ¶æ€æ£€æµ‹å’Œè‡ªåŠ¨ç­¾åˆ°ï¼Œå¯æ‰‹åŠ¨æ·»åŠ ä»»æ„ AI èšåˆä¸­è½¬ç«™ç‚¹
  - æ¯ä¸ªç«™ç‚¹æ”¯æŒå¤šä¸ªè´¦å·ï¼Œè´¦å·åˆ†ç»„ä¸å¿«é€Ÿåˆ‡æ¢ï¼Œä½™é¢å’Œä½¿ç”¨æ—¥å¿—ä¸€ç›®äº†ç„¶
  - æŸ¥çœ‹ç«™ç‚¹æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨å’Œä»·æ ¼ä¿¡æ¯
  - æä¾› New API æ¸ é“ç®¡ç† Beta ç•Œé¢ï¼Œç›´æ¥åœ¨æ’ä»¶å†…ç»´æŠ¤æ¸ é“ä¸é‡å®šå‘
  - å…¨å¹³å°å…¼å®¹ - æ”¯æŒ Chromeã€Firefox æµè§ˆå™¨ï¼Œå¯åœ¨ Kiwi Browser ç­‰ç§»åŠ¨ç«¯ä½¿ç”¨ï¼Œæ”¯æŒæ·±è‰²æ¨¡å¼è‡ªåŠ¨åˆ‡æ¢
  - WXT è´Ÿè´£å¤šæµè§ˆå™¨æ‰©å±•å·¥å…·é“¾ä¸æ„å»ºæµç¨‹
  - [All-API-Hubï¼šå¼€æºAIä¸­è½¬ç«™é›†ä¸­ç®¡ç†å’Œè‡ªå·±çš„New APIå¢å¼ºç®¡ç†ï¼ŒåŸºäº one-api-hub å¤§å¹…é‡æ„å¢å¼º _202511](https://linux.do/t/topic/1001042)
  - æœ€åˆåŸºäº One API Hub å¼€å‘ï¼Œç°å·²å¤§å¹…é‡æ„æ‰©å±•ã€‚æ•°æ®æ ¼å¼ä¿æŒå…¼å®¹ï¼Œæ”¯æŒç›´æ¥å¯¼å…¥
  - https://github.com/fxaxg/one-api-hub /MIT/202509/ts/inactive
    - https://fxaxg.github.io/one-api-hub/
    - ä¸€ä¸ªå¼€æºçš„æµè§ˆå™¨æ’ä»¶ï¼Œèšåˆç®¡ç†AIä¸­è½¬ç«™è´¦å·çš„ä½™é¢ã€æ¨¡å‹å’Œå¯†é’¥ï¼Œå‘Šåˆ«ç¹çç™»å½•
    - [[å¼€æº] One-API-Hubï¼šç®¡ç†æ‚¨çš„æ‰€æœ‰AIä¸­è½¬ç«™è´¦å·çš„ä½™é¢ã€æ¨¡å‹å’Œå¯†é’¥ï¼Œå‘Šåˆ«ç¹çç™»å½• _202507](https://linux.do/t/topic/833269)

- https://github.com/Sponge-Lu/API_detect_tools /MIT/202601/ts
  - ç®¡ç†APIå…¬ç›Šç«™çš„æ¡Œé¢ç«¯ï¼Œå¯ç­¾åˆ°å¯æ·»åŠ ç¦åˆ©ç«™ï¼Œä¸“ä¸ºç®¡ç†å’Œç›‘æ§å¤šä¸ª API ä¸­è½¬ç«™è€Œè®¾è®¡ã€‚
  - åŸºäº Electron + React + TypeScript æ„å»ºã€‚
  - API Key ç®¡ç†ï¼šåœ¨æ¡Œé¢ç«¯ç›´æ¥åˆ›å»ºã€åˆ é™¤ã€åˆ†ç»„ç®¡ç† API Keyï¼Œæ”¯æŒæ‰¹é‡æ“ä½œ

## router-image ğŸ–¼ï¸

- https://github.com/Amery2010/peinture /392Star/MIT/202512/ts
  - https://peinture.9th.xyz/
  - A general-purpose AI image generation framework that supports Hugging Face, Gitee, Model Scope, and more.
  - [ã€å¼€æºã€‘æ´¾å¥‡æ™ºå›¾ï¼ŒAI å›¾ç‰‡ç”ŸæˆæœåŠ¡ï¼Œåˆç†ç™½å«–å„å¤§å¹³å°çš„ç®—åŠ›èµ„æº _202512](https://linux.do/t/topic/1290598)
    - ç›®å‰ Hugging Face å¯¹äºåŒ¿åç”¨æˆ·ï¼Œæ¯å¤©æœ‰ 2åˆ†é’Ÿçš„ç®—åŠ›èµ„æºï¼Œä½¿ç”¨ Tokenï¼Œå¯ä»¥è·å¾—é¢å¤–çš„ 3.5 åˆ†é’Ÿç®—åŠ›èµ„æºã€‚
    - ç›®å‰ Gitee AI ä½¿ç”¨ Token æ¯å¤©éƒ½å¯ä»¥è·å¾— 100 æ¬¡çš„ API è°ƒç”¨æ¬¡æ•°ï¼Œç†è®ºä¸Šå¯ä»¥ç”Ÿæˆ 100 å¼ å›¾ç‰‡ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæç¤ºè¯ä¼˜åŒ–ä¹Ÿä¼šè®¡ç®—å…¥ API è°ƒç”¨æ¬¡æ•°
    - ç›®å‰ Model Scope ä½¿ç”¨ Token æ¯å¤©éƒ½å¯ä»¥è·å¾— 2000 æ¬¡çš„ API è°ƒç”¨æ¬¡æ•°ï¼Œå¯¹äºå•ä¸ªæ¨¡å‹çš„è°ƒç”¨å®˜æ–¹é™åˆ¶ä¸º 500 æ¬¡ï¼Œç†è®ºä¸Šå¯ä»¥ç”Ÿæˆ 500 å¼ å›¾ç‰‡ã€‚
    - æ ¹æ®ç”¨æˆ·åé¦ˆ Hugging Face ä¸ Gitee AI å¯ä»¥ç”Ÿæˆæ— å®¡æ ¸çš„ NSFW å›¾ç‰‡ï¼Œæˆ‘æ²¡æœ‰åœ¨ Model Scope ä¸Šè¯•è¿‡ï¼Œå› æ­¤æ— æ³•ç¡®å®š Model Scope æ˜¯å¦å­˜åœ¨å®¡æ ¸æœºåˆ¶
    - é¢˜å¤–è¯ï¼šGitee AI ä¸ Model Scope çš„æç¤ºè¯ä¼˜åŒ–ä½¿ç”¨çš„æ˜¯ DeepSeek 3.2 è¿™ä¸ªæ¨¡å‹ï¼Œè¿™ä¸ªæ¨¡å‹åœ¨ç”Ÿæˆä¸­æ–‡æè¿°ä¸Šååˆ†æƒŠè‰³ã€‚
  - https://github.com/Amery2010/imagine-server /MIT/202601/ts
    - åŸºäº Hono æ„å»ºçš„ç»Ÿä¸€ AI å›¾åƒç”Ÿæˆ API æœåŠ¡ï¼Œæ”¯æŒå¤šä¸ª AI æä¾›å•†ï¼ˆHugging Faceã€Gitee AIã€ModelScopeï¼‰ï¼Œæä¾›æ–‡ç”Ÿå›¾ã€å›¾ç”Ÿå›¾ã€å›¾ç”Ÿè§†é¢‘ã€å›¾åƒæ”¾å¤§ç­‰åŠŸèƒ½ã€‚
    - æ¨¡å—åŒ–çš„ Provider ç³»ç»Ÿï¼Œè½»æ¾æ‰©å±•æ–°çš„ AI æœåŠ¡æä¾›å•†
    - é›†æˆ Peinture æä¾›å‹å¥½çš„å›¾å½¢ç•Œé¢
    - è‡ªåŠ¨åˆ‡æ¢å’Œç®¡ç†å¤šä¸ª API Tokenï¼Œé…é¢è€—å°½æ—¶è‡ªåŠ¨åˆ‡æ¢
    - ä½¿ç”¨ Unstorage æ”¯æŒ Redisã€Cloudflare KV ç­‰å¤šç§å­˜å‚¨åç«¯
    - å¤šå¹³å°éƒ¨ç½² - æ”¯æŒ Cloudflare Workersã€Vercelã€Node.js ç­‰å¤šç§éƒ¨ç½²ç¯å¢ƒ
    - Token ç»Ÿè®¡ - å®æ—¶æŸ¥çœ‹å„æä¾›å•†çš„ Token ä½¿ç”¨æƒ…å†µ
    - [ã€å¼€æºã€‘Peintureï¼ˆæ´¾å¥‡æ™ºå›¾ï¼‰ çš„æœåŠ¡ç«¯ Imagine Server æ­£å¼å¼€æº ](https://linux.do/t/topic/1404399)
      - å¦‚ä½•åŠ è½½æœ¬åœ°éƒ¨ç½²çš„qwen image edit
      - æœ¬åœ°éƒ¨ç½²çš„ï¼Œæˆ‘ç›®å‰æ²¡åšå…¼å®¹ï¼Œæ‚¨å¯ä»¥æ ¹æ®æ–‡æ¡£æè¿°ï¼Œè‡ªå·±å†™ä¸€ä¸ªè‡ªå®šä¹‰çš„æœ¬åœ°æ¸ é“
      - ç›®å‰å¼€å‘ç²¾åŠ›æœ‰é™ï¼Œåªèƒ½é€‰æ‹©ä¼˜å…ˆçº§æ›´é«˜çš„éœ€æ±‚è¿›è¡Œå¼€å‘ã€‚åç»­ä¼šå¢åŠ  nano banana ã€gpt-image è¿™ç±»å¯¹è¯å‹ AI æ¨¡å‹çš„æ”¯æŒï¼Œæœ¬åœ°æ¨¡å‹ç”±äº API ç±»å‹å¤ªå¤šå¤šæ ·åŒ–ï¼Œæš‚æ—¶æ²¡åŠæ³•ä¸€ä¸€é€‚é…ã€‚
      - æ€ä¹ˆå’Œçƒ­é—¨å¼€æºèŠå¤©uiæ¯”å¦‚openwebui/librechatç»“åˆä½¿ç”¨å•Š
      - åé¢ä¼šå¢åŠ  OpenAI å…¼å®¹æ ¼å¼çš„ API è¾“å‡º
  - [ã€å¼€æºã€‘è¿™æ¬¾å…è´¹ä¸é™é‡çš„ Z-Image ç½‘ç«™ï¼Œæ”¯æŒ A4F å…è´¹æ¨¡å‹ï¼ŒåŒæ—¶å¢åŠ äº† 99% æ²¡å¬è¯´è¿‡çš„ OPFS æ”¯æŒï¼Œå…è®¸ç”¨æˆ·åœ¨æµè§ˆå™¨ä¸­é•¿æœŸä¿å­˜å¤§é‡æ–‡ä»¶ï¼ˆæ— æœåŠ¡å™¨ä½¿ç”¨ç”»å»ŠåŠŸèƒ½ï¼‰ ](https://linux.do/t/topic/1498882)
    - å›¾ç‰‡ç”Ÿæˆåä¼šé»˜è®¤ä¸‹è½½å¹¶ä¿å­˜åˆ°ä¸´æ—¶çš„ OPFS å­˜å‚¨ç©ºé—´ï¼Œè¿™æ ·åœ¨æœ¬åœ°æŸ¥çœ‹æˆ–æ“ä½œå›¾ç‰‡æ—¶å°±æ— éœ€å†ä»ç½‘ç»œä¸Šä¸‹è½½æ–‡ä»¶ï¼Œä¹Ÿæ— éœ€æ‹…å¿ƒæ–‡ä»¶çŸ­æ—¶é—´å†…è¿‡æœŸçš„é—®é¢˜

- https://github.com/lianwusuoai/img-router /MIT/202512/ts
  - ä¸‰åˆä¸€å›¾åƒç”Ÿæˆ API ä¸­è½¬æœåŠ¡- ä¸€ä¸ªæ¥å£ï¼Œå¤šæ¸ é“å›¾åƒç”Ÿæˆ
  - ä¸‰æ¸ é“æ”¯æŒ - ç«å±±å¼•æ“ã€Gitee (æ¨¡åŠ›æ–¹èˆŸ)ã€ModelScope (é­”å¡”)
  - OpenAI å…¼å®¹ - å®Œå…¨å…¼å®¹ /v1/chat/completions æ¥å£æ ¼å¼
  - å›¾ç‰‡å‚è€ƒ - æ”¯æŒä¸Šä¼ å‚è€ƒå›¾ç‰‡è¿›è¡Œå›¾ç”Ÿå›¾
  - å¼€ç®±å³ç”¨çš„å®¹å™¨åŒ–éƒ¨ç½²æ–¹æ¡ˆ
  - [å¼€æºï¼šè±†åŒ…å’ŒZ-Imageå¯¹è¯ç”Ÿå›¾/æ”¹å›¾å…¨å…è´¹ä¸”è‡ªç”± ](https://linux.do/t/topic/1358465)

- https://github.com/coulsontl/uni-image-api /202512/python
  - å°†ç¬¬ä¸‰æ–¹å›¾åƒç”Ÿæˆ/ç¼–è¾‘ API è½¬æ¢ä¸º OpenAI å…¼å®¹æ ¼å¼çš„ä»£ç†æœåŠ¡ã€‚
  - å¯æ‰©å±•æ¶æ„: åŸºäº Provider æ¨¡å¼ï¼Œæ˜“äºæ·»åŠ æ–°çš„ç¬¬ä¸‰æ–¹æœåŠ¡
  - åŸºäº FastAPI å’Œ httpx çš„å…¨å¼‚æ­¥å®ç°
  - æ”¯æŒå°†å›¾ç‰‡ä¸Šä¼ åˆ° S3 å…¼å®¹å­˜å‚¨ï¼ˆAWS S3ã€MinIOã€é˜¿é‡Œäº‘ OSS ç­‰ï¼‰
  - ç¢°åˆ°äº†æœ‰ç›¸åŒæƒ³æ³•çš„ä½¬å‹ï¼›ä¹‹å‰æˆ‘ä¹Ÿåšäº†ä¸€ä¸ªï¼Œä¸è¿‡æˆ‘åªåšäº†ä¸€ä¸ªé­”æ­ï¼Œä½†æ˜¯æ”¯æŒäº†å›¾ç”Ÿå›¾

## model-router

- https://github.com/ulab-uiuc/LLMRouter /400Star/MIT/202512/python
  - https://ulab-uiuc.github.io/LLMRouter/
  - Open-Source Library for LLM Routing
  - an intelligent routing system designed to optimize LLM inference by dynamically selecting the most suitable model for each query
  - Unified CLI: Complete command-line interface for training, inference, and interactive chat with Gradio-based UI.
  - Complete pipeline for generating training data from 11 benchmark datasets with automatic API calling and evaluation.
  - [We open-sourced LLMRouter: the first unified LLM routing library  _202512](https://www.reddit.com/r/LocalLLaMA/comments/1q06z2l/we_opensourced_llmrouter_the_first_unified_llm/)
    - The current LLM routing landscape feels a lot like early GNN research: many promising router algorithms exist, but each comes with its own input/output format, training pipeline, and evaluation setup. This fragmentation makes routers difficult to use, hard to reproduce, and nearly impossible to compare fairly.
    - Over the past year, we worked on several LLM routing projects, including GraphRouter (ICLRâ€™25), Router-R1 (NeurIPSâ€™25), and PersonalizedRouter (TMLRâ€™25). Through repeatedly implementing and benchmarking different routers, we realized that the main bottleneck is not algorithmic novelty, but the lack of standardized infrastructure.
    - Unified support for single-round, multi-round, agentic, and personalized routing
    - Integration of 16+ SOTA LLM router algorithms
    - One-line commands to run different routers without rebuilding pipelines

- https://github.com/Egham-7/adaptive-ai-provider /202510/ts
  - https://llmadaptive.uk/
  - The Adaptive AI Provider for the AI SDK contains language model support for adaptive provider selection across multiple AI services
  - Intelligent Model Selection - Automatically picks optimal models
  - Multi-Provider - OpenAI, Anthropic, Google, DeepSeek, Groq, etc.
  - [Adaptive AI Provider for the Vercel AI SDK â€” real-time model routing using UniRoute (Google Research) : r/vercel _202510](https://www.reddit.com/r/vercel/comments/1o5itci/adaptive_ai_provider_for_the_vercel_ai_sdk/)
    - Itâ€™s based on `UniRoute`, Google Researchâ€™s new framework for universal model routing across unseen LLMs.
    - Adaptive automatically chooses which LLM to use for every request based on prompt complexity and live model performance.
    - It runs automated evals continuously in the background, clusters prompts by domain, and routes each query to the smallest feasible model that maintains quality.
    - it performs live eval-based routing using UniRouteâ€™s cluster-based generalization method, which can handle unseen LLMs without retraining.
    - Typical savings: 60â€“90% lower inference cost.
    - Routing overhead: ~10 ms.

- https://huggingface.co/katanemo/Arch-Router-1.5B /LlamaLic/qwen2
  - [I built the HuggingChat Omni Router : r/ollama _202510](https://www.reddit.com/r/ollama/comments/1odn14n/i_built_the_huggingchat_omni_router/)
  - HuggingFace relaunched their chat app called Omni with support for 115+ LLMs.
  - The critical unlock in Omni is the use of a policy-based approach to model selection. I built that policy-based router: https://huggingface.co/katanemo/Arch-Router-1.5B
  - The core insight behind our policy-based router was that it gives developers the constructs to achieve automatic behavior, grounded in their own evals of which LLMs are best for specific coding tasks like debugging, reviews, architecture, design or code gen
  - Essentially, the idea behind this work was to decouple task identification (e.g., code generation, image editing, q/a) from LLM assignment.
  - The model is also integrated as a first-class primitive in archgw: a models-native proxy server for agents. 
  - https://github.com/katanemo/archgw /4.2kStar/apache2/202510/rust/python
    - https://archgw.com/
    - Arch is a models-native proxy server that handles the plumbing work in AI: agent routing & hand off, guardrails, end-to-end logs and traces, unified access to LLMs from OpenAI, Anthropic, Ollama, etc.
    - Arch handles the pesky plumbing work in building AI agents â€” like applying guardrails, routing prompts to the right agent, generating hyper-rich information traces for RL, and unifying access to any LLM.
    - Arch runs alongside app servers as a containerized process, and builds on top of `Envoy`'s proven HTTP management and scalability features to handle ingress and egress traffic related to prompts and LLMs.
    - Arch was built by the contributors of Envoy Proxy with the belief that: Prompts are nuanced and opaque user requests, which require the same capabilities as traditional HTTP requests including secure handling, intelligent routing, robust observability, and integration with backend (API) systems to improve speed and accuracy for common agentic scenarios â€“ all outside core application logic.
# crawler-ai
- https://github.com/mendableai/firecrawl /AGPLv3/202502/python/rust/ts
  - https://firecrawl.dev/
  - Turn entire websites into LLM-ready markdown or structured data. 
  - Scrape, crawl and extract with a single API.
  - The hard stuff: proxies, anti-bot mechanisms, dynamic content (js-rendered), output parsing, orchestration
  - Batching (New): scrape thousands of URLs at the same time with a new async endpoint.
  - open-version: scrape, extract, map, formats, sdk
  - cloud-version: anti-bot, dashboard, actions, browserless, enterprise
  - This project is primarily licensed under AGPLv3
    - However, certain components of this project are licensed under the MIT 
    - The SDKs and some UI components are licensed under the MIT License. 

- https://github.com/getmaxun/maxun /AGPL/202503/ts
  - https://www.maxun.dev/
  - Open-source no-code web data extraction platform. 
  - Maxun lets you create custom robots which emulate user actions and extract data. A robot can perform any of the actions: Capture List, Capture Text or Capture Screenshot. Once a robot is created, it will keep extracting data for you without manual intervention

- https://github.com/dylan-sutton-chavez/llm-web-crawler /202510/python
  - A horizontally scalable web crawling engine designed for structured content extraction. 
  - It performs URL normalization, HTML parsing, Markdown conversion, and LLM post-processing (using xai_sdk with grok). 
  - Output is serialized in line-delimited JSON (`.jsonl`).
  - A crawler functions similarly to how a graph works. Basically, each web page behaves like a node, where a single node can point to n number of websites, and multiple nodes can point to the same website. The navigation of a crawler is based on the same principle as a graph traversal; in this case, I will base it on a breadth-first search (`BFS`) model.
  - The Crawler module implements a horizontal-scalable architecture, where you can create one Crawler module with hundreds of nodes (sharing the same memmory, but managing hundreds of asynchronous processes).
  - ä¾èµ– requestsã€html-to-markdownã€jsonlinesã€xai_sdk
# perf/large
- https://github.com/MoonshotAI/MoBA /MIT/202502/python
  - Mixture of Block Attention for Long-Context LLMs
  - https://x.com/tuturetom/status/1892753818028216717
    - å¯ä»¥å®ç°è¿‘ä¹æ— é™çš„ä¸Šä¸‹æ–‡çª—å£ï¼Œå°†ä¸€æ•´æœ¬ä¹¦æˆ–ä¸€æ•´ä¸ªä»£ç åº“æ‰”è¿›å»æé—®
# filesystem
- https://github.com/tursodatabase/agentfs /2.2kStar/MIT/202602/rust
  - https://www.agentfs.ai/
  - AgentFS is a filesystem explicitly designed for AI agents. Just as traditional filesystems provide file and directory abstractions for applications, AgentFS provides the storage abstractions that AI agents need
  - AgentFS Specification - SQLite-based agent filesystem specification.
  - [pg-fs: Postgres backed filesystem for AI Agents : r/VercelAISDK](https://www.reddit.com/r/VercelAISDK/comments/1qzbfcv/pgfs_postgres_backed_filesystem_for_ai_agents/)
# utils
- https://github.com/Olow304/memvid /MIT/202506/python
  - https://pypi.org/project/memvid/
  - Video-based AI memory library. 
  - Store millions of text chunks in MP4 files with lightning-fast semantic search. No database needed.
  - Memvid revolutionizes AI memory management by encoding text data into videos, enabling lightning-fast semantic search across millions of text chunks with sub-second retrieval times. 
  - Unlike traditional vector databases that consume massive amounts of RAM and storage, Memvid compresses your knowledge base into compact video files while maintaining instant access to any piece of information.
  - Video-as-Database: Store millions of text chunks in a single MP4 file
  - Efficient Storage: 10x compression compared to traditional databases
  - PDF Support: Direct import and indexing of PDF documents
  - Built-in Chat: Conversational interface with context-aware responses
  - Pluggable LLMs: Works with OpenAI, Anthropic, or local models
  - Offline-First: No internet required after video generation

- https://github.com/mohamad-tohidi/texttools /MIT/202601/python
  - a high-level NLP toolkit built on top of LLMs.
  - utilities for translation, question detection, categorization, NER extraction, and more
# eval/prompt
- https://github.com/promptfoo/promptfoo /9.6kStar/MIT/202601/ts/å¯¹æ¯”è¡¨/code-first
  - https://promptfoo.dev/
  - promptfoo is a developer-friendly local tool for testing LLM applications. 
  - Stop the trial-and-error approach - start shipping secure, reliable AI apps.
  - Test your prompts and models with automated evaluations
  - Compare models side-by-side (OpenAI, Anthropic, Azure, Bedrock, Ollama, and more)
  - thinkingæ¨¡å‹çš„`<think>`å†…å®¹ä¼šç®—åœ¨`max_tokens`èŒƒå›´å†…ï¼Œæ‰€ä»¥å¯èƒ½å–ä¸åˆ°å†…å®¹
  - é€šè¿‡promptfooæµ‹è¯•å¤šä¸ªæ¨¡å‹çš„ç¿»è¯‘èƒ½åŠ›, é¼ æ ‡hoveråœ¨è¡¨å¤´åˆ—å¯ä»¥çœ‹åˆ°æ¨¡å‹ä¿¡æ¯, promptä¸å˜æ—¶åªä¼šå¢é‡è¯·æ±‚æ–°åŠ çš„prompt
  - promptfoo eval --output mt2601-results.html --output mt2601-results.json
  - https://github.com/promptfoo/promptfoo/tree/main/examples/lm-studio
    - This example demonstrates how to use Promptfoo with LM Studio for prompt evaluation. It showcases configuration for interacting with the LM Studio API using a locally hosted language model.
  - The above examples create a table of outputs that can be manually reviewed. By setting up assertions, you can automatically grade outputs on a pass/fail basis.
  - [Does promptfoo accept multimodal input _202407](https://github.com/promptfoo/promptfoo/issues/1164)
    - Yes, it does, and we have several examples.
    - Local Models via LM Studio can easily be adapted for image input too.

- https://github.com/Laszlobeer/llm-tester /202507/python/inactive
  - benchmarking tool for evaluating Ollama language models. 
  - Measure performance metrics including latency, throughput, and token generation speed through a sophisticated PyQt5 GUI.
  - Concurrent Benchmarking: Test with up to 10 simultaneous requests
  - 100+ Diverse Prompts: Pre-configured benchmark questions
  - Summary table shows aggregate metrics
    - Latency
    - Tokens/s
    - Throughput
  - [Introducing OllamaBench: The Ultimate Tool for Benchmarking Your Local LLMs (PyQt5 GUI, Open Source) : r/ollama _202507](https://www.reddit.com/r/ollama/comments/1mbdd4a/introducing_ollamabench_the_ultimate_tool_for/)
    - What would be cool is to run a test prompt on several LLMs at once. Grid Search does it, but we donâ€™t have the benchmarks (and itâ€™s broken right now for OS X).

- https://github.com/dezoito/ollama-grid-search /896Star/MIT/202511/rust/ts
  - [Grid Search on Large Language Models using Ollama and Rust  _202312](https://dezoito.github.io/2023/12/27/rust-ollama-grid-search.html)
  - multi-platform desktop application to evaluate and compare LLM models, written in Rust and React.
  - This project automates the process of selecting the best models, prompts, or inference parameters for a given use-case, allowing you to iterate over their combinations and to visually inspect the results.
  - It assumes Ollama is installed and serving endpoints, either in localhost or in a remote server.
  - Automatically fetches models from local or remote Ollama servers; 
  - A/B test different prompts on several models simultaneously; 
  - Allows limited concurrency or synchronous inference calls (to prevent spamming servers); 

- https://github.com/ianarawjo/ChainForge /2.9kStar/MIT/202510/python/ts
  - https://chainforge.ai/docs
  - https://chainforge.ai/play/
    - The web version of ChainForge has a limited feature set.
  - open-source visual programming environment for battle-testing prompts to LLMs.
  - ChainForge is a data flow prompt engineering environment for analyzing and evaluating LLM responses. It enables rapid-fire, quick-and-dirty comparison of prompts, models, and response quality that goes beyond ad-hoc chatting with individual LLMs.
  - Query multiple LLMs at once to test prompt 
  - Compare response quality across prompt permutations, across models, and across model settings to choose the best prompt and model for your use case.
  - Setup evaluation metrics (scoring function) and immediately visualize results across prompts, prompt parameters, models, and model settings.
  - Use AI to streamline this entire process: Create synthetic tables and input examples with built-in genAI features, or supercharge writing evals by prompting a model to give you starter code.
  - ChainForge is built on ReactFlow and Flask.

- https://github.com/Arize-ai/phoenix /8.2kStar/Elastic/202601/python/ts/å¯¹æ¯”è¡¨/lowcode
  - https://arize.com/docs/phoenix#evaluation
  - open-source AI observability platform designed for experimentation, evaluation, and troubleshooting

- https://github.com/vibrantlabsai/ragas /12.2kStar/apache2/202601/python/code-first
  - https://docs.ragas.io/
  - toolkit for evaluating and optimizing Large Language Model (LLM) applications. 
  - Test Data Generation: Automatically create comprehensive test datasets covering a wide range of scenarios.
  - Seamless Integrations: Works flawlessly with popular LLM frameworks like LangChain and major observability tools.

- https://github.com/confident-ai/deepeval /13kStar/apache2/202601/python/code-frist
  - https://deepeval.com/
  - open-source LLM evaluation framework, for evaluating and testing large-language model systems. 
  - It is similar to `Pytest` but specialized for unit testing LLM outputs
  - DeepEval incorporates the latest research to evaluate LLM outputs based on metrics such as G-Eval, task completion, answer relevancy, hallucination, etc., which uses LLM-as-a-judge and other NLP models that run locally on your machine for evaluation.

- https://github.com/truera/trulens /3kStar/MIT/202601/python
  - https://www.trulens.org/
  - TruLens helps you objectively measure the quality and effectiveness of your agent using feedback functions.

- https://github.com/Helicone/helicone /4.9kStar/apache2/202601/ts
  - https://www.helicone.ai/
  - Open source LLM observability platform. One line of code to monitor, evaluate, and experiment. YC W23
  - Playground: Rapidly test and iterate on prompts, sessions and traces in our UI.
  - Prompt Management: Version prompts using production data. Deploy prompts through the AI Gateway without code changes. Your prompts remain under your control, always accessible.

- https://github.com/agenta-ai/agenta /3.7kStar/MIT+EE/202601/python/ts/æ— å¯¹æ¯”è¡¨
  - http://www.agenta.ai/
  - LLMOps platform: prompt playground, prompt management, LLM evaluation, and LLM observability all in one place.
  - Interactive LLM Playground: Compare prompts side by side against your test cases
  - Multi-Model Support: Experiment with 50+ LLM models or bring-your-own models
  - Version Control: Version prompts and configurations with branching and environments
  - Pre-built and Custom Evaluators: Use LLM-as-judge, one of our 20+ pre-built evaluators, or you custom evaluators
  - LLM Tracing: Debug complex workflows with detailed traces
  - [Changes to Agenta's Open Source and Commercial Features _202503](https://github.com/Agenta-AI/agenta/discussions/2527)
    - We are updating our open-source model starting v0.36 to better support production-ready deployments and to ensure sustainable development of the Agenta platform. 
    - We are introducing the Model Registry feature into the open-source version.
    - All evaluation features (Human Evaluation, Automatic Evaluation, Custom Workflows) are now available exclusively in our commercial offering.

- https://github.com/stellarlinkco/ai-eval /AGPL/202602/go
  - [ã€å¼€æºã€‘ AI-Evalï¼šPrompt è¯„ä¼°ç³»ç»Ÿï¼Œç”¨å•å…ƒæµ‹è¯•è·‘ prompt è¯„ä¼°  _202602](https://linux.do/t/topic/1577572)
  - Go å†™çš„ Prompt è¯„ä¼°ç³»ç»Ÿã€‚æŠŠ Prompt æµ‹è¯•å½“å•å…ƒæµ‹è¯•è·‘ â€”â€” å†™ YAML å®šä¹‰ç”¨ä¾‹ï¼Œé…è¯„ä¼°å™¨ï¼ˆæ¨¡å¼åŒ¹é…ã€LLM Judgeã€RAGã€Agentã€å®‰å…¨æ£€æµ‹ï¼‰ï¼Œè·‘ pass@k å¤„ç† LLM çš„ä¸ç¡®å®šæ€§ã€‚
  - å¸¦ Web APIã€Leaderboardã€CI é›†æˆï¼Œ
  - æ”¯æŒ MMLU/GSM8K/HumanEval æ ‡å‡† Benchmarkã€‚
# model-proxy
- https://github.com/lymanzhao/Ollama-serve /202503/python
  - ä¸€ä¸ª Ollamaè½¬å‘ä»£ç†ï¼Œç”¨äºä¸ºåŸç”Ÿ Ollama æœåŠ¡æ·»åŠ  API å¯†é’¥è®¤è¯åŠŸèƒ½ã€‚
  - è¯¥é¡¹ç›®è§£å†³äº† Ollama å®˜æ–¹ä¸æä¾› API å¯†é’¥éªŒè¯çš„é—®é¢˜ï¼Œä½¿æ‚¨å¯ä»¥æ›´å®‰å…¨åœ°éƒ¨ç½² Ollama æœåŠ¡å¹¶é˜²æ­¢æœªæˆæƒè®¿é—®
# model-2api
- https://github.com/star5o/reverse-check /MIT/202504/js/vue
  - https://reverse-check.no-reverse-api.com/
  - LLM API é€†å‘æ£€æµ‹å·¥å…·
  - æœ¬å·¥å…·æ˜¯ä¸€ä¸ªåŸºäºæ˜¯å¦æ”¯æŒå®˜æ–¹å‚æ•°çš„é€†å‘æ£€æµ‹å·¥å…·ã€‚ä¸èƒ½é€šè¿‡æœ¬å·¥å…·æ£€æµ‹çš„APIæå¤§æ¦‚ç‡æ˜¯é€†å‘çš„ã€‚
  - ç›®å‰é¡¹ç›®å¤„äºåˆæ­¥é˜¶æ®µï¼Œæš‚æ—¶éœ€è¦äººå·¥å¯¹æ¯”å“åº”ç»“æœä¸ç¤ºä¾‹è¿›è¡Œåˆ¤æ–­ã€‚
  - æ”¯æŒå¤šç§æ¨¡å‹æä¾›å•†çš„APIæ£€æµ‹: OpenAI, Claude, Gemini

- https://github.com/router-for-me/CLIProxyAPI /3.4kStar/MIT/202512/go
  - Wrap Gemini CLI, Antigravity, ChatGPT Codex, Claude Code, Qwen Code, iFlow as an OpenAI/Gemini/Claude/Codex compatible API service, allowing you to enjoy the free Gemini 2.5 Pro, GPT 5, Claude, Qwen model through API
  - A proxy server that provides OpenAI/Gemini/Claude/Codex compatible API interfaces for CLI.
  - It now also supports OpenAI Codex (GPT models) and Claude Code via OAuth.
  - [API Key issue _202510](https://github.com/router-for-me/CLIProxyAPI/issues/181)
    - ğŸ macä¸Šé€šè¿‡homebrewå®‰è£…åé…ç½®æ–‡ä»¶åœ¨ `/opt/homebrew/etc/cliproxyapi.conf`
  - [fix: Implement fallback log directory for file logging on read-only system _202512](https://github.com/router-for-me/CLIProxyAPI/pull/772)
    - macOS ä¸‹é¢ï¼Œæ‰“å¼€ logging-to-file: true ä¹‹åï¼Œhomebrew services å¯åŠ¨å¤±è´¥ï¼Œæ’æŸ¥åæ˜¯æ—¥å¿—æ— æ³•å†™å…¥å¯¼è‡´çš„ã€‚
  - [gemini oauth in droid cli: unknown provider _202511](https://github.com/router-for-me/CLIProxyAPI/issues/258)
    - If you just close the terminal / window or donâ€™t pick a real project (or ALL), no Gemini credential file gets written into ~/.cli-proxy-api, and later requests from Droid will hit unknown provider.
    - brew services restart cliproxyapi
  - [CLIProxyAPIé…ç½® Gemini CLIæœ€åä¸€æ­¥å¤±è´¥ï¼šGoogleè´¦å·æƒé™è®¾ç½®ä¸å¤Ÿ ](https://github.com/router-for-me/CLIProxyAPI/issues/480)
    - å¤§é™†ç½‘å‹è¯·åœ¨config.yamlä¸­è®¾ç½®proxy-urlæˆ–å¼€å¯tunæ¨¡å¼çš„ä»£ç†
  - [ç›®å‰å‘ç°çš„ä¸€äº›Cli Proxy APIé—®é¢˜çš„è§£å†³æ–¹æ³• _202602](https://linux.do/t/topic/1592398)
  - https://github.com/router-for-me/Cli-Proxy-API-Management-Center /MIT/202601/ts
    - a WebUI interface based on CLI-Proxy-API, designed to simplify configuration modifications and runtime status monitoring.
    - Since version 6.0.19, the WebUI ships with the main program; access it via `/management.html` on the API url
  - https://github.com/router-for-me/CLIProxyAPIPlus /MIT/202512/go
    - the Plus version of CLIProxyAPI, adding support for third-party providers on top of the mainline project.
    - Added GitHub Copilot support (OAuth login)
    - Added Kiro (AWS CodeWhisperer) support (OAuth login)
  - https://github.com/dongshuyan/CPA-Dashboard 
    - æ§åˆ¶é¢æ¿ - æœåŠ¡ç®¡ç†ä¸è´¦æˆ·ç›‘æ§ Web ç•Œé¢
    - å¯åŠ¨ / åœæ­¢ / é‡å¯ CLIProxyAPI æœåŠ¡
- https://github.com/automazeio/vibeproxy /688Star/MIT/202512/swift
  - Native macOS menu bar app to use your Claude Code & ChatGPT subscriptions with AI coding tools - no API keys needed
  - native macOS menu bar app that lets you use your existing Claude Code, ChatGPT, Gemini, Qwen, and Antigravity subscriptions with powerful AI coding tools like Factory Droids â€“ no separate API keys required.
  - Built on CLIProxyAPIPlus, it handles OAuth authentication, token management, and API routing automatically. One click to authenticate, zero friction to code.
  - ğŸ‘€ æ³¨æ„ msty studio å†…ç½®å¹¶è‡ªåŠ¨å¼€å¯äº†Vibe CLI Proxy, ä¼šå¯¼è‡´é€šè¿‡ç³»ç»ŸåŒ…ç®¡ç†å™¨å®‰è£…çš„cliproxyapiå‡ºç°ç«¯å£å†²çªè€Œä¸å¯ç”¨

- https://github.com/zhalice2011/ProxyLLM /MIT/202601/ts
  - Electron åº”ç”¨ï¼Œç”¨äºæ•è· LLM ç½‘ç«™çš„æµè§ˆå™¨ä¼šè¯ï¼Œå¹¶åœ¨æœ¬æœºæš´éœ² OpenAI å…¼å®¹ API
  - OpenAI å…¼å®¹ APIï¼šPOST /v1/chat/completionsã€GET /v1/modelsï¼Œä»¥åŠ Anthropic åŸç”Ÿ POST /v1/messagesã€‚
  - å¤šç«™ç‚¹æ§åˆ¶é¢æ¿ï¼šæ·»åŠ /åˆ é™¤ç«™ç‚¹ã€æ‰“å¼€/åˆ·æ–°çª—å£ã€æŸ¥çœ‹è¯·æ±‚å¹¶é€‰æ‹©å‡­æ®ã€‚
  - é€‚é…å™¨ä½“ç³»ï¼šå°†ä¸åŒç«™ç‚¹åè®®è½¬æ¢ä¸º OpenAI æ ¼å¼ï¼Œå†…ç½®å¤šç§ç‰¹å®šé€‚é…å™¨ã€‚
  - å‡­æ®æ•è·ï¼šElectron webRequestã€CDPï¼ˆHTTP + WebSocketï¼‰ï¼Œä»¥åŠå¯é€‰æœ¬åœ° MITM ä»£ç†ã€‚
  - Claude Code æ¥ç®¡/æ¢å¤ï¼šå°† Claude CLI æŒ‡å‘æœ¬åœ°ä»£ç†ã€‚

- https://github.com/justlovemaki/AIClient-2-API /1.9kStar/GPL/202512/js
  - an API proxy service that breaks through client limitations, converting free large models originally restricted to client use only (such as Gemini, Antigravity, Qwen Code, Kiro) into standard OpenAI-compatible interfaces

- https://github.com/aiclientproxy/proxycast /632Star/GPL/202512/rust/ts
  - https://aiclientproxy.github.io/proxycast/
  - æŠŠä½ çš„ AI å®¢æˆ·ç«¯é¢åº¦ç”¨åˆ°ä»»ä½•åœ°æ–¹
  - https://x.com/geekbb/status/2002235372345122842
    - æœåŠ¡æ˜¯ä¸­åˆéƒ¨ç½²çš„ï¼Œå·æ˜¯ä¸‹åˆå°çš„

- https://github.com/axibayuit-a11y/2apifare /CC-NC/202512/python
  - å°† GeminiCLI è½¬æ¢ä¸º OpenAI å’Œ GEMINI API æ¥å£
  - å¤šç§è®¤è¯æ–¹å¼ï¼šæ”¯æŒ Authorization Bearerã€x-goog-api-key å¤´éƒ¨ã€URL å‚æ•°ç­‰
  - å¤šç§æµå¼æ”¯æŒ
  - è‡ªåŠ¨è®°å½• IP è¯·æ±‚ç»Ÿè®¡ï¼ˆä»…ç»Ÿè®¡æˆåŠŸçš„ AI å“åº”ï¼‰

- https://github.com/lza6/zai.is-2api-python /apache2/202512/python
  - è§£é” Zai.is çš„æ— é™æ½œèƒ½ (Pythonç‰ˆ)

- https://github.com/lza6/Qwen-2api /apache2/202510/python
  - é€šä¹‰åƒé—®é«˜æ€§èƒ½APIä»£ç†
  - éœ€è‡ªå¤‡ Cookieã€é‡‡ç”¨ Nginx + FastAPI é«˜æ€§èƒ½æ¶æ„ã€æ”¯æŒç²˜æ€§ä¼šè¯ä¸å¤šè´¦å·è½®è¯¢ã€åŸç”Ÿæµå¼ API è½¬æ¢ã€Docker ä¸€é”®éƒ¨ç½²

- https://github.com/BlueSkyXN/AI2API /GPL/202508/go
  - Many AI-> API (OpenAI/DeepSeek)

- https://github.com/ben-vargas/ai-sdk-provider-opencode-sdk /MIT/202512/ts
  - A community provider for the Vercel AI SDK that enables using AI models through OpenCode and the @opencode-ai/sdk. 
  - This provider enables you to use OpenCode's AI capabilities through the familiar Vercel AI SDK interface, supporting generateText(), streamText(), generateObject(), and streamObject().

- https://github.com/lza6/notion-2api /apache2/202510/python
  - å°†ä½ å¼ºå¤§çš„ Notion AI ä½“éªŒï¼Œæ— ç¼è½¬æ¢ä¸ºå…¼å®¹ OpenAI æ ¼å¼çš„ API æœåŠ¡çš„ç¥å¥‡é¡¹ç›®ã€‚è¿™æ„å‘³ç€ï¼Œä½ å¯ä»¥å°† Notion AI ä½œä¸ºåç«¯ï¼Œé©±åŠ¨ä»»ä½•æ”¯æŒ OpenAI API çš„åº”ç”¨ç¨‹åºã€è„šæœ¬æˆ–æœåŠ¡ã€‚
# more
- https://github.com/beuaaa/pywinauto_recorder /MIT/202411/python
  - https://pywinauto-recorder.readthedocs.io/
  - A record-replay tool to automate GUI via pywinauto
  - records user interface actions and saves them in a Python script. The saved Python script can be run to replay the user interface actions previously recorded.
  - "Pywinauto recorder" is a unique inspect/record/replay tool in the open source field because it generates reliable scripts without hard-coded coordinates thanks to Pywinauto.
  - The functions of the generated Python script return Pywinauto wrappers so it can be enhanced with Pywinauto methods.
