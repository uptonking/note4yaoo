---
title: lib-db-app-community-search
tags: [community, database, search]
created: 2023-10-26T19:55:59.634Z
modified: 2023-10-26T19:56:12.974Z
---

# lib-db-app-community-search

# guide

# discuss-stars
- ## 

- ## 

- ## 

- ## What is the sqlite equivalent for document search? 
- https://twitter.com/squarecog/status/1768773259653533755
  - Like if I have a few doc files and I want to create a tiny index and query it from my code, with no other infra to run?
- doesn't really exist unfortunately. sqlite has an FTS module but it's not very good.
- Tantivy came closest 
- Depending on the size, you could use FAISS to embed and index your dataset. Then run similarity search, vector clustering and more as if you had an in memory DB.

# discuss-text-search
- ## 

- ## 

- ## 

- ## If you have a text search feature in your product, how do you implement it?
- https://twitter.com/aboodman/status/1760036352220143772
  - db-fts vs lucene vs ilike

- People underestimate what can be done with client side searching. 9/10 it can, in my experience, be implemented fully client side.
- dataset is small enough that loading everything on the frontend, with fuse.js and periodic indexing works surprisingly well.

- we are making this decision right now. probably going with postgres fts and expecting to replace it in a year when it inevitably gets slow / isn't good enough. or when @paradedb is usable on @render and we can have the best of both worlds.
- Couchbase has an FTS engine that works along the query engine. Itâ€™s really convenient because I can filter the documents upstream within an SQL-like query.

- pinecone hybrid + elastic
- Semantic search with Pinecone, Googleâ€™s Multimodal embeddings, and Firebase cloud functions

- Text search is effectively my entire product, so not typical or representative. But I use Vespa. Would switch to any search product that nicely implemented end to end retrieval with Colbert though.

- Actually building my own right now. wouldnâ€™t recommend it for most people, inverse indexes are a bitch to work with
# discuss-pm-search
- ## 

- ## 

- ## 

- ## 11 ç§è¯­è¨€ï¼Œ700GB æ•°æ®ï¼Œ1.44 äº¿ä¸ªå‘é‡ï¼Œç´¢å¼•æ•´ä¸ªç»´åŸºç™¾ç§‘
- https://x.com/tuturetom/status/1824265560483570115
  - @upstash å¼€æº ã€ŒSemantic Search on Wikipediaã€å¹¶æä¾›åœ¨çº¿ä½“éªŒåœ°å€
- https://github.com/upstash/wikipedia-semantic-search /MIT/202408/ts
  - https://wikipedia-semantic-search.vercel.app/
  - Semantic Search on Wikipedia with Upstash Vector
- è¿™ç±»çš„æ•°æ®å’Œembeddingå¼€æºæ„ä¹‰æ›´å¤§. çœ‹äº†ä¸‹æ˜¯bge-m3çš„embedding model (çœ‹é‡å¤šè¯­è¨€) å…·ä½“chunkæ˜¯ç”¨çš„è‡ªç„¶æ®µ, ç„¶åè¿‡æ»¤æ‰è¿‡çŸ­çš„.

# discuss-recsys
- ## 

- ## 

- ## 

- ## TikTok just open-sourced their recommender system framework (Monolith) -- and it uses Keras _20241220
- https://x.com/fchollet/status/1869949776764252328
  - This means that nearly all the major recommender systems in the industry are built on Keras -- YouTube, TikTok, Spotify, Snap, X/Twitter, and many more (Grubhub...)

- wild how Keras became the unofficial standard for big tech recommenders... feels like Python/PyTorch vs TensorFlow wars are settling

- X/Twitter doesnâ€™t use Keras
# discuss
- ## 

- ## æœç´¢å¼•æ“&çˆ¬è™«å·¥ç¨‹å¸ˆçš„å·¥å…·é“¾æ„Ÿè§‰ç°åœ¨å…¨é¢é¢ä¸´æ´—ç‰Œäº†ã€‚
- https://x.com/karminski3/status/1879333078558179725
  - ä»¥å‰é SVMæ¥åˆ†ç±»ï¼Œé  TF-IDF æ¥æŠ½å…³é”®è¯ï¼Œtrie-tree æ¥è¿‡æ»¤æ•æ„Ÿè¯ï¼ŒåŸºäºæ–‡æœ¬å¯†åº¦ç®—æ³•æ¥æŠ½æ­£æ–‡ï¼Œé ä½™å¼¦ç›¸ä¼¼åº¦ç­‰ç›¸ä¼¼åº¦ç®—æ³•æ¥æ¶ˆé‡ã€‚
  - ç°åœ¨ï¼Œå¤§æ¨¡å‹èƒ½å…¨é¢å–ä»£è¿™äº›ä¼ ç»ŸNLPåšæ³•äº†ã€‚
- ä¸ä»…ä»…æ˜¯è¿™ä¸ªå±‚é¢ï¼Œä¼ ç»ŸNLPçš„å¾ˆå¤šæ–¹å‘éƒ½ä¼šé¢ä¸´é—®é¢˜ã€‚æˆ‘ä»¬åŸæ¥ä¸ƒå…«ä¸ªç®—æ³•(æœ‰æ•™æˆã€åšå£«ã€å¤§å‚ç»å†)å»ºç«‹çš„äº§å“ï¼Œç°åœ¨å‡†å¤‡ç”¨å¤§æ¨¡å‹é‡æ„ï¼Œå‘ç°å¯ä»¥æ²¡æœ‰ç®—æ³•æˆ–è€…åªéœ€è¦ä¸€ä¸ªäº†è§£ç®—æ³•åŸºæœ¬æ¦‚å¿µçš„å·¥ç¨‹ä¹Ÿå¯ä»¥åšåˆ°ã€‚

- ç›®å‰ RAG é¢†åŸŸï¼Œæ„Ÿè§‰è¿˜æ˜¯éœ€è¦ç»“åˆä¼ ç»Ÿçš„æœç´¢é‚£å¥—ã€‚

- å‚åŸŸå¯¹ç²¾ç¡®åº¦æœ‰è¦æ±‚çš„ï¼Œè¿˜æ˜¯bertå’Œä¼ ç»Ÿæ–¹æ³•å¥½ç”¨ï¼Œllmåªæ˜¯æ³›åŒ–å¼ºã€‚ä½†ä»ç§‘ç ”è§’åº¦ä¼ ç»Ÿnlpç¡®å®æ²¡å¿…è¦åšäº†
  - æ˜¯çš„ï¼Œä¸è¿‡æˆ‘è§‰å¾—å‚æœç°åœ¨é¢ä¸´çš„æ–°æŒ‘æˆ˜ä¸å…‰æ˜¯ç²¾åº¦ï¼Œè€Œæ˜¯å¤šç§åª’ä½“ç±»å‹ï¼Œç°åœ¨å¤§å¤šæ•°å‚ç›´ç¤¾åŒºéƒ½æ˜¯çŸ­è§†é¢‘+å›¾äº†ã€‚å¯¹è¿™äº›å†…å®¹è¿›è¡Œç´¢å¼•ä¹Ÿä¸æ˜¯ä¼ ç»ŸNLPèƒ½å¾ˆå¥½è§£å†³çš„äº†
- å›¾ç‰‡, è§†é¢‘å†…å®¹çš„æ–‡å­—åŒ–, å¯¹äºLLMæ¨¡å‹åƒç®—åŠ›, ä¸æ˜¯ä¸€èˆ¬å…¬å¸èƒ½å…»çš„èµ·æ¥çš„. æ¨¡å‹æ˜¯å¼€æº, ä½†æ˜¯å…»ä¸èµ·.

- ## [Elasticsearch SQL | Hacker News_202210](https://news.ycombinator.com/item?id=33320477)
- MongoDB has an SQL interface these days if you need it
- Seems like all the NoSQL databases eventually implement SQL, maybe we should use EventuallySQL instead NoSQL
- Even DynamoDb has one
- Microsoft's CosmosDB (their DocumentDB clone) has a SQL-like (yes) interface.
- Cassandra added CQL which is very similar to but not exactly SQL.
- Hadoop (and any other Spark data source) via SparkSQL

- I would like SQL better if jOOQ-style libraries were common across every major language. A standardized query language is good, but passing in queries as strings will never not feel wrong to me.
# discuss-code-search
- ## 

- ## 

- ## ğŸŒ° The code search on GitHub is a great tool. But how does it work?
- https://twitter.com/Franc0Fernand0/status/1762094007348306234
  - You can search over 200M+ public repositories in seconds with it. 

- The code search problem is not the same as the normal full-text search.
- Full text lets you look through all the words in a file to find a search term. 
  - This is a well-known problem that systems like Lucene and Elasticsearch handle.
- Code search is different and has its own rules:
  - there is no stemming(è¯å¹²)
  - punctuations are ignored
  - words from queries are left intact
- GitHub uses Blackbird: a Rust-based search engine tailored to search through programming languages.
- All text search engines use a data structure called Inverted Index. 
- An inverted index resembles an index section of a textbook:
  - all words are ordered alphabetically
  - each word is followed by page numbers where the word is found
- Blackbird uses a particular type of inverted index called an n-gram index. 
  - Building such a data structure at the GitHub scale was quite challenging. 
- The collection of documents was too large for a single inverted index. 
  - How to deal with this? By sharding.
  - Documents are partitioned across shards based on blob object IDs. This ID is given by the SHA-1 hash of the file contents; thus, identical files always share the same ID. 

- Architectures for crawling and indexing are generally stream processing flows that transform and augment the data as it is collected. Not surprising that Kafka plays a big role there.
