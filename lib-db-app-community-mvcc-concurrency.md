---
title: lib-db-app-community-mvcc-concurrency
tags: [community, concurrency, database-design, mvcc]
created: 2023-11-01T10:14:25.622Z
modified: 2023-11-01T10:15:06.245Z
---

# lib-db-app-community-mvcc-concurrency

# guide

- [é«˜å¹¶å‘ç³»ç»Ÿè®¾è®¡ 40 é—® | JAVA æ¶æ„å¸ˆç¬”è®°](https://zq99299.github.io/note-architect/hc/)
# discuss-stars
- ## 

- ## 

- ## 
# discuss-transactions
- ## 

- ## ğŸ’¡ How do atomic transactions work in a database?
- https://twitter.com/Franc0Fernand0/status/1759563991540494663
- Atomicity makes it possible for a transaction to have only 2 results:
  - it successfully executes all the operations and commit
  - it aborts because of a failure and undoes all the changes
- In a single database, atomicity is possible by saving all the changes to the data in a write-ahead log (WAL).
  - Every time changes are made, the WAL saves them on the disk so that they will last.
  - Each entry of the WAL contains all the information to undo all the changes.
- However, the WAL approach is insufficient if the transaction involves more than one database. 
  - In these situations, the two-phase commit protocol (2PC) is often used. 
  - The protocol says that one process should be the coordinator and the others should be participants.
  - Most of the time, the coordinator is the client process that requires the transaction.
- 2PC protocol has 2 steps:
- 1. Prepare
  - The coordinator requests everyone to get ready to complete the transaction. Each participant answers if they can commit or not. 
  - After answering, the participants wait for further instructions.
- 2. Commit
  - If all participants are ready, the coordinator sends them a commit request. Otherwise, it will ask to abort.
  - This step is a point of no return: the transaction has to be committed or aborted.
- The 2PC protocol works but has some drawbacks: 
  - it's slow since it requires multiple round trips between the processes
  - it gets blocked if the coordinator fails or a participant fails in the commit step
- Replicating the involved processes makes 2PC more robust but adds complexity.

- ## Relies on a global logical clock and claims that an MVCC visibility check can be as simple as an integer comparison. 
- https://twitter.com/sunbains/status/1757617183218442588
  - Order transaction on their â€œrecentnessâ€ which speeds up GC.
- Would love to see a comparison to LMDB, as its the best one(currently) in terms of random read perf.

- ## What is a Transaction
- https://twitter.com/DominikTornow/status/1759623957291147331
  - A transaction is a sequence of a read or a write of a data object that ends in exactly one commit or exactly one abort.

- ## What are transactions in a database?
- https://twitter.com/Franc0Fernand0/status/1754422259869974682
  - Transactions are a way for databases to group a set of operations into one.
  - This is helpful in many ways and simplifies the programming model at the application level.
  - In a single relational database, transactions make sure that the following ACID conditions are met

# discuss
- ## 

- ## 

- ## 

- ## 

- ## ğŸ†šï¸ Trying to get a sense for thread architectures:
- https://twitter.com/eatonphil/status/1773518000043299309
- Single-threaded: Cache-friendly and scales decently if you use some form of async io. Good for tasks with little-to-medium CPU-work since cache won't get busted. i.e. works fine with shared data between tasks. Too much CPU-work though limits your ability to scale.
- Work-stealing & work-sharing: Cache-unfriendly, works fine with sync or async io, since cache is core-local and work-switching threads (to another core) thus busts the cache/makes it ineffective. Fine for tasks with little CPU-work where cache doesn't matter as much. Scales well for little CPU-work tasks.
- Thread-per-core: Cache-friendly so long as work is independent, works fine with sync or async io. Scales best among all options for small or large CPU-work. Even if there is shared data, still probably scales better than work-stealing/sharing and single-thread.
- Multi-process: Basically the same as thread-per-core, if processes are 1:1 with cores?

- cache is not important compared to blocking IO(disk>network) wait, which is the origins async-io is used for. But concurrent programming includes the threading/cache thing, while the `concurrent` concept covers the syntax sugar async/await.

- Thread-per-core with blocking I/O is going to end up leaving lots of cores idle so you pretty much have to use async. I wonder if the cache friendliness/unfriendliness has ever been measured or if it's propaganda. Sadly, results are going to be different between Intel & AMD.

- If you want to build intuition, think about how you are mapping hardware resources (CPU and memory) to your application logic and state.

- ## If you are interested in exploring Race Conditions & Data Races, I recommend Testing for Race Conditions via SMT Solving
- https://twitter.com/DominikTornow/status/1758921755807437258

- ## The diagram below explains what ACID means in the context of a database transaction.
- https://twitter.com/alexxubyte/status/1732783270855876654

- ## ğŸ˜ï¸ When Uber created their in-house database (known as Schemaless), they wanted high-availability writes.
- https://twitter.com/ProgressiveCod2/status/1726136613468852376
  - This was difficult to achieve because all writes in their setup went to the Leader node.
  - And if the Leader node goes down, HA becomes difficult to achieve.
  - To get around this issue, Uber used a technique known as Buffered Writes.
  - Buffered Writes meant that every write request was stored on at least two nodes: - The Primary Leader - The Secondary Leader
  - But there's a lot that goes behind the scenes to make the whole thing work
  - [PC#16 - The Secret Trick to High-Availability_202310](https://progressivecoder.beehiiv.com/p/the-secret-trick-to-high-availability)

- ## Cool thread-safe triple buffering approach made lock-free by atomically swapping the pointers to the buffers
- https://twitter.com/zack_overflow/status/1722275195594133817
  - Thinking about using this for my code editor when I add LSP support
  - The main render thread needs to get data from the second thread which manages the LSP server process

- ## ä»Šå¹´ gopher å¤§ä¼šä¸Šçš„åˆ†äº«ï¼šBuilding a Highly Concurrent Cache in Go: A Hitchhiker's Guide
- https://twitter.com/kscooooo/status/1719976363166498889
- LRUã€LFU éƒ½ç®€å•è¿‡äº†ä¸€ä¸‹ï¼Œè¿˜æœ‰ä¿©è€…çš„ç»“åˆ LRFU (Least Recently/Least Frequently) ï¼Œå·¥ä½œåŸç†ç±»ä¼¼äº LFUï¼Œæ¯ä¸ªé¡¹éƒ½æŒæœ‰ä¸€ä¸ªå€¼ï¼Œå« CRF(Combined Recency and Frequency)ï¼Œé€šè¿‡ä¸€ä¸ªå‚æ•° Î» æ¥å†³å®šå¯¹æœ€è¿‘ entry çš„æƒé‡ã€‚
  - ç„¶åç€é‡ä»‹ç»äº† DLFU (Decaying Least Frequently Used)ï¼Œæ˜¯ LFU çš„å˜ä½“ï¼Œéšç€æ—¶é—´çš„æ¨ç§»ï¼Œentry çš„è®¿é—®è®¡æ•°ä¼šè¡°å‡ã€‚å¯¹æ¯” LFU ä¼šæŠŠé•¿æœŸä¸ç”¨çš„çƒ­é—¨ entry å¹²æ‰ã€‚
- å…¶æ¬¡å°±æ˜¯è€ç”Ÿå¸¸è°ˆçš„ä¼ªå…±äº«ã€‚ä¼ªå…±äº«å°±æ˜¯å¤šä¸ª cpu è®¿é—®äº†ä¸€ä¸ª cache line ä¸Šä¸åŒçš„å˜é‡ï¼Œä¸€ä¸ª cpu ä¿®æ”¹äº†é‚£ä¹ˆå…¶ä»–çš„ cpu çš„ç¼“å­˜å°±å¤±æ•ˆäº†ï¼Œå°±å¾—èµ° cpu åŒæ­¥çš„åè®®(mesi)ï¼Œè¿™ä¸ªå°±æ…¢äº†ã€‚
  - å¦‚æœè®¾è®¡çš„æ•°æ®ç»“æ„æ¯”å¦‚åƒ struct çš„ä¿©æˆå‘˜éƒ½ä¼šä¿®æ”¹çš„è¯ï¼Œå°±ç©ºé—´æ¢æ—¶é—´ï¼Œç»™è¿™ä¿©æˆå‘˜å˜é‡ä¸­é—´å¡æ— ç”¨å­—èŠ‚æŠŠä½ç½®ç»™å äº†ï¼Œè®©è¿™ä¿©æˆå‘˜å˜é‡åœ¨ä¸åŒçš„ cache line ä¸Šã€‚è¿™æ ·å¤šæ ¸ cpu ä¿®æ”¹å„è‡ªçš„æˆå‘˜å˜é‡æœ€å¤§ç¨‹åº¦å°±é¿å…äº† mesi è¿™ç§åŒæ­¥ã€‚
- xsync. Map æˆ‘ä¹‹å‰çœ‹åˆ°è¿‡ï¼Œæ˜¯ java å†™çš„é‚£ä¸ªæ—¶åºæ•°æ®åº“ QuestDb ä¸»ç¨‹å†™çš„å¹¶å‘åº“ï¼Œæ ¸å¿ƒæ€æƒ³å°±æ˜¯æ•°æ®ç»“æ„åŸºäº CLHT(Cache-Line Hash Table) è®¾è®¡çš„ï¼Œè·ŸåŸç”Ÿçš„ map å’Œ sync. Map ç›¸æ¯”ï¼Œå®ƒçš„æ¡¶æ˜¯ç‹¬å  cache line çš„ï¼Œç©ºé—´æ¢æ—¶é—´ã€‚
  - sync. Map æˆ‘è®°å¾—ä¹Ÿæ˜¯ç©ºé—´æ¢æ—¶é—´ï¼Œä½†æ˜¯æ€è·¯ä¸åŒï¼Œå¼„äº†ä¸€ä¸ª read map ä¸“é—¨å¹¶å‘è¯»ï¼Œå†™çš„è¯å°±æ˜¯å¾€ dirty map å†™ï¼Œç„¶ååŒæ­¥ï¼Œåœ¨ read map è¯»ä¸åˆ°å°±å¾€ dirty map é‡Œè¯»ï¼Œkey åˆ çš„è¯å¤šä¸ªä¼šæ”’åœ¨ä¸€èµ·åˆ ï¼Œç»†èŠ‚è¦å¤šå¾ˆå¤šã€‚ 
  - xsync. Map å°±ä¾§é‡äºå¹¶å‘ç¯å¢ƒä¸‹å†™å¤šçš„æƒ…å†µã€‚
- ç„¶åå°±æ˜¯å•ç‹¬å¼€ goroutine å¼„ç¼“å­˜æ¸…ç†ï¼Œé¿å…é˜»å¡ä¸»é€»è¾‘ã€‚é©±é€ç¼“å­˜çš„è¿‡ç¨‹æ¢äº†æ’åºç®—æ³•ï¼Œä¸æ˜¯ç”¨çš„æ ‡å‡†åº“çš„ pdqsortï¼Œç”¨çš„ quickselect ç®—æ³•ï¼Œæ˜¯çº¿æ€§ç®—æ³•ï¼Œåªå¯¹ N ä¸ªæœ€å°å…ƒç´ è¿›è¡Œæ’åºï¼Œä¸å¯¹æ•´ä¸ªæ•°ç»„è¿›è¡Œæ’åºã€‚
  - ç›¸å½“äºå‰ªæäº†ã€‚è¿™ä¸ªå°è±¡è¿˜æ˜¯è›®æ·±åˆ»çš„ï¼Œå½“æ—¶åœ¨é¢‘é“é‡Œä½œè€…è®¨è®ºçš„æ—¶å€™ï¼Œç¤¾åŒºé‡Œå°±æœ‰äººç«‹é©¬å›ç­”äº†è¿™ä¸ªï¼Œå½“æ—¶çœ‹åˆ°è¿˜æ˜¯è§‰å¾—å¦™å•Šï¼Œè¿˜æ˜¯ç³Š crud ä¹…äº†åŸºæœ¬éƒ½æ˜¯ sort æ ‡å‡†åº“ä¸€æŠŠæ¢­ã€‚å½“æ—¶ go runtime çš„ä¸»ç¨‹ michael è¯´éšæœºé©±é€è›®å¥½çš„ï¼Œéƒ½ä¸ç”¨æ’åºäº†ï¼Œä½œè€…å›å¤è¯´éšæœºé©±é€æ˜¯è›®å¥½çš„ï¼Œè¿˜èƒ½ç®€åŒ– 80% çš„å®ç°
- è¿˜æœ‰å¸¸è§åŸå­æ“ä½œæ›¿æ¢é”ï¼Œè¿™é‡Œ go å¹¶å‘åº“ä¸»ç¨‹ bryan å½“æ—¶ç‰¹æ„åœ¨é¢‘é“é‡Œå¼ºè°ƒäº†ä¸€ä¸ªç‚¹ï¼Œå¦‚æœä½¿ç”¨åŸå­æ“ä½œåœ¨æ¯æ¬¡è®¿é—®æ—¶æ›´æ–°å…±äº«å˜é‡ï¼Œå…¶å®ä¹Ÿä¸ä¼šä»åŸå­æ“ä½œä¸­æåˆ°è›®å¤§çš„æå‡ã€‚åŸå­å†™å…¥åªæ˜¯å°†é”å®šä»æ˜¾å¼ï¼ˆåœ¨ä»£ç ä¸­)ç§»åŠ¨åˆ°éšå¼(CPU ç¼“å­˜ä¸€è‡´æ€§åè®® mesi)ï¼Œè¿˜æ˜¯æœ€åä¼šç¢°åˆ°é”å®š cache line äº§ç”Ÿç«äº‰ã€‚
- æ‰€ä»¥å¤§éƒ¨åˆ†ç¯‡å¹…éƒ½æ˜¯å¼ºè°ƒä¼ªå…±äº«ã€cpu ç¼“å­˜ä¸€è‡´æ€§åè®®ã€‚
  - å…¶ä»–çš„æŠ€å·§æœ‰æ¯æ¬¡æ“ä½œè®°å¾—æœ‰è¶…æ—¶å…œåº•ï¼Œç¼“å­˜æ“ä½œæ—¶è®°å¾—è¦åŠæ—¶æ£€æŸ¥ ctxï¼Œè¶…æ—¶äº†å°±ç«‹é©¬é‡Šæ”¾é”è¿”å›ã€‚
  - å†™å¥½ go bench(RunParallel) ã€å–„ç”¨ pprofã€benchstat å¯¹æ¯”æ–°æ—§ bench çš„å®ç°ç­‰ã€‚ç„¶åå·®ä¸å¤šå°±æ²¡äº†
- ç»“åˆäº†ç¤¾åŒºé¢‘é“çš„è®¨è®ºå’Œ ppt çš„æ€»ç»“ï¼Œè§†é¢‘ä»Šå¹´ gopher å¤§ä¼šè¿˜æ²¡æ”¾å‡ºæ¥ï¼Œæ€»ä½“æ¯”è¾ƒç®€å•ï¼Œéƒ½æ˜¯ç¤¾åŒºè€ç”Ÿå¸¸è°ˆçš„ã€‚åšä¸ªç¬”è®°æ–¹ä¾¿è‡ªå·±
