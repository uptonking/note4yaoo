---
title: thread-dev-http-restful-rpc
tags: [graphql, http, restful, rpc, thread]
created: 2021-09-20T18:37:02.986Z
modified: 2021-09-20T18:38:00.319Z
---

# thread-dev-http-restful-rpc

# guide

- solutions
  - [Arrow Flight RPC â€” Apache Arrow](https://arrow.apache.org/docs/format/Flight.html)
# discuss-protobuf
- ## 

- ## 

- ## 

- ## ğŸŒ° How Jira became 33x faster by using Protobuf _202509
- https://x.com/milan_milanovic/status/1963127320538931461
  - Their Issue Service was drowning in JSON, and they knew they had to make a change.
  - The problem wasn't apparent at first. JSON worked perfectly fine when they had thousands of issues. But as they scaled to millions, then hundreds of millions, those "harmless" JSON payloads became their bottleneck.
  - Every request was carrying unnecessary payload and burning CPU cycles.
  - They built ğ—±ğ˜‚ğ—®ğ—¹ ğ—²ğ—»ğ—±ğ—½ğ—¼ğ—¶ğ—»ğ˜ğ˜€ - one for JSON, one for Protobuf, and used feature flags with three modes

- ## Unpopular opinion: use Protocol Buffers, not because the format is that great (it isn't), but because the range of supported languages for codegen can't be beat.
- https://x.com/JustDeezGuy/status/1917589307113537664
  - Further unpopular opinion: Protocol Buffers plus named pipes (Windows) or UNIX-domain sockets (everything else) are a great IPC mechanism for isolated processes on single hosts.

- Protobuf supports twice as many languages as ASN.1 out of the box, with another five times as many languages covered by third parties.

- 1M$ idea: protocol buffers, but with off-heap memory IO bypassing and RDMA

- The one thing protobufs do really badly is having a bunch of optional fields.  At some point of complexity, sending protobufs directly over the wire gets worse than using a dedicated streaming bus with a schema registry.

- Convince me to use protocol buffers over raw binary blobs.
  - Youâ€™ll need to come up with a mapping from those binary blobs to data structures in your code, provide some means of managing the evolution of those structures, account for the possibility of different versions interacting at the same time, etc. The point isnâ€™t Protobuf per se, 

- Protobuf alone *could* be fine, but these technologies come with strings attached as they were designed for server apps and utterly suck for local user apps.

- ## é‡åˆ°ä¸€ä¸ª Protocol Buffers in JS çš„å‘ï¼š.proto float ä¼šå¯¼è‡´ JS number ç²¾åº¦ä¸¢å¤±ã€‚
- https://twitter.com/ThaddeusJiang/status/1749662021535289653
- ç±»å‹ç³»ç»Ÿï¼š
  - DB: Float
  - JS: number
  - proto: float
- ä¸¤ç§è§£å†³æ–¹æ¡ˆï¼š
  1. proto: float -> string ä»¥å­—ç¬¦ä¸²ä½œä¸ºäº¤æ¢æ ¼å¼
  2. proto: float -> double ä¾ç„¶ä»¥æµ®ç‚¹æ•°ä¸ºäº¤æ¢æ ¼å¼ï¼Œåªæ˜¯å¢åŠ æµ®ç‚¹æ•°ç²¾åº¦

- ## ğŸ†šï¸ Is there anyone here who is using Protocol Buffers as the format of their Kafka records? 
- https://twitter.com/gunnarmorling/status/1747197582244200913
  - How has your experience been, and what made you pick protobuf over Avro?
- Protobuf is VERY popular in my experience, likely exceeding avro. Personally, I'm all for Avro and msgpack. Both provide better runtime adaptability without as much code generation.

- Avro without schema registry is terrible in terms of backwards compatibility. Protobuf is much better/easier in this. Also, with protobuf, one can easily employ nice partial deserialization tricks 

- Avro needs the encoding schema to deserialise, so with Kafka that implies the use of a schema registry. Iâ€™m sure itâ€™s better now, but CSR used to be a massive point of friction. +1 for protobuf and @bufbuild

- We use pb for its compatibility guarantee and multiple language support."Everyone uses schema registry" is simply not true for us because we hesitate to adopt it to avoid introducing another point of failure. (also it brings local testability issue IMO)
- How do you exchange schemas between producers and consumers?
  - Just git

- We use Protobuf for sending app events to Kafka and on the downstream use Spark 3.4 which now has support for parsing protobuf messages using descriptor files. We also keep the protobuf schema on Confluent schema registry. Upwards of 500M+ events per day.

- We use protobufs for Kafka (we didn't use Avro in this project). We don't share schema, instead we use protos in a way that respects its clear rules to backward compat. We also have lots of gRPC around so it's natural/easier to use the same serialization (some shared serdes etc)

- ## ğŸ¤¼ğŸ» protobuf's strength lies in its interface definition language, which makes communication between components owned by different teams easy, but it wasn't designed for performance
- https://twitter.com/eatonphil/status/1740057705124139069
- I'm working on a Go package, which will provide simple building blocks for fast zero-alloc marshaling and unmarshaling of protobuf messages with arbitrary nesting and complexity. This package will be used in @VictoriaMetrics source code initially.
- Protobuf is jack-of-all-trades. It doesn't have to be the fastest. Also one place where it really shines is schema evolution and how tolerant it is for backward-/forward-compatibility.
- At Google they use arenas for allocating protobufs to avoid overhead, but this isn't in any of the gRPC libraries. I do prefer the pb IDL to flatbuffers/capnp, but the overhead from allocations is like 99.99% of our profiles, and we even use better codegen: vtprotobuf
- This is where https://capnproto.org shines

# discuss-graphql
- ## 

- ## 

- ## 

- ## é™¤éä½ æœ‰å¾ˆç‰¹åˆ«çš„éœ€æ±‚ï¼Œ100% ç¡®å®š GraphQL éå¸¸é€‚åˆï¼Œå¦åˆ™ RESTful API è¶³å¤Ÿä½ ä½¿ç”¨
- https://twitter.com/beihuo/status/1775960603858960630
  - å› ä¸º GraphQL ä¼šå¼•å…¥å¤§é‡çš„å¤æ‚æ€§ï¼Œæ¯”å¦‚å¦‚ä½•åšç¼“å­˜ï¼Œå¦‚ä½•åš rate limitã€‚
  - æœ€åä½ ä¼šå‘ç°ä½ å¯èƒ½è¿˜éœ€è¦å¼•å…¥ federationï¼Œäº‹æƒ…ä¸€ä¸‹å­å˜äº†ã€‚å„ä¸ªè¯­è¨€å’Œæ¡†æ¶çš„å®ç°ï¼Œåˆæ˜¯ä¸€ä¸ªå‘ã€‚
- è¿˜æœ‰ç»†ç²’åº¦æ•°æ®å®‰å…¨çš„é—®é¢˜ï¼ˆä¸çŸ¥é“æ˜¯ä¸æ˜¯ä½ è¯´çš„federationåŒ…æ‹¬äº†è¿™ä¸ªï¼‰

- https://twitter.com/zhdsuperman/status/1776301948914090407
  - fb æ²¡ç»™ db æŠ½è±¡å®ç°ï¼Œç¤¾åŒºçš„å®ç°å„ä¸ªè¯­è¨€è´¨é‡å·®å¼‚å¤ªå¤§äº†ï¼Œç‰ˆæœ¬åŒ–ã€é‰´æƒã€é™æµã€å®‰å…¨ã€å‚æ•°æ ¡éªŒã€æµ‹è¯•ï¼Œgateway åˆ° db éƒ½è¦å¤§æ”¹ï¼Œå°±ä¸ºäº†å®¢æˆ·ç«¯è¯·æ±‚è°ƒç”¨æ–¹ä¾¿ä¸€ç‚¹ï¼Œæ”¶ç›Šå¤ªå°äº†ã€‚
# discuss-rpc/ipc
- ## 

- ## 

- ## 

- ## Made `bidc` â€” create bidirectional message channels between different JavaScript contexts (main document, worker, iframe, service worker, etc.)
- https://x.com/shuding_/status/1953047622844846565
  - This was highly inspired by the protocol of React Server Components and React Server Actions.

- What made you create this? 
  - Usually from real engineering pain points Iâ€™m trying to solve for a product Iâ€™m working on. If itâ€™s a common problem and I got a good & general solution, Iâ€™d love to abstract it as a utility. 

- Shall we try this for vscode extension webview <-> node communication 

- Any plans to support Chrome extensions?

- "Function reference store is getting large, it is not recommended to send anonymous and inline functions through the channel as they cannot be cached" can weak maps or finalization registry help here?
# discuss
- ## 

- ## 

- ## 

- ## âš–ï¸ Google çš„ AIP æ˜¯æ›´æ–°çš„ REST API è§„èŒƒ
- https://x.com/vikingmute/status/1987808934392992055
  - API Improvement Proposalsï¼Œå€¼å¾—å¤§å®¶çœ‹çœ‹ï¼Œä¹Ÿæ˜¯æ¯”è¾ƒç®€æ´é«˜æ•ˆçš„ API è®¾è®¡è§„èŒƒã€‚
  - [API Improvement Proposals](https://google.aip.dev/)

- ## ğŸ†šï¸ REST APIs are outdated. GraphQL is overrated. Just send JSON over WebSockets and be done with it
- https://x.com/_trish_07/status/1901695896745914395
- Real devs just send raw binary over UDP and pray it reaches

- Iâ€™m guessing you donâ€™t waste time with databases either, just flat file your data and when a user needs something push it over the web socket

- The real solution is managing events on a pub/sub broker. You can still use JSON for the payload.

- ## ğŸª§ REST API Cheatsheet
- https://twitter.com/sahnlam/status/1768159055229723063
  - six fundamental principles of REST API design
  - Key components like HTTP methods, protocols, and versioning
  - Practical tips on pagination, filtering, and endpoint design

- ## gRPC is gaining popularity for service-to-service communication. Here's why:
- https://twitter.com/sahnlam/status/1738787868414550072
  - Speed - gRPC is built on HTTP/2 and Protobufs for maximum throughput and minimal latency. Much faster than JSON over HTTP.
  - Efficiency - The compact Protobuf binary format means smaller payloads than JSON. Less data sent = better performance.
  - Type Safety - Protobufs are strongly typed, eliminating many bugs.
  - Polyglot - Write services in many popular languages, the IDL works across them all.
  - Streaming - gRPC supports bidirectional streaming for real-time data transmission.
  - Great Ecosystem - Tons of tools exist for code gen, load balancing, monitoring, and more.
- gRPC has some drawbacks:
  - More Complex - Defining Protobuf schemas and setting up gRPC can have a learning curve.
  - Not Human Readable - Protobufs are binary, so not as easy to troubleshoot as JSON. Tools like grpcurl a little bit.
  - Limited Browser Support - gRPC works best for backend microservices, not front-end apps.
- For most backend use cases, gRPC delivers an efficient, robust and high-performance communication framework perfect for modern microservices.

- Another drawback: Scaling requires proxy servers to support grpc as well

- ## gRPC ç«Ÿç„¶æ“…è‡ªæŠŠç©ºæ•°ç»„å˜æˆäº† undefinedï¼Œå‡å°‘æ•°æ®ä¼ é€’ï¼Œæä¾›æ€§èƒ½
- https://twitter.com/ThaddeusJiang/status/1734034431285886990
  - å®é™…ä¸Šï¼Œä¸ºäº†èŠ‚çœ 2 ä¸ªå­—ç¬¦å¢åŠ äº†å¾ˆå¤šé»‘ç›’ï¼Œé€ æˆ server å’Œ client çœ‹åˆ°çš„æ•°æ®ä¸ä¸€æ ·ï¼Œææ˜“äº§ç”Ÿ bugã€‚
- è¿™ç®—featureï¼Œä½†æ„Ÿè§‰arrayçš„é»˜è®¤é…ç½®æœ€å¥½æ˜¯trueï¼Œä½†ç°åœ¨é»˜è®¤æ˜¯falseäº†

- ## Forward Proxy vs Reverse Proxy
- https://twitter.com/hackinarticles/status/1710756805037445619

- ## A big optimization that could be added to @trpcio
- https://twitter.com/fabiospampinato/status/1692653720306151712
  - To send a file to the server today you need to read the entire file in memory, encode it as base64, encode that as json, then parse the json, parse the base64, and have it all in memory. All of that is wasted time basically.

- Instead, I think it could work like this:
  - Make a stream for the file.
  - Check if the RPC call contains a single stream or buffer, if so special-case this RPC call.
  - Everything except that is put in a special http header.
  - Send the stream/buffer as the body of the request

- That should be like arbitrarily faster, the bigger the file the greater the improvement.
  - No base64 encoding.
  - Much smaller encoded json payload.
  - Much smaller decoded json payload.
  - No base64 decoding.
  - No need to put the entire thing in memory at once either.

- Actually maybe something like this can even be generalized to an arbitrary number of streams/buffers per call. Like each of those could be replaced with a special token that says "I'm going to send this to you with the followup call with id [...]" or something like that 

- It already can do something like this for the experimental `FormData` support, thereâ€™s just more work to be done on supporting non-json content types before it will be production ready - probably from v11 due to a breaking change we discussed needing
  - For now the best way to transfer a file is to use a signed URL for uploads and downloads to a separate storage service. Base64 is a really bad idea for scalability

- ## What is tRPC?
- https://twitter.com/t3dotgg/status/1438434802839945220
  - tRPC is a genius abuse of Typescript to create a typesafe API on server and client with strong inference and validation.
  - defining server queries and mutations has never been easier.
  - By using TS type defs generated "from the server code", the client is able to AUTO COMPLETE EVERY ENDPOINT AND INFER TYPES CORRECTLY.
- Why should I care?
  - Sharing type definitions in a statically typed system between client and server is incredibly hard to beat.
  - I can change a field's name in DB and get errors where it's used on frontend. The 'surface area' from data -> user is tiny. Debugging is so easy.
- Why not GraphQL?
  - it's heavy.
  - React Query already got me 70% of what I wanted from gql (caching, query invalidation, etc). tRPC gets me the last 30% (and makes backend more fun too)
- Why not Blitz.js?
  - If I was starting up a new web-only project with a team, I'd likely use Blitz. 
  - Main reasons I didn't for this:

    - Only wanted the type validation
    - Bought into NextAuth.js
    - tRPC can be added to existing Next.js app, Blitz would be full replacement
