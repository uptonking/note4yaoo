---
title: pick-discuss-cs
tags: [cs, discuss, pick]
created: '2021-01-25T15:38:45.583Z'
modified: '2021-04-12T16:30:53.967Z'
---

# pick-discuss-cs

# faq

## 

## [公司项目并发量都特小，自己如何实际接触高并发项目？](https://www.zhihu.com/question/267113602)

- 高并发与大数据的技术问题，终极方案几乎都会转成分布式存储+实时流处理的解决方案，
  - 也就是将高并发的请求负载转换成大吞吐、有序队列的方式，降低高并发的同时性请求导致的CPU、内存、I/O这些资源争用的根本性问题，
  - 然后通过数据分片，落地在数据库的不同分布式节点中，实现数据upsert的水平伸缩性。

- 如果你的公司项目没有特别高的并发，那么你可以把目光转移到低延时和高吞吐上。
- 先说低延时。即使你的服务只有1 qps。如果客户端一次请求响应耗时500ms，你能不能想办法优化到250ms，甚至100ms呢？也是技术挑战。
- 在线和离线系统其实都有高吞吐的概念。
  - 说说在线，比如推荐系统中一次请求召回一万个item（item表示一篇文章或者一个短视频），需要做排序，所谓排序其实就是给item打分。
  - 那么请求一次排序服务（ranking）未必能在规定时间内计算完一万个item的打分。
  - 上游简单的处理是拆包，1000个item一包，发10次请求给排序服务。
  - 虽然对于排序服务而言，qps放大了10倍，但是能够让一万个item在规定时间内返回。
  - 如果排序服务能够一次处理10000，或者5000个item，而耗时也不会超，那么这就是在提高排序服务的高吞吐的能力。

## [深度学习领域，你心目中idea最惊艳的论文是哪篇？](https://www.zhihu.com/question/440729199)

- 有两个: ResNet和Transformer。
  - 许多大领域都离不开这两种结构。
  - Transformer更是从NLP领域走入了CV领域，大有一统天下之势。
  - ResNet大道至简，更倾向于从原来的CNN结构设计出发，通过大量的实验和分析，添加了skip connection，一招封神。
  - Transformer则另起炉灶，干脆完全抛弃了RNN的结构，从根本上尝试self-attn加全连接层对于序列建模的能力。
