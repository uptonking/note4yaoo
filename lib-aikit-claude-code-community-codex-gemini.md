---
title: lib-aikit-claude-code-community-codex-gemini
tags: [claude-code, codex, community, gemini-cli]
created: 2025-12-18T12:26:43.556Z
modified: 2025-12-18T12:27:14.982Z
---

# lib-aikit-claude-code-community-codex-gemini

# guide

# discuss-stars
- ## 

- ## 

- ## We need to find tools which can exchange contexts between the tools like Claude Code, CoWork, Codex App, Gemini CLI, Antigravity, Cursor, VSC. 
- https://x.com/sabrishsurender/status/2018525743425474606
  - Context here means all the logs and inferences and not just the end code

- ## æƒ³æ³•å®ç°äº†ï¼Œåœ¨ Cloudflare Containers è¿è¡Œ OpenCode ï¼Œå†é€šè¿‡ S3FS å®ç°æ•°æ®æŒä¹…åŒ– å’Œ Cloudflared è¿›è¡Œè¿œç¨‹è®¿é—®é¢„è§ˆé¡µé¢ã€‚
- https://x.com/miantiao/status/2015283393752416714
  - éšæ—¶éšåœ°ï¼Œä»»æ„ç»ˆç«¯éƒ½å¯ä»¥ Vide ç¼–ç¨‹äº†ã€‚
  - å®¹å™¨ä¼šåœ¨ä½ ä¸ä½¿ç”¨çš„10åˆ†é’Ÿåç¼©æ”¾è‡³ 0ï¼Œä¸æ”¶é’±ã€‚
  - ä»£ç å°± 200 è¡Œï¼Œç›´æ¥å¼€æºäº† https://github.com/miantiao-me/cloud-code
  - Cloudflare Containers çš„æŒä¹…å­˜å‚¨å°±è¦æ¥äº†ï¼Œæœ‰ä¸ªæƒ³æ³•æŠŠ Containers ææˆä¸€ä¸ªäº‘ç«¯ç”µè„‘ï¼ŒæŒ‰éœ€å¯åŠ¨è®¡è´¹ã€‚ å¤–é¢é¢å¥—ä¸€ä¸ª Zero Trust åšè®¿é—®æ§åˆ¶ã€‚

- å¦‚æœæ˜¯æƒ³éšæ—¶è¿œç¨‹è®¿é—®çš„è¯ï¼Œå…¶å®å¯ä»¥è¯•è¯•cfçš„éš§é“ï¼Œå¯ä»¥ç›´æ¥æŠŠä¸€ä¸ªå†…ç½‘çš„ç«¯å£ç»™è½¬å‘åˆ°å…·ä½“åŸŸåä¸Šï¼Œä»è€Œå®ç°å¤–ç½‘è®¿é—®ã€‚ è€Œä¸”ç›®å‰ç›´æ¥ä½¿ç”¨opencodeçš„guiçš„è¯ï¼Œæˆ‘ç›®å‰ä½¿ç”¨ä¸Šreviewä¸­è®°å½•çš„diffä¼šå‡ºç°é—æ¼ï¼Œæ‰€ä»¥ç°åœ¨å·²ç»è½¬å‘vibe kanbanäº†

- èƒ½æ¢å¤ä¸‹æ¬¡æ¥ç€ vibe å—
  - å¯ä»¥çš„ï¼Œ opencode æ•°æ®æŒä¹…åŒ–äº†

- Cold start time æ€æ ·ï¼Ÿä¸Šæ¬¡ï¼ˆä¸€ä¸ªæœˆå‰ï¼‰ç”¨ Cloudare Sandbox è¯•è¿‡ä¸€æ ·çš„ idea è®°å¾—æœ‰ç‚¹æ…¢ï¼Œæœ€åæ¢ E2B äº†ã€‚å¦å¤– S3FS å¾ˆæ…¢ï¼Œè¦git commit éƒ½å¾ˆæ…¢ï¼Œè¦ install node_modules å°±åŸºæœ¬ä¸å¯èƒ½äº†ï¼Œé™¤éæ¯æ¬¡å¯åŠ¨éƒ½é‡æ–° install åˆ° localï¼Œä½†æ˜¯é‚£æ ·å†·å¯åŠ¨å°±æ›´æ…¢äº†ã€‚è¿˜æ˜¯ sandbox è‡ªå¸¦ volume çš„æ¯”è¾ƒé è°±
  - å†·å¯åŠ¨å¹¶ä¸å¿«ï¼ŒåŠ ä¸Š opencode å¯åŠ¨ä¹Ÿæ…¢ï¼Œæ¯æ¬¡å†·å¯åŠ¨å¾— 10s å¤š ä½†æ˜¯éç”Ÿäº§æœåŠ¡ï¼Œå†·å¯åŠ¨æ…¢ä¹Ÿæ— æ‰€è°“äº†ã€‚
  - S3 æ…¢çš„é—®é¢˜æˆ‘å°½å¯èƒ½æŠŠ S3 å’Œå®¹å™¨éƒ½æ”¾åœ¨ç¾è¥¿æ¥å‡å°‘å»¶è¿Ÿï¼Œä½†æ˜¯å®¹å™¨ç›®å‰æ²¡æ³•å¼ºåˆ¶åŒºåŸŸã€‚
  - sandbox è‡ªå¸¦ volume é è°±ï¼Ÿ sandbox æ˜¯åª Cloudflare sandbox å—ï¼Ÿ  è¿™ä¸ªåº•å±‚ä¹Ÿæ˜¯å®¹å™¨+S3, åŸç†åº”è¯¥æ˜¯ä¸€æ ·çš„
# discuss-alternatives
- ## 

- ## 

- ## 

- ## [Notes after using Claude Code and OpenCode side by side : r/opencodeCLI _202602](https://www.reddit.com/r/opencodeCLI/comments/1qu44yh/notes_after_using_claude_code_and_opencode_side/)
  - Claude Code feels guarded and structured. It plans carefully, asks before doing risky stuff, and generally prioritizes safety and predictability.
  - OpenCode feels more like raw infrastructure. You pick the model per task. It runs commands, edits files, and you validate by actually running the code. More control, less hand-holding.
  - Both got the job done when I tried real tasks (multi-file refactors, debugging from logs). Neither â€œfailed.â€ The difference was how they worked, not whether they could.

- The only feature from CC that I miss is that CC can run bash commands in the background and easily check its logs. That's it. For everything else, OpenCode is superior. Once you set your custom modes, and add plugins, it's awesome.
  - There is an opencode pty plugin for that

- The only i miss when moving from CC is /rewind . Opencode has something less powerful /undo but itâ€™s tedious to use and buggy.

- The main thing OpenCode can really fail on is picking back up on things if you need to run out of usage and/or need to switch models/providers. OpenCodeâ€™s flow is already so rigid (with task management being handled in the conversation), and Superpowers expects the full lifecycle of its skills to complete a task, and doesnâ€™t wrap up things if you get interrupted.

- ## [Mistral Vibe 2.0 : r/LocalLLaMA _202602](https://www.reddit.com/r/LocalLLaMA/comments/1qt76qs/mistral_vibe_20/)
- tell us why use it instead of OpenCode. They both seem to copy ClaudeCode as far as I can see.
  - IMHO if you use Devstral, use Vibe. Each agentic tool has a different massive system prompt with slightly different tool definitions. It seems that every AI lab is fine-tuning their model to perform better with their harness. Theyâ€™ll all work on every CLI, sure, but Kimi 2.5 will surely perform better with Kimi CLI, Sonnet with Claude Code, GPT with Codex, etc.
  - Z.ai seems to be the holdout so far, they havenâ€™t released a CLI, so they chose to tune their models for Claude Code. 

- opencode doesn't support markdown tables

- I haven't use mistral-vibe much yet, but I like how short the code is compared to alternatives

- ## [droidæ˜¯å•¥, ä¸ºå•¥å¥½å¤šäººæ¨è, è·ŸClaude codeæˆ–è€…opencodeä¹‹ç±»çš„åŒºåˆ«åœ¨å“ª ](https://linux.do/t/topic/1482186)
- é—­æºç‰ˆæœ¬çš„ opencodeï¼Œå¯ä»¥ç”¨å¤šä¸ªæ¨¡å‹
  - æ¯” claudecode å¥½çš„åœ°æ–¹åœ¨äºæ¨¡å‹å¯ä»¥å¤šé€‰ï¼ŒåŒ…æ‹¬ glmï¼Œclaudeï¼Œgptï¼Œä¸”ç»ˆç«¯èƒ½åŠ›å·®ä¸å¤š
  - æ¯” codex å¥½çš„åœ°æ–¹åœ¨äº windows ä¸‹è¡¨ç°è‰¯å¥½

- å…¶å®å¤§å®¶çš„cliå·¥å…·éƒ½æ›´æ–°å¾ˆå¿«ï¼Œå¯èƒ½ç°åœ¨å¥½ç”¨ï¼Œä½†æ˜¯æ›´æ–°å‡ ä¸ªç‰ˆæœ¬å°±ä¸ä¸€å®šäº†ã€‚ä½†æ˜¯æœ€æ‡‚claudeéƒ½è‚¯å®šæ˜¯claudecodeï¼Œæœ€æ‡‚gptçš„è‚¯å®šæ˜¯codexï¼Œæ²¡å¿…è¦æŠ˜è…¾è¿™äº›å…¶å®ã€‚

- ## [ç¼–ç¨‹cliäº¤æµï¼Œdroidå’Œopencode å¯¹æ¯”ï¼Œè¿˜æœ‰æ¨¡å‹èƒ½åŠ›å¯¹æ¯” _202601](https://linux.do/t/topic/1414233)
  - ç”¨ opencode å’Œ droid ï¼Œç”¨æˆ‘çš„dsl (è¿™ä¸ªç‰¹åˆ«è€ƒéªŒæ™ºåŠ›ï¼Œå› ä¸ºæ²¡æœ‰è®­ç»ƒåˆ°)ï¼Œç”¨ç›¸åŒæ¨¡å‹ï¼Œå¹²åŒä¸€ä¸ªä»»åŠ¡ï¼Œçœ‹çœ‹æ—¶é—´æœ€çŸ­ã€‚
  - ä¸è¿‡opencode æœ‰å­agent å¯ä»¥å‡å°‘ä¸»agentçš„ä¸Šä¸‹æ–‡ï¼Œç¾¡æ…•å•Šï¼Œä¸çŸ¥é“droidæ€ä¹ˆæï¼Œæœ‰æ²¡æœ‰å¤§ä½¬ä¼šæã€‚
  - æ ·æœ¬å¤ªå°‘äº†ï¼Œæˆ‘å¤§æ¦‚åªæµ‹äº†äº”å…­æ¬¡å·¦å³ï¼Œä¸è¿‡åœ¨æˆ‘è¿™ä¸ªè‡ªå®šä¹‰dsl åœºæ™¯ï¼Œè€ƒéªŒæ¨¡å‹è¿ç§»èƒ½åŠ›æƒ…å†µä¸‹ï¼Œåªèƒ½è¯´minimax 2.1 æ˜¯æ¯”è¾ƒå¼ºçš„ã€‚

- å¦‚æœminimaxä¸è¦æ±‚2.1çš„è¯å¯ä»¥è¯•è¯•ç”¨Googleéƒ¨ç½²çš„minimax2ï¼Œç”¨TPUé€Ÿåº¦èƒ½è¾¾åˆ°160tok/sï¼Œæˆ‘ä»¬å·²ç»æ‹¿æ¥è·‘ä¸€äº›æµç¨‹é•¿çš„subagentäº†

- æ˜¨å¤©ç”¨opencodeï¼ŒtokençœŸçš„èŠ‚çº¦

- æœ‰ä¸€ç‚¹æˆ‘è§‰å¾—opencodeåšçš„è¿˜è¡Œ, å°±æ˜¯æ–°ç‰ˆæœ¬çš„deepseekåœ¨opencodeä¸Šå¯¹æ€è€ƒåšçš„é€‚é…æ›´ç§¯æ

- Droidä¹Ÿæœ‰subagentï¼Œä¸è¿‡å®ƒå«droids

- ## [Forked Google's Gemini CLI to work with local LLMs (MLX, llama.cpp, vLLM) : r/LocalLLaMA _202512](https://www.reddit.com/r/LocalLLaMA/comments/1pn0gpa/forked_googles_gemini_cli_to_work_with_local_llms/)
  - So i forked the gemini cli and added local llm support, no google account needed, runs offline.

- ## [Looking for an alternative to ClaudeCode. Is OpenCode + GLM 4.7 my best bet? : r/opencodeCLI _202601](https://www.reddit.com/r/opencodeCLI/comments/1q8bcsg/looking_for_an_alternative_to_claudecode_is/)
- I tried OpenCode + GLM 4.7 and honestly GLM 4.7 has been pretty error-prone for Android work (Gradle/Kotlin DSL quirks, shaky API assumptions, and fixes that donâ€™t compile on the first try).

- glm 4.7 + cc >>>>>> glm 4.7 + opencode

- [Looking for an alternative to ClaudeCode. Is OpenCode + GLM 4.7 my best bet? : r/opencodeCLI](https://www.reddit.com/r/opencodeCLI/comments/1q8bcsg/looking_for_an_alternative_to_claudecode_is/)
  - i tried glm 4.7 with opencode coming from claude code with opus but tbh it felt like bit retarded junior dev compared to cc with opus or sonnet, especially with rust. i wouldnt say its bad, prolly just my expectations that it might come close to what i got used to with cc/opus were maybe just too high, also the language support (slovak) with glm is just bad

- ## [Opencode vs Codex CLI: Same Prompt, Clearer Output â€” Why? : r/opencodeCLI _202601](https://www.reddit.com/r/opencodeCLI/comments/1qdujsl/opencode_vs_codex_cli_same_prompt_clearer_output/)
- Coding agent clients (sometimes referred to as harnesses) have their own prompt engineering flows. those include the system prompt, compacting strategies, context lookups, code indexing and more. Behind the scenes you plugged them to the same model with the same user prompt, but the model received a whole lot of different prompt that just happens to include a part of it that is identical
  - opencode system prompts are open

- ## [OpenCode with GPT is next level : r/codex _202601](https://www.reddit.com/r/codex/comments/1qee31p/opencode_with_gpt_is_next_level/)
- How is OpenCode better than Codex CLI?
  - Interface. Speed. Sub agents. LSP.
- From my experience Codex CLI still offers the best experience. Iâ€™d really like to replace it with Opencode but itâ€™s missing the precision I value so much with the Codex harness. Unfortunately.
  - Codex CLI is better at understanding my intent and is conservative with solutions. While Opencode thinks more, writes more code and brings more work to the table I did not intent. Therefore I have to do more iterations which often just makes it worse.
  - I understand this is probably caused by the fact that OpenAI has locked the system prompt to Codex for ChatGPT subscribers. Which Opencode then has to amend with instructions specific to Opencode. The experience with an API key might be totally different.

- what's the biggest different and benefits of using that over Codex CLI? Is that mainly I can switch models or something else?
  - Ease of use, speed, sub-agents, LSP.

- ## [I tested Claude 4.5, GPT-5.1 Codex, and Gemini 3 Pro on real code (not benchmarks) : r/ChatGPTCoding _202511](https://www.reddit.com/r/ChatGPTCoding/comments/1p9vpyz/i_tested_claude_45_gpt51_codex_and_gemini_3_pro/)
- I tried both Sonnet 4.5 and Gemini 3 Pro High to build a site from scratch. Sonnetâ€™s UI is way cleaner, almost no layout issues. Gemini, on the other hand, had some pretty obvious problems, like everything getting stuck to the left instead of being centered

- ## [I tried Gemini 3 for a couple of days ... Codex is still the best. By far.. : r/codex _202512](https://www.reddit.com/r/codex/comments/1pf7pc1/i_tried_gemini_3_for_a_couple_of_days_codex_is/)
- i use codex for backend and cleaning up code from the others, opus to do both frontend/backend if i run out of antigravity/codex, and gemini for front end. they have their niches but overall opus is the most flexible ime

- Gemini sucks at anything agentic. It ignores instructions, itâ€™s lazy and it canâ€™t handle large contexts. Itâ€™s a benchmaxxed mess.

- I am paying both of the memberships but I will keep the OpenAI one. Gemini takes too much decisions by itself when I give clear instructions.

- I just used gemini 4+ hours yesterday and when the context gets too big it start hallucinating like hell. That never happened with codex.

- I find the same.. Gemini 3 made so many mistakes itâ€™s just not worth the hassleâ€¦ also if you leave it alone it looped on me several times. Codex and Claude simply never give me issues like that.

- ## [Gemini CLI is impressive, but Claude Code is acting like the real senior engineer : r/ClaudeCode _202512](https://www.reddit.com/r/ClaudeCode/comments/1pdyq6z/gemini_cli_is_impressive_but_claude_code_is/)
- I tried most agents and I still find Claude Code to be the most capable and reliable one. There are certain cases where I would use another agent to aid solving problems that Claude Code might get stuck in but usually it is the main agent I use. 
  - Collaborative agents are going to be the future where a team of agents can work on a task or a task would be assigned to the most reliable and efficient agent capable of solving it.

- Opus is superior. However, tou will drastically increase your output quality if you use both (one as the driver, one as the reviewer). Sometimes if its a really complex task I'll even use two reviewers. I actually built an open-source tool to automate this

- I have tested Gemini 3 Pro Preview and Claude Opus 4.5 multiple times having each generate security audit report on multiple popular GitHub projects (Cherry Studio, Chatbox, Jan, etc). Claude has consistently found more issues than Gemini even though it has less than a quarter of the context window as Gemini. When I ask Gemini whether Claudeâ€™s additional issues found were accurate, Gemini has consistently responded that they were accurate.

- Gemini is great at looking at everything and Codex is pretty good for finding weird logic flow bugs. But Opus 4.5, gets it right most of the time. If you tell it to follow a plan, enforce code-quality checks, and test-driven development, basically the same stuff I force myself to do but don't want to. It creates shippable code with few iterations; sometimes straight out of the gate.

- ## [Gemini 3.0 Pro has been out for long enough. For those who have tried all three, how does it (in Gemini CLI) shape up compared to Codex CLI and Claude Code (both CLI and models)? : r/ChatGPTCoding _202512](https://www.reddit.com/r/ChatGPTCoding/comments/1pi4ojr/gemini_30_pro_has_been_out_for_long_enough_for/)
- gemini sometimes one shots things that take "workhorse" codex forever to figure out, but it is a fickle beast. it has moments of brilliance and occasional periods of insanity

- Codex is stupidly slow. It sometimes gets stuck on harder things and basically implements nothing. But pretty good and reliable for basic stuff and never seems to hit limits. It sometimes surprises me with clever solutions.
  - Claude is good for making project wide changes while still being in control. But the sessions limits are absolutely ridiculous
  - Gemini seems pretty good in analyzing the project. But when it uses 2.5 instead of 3 it can get quite stupid more often than Claude or Codex do.
  - At least for my uses cases they are all somewhat similar. Transparency, speed, limits and ease of use matter more to me. Sometimes Claude gets stuck on a problem, sometimes it's Codex, sometimes it's Gemini, and then the other agents somehow manage to solve it. Managing the context matters in that as well, I guess, and in some it's just better or easier.

- I have the max plan for all 3. 
  - Gemini produces the best UI but is the worst at following instructions. 
  - Codex is the best at code review, debugging, and architectural decisions / implementing new architecture, but requires handholding and requires you to prompt it to continue working. 
  - Opus 4.5 is the best actual daily driver, amazing at following instructions, best general "assistant" outside of coding (e.g. LLM cofounder esque activities), and goes without saying also great at coding

- the Gemini CLI with Gemini 3 is excellent for user interfaces. Neither Claude Code nor Codex CLI focuses on that, but Gemini builds much better interfaces.

- Gemini simply doesnâ€™t follow instructions properly like codex

- ## [Best AI Coding Tool: Gemini CLI, Codex, or Claude Code : r/vibecoding _202510](https://www.reddit.com/r/vibecoding/comments/1oa9d5o/best_ai_coding_tool_gemini_cli_codex_or_claude/)
- Sadly, there is no best. They all seem to excel at different things. 
  - In my experience, Codex is a strong backend developer. 
  - Claude seems better at UI/UX. 
  - I use Gemini for planning and research given its huge context window and obvious search ties. But its implementation is terrible.
  - You also want to get in the habit of having the AI double and triple check each others work. If you only use one companyâ€™s LLM, use different sessions with separate context and different agents to analyze the work and catch bugs.
  - The reality is that every new generation of model is likely to surpass the last, so donâ€™t get locked into one company. They are all staggered now it seems so every 2-3 months there is a new SOTA frontier model - use that one.

- ## [Codexã€GeminiCLIçœŸçš„å¼±äºClaude Codeå— _202601](https://linux.do/t/topic/1420013)
  - ä¸¤ä¸ªéƒ½ä½“éªŒè¿‡åï¼Œå‘ç°éƒ½è¿˜æ˜¯ä¸å¦‚CC, è¿™æ˜¯äº‹å®å—ï¼Ÿè¿˜æ˜¯æˆ‘è‡ªå·±çš„ä½¿ç”¨æ–¹å¼ä¸å¯¹
- GEMINI CLIä¸çŸ¥é“ï¼ŒCODEX CLIå¼ºçš„ä¸€æ‰¹
- CODEX CLI éå‰ç«¯ä»»åŠ¡æ— æ•Œã€‚å‰ç«¯å°±æ˜¯é»˜è®¤çš„å®¡ç¾ä¸€èˆ¬ï¼Œæç¤ºè¯åˆ°ä½ä¹Ÿä¸é”™ã€‚

- codexéå¸¸å¼ºï¼Œä½¿ç”¨ä½“éªŒç”šè‡³æ¯”ccå¥½

- çœ‹åœºæ™¯å§ï¼Œå‰ç«¯é¡µé¢GeminiCLIå¾ˆå¼ºï¼Œä¿®bugã€åšæœåŠ¡ç«¯çš„è¯Codexå¾ˆå¼º
- å¼„Javaçš„è¯ï¼ŒCodexæ ¹æœ¬ä¸è¾“CCå•Šï¼Œåªæ˜¯æœ‰ç‚¹æ…¢è€Œå·²ï¼Œæˆ‘åè€Œæ›´å–œæ¬¢Codex
  - +1ï¼Œæˆ‘ç°åœ¨æ¯å¤©æ˜¯æŠŠcodexè¹¬å®Œå†ç”¨ccï¼Œä¸­é—´è¦æ”¹é¡µé¢å°±åˆ‡åˆ°gemini
- geminiåšåšå‰ç«¯è¿˜å¯ä»¥ codexä¸é€Šè‰²cc

- æˆ‘çš„ä½“éªŒ codex 5.2 xh > claude opus 4.5, opus 4.5ç»å¸¸å·æ‡’

- æˆ‘ç°åœ¨ç”¨ cx å†™ä»£ç , cc ç”¨æ¥è§£é‡Šä»£ç , cc è§£é‡Šä»£ç æ¯”è¾ƒè¯¦ç»†ä¸€ç‚¹, ä¹Ÿå¿«ä¸€äº›

- åœ¨åµŒå…¥å¼é¢†åŸŸï¼Œ claudecode ä¸å¦‚ codex ä¸€æ ¹

- codexæŒºå¼ºçš„ï¼Œå°±æ˜¯gptå¤ªæ…¢äº†
- å¤æ‚ä»»åŠ¡codexå¼ºè¿‡ccå°±æ˜¯å®åœ¨æ˜¯å¤ªæ…¢äº†

- codexçœŸçš„å¼ºï¼Œç‰¹åˆ«æ˜¯é…ç½®GPT-5.2-HIGTH

- gemini-cli è™½ç„¶ä»‹é¢ç”¨èµ·æ¥ï¼Œè‡³å°‘è°ƒè‰²ä¸é”™ï¼Œä½“éªŒä¹Ÿè¿˜è¡Œã€‚ ä½†æ˜¯ç¼ºä¸œç¼ºè¥¿çš„ï¼Œé€‚é… skills ä¹Ÿæ˜¯æœ€æ…¢çš„æ‰å¼„å¥½çš„ï¼Œè€Œä¸”å¸¸å¸¸è°ƒç”¨å®ƒ 2.5-flash-lite çš„å»é€‰æ‹©æ¨¡å‹å‘ä»»åŠ¡çš„æ—¶å€™ï¼Œç«Ÿç„¶æ˜¯ 2.5-flash-lite å¼€å§‹æ— é™è½®å›ï¼Œå¡åœ¨é‚£è¾¹ä¸ä¼šåŠ¨

- gemin cliæ˜¯çœŸä¸è¡Œï¼Œæ¯æ¬¡codexå¿™çš„æ—¶å€™è®©ä»–å¹²ç‚¹å¤æ‚çš„å°±å®¹æ˜“å¯„
  - codexæ˜¯çœŸå¯ä»¥ï¼Œå¦‚æœä¸æ˜¯é¢åº¦ä¸å¤ŸçœŸçš„å•¥éƒ½ç›´æ¥äº¤ç»™ä»–å°±è¡Œ
  - æ”¹æ”¹é¡µé¢ä»€ä¹ˆçš„ç¡®å®geminiçš„å®¡ç¾è¿˜ç®—èƒ½çœ‹

- gemini cliæœ€å¥½çš„ç”¨æ³•å°±æ˜¯2apiå‡ºæ¥åšå¯¹è¯

- ## [ä½¿ç”¨åŒæ ·çš„å¤§æ¨¡å‹ï¼ŒClaude code ã€Google Gemini CLIã€Qwen CLI åŒºåˆ«å¤§å— _202601](https://linux.do/t/topic/1443293)
- æ¨¡å‹ä¸€æ ·çš„è¯ï¼Œå¤„ç†é—®é¢˜åŒºåˆ«ä¸å¤§å§ï¼Œå°±çœ‹ä½¿ç”¨ä¹ æƒ¯å’Œä½ ç”¨é€”äº†ï¼ŒCC æƒé™å¤šï¼Œæ–‡ä»¶è¯»å†™ã€ç»ˆç«¯æ‰§è¡Œã€å·¥ç¨‹æœç´¢è¿™äº›éƒ½è¡Œï¼Œå…¶ä»–çš„æ™®é€šCLIåªèƒ½ç»™ä½ å»ºè®®ä»£ç ï¼Œè€Œä¸”CCè¿˜æœ‰MCP

- ä½¿ç”¨ä½“éªŒå®Œå…¨ä¸ä¸€æ ·ï¼ŒClaude Code> Gemini > Qwen
  - å³ä¾¿æ˜¯ç›¸åŒæ¨¡å‹ï¼ŒSkillsï¼ŒSub-Agentsï¼Œä¸°å¯Œçš„å·¥ä½œæµç”Ÿæ€ï¼Œéƒ½ä¸æ˜¯GEMINIå’ŒQWENå¯ä»¥æ¯”çš„

- claude codeåŸç”Ÿä¸å¸¦å›é€€çœŸçš„æŒºç—›è‹¦çš„ï¼Œå¦‚æœåªè€ƒè™‘å®¿ä¸»çš„è¯æˆ‘è¿˜æ˜¯æ›´å–œæ¬¢cursorã€‚

- å†™ä»£ç è¿™ä»¶äº‹æƒ…ä¸Šï¼Œè¿˜æ˜¯æœ‰IDEçª—å£æ›´åŠ ç›´è§‚ã€‚ä¹ æƒ¯äº†cursorï¼Œcliä¸å¦‚cursorã€‚
  - å¦å¤–è¿‘æœŸåœ¨ç ”ç©¶è°ƒç”¨AIç”Ÿæˆä¸€äº›æŠ¥å‘Šï¼Œè¿™ä¸€å—è°ƒç”¨claude -pæŒºå¥½ç”¨ï¼Œè¿™ä¸€ç‚¹ä¹Ÿç®—æ˜¯cliå·¥å…·çš„ä¼˜åŠ¿äº†å§ã€‚
  - ä¸ºä»€ä¹ˆé‡‡ç”¨è¿™ç§æ–¹å¼ï¼Œå› ä¸ºå·¥ä½œç¯å¢ƒä¼šæœ‰å¾ˆå¤šä»£ç ã€æ•°æ®ï¼Œéœ€è¦AIè¿›è¡Œåˆ†æï¼ŒOpenApiçš„æ–¹å¼ä¸å¤Ÿå‹å¥½äº†
# discuss-opencode
- ## 

- ## 

- ## 

- ## [åˆ†äº«ä¸€ä¸ªæ‹¿opencodeå¹²écodingæ´»çš„æ€è·¯(DIY cowork) ](https://linux.do/t/topic/1534786)
  - è‡ªå·±å¹³æ—¶é™¤äº†codingè¿˜æœ‰ä¸€äº›æ‚æ´»ï¼Œå°¤å…¶æ¶‰åŠåˆ°ä¸€äº›æ–‡ä»¶ææ–™å°è´¦çš„æ”¶é›†ã€å‡†å¤‡ã€å¤„ç†ã€‚å› æ­¤è¿™æ®µæ—¶é—´æŠ˜è…¾äº†ä¸‹ï¼Œæ‹¿opencodeè‡ªå·±è·‘å‡ºäº†ä¸€å¥—å¯¹è‡ªå·±è€Œè¨€è¿˜ç®—å¯ä»¥çš„æµç¨‹ï¼Œåœ¨è¿™é‡Œç»™å¤§å®¶åˆ†äº«ä¸‹ã€‚
  - å‡†å¤‡äº†ä¸€ä¸ªæ–‡ä»¶å¤¹ï¼švibe_workingï¼Œé‡Œé¢çš„ç»“æ„æ˜¯ï¼š
  - 0.runtime: RULES
  - 1.todo
  - 2.processing
  - 3.archived
  - todoé‡Œé¢å°±æ˜¯å¾…å¹²çš„äº‹æƒ…ï¼Œä»¥æ–‡ä»¶å¤¹ä¸ºä¸€ä¸ªé¡¹ç›®ã€‚processingå°±æ˜¯å¤„ç†ä¸­çš„ï¼Œå¤„ç†å®Œåæ”¾archivedé‡Œã€‚
  - ä¸çŸ¥é“æœ‰æ²¡æœ‰ä½¬å‹ä¼šæœ‰skillsç„¦è™‘ï¼Œæ€»è§‰å¾—è¦å‡†å¤‡ä¸€å †skillsæ¥å¼€å¹²ã€‚æˆ‘è‡ªå·±çš„ç»éªŒæ˜¯ï¼Œåªè¦å…ˆå¼„ä¸ªauthropicå®˜æ–¹çš„skill-creatorè¿™ä¸ªskillï¼Œåç»­çš„éƒ½ä¸æ€¥ï¼Œç”šè‡³å¤§éƒ¨åˆ†éƒ½ä¸ç”¨
  - ä½ éœ€è¦å“ªäº›skillï¼Œå®Œå…¨å¯ä»¥åœ¨æµç¨‹è·‘é€šåï¼Œå’Œopencodeè¯´ä¸‹æŠŠåˆšæ‰çš„æ•´ä¸ªæµç¨‹å˜æˆä¸€ä¸ªskillï¼Œå®ƒå°±ä¼šè°ƒç”¨skilll-creatorå»åˆ›å»ºå¯¹åº”çš„skilläº†ã€‚æˆ‘å°†å…¶å‘½åä¸ºç”Ÿé•¿å‹skillï¼Œå³å¾ˆè‡ªç„¶çš„ç”¨å®ƒï¼Œç”¨å®Œå¥½ç”¨çš„èƒ½è·‘é€šçš„ï¼Œå°±æŠŠæ•´ä¸ªè·‘é€šçš„æµç¨‹å˜æˆå¯¹åº”çš„skillï¼Œæ•´ä¸ªskillæ— éœ€ä½ è‡ªå·±åŠ¨æ‰‹å»å†™ã€‚
  - æˆ‘è‡ªå·±å°è¯•äº†å‡ ä¸ªé¡¹ç›®äº†ï¼ŒåŒ…æ‹¬wordã€excelã€pdfç­‰æ–‡ä»¶çš„å¤„ç†éƒ½å¾ˆå¯ä»¥ï¼Œè€Œä¸”è¿˜æœ‰ä¸€ä¸ªè¿™ç±»å› ä¸ºæ²¡æœ‰ç‰¹åˆ«éš¾çš„codingé—®é¢˜ï¼Œå®Œå…¨å¯ä»¥ç”¨å›½å†…çš„å‡ ä¸ªæ¨¡å‹ï¼Œæ›´åŠ ä¾¿å®œã€‚
  - ç­‰ä½ è‡ªå·±å·¥ä½œä¸Šçš„å‡ ç§å¸¸è§çš„æ´»éƒ½è·‘è¿‡ä¸€éåï¼Œæ±‡æ€»æˆäº†æˆç†Ÿçš„skillï¼Œåç»­å®Œå…¨å¯ä»¥è®©å…¶è‡ªåŠ¨åŒ–æ“ä½œäº†ã€‚

- ## [OpenCode Ecosystem feels overwhelmingly bloated : r/opencodeCLI _202601](https://www.reddit.com/r/opencodeCLI/comments/1qmwcp1/opencode_ecosystem_feels_overwhelmingly_bloated/)
  - I often check OpenCode ecosystem and update my setup every now and then to utilize opencode to the max. I go through every plugins, projects ...etc. However, i noticed most of these plugins are kinda redundant. Some of them are kinda promoting certain services or products, some of them feel outdated, some of them are for very niche use cases.
  - It kinda takes time to go through every single one and understand how to utilize it. I wonder what are you plugin and project choices from this ecosystem ?

- You don't need to use any of that shit. Opencode is just fine on its own
  - Opencode with few selected skills is most certainly 80/20 rule.

- I've been running OpenCode with absolutely nothing but custom sub agents, custom commands, and a few MCP servers.
  - Just because the ecosystem is bloated doesn't mean you have to use bloated software.

- Reminds me of MCP; you go crazy adding a tonâ€¦ 6 months later you stop using MCP
  - The only plugin I use is to send notifications when the agent is waiting on me.
  - I probably will try to find a plugin (or write one) that helps protect against unexpected deletesâ€¦ had a CC hook for thatâ€¦ just not ported
- I think all abstractions like skills, mcp, sub agents etc are anti-patterns. They will all disappear when the models get better

- ## [Does Oh-My-Opencode really provide an advantage? : r/opencodeCLI _202601](https://www.reddit.com/r/opencodeCLI/comments/1q425mn/does_ohmyopencode_really_provide_an_advantage/)
- I tested it with a few feature implementations, in parallel with vanilla Opencode and Claude Code, and I didn't like how it performed. It used a ton more tokens and I didnt find the work any better. YMMV. I do have very detailed plans so maybe it negates some of what its supposed to bring

- I have similar observations â€” everything from ohmyopencode runs fast at first, but after 2â€“3 tasks the tokens are gone for 4 hours. I had the same issue with my own sub-agents (architectâ€“builderâ€“reviewer). The orchestrator rarely used the subtasks with cheaper models.
  - Iâ€™m starting to think that a simple plan/build setup with MCP for documentation and web search might actually solve things better and cheaper.

- Dude you are not wrong. I also tried it and I was being carless found out quickly that both my Opus, GLM and codex had downgraded ALOT from their respective original CLIS. The systemprompting in OH my Opencode is shit it is based on a bible of instructions and other weird rules LLMs in general should followi. And all this without any backup about evidence in LLM productivity. The models will become less intelligent unless you dont rewrite it all but theb you could just make your own setup.

- I think no. Most of the heavy lifting lies in the model capability itself nowadays. With just 200K context, doing extra fancy things just hurt the performance and gain you nothing but being rate limited imo. The Keep It Simple Stupid principle always stand.

- ## [OpenCode + OpenWebUi? : r/opencodeCLI _202511](https://www.reddit.com/r/opencodeCLI/comments/1oljb0k/opencode_openwebui/)
  - Is There a way to integrate opencode with a web interface instead of using it via TUI?

- Opencode has sdk to interact with opencode server. TUI actualy client of the server. So I think its possible to build web client for it

- You can use official desktop package
  - itâ€™s also a web client

- ## [Codex in OpenCode : r/codex _202512](https://www.reddit.com/r/codex/comments/1pz5p2r/codex_in_opencode/)
- When comparing opencode with another tool, it's better to compare it with CC than codex, as a TUI. Because opencode is so ahead of codex in feature parity and trades blows with CC in QOL features. I use it as my daily driver and it has nearly all the features I want and if not, there are plugins. The automatic LSP and formatter integrations will save you a lot of compilation errors because the agent automatically gets the errors fed back to it when it makes syntax errors or similar, which is very valuable. Automatic formatting will make your code cleaner, the codex team have instructions in their AGENTS.md for how to run just fmt after every step to ensure formatting etc, this comes automatically in opencode, something that even CC doesn't have. They're now adding native LSP tools like symbol searching, renaming etc so soon the agent will not be globing and rg-ing its way around

- Would you say that after switching to using Codex in/with OpenCode you canâ€™t see yourself using pure Codex Cli alone because itâ€™s just better (an upgrade) to use OpenCode on top? 
  - I return to codex sometimes to just see what's up but their development is very slow in comparison with competitors and honestly opencode is the main cli tool that is very active, not vibe coding targeting, that's actually using good engineering in its making that's provider agnostic. Subagents are implemented via a native tool called task, it spawns a subagent that you can zoom in to see its context which is a better UX than CC. There's a built-in subagent for exploration, read-only. But you can create subagents as you want, also main agents are a thing, they're translated to modes that you can tab between. Slash commands can spawn subagents with extra context which is powerful if you want an agent that's focused and not polluted by your chat's context, that's the system for their review slash command. They added skills support lately which is awesome as well
- i just run multiple codex instances and then have them read and write to a md file or a database if they need ot memorize stuff....like all these things are super simple and dont require more complexity is my opinion.

- there are also people who love the simplicity of Codex

- I use both Codex CLI and OpenCode; OpenCode has some cool features (switching agents with different models and different briefings), sub-agents etc. I rarely use more than a planning agent and an edit agent in OpenCode; most of the time I just use Codex CLI TBH. I'm using OpenCode with the OAuth plugin to use my subscription which works very well.

- ## [coming as a CC user, what does OpenCode has that's got everyone raving about? : r/opencodeCLI _202601](https://www.reddit.com/r/opencodeCLI/comments/1qa4h9e/coming_as_a_cc_user_what_does_opencode_has_thats/)
- While one of the biggest differences is that OpenCode not bind with models from one company. You can choose any models you want. Every agent can have its own model so you can choose the best model in different tasks

- No flickering.
  - Copy and paste works reliably.
  - LSP
  - Clear view of the task list.
  - Sub-agents from different providers for better self-checking.
  - It's faster.
  - Better content management.
- Copy and paste doesn't work for me at all in WSL lol. In CC it works fine though

- haven't used cc for a while, but really like the /undo OpenCode command that reverts last AI changes.
  - CC has /revert or double Esc for this
- I still wonder how many vibecoders don't know that git basically exists.
  - Using the same git for human and AI sucks. I want the main git to only record "verified" changes and a separate temporary history for all the random AI generated intermediate steps. I don't even want the agent to be able to modify the main git without permission. I think Roo code uses a "shadow git", which might be the better option.

- Lsp integration is nice

- flexibility with your workflow, you can set any model and customize it to any extent like max token window, thinking, etc there is so many settings good for nerds or newbs
  - fast support from the team, discord always active
  - most important of all, context management is superior compared to cc, output are better. i one shotted my real work tasks as RND in my company 95% of the times.

- Agents, scripts as tools for agents

- ## [Why is opencode so popular? : r/vibecoding _202601](https://www.reddit.com/r/vibecoding/comments/1qf0u10/why_is_opencode_so_popular/)
  - It looks cool, it can use literally any model, it's got plugins for providers, it's super customizable
  - But I'm struggling to get into it because:
  - There's no sandbox option
  - There are two primary agents by default in OpenCode. Build mode is basically yolo. It edits and runs commands freely with zero permission.

- ## [OpenCode å¯åŠ¨é€Ÿåº¦æ…¢ï¼Ÿå¯èƒ½æ˜¯è¿™ä¸ªåŸå› ï¼ˆä» 29s ä¼˜åŒ–åˆ° 3sï¼‰ä»¥åŠæ’ä»¶åˆ†äº« ](https://linux.do/t/topic/1443795)
  - æˆ‘çš„ OpenCode å¯åŠ¨é€Ÿåº¦éå¸¸æ…¢ï¼Œä½“éªŒè¿œä¸å¦‚ Claude Code 
  - é€šè¿‡ `opencode --print-logs` æ‰“å°æ—¥å¿—ï¼Œå‘ç°æ—¶é—´åŸºæœ¬éƒ½è€—åœ¨æ’ä»¶å®‰è£…ä¸Š
  - oh-my-opencode@latest å®‰è£…	12.89s	æ¯æ¬¡å¯åŠ¨éƒ½é‡æ–°ä¸‹è½½

- ## å¦‚æœä½ å–œæ¬¢ Claude Codeï¼Œé‚£ä¹ˆä½ ä¸€å®šè¦ç”¨ OpenCodeã€‚
- https://x.com/huangyihe/status/2007472975952408724
  - æ¨¡å‹è‡ªç”±ï¼šClaudeã€GPTã€Geminiç”šè‡³æœ¬åœ°æ¨¡å‹ï¼Œéšä¾¿åˆ‡æ¢ï¼Œè°å¼ºç”¨è°ã€‚
  - å®Œç¾å…¼å®¹ï¼šClaude Skillsæ‹¿æ¥å³ç”¨ï¼Œå¤åˆ¶ç²˜è´´è¿›.opencode/skillså³å¯ã€‚
  - åŸç”Ÿå¤šAgentï¼šå†…ç½® Plan/Build åŒæ¨¡å¼ï¼Œé…åˆOh My OpenCodeï¼Œç›´æ¥å˜èº«AIå¼€å‘å›¢é˜Ÿã€‚

- è¿™ç§â€œæ··åˆæ¨¡å‹æ¶æ„â€åœ¨å¤„ç†é•¿ä¸Šä¸‹æ–‡æ—¶å­˜åœ¨ä¸€ä¸ªè‡´å‘½éšæ‚£ï¼šä¸åŒå‚å•†æ¨¡å‹çš„ Tokenizer å·®å¼‚ã€‚å¦‚æœåœ¨ Plan é˜¶æ®µç”¨äº† Claudeï¼ˆåŸºäº BPE å˜ä½“ï¼‰ï¼Œè€Œåœ¨ Build é˜¶æ®µåˆ‡åˆ°äº†æœ¬åœ°çš„ Llama 3ï¼ˆåŸºäº TikToken å˜ä½“ï¼‰ï¼Œåœ¨ä¼ é€’ Context æ—¶æ˜¯å¦ä¼šå‘ç”Ÿ Token Count çš„å‰§çƒˆæŠ–åŠ¨ç”šè‡³æˆªæ–­ï¼Ÿç‰¹åˆ«æ˜¯å½“ä¸Šä¸‹æ–‡è¶…è¿‡ 32k æ—¶ï¼Œæœ¬åœ°å°æ¨¡å‹çš„â€œæ³¨æ„åŠ›è¿·å¤±â€ï¼ˆLost in the Middleï¼‰ç°è±¡ä¼šå¯¼è‡´ç”Ÿæˆçš„ä»£ç å®Œå…¨å¿½ç•¥ Plan é˜¶æ®µå®šä¹‰çš„æ¥å£è§„èŒƒã€‚
  - å¯ä»¥å¢åŠ ä¸€ä¸ªAIéƒ½è¯»çš„æ˜ç™½çš„ç®¡é“plané˜¶æ®µè®©GPTå†™ï¼Œå†™æˆmdæ”¾åˆ°.claudeä¸‹é¢ï¼Œç„¶åæ¢æˆClaudeè®©å®ƒæŒ‰ç…§mdæ ¼å¼çš„planå»å®Œæˆå³å¯ã€‚è€Œä¸”æœ¬èº«è¿™ç§VBCæ–¹å¼ä¹Ÿæ›´åŠ è§„èŒƒ
  - è¿™éœ€è¦ä¸¥æ ¼çš„ä¸Šä¸‹æ–‡å·¥ç¨‹æ¥æ§åˆ¶ï¼Œæ¯å®Œæˆä¸€ä¸ªä»»åŠ¡æ›´æ–°æ–‡æ¡£

- å¾—çœ‹å•¥ä»»åŠ¡ï¼Œå¤šagentåˆ°ç°åœ¨ä¾ç„¶æœ‰ä¸Šä¸‹æ–‡æŸå¤±çš„é£é™©ï¼Œä¸å¦‚cxä¸€å£æ°”åšå®Œ
# discuss-qwen-code
- ## 

- ## 

- ## 
# discuss-gemini-cli
- ## 

- ## 

- ## [gemini-cli å¤ªå¼±äº† _202601](https://linux.do/t/topic/1476572)
  - æˆ‘ä¸ªäººå¾ˆå–œæ¬¢åœ¨ç»ˆç«¯ä¸Šå·¥ä½œï¼Œæ‰€ä»¥ä¹Ÿå°è¯•äº†å„ç§CLIã€‚å…¶ä¸­æ˜æ˜¾æ„Ÿè§‰geminiçš„è¿™ä¸ªCLIæ˜æ˜äº¤äº’å¾ˆå¥½ï¼Œæ•´ä½“UIçœ‹ç€ä¹Ÿå¾ˆèˆ’æœï¼Œä½†å®é™…ä¸Šä¸€è¾“å‡ºå†…å®¹ï¼Œç»å¸¸å°±æ˜¯ä¸çœ‹ä¸Šä¸‹æ–‡çç¼–ã€‚ã€‚antigravityé‡Œå°±è¿˜å¥½äº›
- æ¨¡å‹ä¸åŒï¼ŒAntigravityé‡Œé¢ç”¨çš„æ˜¯opus

- åŒæ„Ÿã€‚æœ‰æ—¶å€™æˆ‘æ„Ÿè§‰googleä»–ä»¬å®¶çš„ai codingé¢†åŸŸçš„å·¥å…·å’Œç†å¿µè‡ªæˆä¸€æ´¾ï¼Œç”šè‡³ä¼šæ€€ç–‘æ˜¯ä¸æ˜¯è‡ªå·±ä¸ä¼šç”¨ï¼Œæ€ä¹ˆä¼šè¿™ä¹ˆéš¾ç”¨ã€‚
# discuss-codex-xp
- ## 

- ## 

- ## 

- ## [error sending request for url (https://api.openai.com/v1/responses) Â· Issue Â· openai/codex](https://github.com/openai/codex/issues/4885)
- I guess it's a network proxy problem. Last week I solve it by change my proxy point. But this week I can't fix it again
  - export ALL_PROXY="http://127.0.0.1:7890" is ok
  - that works for cli, but not for vscode codex entension with ssh connection in linux server.
- é—®é¢˜ä¸€èˆ¬æ˜¯ VSCode ä» GUI å¯åŠ¨æ—¶æ²¡æœ‰ç»§æ‰¿ä»£ç†/ç¯å¢ƒå˜é‡ã€‚ä»èƒ½ç”¨ codex çš„ç»ˆç«¯è¾“å…¥code . å¯åŠ¨vscode(å…ˆåœ¨ç»ˆç«¯ä¸­å…ˆè¿è¡Œä¸€ä¸‹codexï¼Œç„¶åé€€å‡ºcodexï¼Œæœ€åå†å¯åŠ¨vscode)ï¼Œå¦‚æœæ–°æ‰“å¼€çš„vscodeé‡Œèƒ½ç”¨codexæ’ä»¶ï¼Œåˆ™å°±æ˜¯è¿™ä¸ªé—®é¢˜ï¼æƒ³è¦æ ¹æ²»è¿™ä¸ªé—®é¢˜æœ‰ä¸¤å¤§æ–¹æ³•ï¼šâ‘ åœ¨vscodeé‡Œé…ç½®ç³»ç»Ÿä»£ç†ï¼›â‘¡æŠŠä»£ç†/Keyå†™å…¥åˆ°â€œç³»ç»Ÿçº§ç¯å¢ƒâ€ï¼Œä½¿å¾—GUIå¯åŠ¨vscodeä¹Ÿå¯ä»¥èµ°ä»£ç†ã€‚

# discuss-codex
- ## 

- ## 

- ## [Codex 5.3 ä¼˜åŒ– ï¼šå·¥ä½œå¹¶è¡ŒåŠ é€Ÿ + å›ç­”ç®€æ´è½»å¿« ](https://linux.do/t/topic/1603762)

- ## [codexæ±¡æŸ“è¿™ä¹ˆä¸¥é‡å—ï¼Ÿ  _202602](https://linux.do/t/topic/1585312)
- OpenAI è€é—®é¢˜äº†ï¼Œè¯­æ–™æ±¡æŸ“éå¸¸ä¸¥é‡
- æ¯æ¬¡å°±æ˜¯æ³°æ–‡ + ä»€ä¹ˆå½©ç¥¨ä¸­å¤§å¥–è¿™äº›

- ## [codexå†™ç®—æ³•åç«¯ä¸æ˜¯ccodeèƒ½æ¯”çš„ _202602](https://linux.do/t/topic/1552314)
  - äº²èº«ä½“éªŒï¼Œå¥½å‡ æ¬¡è®©ä»–ä¿©ä¸€èµ·å¹²åŒä¸€ä¸ªé¡¹ç›®ï¼Œåªè¦æ¶‰åŠåˆ°æ¯”è¾ƒå¤æ‚çš„é€»è¾‘æˆ–è€…ç®—æ³•ã€‚ codex ä¸€èˆ¬éƒ½èƒ½æŠŠç»“æœå¼„å‡ºæ¥ã€‚
  - ä½†æ˜¯ claudecode é™·å…¥ bug åä¸€ç›´æ‹—ä¸è¿‡æ¥ï¼Œæ”¹æ¥æ”¹å»è¿˜æ˜¯æœ‰ bugã€‚
  - claude æ—¶å€™ç®€å•çš„å¢åˆ æŸ¥æ”¹ä¸šåŠ¡ï¼Œä½†æ˜¯æ¶‰åŠåˆ°å¤æ‚é€»è¾‘è¿˜æ˜¯äº¤ç»™ codex æ¥åšå§ã€‚ä¸“ä¸šäº‹äº¤ç»™ä¸“ä¸šçš„äººæ¥åš

- æ˜¯çš„ï¼Œä½†æ˜¯ codex æœ‰æ—¶å€™å¤ª nerdï¼Œå¾— claude ç›‘å·¥ / æ¶¦è‰² prd / æé†’å†™æ³¨é‡Š

- æ˜¯çš„ï¼Œä½†æ˜¯ codex æœ‰æ—¶å€™å¤ª nerdï¼Œå¾— claude ç›‘å·¥ / æ¶¦è‰² prd / æé†’å†™æ³¨é‡Š

- ## [çœ‹åˆ°æœ‰äººè¯´codexå¥½ç”¨ï¼Œä½†ä¸ºä»€ä¹ˆæˆ‘æ„Ÿè§‰å®ƒå·¥ä½œæ•ˆç‡å¥½ä½ ](https://linux.do/t/topic/1515526)
  - çœ‹åˆ°æœ‰å†™ä½¬è¯´codexå¥½ç”¨ï¼Œä½†æ˜¯æˆ‘åœ¨å®é™…ä½¿ç”¨è¿‡ç¨‹ä¸­æ€»æ„Ÿè§‰codexè¿‡äºå•°å—¦ï¼Œä¸€ä¸ªåŒæ ·çš„é—®é¢˜claude code å¾ˆå¿«å°±èƒ½è§£å†³äº†ï¼Œcodexèƒ½å•°å—¦åŠå¤©ã€‚æ‰€ä»¥è¿™ä¸ªå¥½ç”¨æ˜¯æ€ä¹ˆæ ·æ‰å¥½ç”¨ã€‚

- æˆ‘è§‰å¾—å› ä¸ºä»–ä¾¿å®œï¼Œå·®è·æ²¡æœ‰æ‹‰å¼€å¤šå°‘ï¼Œå¹²å˜›ä¸ç”¨

- å¾ˆå¤šé—®é¢˜ ç”¨gpt5.1-mini æˆ–è€… æŠŠæ€è€ƒæ—¶é—´è°ƒå°ä¸€ç‚¹ã€‚
- è¦ç”¨gpt5.2

- codexæˆ‘éƒ½æ˜¯ç”¨æ¥è§£å†³Claude Codeè§£å†³ä¸äº†çš„é—®é¢˜çš„ã€‚ä¸€èˆ¬Claude Code 3æ¬¡æ”¹ä¸å¥½çš„æˆ‘éƒ½ç›´æ¥è®©codexæ¥æ”¹äº†ï¼Œæ•ˆæœè¿˜ä¸é”™ã€‚æˆ–è€…å¯¹æ•´ä¸ªæ–‡ä»¶è¿›è¡Œè´¨é‡å®¡æŸ¥å•¥çš„ã€‚
- é—®é¢˜å°‘å•Šã€‚ã€‚ã€‚ccå¿«æ˜¯å¿«ã€‚ã€‚ã€‚ä¸€ä¸ªé—®é¢˜åå¤æ”¹ï¼Œæ€»ä¸å¥½å•Šã€‚ã€‚cxæ…¢è¿‡æ…¢ï¼Œä½†æ˜¯ä¸€èˆ¬ä¸€æ¬¡è¿‡ã€‚
- ä½†æ˜¯codexçš„æ­£ç¡®ç‡é«˜å•Šï¼Œå®ƒè™½ç„¶æ²¡æœ‰claude codeå¿«ï¼Œä½†æ˜¯æˆ‘éƒ½ä½¿ç”¨åæ„Ÿè§‰codexçš„æ­£ç¡®ç‡è¦é«˜

- 1. DEBUGï¼Œæ¯”å¦‚è¯´æœ‰ä»€ä¹ˆä½ æ“ä½œæ—¶å€™å‘ç°çš„BUGï¼Œä½ ç”¨è‡ªå·±çš„è¡¨è¿°å‘Šè¯‰codexï¼Œå®ƒå€’è…¾æ€è€ƒåŠå¤©åèƒ½å‡†ç¡®è¯†åˆ«åˆ°é—®é¢˜æ‰€åœ¨ã€‚ccè™½ç„¶å¿«ï¼Œä½†æ˜¯æ ¹æœ¬é—®é¢˜æœ‰æ—¶å€™å°±æ²¡è§£å†³ï¼Œåªè§£å†³äº†è¡¨è±¡ï¼Œå†æ¬¡æµ‹è¯•BUGè¿˜åœ¨ã€‚æ‰€ä»¥å¾ˆå¤šworkflowé‡Œccå†™å®Œéƒ½ä¼šè®©codexå»åšä»£ç reviewã€‚
  - 2. é¡¹ç›®çš„åç«¯è§„åˆ’ã€‚gpt5.2-highå’Œxhighçš„è§„åˆ’å®Œæ•´æ€§æ¯”ccå¥½ã€‚
  - 3. å®˜æ–¹è´¦å·ä½¿ç”¨codexå®ƒçš„auto compactä¸¢å¤±çš„ä¿¡æ¯å°‘ã€‚å› æ­¤ä¼šæœ‰åšå¥½è§„åˆ’å’Œæ­¥éª¤åè®©codexè¿è·‘ä¸€ç™¾å¤šä¸ªissueåå‡ äºŒåä¸ªå°æ—¶éƒ½æ²¡å¤§æ¯›ç—…å‡ºç°çš„åœºæ™¯ã€‚

- ## ğŸ†š [Codex or cline : r/CLine _202511](https://www.reddit.com/r/CLine/comments/1p3j75w/codex_or_cline/)
- I need to spend more time with Codex, Iâ€™ll say that first but it is Cline for me atm because:
  - Can use multiple LLMs easily with openrouter
  - Plan/Act mode is fantastic - I donâ€™t like agents that can just go off and start editing code without my say so
  - Task based approach on Cline also shows the cost in dollars of each task this is great to measure cost/benefit
  - I build three tier apps so always test changes locally (lowcost) for app and app layer (personally I always use DB in cloud eg Atlas MongoDB)
  - As per 4 not sure how to test deployment in cloud with Codex presumably have to spin up more envs?
  - As per 5 no value for me doing dev from chat on my phone in the middle of the night. If I canâ€™t test the result on desktop whatâ€™s the point?

- Both cline and codex now have VS Code extensions and CLIs. CLI is a crucial component, allowing them to run automatically on the server.
  - However, I still feel that the CLI is not convenient enough. I have been using Warp recently, which puts AI capabilities directly in the terminal, so there is no need to enter additional commands to start a CLI, which is very convenient.
  - Of course, I now see most tools trying to cover all aspects, including mobile apps, the web, and terminals. If you choose now, I think you can use each one for a month to compare your experience, cost, and other factors, since everyone's usage scenarios are different.

- ## [why nobody ads codex in vibe code platforms ? : r/codex _202511](https://www.reddit.com/r/codex/comments/1os38ox/why_nobody_ads_codex_in_vibe_code_platforms/)
- Because Codex is more of an engineers tool. Itâ€™s slow, but with proper instruction, does well.
  - Vibe coders donâ€™t know what to tell the AI, they depend on the AI figuring it out for them. And because codex is so slow, it just wouldnâ€™t be very useful for the vast majority of them.

- ## ğŸ› [Does Codex do sub agents? : r/codex _202510](https://www.reddit.com/r/codex/comments/1ohto4f/does_codex_do_sub_agents/)
- Codex only works problems sequentially.
  - Claude has sub agents where you can spin up other agents with specific instructions and have them operate in parallel, directed by Claude or another subagents (or no other agent).

- no but Codex doesn't do dom agents either
  - what we need is an agent that can switch between the two roles

- ## [Codex CLI vs Claude Code vs Claude Code + Z.ai API â€” which oneâ€™s worth it? : r/ClaudeCode _202509](https://www.reddit.com/r/ClaudeCode/comments/1nepo9y/codex_cli_vs_claude_code_vs_claude_code_zai_api/)
- I use CC to analyze and generate tasks, which I then use with GLM to complete. It works quite well and does a more than acceptable job.

- Codex CLI is genuine crap. Anything is better than codex CLI as tool.
  - Codex cli uses freaking toml, huge red flag.
  - There is not local mcp config, no way to share it or version it for project.
  - And tool configuration... I didn't comprehend it.
  - their SDKs are nightmare to work with, literally made by smartasses who never worked with direct clients.
- literally every cli tool tries to be compatible, where codex just being special.
