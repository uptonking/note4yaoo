---
title: toc-lib-search-cn-chinese
tags: [Chinese, cn, search, toc, ä¸­æ–‡æœç´¢]
created: 2023-01-02T21:20:41.586Z
modified: 2023-01-14T15:46:16.644Z
---

# toc-lib-search-cn-chinese

# guide
- ä¸»æµæœç´¢å¼•æ“è‡ªèº«æˆ–ç¤¾åŒºå¤§å¤šå·²æä¾›ä¸­æ–‡æœç´¢æ–¹æ¡ˆ
  - ä¸­æ–‡æŒ‰æ‹¼éŸ³é¦–å­—æ¯æ’åº
# search-chinese
- level-min /4Star/MIT/202208/ts
  - https://github.com/heyauri/level-min
  - ä¸€ä¸ªæ”¯æŒä¸­æ–‡çš„è½»é‡çº§å…¨æ–‡æœç´¢åº“ï¼ŒåŸºäºNodeä¸LevelDBã€‚
  - ä¾èµ–segmentitã€naturalã€stopwordã€level8ã€franc
  - TF-IDF Similarity based full text search
  - With a built-in text processing procedure: Tokenizer, Porter Stemmer and Stopwords filter.

- https://github.com/xieyezi/lyra-cn
  - a tool for offline search Chinese.
  - æ·»åŠ å¯¹æ‹¼éŸ³çš„æ”¯æŒï¼Œå¦‚æœç´¢"ç ä¼"çš„ç»“æœåŒ…å«"çœ‹æ³•"

- https://github.com/chankamlam/chinese-search /201904/js
  - å…¨æ–‡æ£€ç´¢ç»„ä»¶, åŸºå±‚å®ç°ä¾èµ–nodejiebaä¸­æ–‡åˆ†è¯å’Œrediså­˜å‚¨

- racci /18Star/ISC/201706/js
  - https://github.com/iinitd/racci 
  - A lightweight search engine for Node.js, Chinese supported.
  - ä¾èµ–nodejiebaã€segmentã€lowdb
  - Support two search mode: full-text search and field search

- https://github.com/luckykaiyi/nodejieba /MIT/202305/cpp/ts
  - "ç»“å·´"ä¸­æ–‡åˆ†è¯çš„Node.jsç‰ˆæœ¬
  - forks
  - https://github.com/Mister-Hope/nodejs-jieba

- https://github.com/sxyizhiren/cn-search
  - ch-search , a light-weight chinese search engine based on reds, english support also.

- pinyin-match /679Star/MIT/202112/js
  - https://github.com/xmflswood/pinyin-match
  - æ‹¼éŸ³åŒ¹é…ï¼Œå…·å¤‡åˆ†è¯ã€ç¼©å†™ã€å¤šéŸ³å­—åŒ¹é…èƒ½åŠ›ï¼Œæ”¯æŒç¹ä½“ç‰ˆ
  - ç®€ä½“ç‰ˆ27KB (gzip â‰ˆ 19KB)ï¼Œç¹ä½“ç‰ˆ86KB (gzip â‰ˆ 60KB)
  - [å¦‚ä½•å®ç°ä¸€ä¸ªé«˜æ•ˆçš„æ‹¼éŸ³åŒ¹é…åº“ï¼Ÿè§£å†³å¤šéŸ³å­—ï¼Œé¦–å­—æ¯åŒ¹é…ç­‰é—®é¢˜ - æ˜é‡‘](https://juejin.cn/post/6844904161461403661)
  - https://github.com/ReAlign/pinyin-so /202005/ts
    - æ‹¼éŸ³æœç´¢æ–¹æ¡ˆï¼Œæ”¯æŒ å…¨æ‹¼/ç®€æ‹¼/åŒéŸ³å­— ç­‰ã€‚
# tokenizer
- https://github.com/fxsjy/jieba
  - â€œç»“å·´â€ä¸­æ–‡åˆ†è¯ï¼šåšæœ€å¥½çš„ Python ä¸­æ–‡åˆ†è¯ç»„ä»¶

- https://github.com/cxumol/jieba-wasm-html
  - ç»“å·´åˆ†è¯ç½‘é¡µç‰ˆ, åŸºäº WebAssembly çš„çº¯å‰ç«¯å®ç°; äº¦å¯ç”¨äº Deno
  - Fast Jieba Chinese text segmentation on browser. 
- https://github.com/fengkx/jieba-wasm
  - WASM binding to jieba-rs
- https://github.com/HerrCai0907/jieba.js
  - compile cpp version to wasm and can run in javascript

- chinese-tokenizer /72Star/MIT/201906/js
  - https://github.com/yishn/chinese-tokenizer
  - Simple algorithm to tokenize Chinese texts into words using CC-CEDICT.
  - This tokenizer uses a simple greedy algorithm: It always looks for the longest word in the CC-CEDICT dictionary that matches the input, one at a time.
  - ğŸ´ forks
  - https://github.com/tadashi-aikawa/chinese-tokenizer
    - does not depend on Node.js.

- segmentit /189Star/MIT/201902/js
  - https://github.com/linonetwo/segmentit
  - ä»»ä½• JS ç¯å¢ƒå¯ç”¨çš„ä¸­æ–‡åˆ†è¯åŒ…ï¼Œfork from leizongmin/node-segment
  - æœ¬æ¨¡å—åŸºäº node-segment é­”æ”¹ï¼Œå¢åŠ äº† electronã€æµè§ˆå™¨æ”¯æŒï¼Œå¹¶å‡†å¤‡é’ˆå¯¹ electron å¤šçº¿ç¨‹è¿è¡Œç¯å¢ƒè¿›è¡Œä¼˜åŒ–ã€‚
  - ä¹‹æ‰€ä»¥è¦èŠ±æ—¶é—´é­”æ”¹ï¼Œæ˜¯å› ä¸º segment å’Œ nodejieba è™½ç„¶åœ¨ node ç¯å¢ƒä¸‹å¾ˆå¥½ç”¨ï¼Œä½†æ ¹æœ¬æ— æ³•åœ¨æµè§ˆå™¨å’Œ electron ç¯å¢ƒä¸‹è¿è¡Œã€‚
  - æˆ‘æŠŠä»£ç é‡æ„ä¸º ES2015ï¼Œå¹¶ç”¨ babel æ’ä»¶å†…è”äº†å­—å…¸æ–‡ä»¶ï¼Œå…¨éƒ¨è½½å…¥çš„è¯å¤§å°æ˜¯ 3.8Mï¼Œä½†å¦‚æœæœ‰äº›å­—å…¸ä½ å¹¶ä¸éœ€è¦ï¼Œå­—å…¸å’Œæ¨¡å—æ˜¯æ”¯æŒ tree shaking çš„
# chinese-utils
- https://github.com/ray306/CharDB
  - A Comprehensive Database and Search Engine of Chinese Characters
# more-search-chinese
