---
title: lib-utils-git-community
tags: [community, git]
created: 2023-08-29T10:13:16.125Z
modified: 2023-08-29T10:13:31.070Z
---

# lib-utils-git-community

# guide
- [Fossil: The Fossil Sync Protocol](https://www.fossil-scm.org/home/doc/trunk/www/sync.wiki)
  - The "bag of artifacts" data model used by Fossil is apparently an implementation of a particular Conflict-Free Replicated Datatype (CRDT) called a "G-Set" or "Grow-only Set". 
# discuss-stars
- ## 

- ## 

- ## üîÅ i have a `git clone` a repo named repo1 on my macbook, and i use cmd+c/v to make a hard copy of  repo1 to repo2. 
  - i have made many `git commit` to repo1, how can i migrate all changes from repo1 to repo2 using git commands locally. give me some suggestions and explain it
- Since you used cmd+c/v to copy the repository, repo2 is technically a valid Git repository that shares the same history as repo1 up until the moment you copied it. Because they are both on your local disk, you can simply tell Git to treat repo1 as a "server" for repo2

```sh

git remote add local_source ../repo1

git pull local_source main

```

- [Migrate Changes Between Repos](https://chatgpt.com/c/69622882-66c8-8332-9c96-4b14e2e2eede)

- the cleanest approaches are either 
  - (A) create a single squash commit directly into repo2 by cherry-picking the range from repo1 (no changes to repo1), 
  - or (B) create a squashed branch in repo1 then fetch/merge it into repo2.
  - plus a patch-based option (C) you can use if you prefer a portable file.

```sh
# squash - create a single squashed commit inside repo2 (no rewriting repo1)
cd /path/to/repo2
git remote add repo1 /path/to/repo1   # run once
git fetch repo1

git log --oneline repo2/main..repo1/main    # commits present in repo1 not in repo2

# Cherry-pick them into the index without committing, then make one commit
git checkout main 
# takes the last 4 commits on repo1/main and applies them to the index
# Using --no-commit accumulates all changes in the index
git cherry-pick --no-commit repo1/main~4..repo1/main

# If you want to preserve original authorship information, you‚Äôll need to add Co-authored-by: lines manually in the commit message
```

```sh
# squash - Alternative: create a squashed branch in repo1, fetch it into repo2
cd /path/to/repo1
git checkout -b squashed-for-repo2 main
# Method 1: interactive rebase to combine N commits
git rebase -i HEAD~N   # mark the last N commits as `s` (squash) or `f` (fixup), then save

# OR Method 2: create a single commit from last N commits
git reset --soft HEAD~N
git commit -m "Squashed: short summary of N commits"

cd /path/to/repo2
git remote add repo1 /path/to/repo1   # if not already added
git fetch repo1

# either merge (creates a merge commit)
git merge repo1/squashed-for-repo2

# or cherry-pick that single squashed commit SHA from repo1:
git cherry-pick <sha-of-squashed-commit>
```

```sh

# Patch file / bundle approach (portable)
# Create a single squashed commit in repo1, export it as a patch
cd /path/to/repo1
# create squashed commit on branch squashed-for-repo2 (see B)
git format-patch -1 HEAD -o /tmp/patches   # creates a single patch file for the squashed commit

cd /path/to/repo2
git am /tmp/patches/*.patch
# or if you want to inspect before applying: git apply --check <patch>

# ‚ú® Or use git bundle to transfer full refs:
cd /path/to/repo1
git bundle create ../repo1.bundle repo1/main
# copy repo1.bundle to repo2 machine (local here)
cd /path/to/repo2
git fetch ../repo1.bundle refs/heads/*:refs/remotes/repo1/*
git merge repo1/main   # or cherry-pick, whatever you prefer

```

- `git format-patch` supports binaries automatically (Git ‚â•2.9).

```sh
# In repo1, check what commits exist on feat-editor
cd /path/to/repo1
git log --oneline --decorate

git checkout -b feat-editor-squashed
BASE=$(git merge-base feat-editor main)   # adjust if base branch ‚â† main
git reset --soft $BASE
# git reset --soft HEAD~N
git commit -m "feat(editor): squashed changes"
# get 0001-feat-editor-squashed-changes.patch
git format-patch -1 HEAD -o /tmp/repo1-editor-patch

# git format-patch -o /tmp/patches $(git log --oneline repo2/main..HEAD | wc -l)

cd /path/to/repo2
# Dry run
git apply --check /tmp/repo1-editor-patch/*.patch
# If this passes, apply it properly with commit metadata:
git am /tmp/repo1-editor-patch/*.patch

```

- `git am` consumes patch files as commits (author/date/message preserved) and commits them for you, while `git apply` just applies the diff to your working tree/index and does not create commits or preserve commit metadata. 
- Use `git am` when you want to import patches as authored commits (the usual choice for git format-patch output). 
  - It takes the code changes AND the metadata (Author, Date, Commit Message) and creates a commit in repo2 for every `.patch` file found.
- Use `git apply` when you want to inspect or tweak the changes before committing.
  - Git treats the patches strictly as data. It modifies the files in your working directory, but it DOES NOT create any commits.

- 
- 
- 
- 
- 

- ## ü§î What makes Git so popular?
- https://twitter.com/sahnlam/status/1765986551123882087
- ùóïùó≤ùó≥ùóºùóøùó≤ ùóöùó∂ùòÅ, developers struggled with source control. Systems like CVS and Subversion caused:
  - Collaboration Bottlenecks - Pushing to a shared central codebase created bottlenecks and isolated work.
  - Slow Branching/Merging - Diverging code streams and combining changes was clumsy and inefficient.
  - Scaling Issues - Performance degraded as projects and users grew. Centralized systems didn't scale.
  - Release Headaches - Coordinating versions across teams was messy.
- Git ùóøùó≤ùòÉùóºùóπùòÇùòÅùó∂ùóºùóªùó∂ùòáùó≤ùó± source control by:
  - Enabling decentralized collaboration through distributed repositories.
  - Streamlining local branching and merges.
  - Allowing offline work with full local codebase copies.
  - Optimizing performance even for large projects.
  - Tracking every change at a granular level.
- ùóöùó∂ùòÅùóõùòÇùóØ ùóÆùó∞ùó∞ùó≤ùóπùó≤ùóøùóÆùòÅùó≤ùó± Git's popularity by adding:
  - Web-based collaboration around remote repositories
  - Pull requests and code reviews
  - Social coding features like stars and follows
- However, Git ùó∂ùòÄùóª'ùòÅ ùòÑùó∂ùòÅùóµùóºùòÇùòÅ ùó±ùóºùòÑùóªùòÄùó∂ùó±ùó≤ùòÄ:
  - The conceptual model is complex with a steep learning curve.
  - The command line interface is unintuitive and confusing.
- Despite these complaints, Git's collaboration features and flexible workflows cement(Âä†Âº∫ÔºõÂ∑©Âõ∫) its place in modern development. This game-changing tool revolutionized source control for the better.

- ## üöÄüåµ [A Git client for simultaneous branches on top of your existing workflow | Hacker News _202402](https://news.ycombinator.com/item?id=39357068)
- > Quick warning. You cannot use both GitButler virtual branches and normal Git branching commands at the same time, you will have to "commit" to one approach or the other.
  - Basically anything you do with git (or another GUI) will get blown away by GitButler; or if you change branch away from it then it will stop working.
- This limitation stems from the fact that GB introduces an additional dimension of versioning on top of Git. 
  - One way of thinking of what it does with virtual branches is like "multiplexing" multiple branches onto the same working directory. On the way out they get "demuxed" into plain git trees.
  - With that said, the tool is very cautious not to mess with any existing branches. This is the very reason it operates on a separate integration branch. Switching between the "special/integration" branch and any other branch is also not an issue.

- For my own sake, allow me to articulate the core value proposition once more. GitButler's virtual branches permit two novel use cases:
  - A developer can lazily assign diffs/changes to belong to separate logical branches while maintaining their content within the same working dir. 
  - A developer can apply and unapply the content of remote branches to their working directory for the purpose of testing & review. 

- üÜöÔ∏è there _is_ a way to work on multiple branches at the same time: worktrees. What's the advantage of a tool like this over that?
  - With worktrees you can have different branches in different working directories and work on them at the same time. But practically, there is very little difference to just cloning the repo twice and working on different branches in the two checkouts.
  - The way we're doing it, the branches are both in the same working directory at the same time.
- This can have a couple of advantages 
  - one is if you have an annoying bugfix and you need it in order to keep working on your feature, you can have them both applied but you don't have to commit one into the history of the other. You cannot do this with worktrees.
  - Another is trying out multiple branches together. If they don't conflict, you can essentially get the result of a multi-way merge without creating any merge artifacts. Say you merge three work in progress branches to test them together, then keep working on each independently. Also, in this case, you _know_ that you can merge them in any order and the result will work because you've actually worked on the merged tree.

- üîÄ The CRDT thing happens in GitButler, but we hid the UI to search and find old changes for now
  - We still record the data locally and could theoretically recreate the state of your working directory and branches at any time.

- Is there a way to identify commits made by GitButler? Can I configure my host to reject them automatically?
  - GitButler creates normal Git commits and trees with libgit2. It's not dissimilar to using a tool that implements it's own interactive adding or something. The point is that Git is the database and Git hosts (such as GitHub) matter in our workflows, but actually creating the trees that represent the trees you want to share can happen in any way. We are changing how to conceptualize and execute how to get the trees you want, but the output is Git objects.

- Intellij IDE support this through changelists.
- The listed cons of ‚Äúchangelists‚Äù:
  1. Not part of Git at all‚Äînot committed
  2. Can‚Äôt be shared because, duh, not part of Git
  - That sounds like a fail to me. The whole point of using Git commits is that once committed, it‚Äôs just there. And things can be shared. The point of collaborative version control.

- doesn't work with other tools + GUI only => non starter

- 
- 
- 

- ## At Github, anyone can commit for you just by specifying your email in --author.
- https://twitter.com/sitnikcode/status/1759538798180876516
  - This is why I enabled signing commits in git using my SSH key using this guide
  - [Git Tips 2: New Stuff in Git](https://blog.gitbutler.com/git-tips-2-new-stuff-in-git/)

- ## üÜöÔ∏è Git Merge vs. Rebase vs. Squash Commit
- https://twitter.com/sahnlam/status/1767434052695621850
- ùóöùó∂ùòÅ ùó†ùó≤ùóøùó¥ùó≤ 
  - This creates a new commit in the target branch. 
  - The new commit ties the histories of both main and feature branches together. 
  - Git merge is non-destructive - it introduces a new commit without altering existing ones.
- ùóöùó∂ùòÅ ùó•ùó≤ùóØùóÆùòÄùó≤
  - Rebase transplants commits to the tip of another branch. It creates new commits for each one moved over.
  - The benefit is linear history. But be cautious with shared branches to avoid confusing collaborators.
- ùóöùó∂ùòÅ ùó¶ùóæùòÇùóÆùòÄùóµ ùóñùóºùó∫ùó∫ùó∂ùòÅ
  - Squashing condenses multiple commits into one, streamlining the commit history.

- 
- 
- 
- 

- ## üÜöÔ∏è Git Merge vs. Rebase vs. Squash Commit
- https://twitter.com/alexxubyte/status/1751645221602152881
  - Á§∫ÊÑèÂõæ
- ùêÜùê¢ùê≠ ùêåùêûùê´ùê†ùêû This creates a new commit G‚Äô in the main branch. G‚Äô ties the histories of both main and feature branches.
  - Git merge is ùêßùê®ùêß-ùêùùêûùê¨ùê≠ùê´ùêÆùêúùê≠ùê¢ùêØùêû. Neither the main nor the feature branch is changed. 
- Git rebase moves the feature branch histories to the head of the main branch. It creates new commits E‚Äô, F‚Äô, and G‚Äô for each commit in the feature branch. 
  - The benefit of rebase is that it has ùê•ùê¢ùêßùêûùêöùê´ ùêúùê®ùê¶ùê¶ùê¢ùê≠ ùê°ùê¢ùê¨ùê≠ùê®ùê´ùê≤. 
  - Rebase can be dangerous if ‚Äúthe golden rule of git rebase‚Äù is not followed. 

- ## [what's the difference between a DAG and a tree, specifically with regards to Git?](https://stackoverflow.com/questions/26395521/dag-vs-tree-using-git)
- The difference between them is that nodes in a DAG can have multiple parents. The most common case of this in Git is when you do a merge. A merge commit will have all of the commits that were merged as parents. 
  - A tree doesn't allow nodes to have multiple parents.
- a tree can have at most only one root, whereas a DAG can contain several roots, and even multiple disconnected subgraphs
- Most git repositories that I've worked with only have a single root commit. Although it's technically possible to create multiple root commits

- ## üåµüì° [What comes after Git | Hacker News_202207](https://news.ycombinator.com/item?id=31984450)
- Kubernetes didn't brought open-source collaboration to a new level. No matter how relevant Kubernetes is today, it's just a drop in the huge ocean of OSS. Maybe level in this context refers to 'gitops' which many of us where doing years before the term was coined and without K8s involved. Or perhaps the author refers to the fact that most gitops K8s frameworks will work via polling which is a fundamental scalability flaw.

- My main complaint is it's leaking abstractions. You basically need a PhD in git's internal data structures to use git. Well not the 5% of git you typically need in your day-to-day, but the other 95%, which you need when the 5% you do need somehow goes wrong, through one of the many foot-guns git offers.

- The model's basically a directed acyclic graph (not a tree), with each edge being the diff between the two nodes it connects. I think the UX could be improved if it built on the language of graphs to make that model more apparent - node, edge, etc.
  - There are a lot of people, even in this comment section, whose internal model of git is "it's a tree". Langauge like "branch" reinforces that model, and I don't think it does beginners any favours in the long run.
- It stores a full copy of every node, not the diff. The diff is just something that's rendered on-demand, and "gc"/"repack" compaction and it being content-addressable makes sure that the storage space doesn't balloon as a result of everything being a full snapshot. This distinction makes a difference in some cases, there are other VCSs that store diffs as a fundamental property.

- I personally believe that making diffs more human friendly is the next step of evolution we need. I feel like git was perfect when "code" was nearly almost completely text and patches were sent over email, but there's a lot more boilerplate+blob data that goes into git today and git needs to evolve to support this.
- Semantic diffs are great, but we can't entirely automate away "narrative problems" in a PR. No matter how good a diff is, a diff tells you what changed but not why and sometimes not even how. That's what we need good commit messages for. That's what we need good PR descriptions to do. If a branch has a ton of seemingly unrelated files modified (automated tool output or not), sometimes you have to ask the narrative questions: "Why did this change? What does it have to do with the other changes in this branch?"
- Semantic diff ‚Äì Can we figure out how to use version control to have more context-aware merges? Can you believe that we still rely on a text diffing algorithm from 1976 (and its shortcomings)? Git still has trouble with file renaming. GitHub Copilot, but for merge conflicts? Semantic diff has been tried before, but language-specific implementations will likely never work.
  - in case anyone missed it: https://github.com/Wilfred/difftastic
  - Difftastic output is intended for human consumption, and it does not generate patches that you can apply later.

- ü™® I've been using fossil for personal projects for like a decade now and I much prefer it over git. The characteristics that get me to stick with it are 
  - 1. Single file executable. No dependencies to "install". Just the executable and you're good. 
  - 2. The whole repo is a single sqlite DB file. Fabulous for backups, sharing, hosting etc. 
  - 3. You cannot rewrite history unlike git. Hence the name. Folks using git have no idea what kind of a peace of mind this gives me. 
  - 4. Integrated issue tracker stored in the same repo. Complete with cross references to commits. 
  - 5. Allows repeated use of same tag name. This is so convenient in personal projects I miss it in git. You can mark a commit as "published" and later look at the whole history of all previous commits tagged as "published".
- Other niceties
  - 1. Integrated wiki - I've occasionally used it, but usually prefer to write documentation in separate files. 
  - 2. Integrated webserver - fossil ui runs on the same thing so I do use it. The webserver comes complete with user account management and permissioning. 
  - 3. Can export and import to/from git.
- How is large file support? What strategy is employed for binary file handling? How does it compare to git LFS / annex / mercurial? Aside from that, Fossil is very intriguing.
  - Fossil is, because of its sqlite dependency, limited to blobs no larger than 2GB each. Some of its algorithms require keeping two versions of a file in memory at once, so "stupidly huge" blobs are not something it's ideal for. 
  - it handles binaries just fine and can delta them just fine. It cannot do automatic merging of binary files which have been edited concurrently by 2+ users because doing so requires file-format-specific logic. (AFAIK _no_ SCM can merge (as opposed to delta) binaries of any sort.)
- I do hope someday git and others employ either a git annex or mercurial-style scheme where if it's a large binary file: 1. no diff is performed, and 2. only the latest version is kept within the history. This would blow wide open the possibilities for using Fossil in binary-heavy projects such as machine learning, games, simulation. I could see the SQLite limitation worked around by just splitting up binary data into multiple pieces.
  - üëâüèª That will never happen in fossil: one of fossil's core-most design features and goals is that it remembers _everything_, not just the latest copy of a file. The way it records checkins, as a list of files and their hashes, is fundamentally incompatible with the notion of tossing out files. It is capable of permanently removing content, but that's a feature best reserved for removal of content which should never have been checked in (e.g. passwords, legally problematic checkins, etc.). Removing content from a fossil repo punches holes in the DAG/blockchain and is always to be considered a measure of last resort. In my 14+ years in the fossil community, i can count on 2 fingers the number of times i've recommended that a user use that capability.
  - Sharding large files over multiple blobs doesn't solve some of the underlying limitations, e.g. performing deltas. Fossil's delta algorithm requires that both the "v1" and "v2" versions of a given piece of content be in memory at once (along with the delta itself), and rewriting it to account for sharded blobs would be an undertaking in and of itself. That's almost certain to never happen until/unless the sqlite project needs such a feature (which, i'm confident in saying, it never will).
  - TL; DR: fossil is, plain and simple, not the SCM for projects which need massive blobs.

- The only major problem I see with Git is that it's just a pain if you're working in a gigantic monorepo.
  - Separate version control software can be designed for solving a specific problem - but I don't think Git should need to evolve beyond the problems it's designed to take on.

- The large file problem is a major issue in games, and basically means that developers who would much rather use Git, don't have the option of using Git because it would be crushed under the weight of all the art assets. So instead everyone's forced to use Perforce or Subversion, with all the workflow impediments that involves.
  - A lot of groups with large file problems seem to be converging on Git LFS at this point over Perforce/Subversion. Most of the major hosts (Github, Bitbucket, Gitlab) all have LFS hosting support, though it is not always cheap. (Arguably still cheaper than Perforce/Subversion, especially in accounting for those workflow impediments and the developer time they cost.)
  - LFS is a plugin to install, but that's maybe a strong indicator in favor of the git model that there are common plugins to solve some things like this. (And many distributions of git now also bundle LFS.)

- The project management features don‚Äôt have to live inside VCS, but it would be nice to sync them there or derive some of the primitive data structures there ‚Äî comment trees, approvals, CI red/green results at integration time.

- My main headache with git ‚Äî which is absent from the list in the blog ‚Äì is that it tracks snapshots instead of tracking changes. 
  - All git can do is to compare snapshots and allow you to impose a resemblance causal order onto them (which you can freely manipulate anyway with rebasing, squashing etc.). If your workflow consists of trying out many different ideas and then choosing which of them to keep and which to discard, git can be extremely painful ‚Äî you either end up with a history that is a complete mess or waste a lot of time rebasing and reorganising the (fake anyway) order of snapshots. That's why I am exited for tools like Pijul that attempt to actually track changes.

- Snapshots do have the advantage of not having to know anything about the data. Tracking changes necessarily needs to define a way to describe how things may change. Perhaps another take on the issue is that changing data should be structured to be more snapshot friendly?

- > Git is line-oriented and has no notion of semantic diffs and semantic merges. This makes it a raw tool when working with, ironically, source code.
  - Git is a content addressable snapshot system, with bolted on code to make it retrospectively appear to be a line-oriented system. It's worse than you thought.
- It's not worse. Snapshots are exactly what you want if you would like to have format-aware diff/merge or to experiment with alternate algorithms. But it's easier to complain about git and throw out pie-in-the-sky ideas about "modernizing our tools" than to try the actually-existing AST-based diff/merge tools and realize it's 100x more complex for no workflow gain.

- Diffs aren't actually a first-class object either, they're made up on the spot. Git just stores a complete snapshot for each commit; delta compression in the repo is incidental(Ê¨°Ë¶ÅÁöÑ; ‰º¥ÈöèÁöÑÔºõË°•ÂÖÖÁöÑÔºõÈôÑÂ±ûÁöÑ) and unrelated to the diffs you see.

- üò© Git doesn't understand move and copy operations very well, and has to be tricked into doing it.

- I‚Äôm not qualified to go into specifics but I hate it. All version control needs to do is pull, push and branch. Version on branch is newer? You need to pull down before you can check in. Instead what we get is over complicated nonsense with commits and stashes, rebases and heads, reparenting etc. I get it you don‚Äôt want to store your code on your local machine but that‚Äôs what backups are for, that‚Äôs not what the version control system should be doing.

- üÜöÔ∏è I like the patch-based approach of Pijul and Darcs: rearranging patches seems less fragile than rebasing snapshots.
  - Pijul works quite differently from Darcs: the primary datastructure in Darcs is indeed a list of patches, and the main operation is rearrangement.
  - Pijul is instead a CRDT, meaning that independent patches can be applied in any order without changing the result, which makes rearrangement unnecessary, and the system much faster.

- Implicit branching in Pijul is a killer feature (IMO)
- for distributed version control, the "first-class conflicts" of Pijul seems to be a step in the right direction.

- My main issue with Git, other than the terrible UX of the CLI, is just how common it is for one to want to rewrite the commit history - an operation for which there's no version control.

- You might be interested in my project git-branchless https://github.com/arxanas/git-branchless or the Git-compatible Jujutsu SCM https://github.com/martinvonz/jj, both of which have version control for commit history via an operation log. Both feature sensible undo commands.

- A client side virtual file system (FUSE), so that you can work with large repos that exceed the size of your own system.
  - Version control systems like Piper (Google internal) and Eden (Facebook), GitVFS (Microsoft) already do this, but adoption is marginal.
- I really want a system-wide content addressable store that a lot of different things can use.
- It's also interesting to note that at this point Microsoft seems to be pivoting away from GitVFS. They've put a lot of collective engineering work in git sparse clones and git partial clones and the intersection of the two ("sparse cones") and optimizations like git commit graph pushing git itself to better at virtualizing its object store, not touching objects it doesn't need, and better handling just-in-time scenarios for object retrieval when it really does need them.

- Native large file support. Git annex functionality built in = gg every other source control system.
  - Git annex "competitor" Git LFS is bundled in many distros of git today and supported by most of the major hosting providers at this point (if you are willing to pay for LFS space).

- most of my problems with git went away when I started using worktrees

- The semantic diffing bullet point has me wondering what attempts there are at making open source semantic diff tools. I love the closed source tool SemanticMerge, but the company behind it decided to be shitwads and pull the product so they could add a selling point to their proprietary version control system.

- git is like cpp, you have to use a subset

- ## [What comes after Git? | Hacker News_202012](https://news.ycombinator.com/item?id=25535844)

- ## [Fossil versus Git | Hacker News_202309](https://news.ycombinator.com/item?id=37622064)

- My problem with Fossil is that it is a "one solution for all problems". Fossil packs all solutions together while the Git ecosystem provides several different solutions for each problem.
  - When you want to do things that Fossil is not meant to do, then you're in trouble. I have no idea on how to do CI/CD and DevOps with Fossil and how to integrate it with AWS/Azure/GCP.
  - I find the whole ecosystem of Gitlab/Github, Notion, Jira and stand-alone alternatives like Gitea, Gogs, Gitprep and others to be more flexible and versatile.
- To get publicity or outside contributions it's hard to avoid the GitHub trap.

- I don't know Fossil. However, the first entry in the comparison table puts me off. "VCS, tickets, wiki, docs, notes, forum, chat, UI, RBAC" I don't want my version control system to be a wiki. Or a chat app, or any of that
- These additional capabilities are available for Git as 3rd-party add-ons, but with Fossil they are integrated into the design, to the point that it approximates "GitHub-in-a-box.
  - To clarify the actual benefit: this means that tickets, etc. are also distributed, i.e. available and backed up locally with every contributor, and not dependent on lock-in to a single vendor like GitHub.
- Versioning/distributing tickets is indeed useful; but can't this be "implemented" in git already, by defining a file-based format ( `issue/$YYYYMMDDHHMMSS-$title.md`, but the variants are endless), and versioning those files?

- ü§î If Fossil is so against deleting commits, what do you do if you've accidentally committed sensitive information that cannot live in any form in the repo?
  - Fossil provides a mechanism called "shunning" for removing content from a repository.
  - Every Fossil repository maintains a list of the hash names of "shunned" artifacts. Fossil will refuse to push or pull any shunned artifact. Furthermore, all shunned artifacts (but not the shunning list itself) are removed from the repository whenever the repository is reconstructed using the "rebuild" command.
- It is a problem in all decentralized systems. Once you publish something, there is no going back. Anyone of your peers can decide to leave with your sensitive data. That's also what make them so resistant to data loss.

- Source control is all about managing diffs. Large files are fine, binary doesn‚Äôt make sense. Most of the time binary file diffs aren‚Äôt human readable.
  - I store binary files outside of git but keep build logs containing binary file CRCs on git

- Most binary files that people want to store in a VCS are stuff like .psd, .xlsx, .docx, and the like - data that's created by people by hand, but not stored as text.
  - Xlsx and docx are just zipped up xml text. You can store it as text if you like and I think there are many git modules to handle this. But the xml isn‚Äôt really that diffable so I don‚Äôt bother.

- if you have large files in your repository, you have a design problem.
  - Not in gamedev where you can have hundreds of gigs of art assets (models, textures, audio...), but you still want to version them or even have people working on them at the same time (maps...). But that is a different can of worms entirely.
- git is for when you want to track changes to part of a file.
  - In your scenario, you just want to track different versions of a file.
- That's what object storage with versioning turned on is for e.g. GCS or S3
  - Although blob storage work well for versioning, you have to make heavy use of the underlying proprietary API to get these versions, and I am not quite sure you can do more complex operations, like diff and bisect between those versions the way you could with git.
- Why use git at all then? Just use an object store with versioning turned on.
  - Because git excels in relatively small size text files and patching and difficult. You can't binary blobs like jpegs, audio, video easily.

- Git is designed with a strong emphasis on text source and patches. It simply isn't designed for projects with large assets like 3D animation, game dev, etc. 
  - Having said that, solutions like **LFS, Annex and DVC** (not git-specific) work really well (IMO). If you don't like that, there are solutions like Restic that can version large files reasonably well (though it's a backup program).

- Lots of people are saying that having large files in a repo is wrong, bad, bad design, incorrect usage. Forget that you know git, github, git-lfs, even software engineering for a moment. All you know is that you're developing a general project on a computer, you are using files, and you want version history on everything. What's wrong with that?
  - The major issue with big files is resources: storage, and network bandwidth. But for both of these it is the sum of all object sizes in a repo that matters, not any particular file, so it's weird to be harking on big files being bad design or evil.

- That's why Perforce is still the SCM of choice for a lot of creatives. I don't know if they still do it, but Unreal used to ship a Perforce license with their SDK.
  - That's also why perforce is slow as heck unless you throw massive resources at it. 

- In the age of Large Language Models, large blobs will become the rule, not the exception. You‚Äôre not going to retrain models costing $100M to build from scratch because of the limitations of your SCM.
  - I don‚Äôt store those in my scm. It‚Äôs not a limitation of my scm that I can‚Äôt store a 20gig model directly in the repo.

- I like the ‚Äúseparation of powers‚Äù between git and GitHub functions (and gitlab).
  - It‚Äôs nice to be able to start git repos locally and only push to GitHub when I need to.
  - Git is sort of like a protocol with gitlab, GitHub, and others built on top.
- Gitea is already "GitHub in a box".

- I haven‚Äôt used Fossil but I have used gittrac, cvstrac in git mode. Cvstrac was what SQLite used before fossil, basically wiki and issue tracker built on top of SQLite, just add CVS, SVN or Git. A very small system compared to Gitea or other forges, but incredibly powerful thanks to SQL and very productive. Fossil is just the logical continuation and shares the same clarity of design and elegant implementation of SQLite.

- why would I want my versioning system coupled to a bunch of random services?
  - Doing one thing and one thing only is a feature, not a bug.

- ## [Git vs. Fossil: what you should have done vs. what you did | Hacker News_202107](https://news.ycombinator.com/item?id=27736980)

- Fossil does anything Git will do, except for one thing: Fossil does not (easily) sync individual branches. (You can do it, but it is a pain.) Git comes with the idea that individual developers keep their own private branches and only share them after they've been cleaned up. The idea behind Fossil is that everybody shares everything.
  - There are advantages and disadvantages to both approaches.

- Fossil's bisect works better than Git's in my experience, since Fossil's data model permits bidirectional tracing, whereas Git can go backwards in time only. This allows commands like "fossil bisect status" to show where you are in the decision tree, since it has to trace forward in time as well to provide the answer.

- The only reason I am aware of for keeping history is bisecting it to track regressions. The "development history" is completely useless for this purpose. What I want is the version history. That's why git is called a version control system.

- ü§î what if I accidentally commit (not push) a piece of sensitive data (say a private key), but notice before I commit. In Git, I would simply remove it, and amend, and it is now gone from the Git history. It sounds like with Fossil, it would remain in the history, or am I misunderstanding something?
- Careful, amending doesn‚Äôt actually remove the bad commit, but it rather creates a new one and changes the appropriate branch pointer towards it. The old commit is still there, browsable if you know what you‚Äôre doing. 
- In Fossil it will remain in your local repository but you can put the hash for the data you accidentally committed in a "blacklist" so that it wont be pushed/pulled. I think you can also rebuild the local repository to purge any data, though i'm not 100% sure about that.
  - Fossil has autosync by default, so the commit has probably reached another instance anyway. But it has a provision exactly for those cases, the shunning mechanism.

- One of the repos I interact with, the team rebases all their local branch commits to master. It is very difficult to read the commit history and get a sense of anything except Jira issue codes. One needs to look at the individual files and read the code to understand what the commit was for.
  - This is why the best Git workflows IMO involve rebasing and squashing the branch down to a couple of well-defined "logical commits", then merging that (with --no-ff of course) into master/main/trunk. This forces individual programmers to think somewhat carefully about leaving a sensible commit history behind.
- I think that's a consequence of rebasing. If you just merge instead, you can use the branching/merging to get a sense of complete features/changes.

- ## [Fossil vs Git | Hacker News_201901](https://news.ycombinator.com/item?id=19006036)

- SQLite uses cathedral-style development. 95% of the code in SQLite comes from just three programmers, 64% from just the lead developer. And all SQLite developers know each other well and interact daily. Fossil is designed for this development model.

- It's sad because Fossil underneath the covers is a lot like Git, but with a SQL RDBMS as the store. Fossil's design is much more powerful than Git's for that reason alone. But **that super-opinionated attitude they have is a disaster**. Run away.
- I'm also not convinced it's a good idea to merge your bug tracker and version control.

- I choose fossil at a time when it wasn't clear which one of fossil, Mercurial, or git would "win".
  - I choose it because it had a very clear and easy UI, guided you towards a way of working that is suitable for small teams (ie 99.99% of all projects), and had an approach to history which made it unlikely you'd ever accidentally lose work.
- For what it's worth, Git has a command for an instant web server https://git-scm.com/docs/gitweb

- Branches in Fossil have persistent names that are propagated to collaborators via push and pull. All developers see the same name on the same branch. Git, in contrast, uses only local branch names, so developers working on the same project can (and frequently do) use a different name for the same branch.
- branches are just bookmarks for commits. And Git very much has local tracking branches (that track upstream branches), so it's as Fossil-like as you want, but doesn't pretend to enforce a merge-only workflow.
- That's really the bottom line when it comes to Git vs. all the others: Git doesn't enforce a merge-only workflow, not even as a default, while all the others generally do.

- One thing that isn't mentioned is whether Fossil supports working offline as well as Git does.
  - The way fossil works is that by default autosync is turned on, which means that if you are connected to the internet all of your commits, wiki and issue tracker changes are synced to the server.
  - In the case that you're not connected, everything still works as expected, and will sync back up next time you're online and try to commit or just run fossil update.

- Your commit history should read like a published novel, not a first draft.
  - I think I might‚Äôve read something like that in the Pro Git book and it rings true with me.
  - The philosophy of Fossil is to preserve the full history, which I think is a mistake.
- Both approaches have value. And you'll find books advocating both ways.
- A nice feature would be the ability to group and split commits afterwards; like adding a "novel branch". So that you could keep both the exact history and a parallel high level description.
  - Your high-level description resemble a cover letter used on some open-source project to introduce a patch series, justifying the changes. You could achieve the same by using an empty commit, or tracking those in the bug tracker.
  - DCVSs are already complex enough, this just seems like scope creep, trying to emulate a feature that is actually part of another tool (the bug tracker or the mailing list, depending on the structure).
  - Another issue is that it would foster a mentality where people would simply don't care about the exact history and push really badly structured commits, relying on the second-level history to explain their work.

- Fossil's design and implementation are indeed admirable. Its insistence on merges is not.

- As someone currently working in a project where parts are managed with git and others with fossil, I have a strong preference towards git. 
  - One major issue with fossil is the non-existent ecosystem. It simply does not integrate well with other frameworks and tools (e.g. Yocto/OE)
  - The irony is that they have big performance issues with fossil, precisely due to the fact that **fossil records everything and the push/pull commands sync the entire repo, not just one branch**.
- Fossil also lacks an equivalent to git submodules, which should be added to the list of features found in git, but not in fossil.

- I agree with those who said they prefer git's "clean" commit history.

- Fossil is better. Because it has a better design. 
  - Because it uses SQL (which makes it possible to write queries on the fly in ways that cannot be done in other VCSes). 
  - The use of SQL, and Fossil's use of fairly generic SQL, allowing the use of RDBMSes other than SQLite3, is brilliant, and would make it trivial to make Fossil scale better than MSFT is making Git scale, though with the caveat that you'd probably still end up wanting things like a Bloom filter for speeding up file-level log/blame, but you could probably make Bloom filters a transparent, RDBMS-level query optimization.
- Fossil is worse. 
  - Because it doesn't have a CoW design in the format of its DB, though it does have a CoW design in its SQL schema. 
  - However, because SQLite3 is so good at handling power failures and such, this has not been a big deal (and indeed, Git has had more problems there owing to its ad-hoc storage model). 
  - This, of course, could be fixed by adopting a CoW backend for Fossil. This problem is hardly fatal.
- Fossil is worse. Because of its insistence on merge workflows and not implementing rebase.
- Fossil is worse. Because it has minimal mindshare(ÂøÉÁêÜ‰ªΩÈ¢ù, ËÆ§Áü•‰ªΩÈ¢ù). Mindshare is absolutely critical. The lack of rebase support is part of the reason that Fossil cannot get the kind of mindshare that would allow it to replace Git.
  - rebase is really just a feature that can be built by using scripting on top of a cherry-pick primitive (which Fossil does have)
- Incidentally, GitHub used to also insist on merges in its browser UI, but eventually they added the "rebase and merge" feature.
- Mercurial too resisted rebase. Boy did they. And they gave in and implemented it. Ironically many people rebased in Mercurial long before the feature was adopted

- Fossil does have private branches and the recommended way to publish private work is to integrate it into a non-private branch and sync as usual.

- Git has the following shortcomings which are major (some shared by other VCS too)
  - 1) UI- terrible, terrible UI
  - 2) Unncessarily complex data model
  - 3) Doesn't scale well to large repos (until Microsoft's VFS- windows only)
- I think git and hg are both pretty bad in different ways.
  - Both have pretty terrible UI but so long as one uses magit, git comes out way on top.
  - The data models are different and suffer different problems.
    - A **main issue with git is that it is stupid about file copies and renames**. 
    - An issue with hg is that it doesn‚Äôt work well with long running forked histories (i.e. like git branches) because it stores the set of revisions of a file as a list of blocks of ‚Äúcomplete file‚Äù or ‚Äúdiff from previous version in this list‚Äù
  - Both have scaling problems to large repos and algorithm/data structure problems which cause too many operations to be e.g. O(size of history) at least. 
- Another interesting vc system being developed at the moment is pijul which can be simply described as ‚Äúlike darcs but fast and more likely to be correct‚Äù. It feels a bit like it‚Äôs fitting in with the current trend of CRDTs, although it‚Äôs core data structure is not a CRDT as that would imply that all merges have some deterministic resolution (ie merge conflicts do not happen) and that is not the case, instead files are allowed to be merged into a first-class conflicted state which can then be resolved by later patches.
- Git has no first-class concept of file name changes. Instead it tries to use heuristics to spot renames and sometimes they work and sometimes they won‚Äôt.
- The data model in Git is hardly more complex than Fossil's or Mercurial's, and it's copy-on-write all the way, which makes it very safe (think ZFS).
- The simple data model is the best part of git so I have no idea what you are referring to. I do not see how one could make it any simpler and still use it to implement a DVCS. The main reasons I picked Git over Mercurial were the data model and the performance.

- ## üî• [Git‚Äôs database internals II: commit history queries | Hacker News_202208](https://news.ycombinator.com/item?id=32651934)
- 
- 
- 

- ## üî• [Git‚Äôs database internals I: packed object store | Hacker News_202208](https://news.ycombinator.com/item?id=32637643)
- 
- 
- 

# discuss-git-versioning/vcs
- ## 

- ## [Working with stacked branches in Git is easier with ‚Äìupdate-refs (2022) | Hacker News _202407](https://news.ycombinator.com/item?id=40963427)
- I like to work with Gerrit, which approaches the core problem in a different way
  - "Stacked branches" seem to be a terminology which derives from Github/etc's approach to Pull Requests, where one PR maps to one atomic change. The PR can either be integrated in the repo as a merge, in which case you maintain the history of the PR and all its changes through its reviews, or as a squash-merge, in which case you flatten the PR's review history into one commit.
  - Gerrit took a different approach, and requires you to add metadata to each commit's message, the Change-Id. This way Gerrit can track your commit through its review evolution (since its SHA will change with each iteration). This also allows Gerrit to trivially track a series of related changes through their overall evolution
- In any case, both solutions demonstrate that Git lacks a way to track the evolution of specific commits throughout their review history (a 2D branch in a way), so review tools like Github/etc and Gerrit had to create their own solution on top of it.

- ## [Show HN: I created a plugin for Figma to track changes in the design | Hacker News](https://news.ycombinator.com/item?id=42098378)

- ## [Git scraping: track changes over time by scraping to a Git repository (2020) | Hacker News _202308](https://news.ycombinator.com/item?id=37082289)
- The core idea I believe is tracking incremental changes and keeping past history of items. Git is good for text, though for large amounts of binary data I would recommend filesystem snapshots like with btrfs.

- some covid datasets were published as git repositories. the cool part was that it added a publish date dimension for historical data so that one could understand how long it took for historical counts to reach a steady state.

- Git scraping also lets you easily track changes made to textual content, which I don't think would fit neatly in a time series database.

- ## [Extremely Linear Git History | Hacker News _202211](https://news.ycombinator.com/item?id=33704297)
- Github-style rebase-only PRs have revealed the best compromise between 'preserve history' and 'linear history' strategies

- Mercurial always has had sequential revision numbers in addition to hashes for every commit. They aren't perfect, of course. All they indicate is in which order the current clone of the repo saw the commits. So two clones could pull the commits in different order and each clone could have different revision numbers for the same commits.

- The problem is that rebasing commits has the potential of screwing up the integrity of your commit history.

- Sane revision numbers are among the many reasons I prefer SVN to GIT.
  - You could automatically tag each uploaded commit with a number drawn from a sequence - using a git post-update hook. The only problem is that this centralizes the process. It's not possible to have fully "blessed" commits without pushing them first. And that's how SVN works, too.

- Gitlab supports an option called "Fast-forward merge"

- A neat trick with this tool is to generate a commit message that corresponds to a given issue number. It could almost be useful.

- Another approach could be to use prefixes.

- ## [Git Is Not Revision Control (2017) | Hacker News _201807](https://news.ycombinator.com/item?id=17475392)
- I opened the link expecting to see an introduction to a patch-based system like Darcs or Pijul.

- For me, rewriting history is a feature of Git, and not a bug. I used to use Mercurial, which prioritized immutability of history

- ## [Git evolve: tracking changes to changes | Hacker News _202211](https://news.ycombinator.com/item?id=33567930)
- Git makes the commit history permanent and there are a lot of issues if you keep changing the commit using commit amend or rebase. Git kind of fights with you if you try to edit commits after the commits have been made and pushed to remote
  - One option is to ‚Äúevolve‚Äù the commits without git. Create local branch but do not push them, convert the branch to a patch set, a series of files

- ## [Version Control Beyond Git | Hacker News _202405](https://news.ycombinator.com/item?id=40424452)
- The real issue is though, that each time someone writes a new VCS they seem to want to make it centralised again, often with silly ideas like auto-uploading changes. I do dislike the git stash and the "mess" of untracked files in git status, but I'm not sure what the true answer is.

- The feature I think I would most like to see is support for patches as a more first-class object. For example reverts and cherry picks have no real metadata. This leads to conflicts when merging branches that have cherry picks (although they often auto-resolve if they are exactly the same diff) and makes asking "Does $branch contain $patch" basically impossible to answer.
  - https://pijul.org/ greatly improves this by making patches a first class object (and commits are basically sets of patches). I think it has some great ideas to improve the really gnarly parts of Git low-level behaviour. (Not just surface-level UI issues)
# discuss-git-diff
- ## 

- ## 

- ## üí° [Show HN: Locust ‚Äì ‚ÄúGit diff‚Äù over abstract syntax trees | Hacker News _202011](https://news.ycombinator.com/item?id=24999775)
- I can't wait until the future when we have version control at the AST level instead of using text files.

# discuss-collab/crdt
- ## 

- ## 

- ## 

- ## Is the git data model a CRDT? If not, would a CRDT make for a "better git"?
- https://x.com/francesc/status/794647418222448640
- git objects are immutable and append-only so I believe so.  The main thing that isn't are repo-specific git refs
  - the commit graph itself is conflict free; it's only if you choose to try to merge the content of the tree you get conflicts
  - but if you don't (like with tracking refs or `git merge -s ours` ), the storage, replication, etc are all conflict free.

# discuss-internals-git
- ## 

- ## 

- ## üï∏Ô∏è Did you know Git implements its own network protocol?
- https://x.com/NeelShetty6/status/1985781254177091745
  - it doesn't utilize HTTP, it has its own binary wire format built on pkt-line communication over raw TCP
  - you can check it by setting the `GIT_TRACE_PACKET=1` environment variable, here you can see git negotiate with the remote in real time.
  - A pkt-line is a variable length binary string.  The first four bytes of the line, the pkt-len, indicates the total length of the line, in hexadecimal.  The pkt-len includes the 4 bytes used to contain the length‚Äôs hexadecimal representation.
  - Git sends a series of want and have lines to describe which objects it needs, and the server responds with compressed packfiles containing only the missing data. The result is a minimal, binary-efficient data stream designed for low latency and huge repositories.
  - üÜö Compared to HTTPS, this native protocol is faster because it avoids the overhead of HTTP headers, TLS handshakes, and stateless request cycles. It‚Äôs a persistent, full-duplex channel optimized for Git‚Äôs data model
  - Git‚Äôs own protocol exists because sometimes you need a transport designed around your object graph

- Git also supports another non-HTTP protocol: SSH
  - Yes, it uses pkt line format even with an ssh connection. Ssh is just for establishing the connection, auth n stuff

- `GIT_TRACE_PACKET=1` also works with ssh remotes, so I guess it's the same protocol either it's raw TCP or tunneled through ssh
  - Yes, http is different

- Does it avoid TLS completely here ? Would that not be sec concern though i suppose the protocol could handle that on its own maybe
  - Yes, they address this and recommend to use it alongside ssh or making it read only
# discuss-parallel/worktree üîÄ
- ## 

- ## 

- ## ü§º I talked with @steipete yesterday and we both realized that we gave up on worktrees and just use multiple checkouts. 
- https://x.com/mitsuhiko/status/2011773404207337549
  - Turns out, we're simple people.
  - They are just stable checkouts with stable identities, stable node_modules, fixed ports and databases etc.
  - (And yes, I had a vibecoded worktree manager. Ended up just not using it)

- i think `--shared` shares the .git folder

- what are downsides to multiple checkouts
  - From my experience, with git clone --shared/--reference very little, I guess the main concern would be disk space. I just like it. YMMV
- Are stashes and branches shared?
  - No but if you do a reference clone then you can access them by sha
- Slower, can't share the stash, can't use branches without pushing and looking, rebasing is more work, in short I completely miss why people don't want to use it.
- When you wanna merge, pull master, and keep iterating in the same agent session you can't.
- The only benefit I see is, that you can easily view all local branches in one git client without push/pull. And you can easily merge them locally. 
  - Worktrees only share the .git folder, which is usually rather small.
- Agent sessions are also tied to the directory (at least in CC) so you can't resume a session when you close a worktree (I don't think).

- on macOS APFS you can duplicate the folder and rely on copy on write to save space, only files that would be updated are actually written to disk

- super interesting - i've really taken to worktrees (with a really lightweight manager). key thing i needed was a .scratchpad file in the root so i could tell them apart for context switching!
  - I find the UX around switching a work tree into the main folder to be pretty bad, and managing my node modules and other local DX things is also annoying. Also my diff viewer does not work well with worktrees, let alone me remembering which work trees are alive or not.
  - I'm sure there are ways, but now I have multiple checkouts named after "main", "papercuts", "refactor" and I only keep one type of activity going on simultaniously.

- I think switching a branch into the main folder is one of the best reasons to not use worktrees. without a 1:1 branch:worktree mapping, you lose many of the benefits; it's difficult to know where things are...

- I really tried getting used to worktrees as well, even tried a few different utils and I just couldn‚Äôt do it. Multiple directories and life is good now

- that‚Äôs what multiple users working on the same project would do

- today and yesterday had me feeling like this, worktrees confuse the agent too much

- two clone repos is enough for my brain

- have actually been using work trees lately and it's great, easier to be working on different things concurrently. It's not great if you have .env files and things like that though. Or if your package/build manager  is just not really worktree friendly

- ## ËøáÂæÄÊâãÊï≤‰ª£Á†ÅÁöÑÁâ©ÁêÜÁâπÊÄßÔºåGit ÂéãÊ†πÂ∞±Ê≤°ÊÉ≥ËøáÊúâ‰∏ÄÂ§©Êàë‰ª¨ÂèØ‰ª•Âú®‰∏ÄÂè∞Êú∫Âô®‰∏äÂºÄÂêØ‰ªªÊÑèÊï∞ÈáèÁöÑÁ™óÂè£Âπ∂Ë°åÂºÄÂèëÔºåWorktree ËøôÁßç‰∏∫ËæπÁºòÂú∫ÊôØËÆæËÆ°ÁöÑÂäüËÉΩ‰∏ÄË∑ÉÊàê‰∏∫ÂºÄÂèëÊ†áÈÖçÔºå‰ªéÊó†‰∫∫ÈóÆÊ¥•Âà∞ËÅöÂÖâÁÅØ‰∏ãÔºåÂÆÉÊòæÁÑ∂Ê≤°ÈÄÇÂ∫îÂ•ΩÔºö
- https://x.com/victor_wu_eth/status/2010605107176710630
  - ‚Ä¢ ËÖêË¥•ÂíåË∞ÉËØïÈóÆÈ¢òÔºöWorktree ÂÆπÊòìÂØºËá¥ Git ‰ªìÂ∫ì„ÄÅÂåÖ‰æùËµñÊàñÊûÑÂª∫ËøáÁ®ãËÖêË¥•ÔºåË∞ÉËØïËøô‰∫õÈóÆÈ¢òÂæÄÂæÄÊäµÊ∂à‰∫ÜÂπ∂Ë°åÂºÄÂèëÁöÑÊïàÁéáÊèêÂçá„ÄÇ‰æãÂ¶ÇÔºåÂú®Âπ∂Ë°åÂ§ÑÁêÜÊó∂ÔºåÁéØÂ¢É‰∏çÁ®≥ÂÆö‰ºöÂºïÂèëÈ¢ëÁπÅÁöÑ‰øÆÂ§çÈúÄÊ±Ç„ÄÇ
  - ‚Ä¢ Êú™Ë∑üË∏™Êñá‰ª∂‰∏çÂ§çÂà∂ÔºöWorktree ‰∏ç‰ºöËá™Âä®ÊãâÂèñÊú™Ë∑üË∏™ÁöÑÊñá‰ª∂ÔºàÂ¶Ç .env Êàñ node_modulesÔºâÔºåËøô‰ºö‰∏≠Êñ≠Â∑•‰ΩúÊµÅÁ®ãÔºåÈúÄË¶ÅÊâãÂä®Â§ÑÁêÜÔºåÂ¢ûÂä†‰∫ÜËÆ§Áü•Ë¥üÊãÖÂíåÊó∂Èó¥ÊàêÊú¨„ÄÇÂ¶ÇÊûú‰∏çÂπ∂Ë°åÂÆûÁé∞Â§ö‰∏™ÂäüËÉΩÔºåËøôÁßçÁóõÁÇπÂ∞§ÂÖ∂‰∏çÂÄºÂæó„ÄÇ
  - ‚Ä¢ UX ÂíåÁÆ°ÁêÜÂ§çÊùÇÔºöWorktree Ë¢´ËßÜ‰∏∫‰ΩéÁ∫ß HackÔºåÈúÄË¶ÅÊâãÂä®ÁÆ°ÁêÜÂ§ö‰∏™ÂëΩÂêçÁ©∫Èó¥ÂíåÁõÆÂΩïÔºå‰∏é Git ÁöÑÊ†∏ÂøÉÊ®°ÂûãÂÜ≤Á™Å„ÄÇÊï¥‰ΩìÁî®Êà∑‰ΩìÈ™åÁ≥üÁ≥ïÔºåÂÆπÊòìÂá∫ÈîôÔºåÂ∞§ÂÖ∂Âú®Â§ö‰ºöËØùÊó∂ AI Agent ‰ºöÊ∑∑Ê∑Ü‰ªªÂä°ÔºåÂØºËá¥ÊÑèÂ§ñÈáçÁΩÆÊàñÂàáÊç¢„ÄÇ
  - ‚Ä¢ ÈöîÁ¶ª‰∏çË∂≥ÔºöÂØπ‰∫éÈúÄË¶ÅÁ´ØÂè£ÁõëÂê¨ÊàñÂÆåÊï¥ÈöîÁ¶ªÁöÑÂú∫ÊôØÔºåWorktree ‰∏çÂ§üÂèØÈù†„ÄÇÊúâ‰∫õÂºÄÂèëËÄÖÂª∫ËÆÆÁî® Docker ÂÆπÂô®Êõø‰ª£Ôºå‰ª•ÈÅøÂÖçÁ´ØÂè£ÂÜ≤Á™ÅÊàñÁéØÂ¢ÉÊ±°Êüì„ÄÇ
  - ‚Ä¢ ÂêàÂπ∂Âíå AI Â§ÑÁêÜÈóÆÈ¢òÔºöAI Agent ÊúâÊó∂Êó†Ê≥ïÊ≠£Á°ÆÂú®Êñ∞ÁöÑ Worktree ‰∏äÂêØÂä®Â∑•‰ΩúÔºåÊàñÂ§ÑÁêÜËØ°ÂºÇÁöÑÂêàÂπ∂ÂÜ≤Á™ÅÔºåÂØºËá¥Êï¥‰Ωì‰ΩìÈ™åÁ≥üÁ≥ï„ÄÇÁâπÂà´ÊòØÂú®Â∑•ÂÖ∑ÈõÜÊàêÊó∂ÔºàÂ¶Ç WindsurfÔºâÔºåÂèØËÉΩ‰ºöÈªòËÆ§ÂõûÊ†πÁõÆÂΩïÔºåÊó†Ê≥ïÁîüÊàê Commit„ÄÇ
  - Vibe Coding Âà∞Áé∞Âú®ÔºåÊàëÂØπ Worktree ÁöÑËØÑ‰ª∑Â∞±ÊòØÔºöËøòËÉΩÂíãÂú∞Ôºå‰Ω†Âè™ËÉΩÁî®ÂÆÉ‰∫Ü„ÄÇ

- ÊàëÁé∞Âú®ÊòØÊØè‰∏™‰ªªÂä°‰∏¥Êó∂ local clone ‰∏Ä‰∏™ÂÆåÊï¥ÁöÑ‰ªìÂ∫ìÔºåÁÑ∂ÂêéÁî®ÂÆå‰∫ÜÂà†Êéâ„ÄÇ
  - Áî®linuxÁöÑËØùÂèØ‰ª•ËØïËØïhttps://github.com/zhengbuqian/boqÔºåÂÆπÂô®ÂÆåÂÖ®Â§çÂàªÊú¨Êù•ÁöÑÂºÄÂèëÁéØÂ¢ÉÔºåoverlayÊ®°ÂºèÊòØcopy on writeÔºåÁªßÊâøÊâÄÊúâ‰æùËµñÔºå‰øÆÊîπ‰∏çÂΩ±ÂìçhostÔºå‰πüÂèØ‰ª•Âø´ÈÄüÂ§çÂà∂Â§ö‰∏™„ÄÇÁõÆÂâçÁî®‰∏ãÊù•ÂîØ‰∏ÄÁöÑÈóÆÈ¢òÊòØhost‰øÆÊîπ‰∫ÜÊñá‰ª∂‰ºöÂØºËá¥Âú®ÂÆπÂô®ÂÜÖ‰πüÂèØËßÅÔºåÊàëÊòØÂ∞ΩÈáèÊâÄÊúâÂ∑•‰ΩúÈÉΩÂú®boqÂÜÖÂÆåÊàê

- ÁºñËØë cpu100% ÁöÑÂú∫ÊôØÊÄé‰πàÁ†¥

- git ‰∏ç‰ºöÊîπÔºåÂè™‰ºöÂá∫Áé∞Êñ∞git

- ## ÊàëÂæàÂ•ΩÂ•á‰Ω†‰ª¨Á∫Ø vibe ‰∏çË∑ëÈ°πÁõÆÂêó Â¶ÇÊûúË¶ÅË∑ëÁöÑËøô‰πàËß£ÂÜ≥ÊØè‰∏™ worktree ÈÉΩË¶ÅÂÆâË£Ö‰æùËµñÁöÑÈóÆÈ¢ò Áî®ËΩØËøû or
- https://x.com/yetone/status/2006325355381137659
- ÂèØ‰ª•ËÆæÁΩÆÂêØÂä®ËÑöÊú¨ÔºåÁõ¥Êé•‰∏ÄÈîÆrun

- pnpm Â•ΩÂÉèÂèØ‰ª•ËÆæÁΩÆÂÖ®Â±ÄÁºìÂ≠òÔºåÊñ∞ÁöÑworktreeË£ÖËµ∑Êù•‰πüÂæàÂø´

- Â¶ÇÊûúÊòØ Node.js È°πÁõÆÔºåÁî® pnpm Â∞±Ê≤°ÈÇ£‰πàÂ§ßÂéãÂäõ‰∫Ü„ÄÇPython È°πÁõÆÔºåÂèØ‰ª•ËÆ©‰∏çÂêå worktrees ÂÖ±‰∫´Âêå‰∏Ä‰∏™ËôöÊãüÁéØÂ¢É„ÄÇ ÈúÄË¶ÅÈáçÂ§çËß¶ÂèëÂÆâË£ÖÁöÑÈóÆÈ¢òÂèØ‰ª•‰∫§Áªô git hooks„ÄÇ

- ÊàëÁé∞Âú®Êêû‰∫Ü‰∏Ä‰∏™ skill ÊØèÊ¨°ÂºÄ worktree Â∞±Ëá™Âä®ÈÖçÁΩÆÁéØÂ¢É

- ÊàëÁé∞Âú® worktree ÁöÑÊúÄÂ§ßÈóÆÈ¢òÊòØÔºå‰∏§‰∏™ ts-server Áõ¥Êé•ËÆ©ÁîµËÑëÂç°‰Ωèx

- ‰ª•ËØïËØïÔºåÂ§ö‰∏™ AI agent Âπ∂ÂèëË∑ëÁ°ÆÂÆûÂèØ‰ª•ÊèêÈ´òÊïàÁéáÔºåÈÇ£‰∏™ conductor ÁöÑÊêûÊ≥ïÊàëËøòÊòØÂèØ‰ª•Êé•ÂèóÁöÑÔºåÈôç‰Ωé‰∫ÜËõÆÂ§ö worktree ÁöÑÊàêÊú¨

- Ë¶ÅËµ∑Â§ö‰∏™ electron ËøõÁ®ã‰πüÊòØÂæàÈöæ‰ª•Êé•ÂèóÁöÑ
  - ÊµãËØïÁöÑÊó∂ÂÄôÂÖàÂÖ≥ÊéâÁ¨¨‰∏Ä‰∏™ËøõÁ®ãÂÜçÂºÄÁ¨¨‰∫å‰∏™‰∏çË°åÂêó

- Ëøô‰πüÊòØÊàë‰∏çÁî® worktree ÁöÑÂéüÂõ†ÔºåÊØèÊ¨°ÂÆâË£Ö‰æùËµñËä±Êó∂Èó¥Ôºå‰∏ªË¶ÅÊòØÁ£ÅÁõòÈ°∂‰∏ç‰Ωè‰∫Ü„ÄÇ

- ËøôÁßçÊ®°ÂºèÊàë‰∏ÄÁõ¥ÊØîËæÉÂ•ΩÂ•á„ÄÇÂ¶ÇÊûúÊòØ‰∏Ä‰∫õÁé©ÂÖ∑ÁöÑÈ°πÁõÆÔºåÈÇ£Â∞±Á∫ØÁ≤πÂΩìÊó∂Êµ™Ë¥πtokenÁé©Áé©Â•Ω‰∫Ü„ÄÇÂ¶ÇÊûúÊòØÂú®ÁúüÂÆûÁöÑÈ°πÁõÆÔºå‰∫∫ÁöÑÊ≥®ÊÑèÂäõ‰πüÂÆåÂÖ®‰∏çÂ§üÂïäÔºåÂ∞ΩÁÆ°AIÂèØ‰ª•ÁîüÊàêÈÉ®ÂàÜ‰ª£Á†ÅÔºå‰ΩÜËøòÊòØÈúÄË¶Å‰∫∫ÁöÑÊ≥®ÊÑèÂäõÁöÑÔºåËøôÁßçÂºÄN‰∏™ÁöÑÊâìÊñ≠ÁöÑÊàêÊú¨‰ºöÂæàÂ§ß„ÄÇ
# discuss-git-ai üëæ
- ## 

- ## 

- ## 

- ## Who's building an IDE for reviewing code instead of writing code?
- https://x.com/schickling/status/2015870972184662197
  - Don't only show me diffs. Show me before/after UIs, terminal output, benchmarks, historic trends, playgrounds, demos, test results etc.

- ci already solved this

- We're experimenting with many versions of this internally at @cursor_ai ! With an agent-first development flow, Cursor today is probably the most fleshed out IDE for reviewing code. But lots more that we are excited to do here!

- https://github.com/intent-solutions-io/iam-git-with-intent /ts
  - CLI tool that automates PR workflows. Resolves merge conflicts, creates PRs from issues, reviews code, runs in full autopilot with approval gating.

- https://github.com/peterjthomson/ledger /MIT/ts
  - modernised git interface for improved agent and human collaboration, review and control
  - A modernised git interface for macOS ‚Äî view pull requests, worktrees, branches and stashes at a glance
  - Â§öÂàóËßÜÂõæ
# discuss-git-protocol/spec
- ## 

- ## 

- ## 

- ## 

- ## ‚è≥ the author of git ai put together a spec for annotating commits with information about what code is ai generated
- https://x.com/thdxr/status/2014689039958364209
  - need to review deeper but opencode will probably implement this
  - we can't have this kind of functionality only exist in proprietary products like cursor blame

- I find it annoying in Cursor how it treats AI edits with special diff UI elements for "Keep / Undo". I like to look at AI output and tweak edits by hand sometimes. I've found myself just hitting Cursor's "Keep All" button immediately and then using traditional git diff viewer

- this would be huge for debugging. half the time i'm staring at AI-generated code trying to reverse-engineer what prompt led to this decision. knowing "claude wrote this at iteration 3 with X context" would save so much time

- so basically we're adding metadata to commits so future devs can blame the ai instead of each other cool
# discuss
- ## 

- ## 

- ## 

- ## [Git Things | Hacker News _202401](https://news.ycombinator.com/item?id=38830194)
- 
- 
- 

- ## [Git ËøúÁ®ã‰ª£Á†ÅÊâßË°åÊºèÊ¥ûÔºàCVE-2024-32002ÔºâÂ§çÁé∞ - starnight\_cyber - ÂçöÂÆ¢Âõ≠ _202405](https://www.cnblogs.com/Hi-blog/p/18224773/git_rce_CVE-2024-32002)
- [„ÄêÂ∑≤Â§çÁé∞„ÄëGitÂ≠òÂú®ËøúÁ®ã‰ª£Á†ÅÊâßË°åÊºèÊ¥ûÔºàCVE-2024-32002Ôºâ](https://mp.weixin.qq.com/s/BRr5PCTgYkfPkvHwDckVMQ)
- ÂéüÁêÜÊòØ Âà©Áî® git submodule --recursive Â∞ÜÊÅ∂ÊÑè‰ª£Á†ÅÊ≥®ÂÖ•Âà∞Â≠êÈ°πÁõÆÁöÑ.gitÁõÆÂΩïÁöÑgit-hooks

- ## Git is and has always been local first, distributed model. 
- https://twitter.com/oleg008/status/1778716391488598085
  - Isn't it a bit weird that we ended up relying on centralized services even though there is no need at all? 
  - All the collaboration data could be equally in git just like the code, all synced and distributed.
- There is certainly a need for one primary remote repository. You would have crazy inconsistencies, availability-problems and merge-problems otherwise.

- That‚Äôs what I like about fossil-scm It has the other supporting functions that the centralized services give you. 
- I think Fossil SCM does this for issues, wiki, forum etc?

- ## üß© for git, there are 4 locations for your code:
- https://twitter.com/sahnlam/status/1769954179886547365
  - Working Directory
  - Staging Area
  - Local Repository
  - Remote Repository (like GitHub)
- Basic commands move code between these locations:
  - git add stages changes
  - git commit saves them locally
  - git push shares them remotely
  - git pull fetches updates from others
- Concepts like git clone, merge, rebase enable collaboration.

- ## üåµ Explaining Git branching strategies.
- https://twitter.com/ChrisStaud/status/1752341883198853588
- Let's take a look at some common approaches to branching:
  - Feature branching is a popular approach as development tasks are usually revolved around a feature. It involves having a branch for every feature being developed to keep the changes isolated from the main branch.
  - Gitflow has two permanent branches ‚Äî a production and a pre-production branch, often referred to as the ‚Äúprod‚Äù and ‚Äúdev‚Äù branches. There are additional temporary branches for each feature, scheduled releases, and urgent bug fixes.
  - Gitlab flow combines feature-branching and environment-based branching.
  - GitHub flow takes a simplified process that is similar to feature branching. 
  - With trunk-based development, branches are very short-lived. Changes are merged into the main branch within a day or two. Feature

- ## A rewindable file system demo I cooked up.
- https://twitter.com/JungleSilicon/status/1729012610048360626
- Have you ever managed to get a conflict free data type in front of git, so you can sync to GitHub? 
  - You can do it, but it usually involves diffs - there's also a problem that git uses snapshots where as crdt's/ot are more granular.
  - So let's say we are both collaborating using crdts, if someone then goes and makes a commit outside of that system, we need to then have a bridging layer that converts that snapshot into operations.
- I'm guessing because that git commit would likely be larger than a crdt change, that'd also cause issues?
  - The size isn't really a big issue, it's mostly that there's less information with git than crdts. Git just have *snapshots*, you don't *really* know how A transformed into B.

- ## üå∞ [Ask HN: Apps that are built with Git as the back end? | Hacker News_202210](https://news.ycombinator.com/item?id=33261862)
- The Office 365 backend uses git to store snapshots of documents
  - https://github.com/microsoft/FluidFramework/tree/main/server/gitrest
  - the content-addressable filesystem that it uses is git. It uses git with a javascript implementation of it 

- Using Git for content has some great benefits. Like complete version history, easy reverts (for devs at least), (feature) branch support, Git hooks, ... And of course, you own your content at all times.

- Git is good at creating files and managing versions/branches but not good at search files or their content. I'm not a git expert to fully backup that claim but that's been our experience. You can layer on your own search capabilities if you need it but then you might want to start asking if a full DB is better.

- ## Áî® git Êù•ÂΩìÁΩëÁõòÁî®Â¶Ç‰ΩïÔºü
- https://v2ex.com/t/525782
- Áõ∏ÊØî‰º†ÁªüÁΩëÁõòÁöÑ‰ºòÂäø
  - Êñπ‰æøËøÅÁßª
  - ÁâàÊú¨ÁÆ°ÁêÜÊõ¥Êñπ‰æø
  - Á®ãÂ∫èÂëòÁöÑ‰ª£Á†ÅÂíåÂ∑•‰ΩúÁ©∫Èó¥ÂèØ‰ª•‰∏ÄËµ∑‰∏ä‰∫ë‰∫Ü

- Áº∫ÁÇπ
  - gitÂ§ÑÁêÜ‰∫åËøõÂà∂Êñá‰ª∂Â§™ÊÖ¢‰∫Ü
  - Ê≠£ËßÑÁî®Ê≥ïÊòØÁî® GitHub LFS ÊúçÂä°ÔºàÊî∂Ë¥πÔºâ
  - dropbox‰∏ÄÁ±ªÁöÑÁΩëÁõòÈÉΩÊòØ‰Ω†ÁºñËæëÂÆåÊñá‰ª∂‰øùÂ≠òÂ∞±Ëá™Âä®‰∏ä‰º†‰∫ÜÔºågit ËøòÈúÄË¶Å commit pushÔºåÁõ∏ÊØî‰πã‰∏ã git ÁöÑÂ≠òÂú®ÊÑüËøòÊòØÂ§™Âº∫‰∫Ü

- ## [ÈöèÁùÄÁâàÊú¨‰∏çÊñ≠ÁöÑÊõ¥Êñ∞Ôºå‰ª•ÂâçÁöÑÁâàÊú¨ÂÜÖÂÆπ‰ºö‰∏ç‰ºöË∂äÁßØË∂äÂ§öÔºåÂØºËá¥Âç†ÊçÆÂ§™Â§öÁ°¨ÁõòÂÆπÈáèÔºü](https://www.zhihu.com/question/370933878)
- ‰ºöÔºåÈùû‰∫åËøõÂà∂Êñá‰ª∂Âè™ËÆ∞ÂΩïÂ∑ÆÂºÇÈÉ®ÂàÜ
- ‰ºöÁöÑ„ÄÇgit‰ºö‰øùÁïô‰Ω†ÊØèÊ¨°Êõ¥Êñ∞ÁöÑÂÆåÊï¥Êñá‰ª∂, ÊâÄ‰ª•ÈöèÁùÄcommitÁöÑÂ¢ûÂä†, ‰ªìÂ∫ìÊâÄÂç†‰ΩìÁßØËÇØÂÆö‰ºöÈöèÁùÄÂ¢ûÂä†„ÄÇÂπ∂‰∏îgit‰ºöÊääËøúÁ´Ø‰ªìÂ∫ìÁöÑÊâÄÊúâcommitÊãâÂà∞Êú¨Âú∞, Êú¨Âú∞Â≠òÂÇ®‰πü‰ºöÂ¢ûÂä†.
  - gitËÆæËÆ°ÁöÑÂàùË°∑‰∏ªË¶ÅÊòØ‰∏∫‰∫Ü‰ª£Á†ÅÁÆ°ÁêÜ, ‰ª£Á†Å‰Ωú‰∏∫ÊñáÊú¨Êñá‰ª∂ÁªèËøáÂéãÁº©‰πãÂêé‰∏ç‰ºöÂæàÂ§ß. 
- ÈÇ£‰πàÂ¶ÇÊûú‰∏ÄÂÆöË¶ÅÊ∑ªÂä†‰∫åËøõÂà∂ÁöÑÂ§ßÊñá‰ª∂ÊÄé‰πàÂäû?
  - Âª∫ËÆÆ‰ΩøÁî®Git LFS, Ëøô‰∏™Ê®°Âùó‰∏ìÈó®Áî®Êù•ÁÆ°ÁêÜÂ§ßÊñá‰ª∂ÁöÑ. Â§ßÊ¶ÇÂéüÁêÜÂ∞±ÊòØ, Âú®Ê∑ªÂä†Â§ßÊñá‰ª∂ÁöÑÊó∂ÂÄô, Â¶ÇÊûúË¢´Ê†áËÆ∞‰∏∫LFS, Áõ∏Â∫îÁöÑgit‰ºöËá™Âä®Ê∑ªÂä†‰∏Ä‰∏™ÊèèËø∞ÊñáÊ°£. Êé®ÈÄÅÂà∞ËøúÁ´ØÁöÑÊó∂ÂÄô‰ºöÂÆåÊï¥‰∏ä‰º†Êñá‰ª∂ÂíåÊèèËø∞ÊñáÊ°£. Âú®ÂÖ∂‰ªñÂºÄÂèëËÄÖÊãâÂèñ‰ª£Á†ÅÊó∂, Ê†áËÆ∞‰∏∫LFSÁöÑÊñá‰ª∂Âè™ÊãâÂèñ‰∏Ä‰∏™Áõ∏ÂÖ≥ÁöÑÊèèËø∞ÊÄßÊñáÊ°£. Âè™ÊúâÂú®ÂøÖÈ°ªËé∑ÂèñËØ•Êñá‰ª∂Êó∂Êâç‰ºö‰∏ãËΩΩ. ËøôÊ†∑ÂÖ∂‰ªñÂºÄÂèëËÄÖÂèçÂ∫îÊõ¥Âø´ÈÄü.
- .gitÊñá‰ª∂‰∏ªË¶ÅÁî®Êù•ËÆ∞ÂΩïÊØèÊ¨°Êèê‰∫§ÁöÑÂèòÂä®ÔºåÂΩìÊàë‰ª¨ÁöÑÈ°πÁõÆË∂äÊù•Ë∂äÂ§ßÁöÑÊó∂ÂÄôÔºåÊàë‰ª¨ÂèëÁé∞ .gitÊñá‰ª∂Ë∂äÊù•Ë∂äÂ§ß„ÄÇ
  - gitÁªôÂá∫‰∫ÜËß£ÂÜ≥ÊñπÊ°àÔºå‰ΩøÁî® `git branch-filter` Êù•ÈÅçÂéÜgit history tree, ÂèØ‰ª•Ê∞∏‰πÖÂà†Èô§history‰∏≠ÁöÑÂ§ßÊñá‰ª∂ÔºåËææÂà∞ËÆ©.gitÊñá‰ª∂Áò¶Ë∫´ÁöÑÁõÆÁöÑ„ÄÇ

- ref
  - [gitee‰ªìÂ∫ì‰ΩìÁßØËøáÂ§ßÔºåÂ¶Ç‰ΩïÂáèÂ∞èÔºü](https://gitee.com/help/articles/4232#article-header0)

- ## üÜöÔ∏èü§î [‰∏∫‰ªÄ‰πàÂÖ∂‰ªñÂäûÂÖ¨È¢ÜÂüü‰∏ç‰ΩøÁî®git?](https://www.zhihu.com/question/329750471)
- GitÂØπÈùûÁ∫ØÊñáÊú¨ÂÜÖÂÆπÊîØÊåÅÂπ∂‰∏çÂ•ΩÔºåËôΩÁÑ∂ËÉΩÁÆ°ÁêÜÁâàÊú¨Ôºå‰ΩÜÊòØÊó†Ê≥ïÊñπ‰æøÁöÑdiffÔºåmerge„ÄÇ
- Git‰∏ÄËà¨ÂØπÊñáÊú¨Êñá‰ª∂ÊîØÊåÅÊØîËæÉÂ•ΩÔºå‰ΩÜword„ÄÅexcelÁ≠âofficeÊñáÊ°£ÊòØ‰∫åËøõÂà∂Êñá‰ª∂„ÄÇ
- ÊúÄÂ•ΩÁöÑÊñπÊ°àÊòØÂú®Âä†Â∑•ÂÜÖÂÆπÈò∂ÊÆµÂíåÊ†ºÂºè‰ºòÂåñÈò∂ÊÆµÂÆåÂÖ®Ââ•Á¶ª„ÄÇ
- svnÁªôÁæéÊúØÁ≠ñÂàíÁî®, gitÁªôÁ®ãÂ∫èÁî®

- ## [‰ΩøÁî®gitÁÆ°ÁêÜpptÁâàÊú¨Á≠âÊñáÊ°£ÂêóÔºü](https://www.zhihu.com/question/22322435)
- GitÈÄÇÂêàÁÆ°ÁêÜÊñáÊú¨ÂÜÖÂÆπ, ‰ΩÜ‰∏çÈÄÇÂêàÁÆ°ÁêÜ‰∫åËøõÂà∂ÂÜÖÂÆπ
  - Git Â±û‰∫éÂàÜÂ∏ÉÂºèÁâàÊú¨ÊéßÂà∂Á≥ªÁªü, ÈúÄË¶Å clone Êï¥‰∏™‰ªìÂ∫ìÂêéÊâçËÉΩ checkout Âá∫ÊúÄÊñ∞ÁöÑÁâàÊú¨, ‰øÆÊîπÂêéÊèê‰∫§. ËÄå‰∫åËøõÂà∂ÂÜÖÂÆπÊØîËæÉÈöæÂéãÁº©, ‰ºöÂØºËá¥Êï¥‰∏™‰ªìÂ∫ìÂç†Áî®ÁöÑÁ©∫Èó¥È£ûÈÄüÂ¢ûÈïø. Ê≤°Â§ö‰πÖ‰Ω†ÂèØËÉΩÂ∞±‰ºöÂèëÁé∞, ‰Ω†ÈúÄË¶Å‰øÆÊîπ‰∏Ä‰∏™ 2MB ÁöÑ PPT, Âç¥ÈúÄË¶ÅÂÖà clone ‰∏Ä‰∏™ 200MB ÁöÑ‰ªìÂ∫ì, ËÄå‰∏îËøáÂéªÁöÑÈÇ£‰∫õÁâàÊú¨Âü∫Êú¨‰∏äÂèà‰∏çÂÜçÈúÄË¶Å‰ΩøÁî®‰∫Ü.
  - Âá∫Áé∞ÂÜ≤Á™ÅÊó∂, ‰∫åËøõÂà∂ÂÜÖÂÆπ(ÁâπÂà´ÊòØ‰Ω†‰ΩøÁî®Âú∫ÊôØ‰∏≠ÊèêÂà∞ÁöÑPPT)Âü∫Êú¨‰∏çÂ≠òÂú®Ëá™Âä®ÂÆåÊàê merge ‰∏î‰∏çÂá∫Áé∞ conflict ÁöÑÂèØËÉΩÊÄß. Êç¢Ë®Ä‰πã, ‰∏ÄÊó¶Âá∫Áé∞ÂàÜÊ≠ß, Â∞±ÂøÖÁÑ∂ÈúÄË¶ÅÊâãÂ∑•ÂêàÂπ∂, ‰ª£‰ª∑‰∏çÂ∞è, ËÄå‰∏îÂÆπÊòìÂá∫Áé∞Êìç‰ΩúÂ§±ËØØ.
  - Ê†πÊçÆ‰Ω†ÁöÑ‰ΩøÁî®Âú∫ÊôØÊù•Âà§Êñ≠, Â∫îËØ•‰∏ªË¶ÅÊòØÂú® Windows ‰∏ãÂ∑•‰ΩúÁöÑ. Git Âú® Windows ‰∏ãÁõ∏ÊØîÂú®ÂÖ∂‰ªñÂπ≥Âè∞‰∏ãË¶ÅÈöæÁî®ÂæóÂ§ö..
- ÂÉè‰Ω†ËøôÁßçÂú∫ÊôØ, Ë¶Å‰πà‰ΩøÁî®‰º†Áªü‰∏≠ÂøÉÂºèÁâàÊú¨ÊéßÂà∂Á≥ªÁªü, ÊØîÂ¶Ç SVN, Ë¶Å‰πàÈÄöËøáÂú®Á∫øÁöÑÂçè‰ΩúÁéØÂ¢É, ÊØîÂ¶Ç Microsoft Ëá™Â∑±ÁöÑ Office Web Áâà, ÊàñËÄÖ Google Doc. 
- ‰ΩÜÂõûÂà∞ÊúÄÂàùÁöÑÈóÆÈ¢ò: ‰Ω†ÈúÄË¶ÅÁöÑÁúüÁöÑÊòØ‰∏Ä‰∏™"ÁâàÊú¨ÊéßÂà∂Á≥ªÁªü"Âêó? ‰πüËÆ∏‰ªÖ‰ªÖÊòØ‰∏Ä‰∏™ÈõÜ‰∏≠ÂàÜ‰∫´ÁöÑÂú∞Êñπ, ‰πüËÆ∏‰ªÖ‰ªÖÊòØÂ∏åÊúõ‰∏Ä‰∏™‰∫∫‰øÆÊîπÁöÑÊó∂ÂÄô, Âè¶‰∏Ä‰∏™‰∫∫‰∏çËÉΩ‰øÆÊîπ, ËÄåÂ∑≤.
- ÂÖ∂ÂÆûÔºÅ‰Ω†‰ª¨ÂøΩÁï•‰∫Ü‰∏Ä‰ª∂‰∫ãÊÉÖÔºÅpptxÊñá‰ª∂ÂÆûÈôÖ‰∏äÊòØ‰∏™zipÊñá‰ª∂ÔºåËß£ÂéãÂºÄÊù•ÂÖ®ÊòØÊñáÊú¨ÁöÑxmlÂíå‰Ω†Âä†ËøõÂéªÁöÑËßÜÈ¢ë„ÄÅÂõæÁâáÔºåÊòØÂèØ‰ª•Áî®gitÁÆ°ÁêÜÁöÑÔºÅ
