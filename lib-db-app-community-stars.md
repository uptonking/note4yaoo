---
title: lib-db-app-community-stars
tags: [community, database]
created: 2021-08-30T15:51:01.157Z
modified: 2023-09-16T17:54:21.231Z
---

# lib-db-app-community-stars

# guide

# discuss-stars
- ## 

- ## 

- ## [Redditâ€™s database has two tables_201209](https://kevin.burke.dev/kevin/reddits-database-has-two-tables/)
  - Lesson: Donâ€™t worry about the schema.
  - it looks like they use two tables for each â€œthingâ€, so a thing/data pair for accounts, a thing/data pair for links, etc.

- ## Most databases were built when data was static and queries were dynamic. 
- https://twitter.com/tantaman/status/1699826662408409383
  - For applications, most queries are static and the data is dynamic
- What you really want is a database where a query is the same things as an index, is the same thing as a subscription... These are all the same underlying mechanic.

- ## Myth(ç¥è¯ï¼Œæƒ³åƒæˆ–è™šæ„çš„äººç‰©): Using UUID as the primary key will slow down inserts. 
- https://twitter.com/gwenshap/status/1686148804821811200
  - Fact: Not in Postgres.
  - I often recommend using UUIDs instead of integer sequences as primary keys. I was surprised to discover that many developers are uncomfortable with them and believe they will slow down inserts. 
  - [UUIDs are Bad for Performance in MySQL - Is Postgres better? Let us Discuss - YouTube](https://www.youtube.com/watch?v=Y5mWz4vK10A)
- It makes the code easier as well because you can generate IDs on the client.
  - Exactly! this also makes the system as a whole more scalable. This is not something you need early on, but changing PKs later is super hard and starting with UUIDs is not.

# discuss-sql
- ## 

- ## 

- ## 

- ## ğŸ¤” What database has the best query language thatâ€™s not sql?
- https://twitter.com/aboodman/status/1607790827996327936
- tinybase > tinyQL
- I think graphQL occupies a pretty useful and pragmatic niche.
  - SQL suffers from cartesianification. Results are a square tabular matrix, which does not effeciently express heirarchical data. Probably graphQL tree shaped results actually fits app data better.
- iâ€™m biased (due to previous employment), but definitely think neo4j and cypher is the answer youâ€™re looking for!  ASCII art ftw!  
- Vertipaq with DAX language
- #datomic's #datalog is very intuitive if all you need are inner joins, which is just unification of variables. The minute you need anything else, things get ugly. Uglier than SQL? Who knows, pick your poison.
- Kusto Query Language (KQL), used by Azure Data Explorer and other Azure products. I'm a skeptic when it comes to query languages and DSLs and yet... KQL is awesome IMO
- Malloy fixes my vote for SQLs biggest flaw â€” combining entity relationships with querying. Malloy separates them, which is genius, especially for ML
- EdgeDB is an open-source database designed as a spiritual successor to SQL and the relational paradigm
- My biggest gripe with SQL is the lack of composability. When writing complex code, I can easily pull out functions. When complex writing SQL, I end up with a giant unmaintainable blob. I hope whatever solution you find addresses this!
- @perplexity_ai â€˜s birdsql. Query in natural language (English), GPT figures out the sql. Hot take: natural language is the best query language.

# discuss-db-oplog
- ## 

- ## 

- ## 

- ## 

- ## Write-ahead logging is a standard way to ensure data integrity and reliability. 
- https://twitter.com/arpit_bhayani/status/1508665078929047552
  - Any changes made on the database are first logged in an append-only file called write-ahead Log or Commit Log. 
  - Then the actual blocks having the data (row, document) on the disk are updated
  - An operation like Update Query, Delete Query is logged in the commit log and not the actual changes making the write lightning-fast.
  - WAL also takes care of its data integrity by writing a CRC-32 before logging the operation. This CRC is checked during reading and replicating

- Advantages of using WAL
  - we can skip flushing the data to the disk on every update
  - significantly reduce the number of disk writes
  - we can recover the data in case of a data loss
  - we can have point-in-time snapshots

- A write-ahead log is the append-only source of truth in a database; each transaction appends events to it before table files are updated. Change data capture (which Marta is referring to) lets you retrieve and consume changes from that log. 
# discuss-db-streaming
- ## 

- ## 

- ## Understanding the Differences between Lambda and Kappa Data Processing Architectures for Big Data_202303
- https://twitter.com/moderndatastack/status/1637808211565891584
  - [Data processing architectures â€” Lambda vs Kappa for Big Data_202303](https://medium.com/towards-data-engineering/data-processing-architectures-lambda-vs-kappa-for-big-data-8cc9a7edeffd)
  - [Modern Data Architecture: An Overview of Lambda and Kappa Architectures_202003](https://www.credera.com/insights/modern-data-architecture-an-overview-of-lambda-and-kappa-architectures)

- Lambda and Kappa are two data processing architectures used to analyze large volumes of data in real time
- Lambda Architecture has three layers  
  - the batch layer, which processes historical data in batches, 
  - the speed layer, which processes real-time data streams in a distributed manner, 
  - and the serving layer, which provides queryable views of the data.
- Kappa Architecture, on the other hand, eliminates the batch layer and processes real-time data using a stream processing system, which stores the data in a database.
- Lambda is ideal for scenarios where historical data analysis is important, while Kappa is perfect for situations where real-time insights are critical.
- 
- 
- 
- 

# discuss
- ## 

- ## 

- ## 

- ## [sql server - Will index be fully loaded into memory_201011](https://stackoverflow.com/questions/4296027/will-index-be-fully-loaded-into-memory)
- No, it's treated like any other data stored on disk. It's loaded into memory disk page by disk page. And a page stays in memory as long as it's regularly accessed.

- The answer to this is in several parts:
  - The size of the index.
  - What parts are accessed.
  - Memory pressure.
- SQL Server cached the index in memory as it was being read.
  - However, if I had put other memory pressure on SQL Server, it would have dropped out those cached index pages by order of lowest reads.

- ## [åˆ°ç°åœ¨ä¸ºæ­¢ï¼ŒNoSQL è¿åŠ¨ç»™æ•°æ®åº“ç³»ç»Ÿç•™ä¸‹ä»€ä¹ˆå®è´µçš„æ€æƒ³ï¼Ÿ - çŸ¥ä¹](https://www.zhihu.com/question/264416654/answers/updated)
- https://www.zhihu.com/question/264416654/answer/2713792035
- å¦‚æœéè¦ç»™NoSQLä¸€ä¸ªå†å²å®šä½çš„è¯ï¼Œé‚£åº”è¯¥æ˜¯ä¸€æ¬¡å¯¹å…³ç³»å‹æ•°æ®åº“çš„è§£æ„è¿åŠ¨ã€‚
  - è¿™æ¬¡è§£æ„è¿åŠ¨çš„å‘èµ·æ˜¯ç”±äºäº’è”ç½‘åº”ç”¨çš„å…´èµ·ï¼Œç”±äºäº’è”ç½‘å¯¹å­˜å‚¨çš„ä½¿ç”¨é‡è§„æ¨¡è½»é€»è¾‘ï¼Œæ‰€ä»¥å¯¼è‡´ä¼ ç»Ÿçš„å…³ç³»å‹æ•°æ®åº“ä½¿ç”¨æˆæœ¬è¿‡é«˜ã€‚
  - é—®é¢˜åœ¨äºå½“æ—¶é‚£ç¾¤å¹´è½»çš„äº’è”ç½‘ç¨‹åºå‘˜æ²¡æœ‰å¥½å¥½å›é¡¾æ•°æ®åº“çš„å‘å±•å²ï¼Œè€Œæ˜¯å¸¦ç€æ“ä½œç³»ç»Ÿï¼ˆæ–‡ä»¶ç³»ç»Ÿï¼‰çš„åŒ…è¢±å»è§£æ„çš„ï¼Œå†åŠ ä¸Šæ“ä½œç³»ç»Ÿé˜µè¥å’Œæ•°æ®åº“é˜µè¥å†æ¥çš„å¯¹å’ï¼Œå¯¼è‡´äº†è¿™åœºä¸åº”è¯¥å‘ç”Ÿçš„é‡å¤é€ è½®å­è¿åŠ¨ã€‚ 
  - å¦‚æœå¯¹æ•°æ®åº“å†…æ ¸å¼€å‘äº†è§£çš„åŒå­¦åº”è¯¥çŸ¥é“ï¼Œæ‰€æœ‰å…³ç³»å‹æ•°æ®åº“éƒ½æ˜¯ä»é”®å€¼æ•°æ®åº“å‘å±•èµ·æ¥çš„ï¼Œæ•°æ®å­˜å‚¨å¼•æ“æœ€åº•å±‚éƒ½æ˜¯ä¸€ä¸ªé”®å€¼æ•°æ®åº“ã€‚è¿˜æœ‰ç°åœ¨æµè¡Œçš„å„ç§æ¶ˆæ¯ä¸­é—´ä»¶ï¼ˆRABBIT MQä¹‹æµï¼‰ä¹Ÿæ˜¯å…³ç³»æ•°æ®åº“ä¸­çš„ä¸€ä¸ªé›¶ä»¶è€Œå·²ï¼ˆconnectionï¼‰ï¼Œæ˜¯åœ¨ç½‘ç»œå…´èµ·åï¼Œæ•°æ®åº“æä¾›CSæ¶æ„ä¸‹è¯ç”Ÿçš„è¿œç¨‹è®¿é—®æ–¹æ¡ˆã€‚æ‰€ä»¥å°±åƒä¸€ä¸ªå°ç”·å­©å–œæ¬¢æ‹†ç©å…·è½¦ï¼ŒæŠŠç”µåŠ¨æœºæ‹¿ä¸‹æ¥å•ç‹¬è½¬ï¼›æŠŠè½®å­æ‹†ä¸‹æ¥å•ç‹¬æ»šï¼Œè‡ªå¾—å…¶ä¹ã€‚

- Nosqlå¼ºç›—å›¢ä¼™ç”Ÿç”Ÿä»å…³ç³»å‹æ•°æ®åº“ä¸€ç»Ÿå¤©ä¸‹çš„å±€é¢é‡Œæ’•ä¸‹ä¸€å¤§å—è‚‰ï¼Œè¿™äº›å¹´Nosqlæä¾›äº†å‰æ‰€æœªæœ‰çš„scalabilityèƒ½åŠ›å’Œå¯ç”¨æ€§ï¼Œåœ¨è¶…å¤§å¹¶å‘æƒ…å†µä¸‹ï¼Œæˆ‘ä¸ªäººç»éªŒæ˜¯åŸºäºNosqlçš„ç³»ç»Ÿæ¯”åŸºäºå…³ç³»å‹æ•°æ®åº“ç—›è‹¦å°‘äº›ã€‚
  - åœ¨Nosqlæ¶æ„ä¸­ï¼Œä¸åŒèŠ‚ç‚¹ä¹‹é—´ä¸â€œshareâ€æ•°æ®ï¼Œæ¯ä¸ªèŠ‚ç‚¹åªè¦ç®¡è‡ªå·±é‚£ä¸€äº©ä¸‰åˆ†åœ°å°±å¥½ï¼Œä½ å¯ä»¥éå¸¸å®¹æ˜“çš„æŠŠæ•°æ®åˆ†å¸ƒåˆ°æˆåƒä¸Šä¸‡çš„æœåŠ¡å™¨ä¸Šï¼Œè¯»å’Œå†™éƒ½æ›´å®¹æ˜“æï¼Œä¸€å°éƒ¨åˆ†èŠ‚ç‚¹â€œåâ€äº†ï¼Œä¹Ÿä¸å®¹æ˜“è®©ä½ çš„æœåŠ¡å®Œå…¨è·ªäº†ï¼Œä½ ä¹Ÿæ¯”è¾ƒå®¹æ˜“æ›¿æ¢ï¼Œå„ç§å§¿åŠ¿åšrolling restartã€‚
  - Mysqlå½“ç„¶ä¹Ÿèƒ½shardingï¼Œæä¾›çš„åŠŸèƒ½æ˜¯ä¸€æ ·ä¸€æ ·çš„ï¼Œä¸è¿‡ä½ åˆ†å¼€ä¹‹åè¿™ä¸ªsqlæŸ¥è¯¢å¯å°±å—é™åˆ¶äº†ï¼Œè¦ä¸ä»£ä»·æ›´å¤§ã€‚
  - ç°åœ¨æˆ‘ä»¬æ¥çœ‹Mysqlç­‰ï¼Œè‡ªåŠ¨shardingæˆ–è€…è¯´auto-scaleæ˜¯æœ‰å„ç§è§£å†³æ–¹æ¡ˆäº†ï¼Œä¸è¿‡è¿™æ˜¯è½åä¸€æ­¥çš„ï¼ŒMongoDBç­‰nosqlæ˜¯æå‰ä¸‰åˆ°äº”å¹´å°±ç©çš„è½¬äº†ã€‚è¿™äº›å¹´ï¼ŒNosqlå›¢ä¼™æ˜¯é€¼ç€Mysqlå’ŒOracleåœ¨scalabilityæ–¹é¢ä¸æ–­æ”¹é©
  - å¦ä¸€æ–¹é¢ï¼Œä¹Ÿå‡ºç°äº†Newsqlè¿™ä¸ªè¿™ç§æ–¹æ¡ˆï¼Œé‰´äºNosqlåˆ†å¸ƒå¼å­˜å‚¨çš„ä¼˜åŠ¿ï¼Œnewsqlçš„åº•å±‚è¿˜æ˜¯Nosqlé‚£ç§ï¼Œé¡¶å±‚åˆè¦å’Œsqlå…¼å®¹ï¼Œé‚£ä¸­é—´å°±éœ€è¦ä¸€ä¸ªå¯¹ç”¨æˆ·é€æ˜çš„è‡ªåŠ¨shardingå±‚ã€‚è¿™ç©æ„èƒ½åšåˆ°å¤šå¥½ï¼Œå¦‚ä½•ä¼˜åŒ–ï¼Œå°±å…·ä½“é¡¹ç›®å…·ä½“å¯¹å¾…äº†ã€‚

- ä¸€å¼€å§‹ç›´æ¥å¿«åˆ€æ–©ä¹±éº»ï¼ŒBigTableå°±æ˜¯KVæŠ½è±¡åŠ GFSï¼Œç»“æœè¿™ç§æ¶æ„æŠ›å¼ƒäº†äº‹åŠ¡å’ŒSQLèƒ½åŠ›ï¼Œè§£å†³äº†ä¸€äº›é—®é¢˜å’Œå¸¦æ¥äº†æ–°çš„é—®é¢˜ï¼Œæœ‰æ–°çš„é—®é¢˜å°±è¦è§£å†³ã€‚

- è¯´ç™½äº†NOSQLå°±æ˜¯ä»…æä¾›åŸå­å±‚é¢çš„å­˜å‚¨ï¼ˆç»“æ„åŒ–åŠéç»“æ„åŒ–ï¼‰æœåŠ¡è‡³äºäº‹åŠ¡åŠSQLå…¼å®¹æ€§ä¸æ˜¯NOSQLå¿…é¡»è¯¥è´Ÿè´£çš„å†…å®¹ï¼Œä»è€Œå¤§å¤§æå‡äº†æ‰©å±•æ€§å’Œæ€§èƒ½
- ## dbt (data build tool) enables analytics engineers to transform data in their warehouses by simply writing select statements. 
  - dbt handles turning these select statements into tables and views.
  - dbt does the T in ELT (Extract, Load, Transform) processes â€“ it doesnâ€™t extract or load data
  - A dbt project is a directory of .sql and .yml files. 

# uuid vs auto-increment

## [Best practices on primary key, auto-increment, and UUID in RDBMs and SQL databases](https://stackoverflow.com/questions/52414414)

- What I always do, even if it's redundant, is I create primary key on auto increment column (I call it `technical key`) to keep it consistent within the database, 
  - allow for "primary key" to change in case something went wrong at design phase 
  - and also allow for less space to be consumed in case that key is being pointed to by foreign key constraint in any other table 
  - and also I make the candidate key unique and not null.
- Technical key is something you don't normally show to end users, unless you decide to. 
  - This can be the same for other technical columns that you're keeping only at database level for any purpose you may need like modify date, create date, version, user who changed the record and more.

```SQL
CREATE TABLE users(
  pk INT NOT NULL AUTO_INCREMENT,
  id UUID NOT NULL,
  PRIMARY KEY(pk),
  UNIQUE(id)
);
```

- This question is quite opinion-based so here's mine.
- My take is use the second one, a separate UUID from the PK. The thing is:
  - The PK is unique and not exposed to the public.
  - The UUID is unique and may get exposed to the public.
- If, for any reason, the UUID gets compromised, you'll need to change it. Changing a PK may be expensive and has a lot of side effects. If the UUID is separate from the PK, then its change (though not trivial) has far less consequences.

- if you make it an increasing number, your competitors will know how many users you have and how fast you are adding new ones.

- I came across a nice article that explains both pros and cons of using UUID as a primary key. 
  - In the end, it suggests using both but **Incremental integer for PK and UUIDs for the outside world**. 
  - Never expose your PK to the outside.
