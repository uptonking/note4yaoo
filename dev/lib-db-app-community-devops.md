---
title: lib-db-app-community-devops
tags: [community, database, devops]
created: 2023-10-26T18:47:03.513Z
modified: 2023-10-26T18:47:22.664Z
---

# lib-db-app-community-devops

> about database migration/upgrade

# guide

# discuss-stars
- ## 

- ## Running your database using a non-UTC time-zone is a mistake. Fight me.
- https://x.com/GrahamJCampbell/status/1894419202976477664
- Yes, for all data tasks, everything shall be normalized and standardized and when it comes to dates it is Zulu, aka GMT aka UTC, which is used in science and space as well.

- That's fine as soon as you store the timezone along with the date time. But all SQL based database have a broken date time that uses a legacy string representation. At least postgres as a timestamptz. Guess what, MongoDB only stores UTC date times.
# discuss-change-schema
- ## 

- ## 

- ## Problem: We need to rename a DB column, but we want to avoid a breaking change. Solution:
- https://twitter.com/housecor/status/1729893167812555124
  1. Add new column (Ticket 1)
  2. Update all code to reference new column (Ticket 2)
  3. Release. Now no code references the old column. ğŸ˜€
  4. Delete the old DB column (Ticket 3)
- Don't forget migrating the data and updating any DB logic (sprocs, etc.) to reference the new column.
- Expand and contract pattern
- Or just use MongoDB

# discuss-migration/upgrade
- ## 

- ## 

- ## those of you with databases inside a vpc what is your migration process like?
- https://x.com/thdxr/status/1891245539112489344
  - sst autodeploy can run in a vpc so there's no issue here but otherwise i deploy a lambda in a vpc that does the migration
  - do people actually setup the custom thing for github actions?

- My coworkers huddle me on Slack. They open GitHub, I open Supabase. We both count down from 3, and then they hit merge and simultaneously I manually run the migration in the Supabase SQL editor. Only way Iâ€™ve found to keep everything in sync
- think our approach is similar to yours but we use ECS so was quicker at the time to spin up a task that does the migration and exits

- One example Iâ€™ve built:
  - CI builds/pushes migration specific docker image
  - before deploying services, makes new migration ECS task def
  - ECS task execute migration docker
  - db migration succeeds? Move on to service deploy.

- ## å¤ªä¹…æ²¡åšæ•°æ®è¿ç§»éƒ½å¿˜äº†è¦åå»ºç´¢å¼•ã€‚
- https://twitter.com/forevertjt/status/1719732968636465590
  - æ’å…¥åˆ°åƒä¸‡çº§ä¹‹åç´¢å¼•å°±æ˜æ˜¾å½±å“æ’å…¥é€Ÿåº¦äº†ï¼ŒæŠŠç´¢å¼•éƒ½å¹²æ‰å°±å¿«å¾ˆå¤šäº†ã€‚

- ## ğŸ”¥ [Ask HN: How do you manage direct updates to databases in a production system | Hacker News_202112](https://news.ycombinator.com/item?id=29563226)
- 
- 
- 

- ## ğŸ”¥ [Migrating a 40TB SQL Server Database | Hacker News_202007](https://news.ycombinator.com/item?id=23998503)
- 
- 
- 

- ## ğŸ”¥ [Ask HN: How does your development team handle database migrations? | Hacker News_201905](https://news.ycombinator.com/item?id=19880334)
- Would be cool to have git for databases.
  - Thatâ€™s basically the proposition of any event sourcing system. but youâ€™re kinda right, that involves a level of code complication (but then it would be so simple as you described to restore / rebase / etc)

- ## ğŸ”¥ [An Unlikely Database Migration | Hacker News_202101](https://news.ycombinator.com/item?id=25767128)
- 
- 
- 

- ## ğŸ”¥ [On Uberâ€™s Choice of Databases | Hacker News_201607](https://news.ycombinator.com/item?id=12187797)
- 
- 
- 

- ## ğŸ”¥ [Migrating bajillions of database records at Stripe | Hacker News_201509](https://news.ycombinator.com/item?id=10150438)
- 
- 
- 

# discuss-db-cloud/k8s
- ## 

- ## ç™½å«–çš„supabaseçš„é¡¹ç›®ä¸è¦æš‚åœè¶…è¿‡90å¤©ï¼Œå¦åˆ™ä½ å°†å‡çº§åˆ°proæ‰èƒ½æ¢å¤æ•°æ®ã€‚åˆ«é—®æˆ‘æ€ä¹ˆçŸ¥é“çš„ã€‚
- https://x.com/mundane799699/status/1896213016196333720
- æˆ‘èµ¶ç´§å»çœ‹çœ‹ appwrite æ˜¯ä¸æ˜¯ä¹Ÿè¿™æ ·ã€‚

- è¶…è¿‡7å¤©ä¸æ´»è·ƒä¼šè¢«æ¸…ç†æ‰ï¼Œä½†å¯ä»¥è¢«æ¢å¤

- ## ä½ ä»¬å¹³å¸¸æ›´å–œæ¬¢ç”¨severlessçš„æ•°æ®åº“è¿˜æ˜¯å–œæ¬¢è‡ªå·±ç‹¬ç«‹éƒ¨ç½²è‡ªå·±ç»´æŠ¤ä¸€ä¸ªæ•°æ®åº“å‘¢ï¼Ÿ
- https://x.com/PennyJoly/status/1898582842260742297
- æˆ‘é€‰æ‹©è‡ªå·±éƒ¨ç½²ï¼Œå› ä¸ºäº‘æœåŠ¡æ•°æ®åº“ï¼Œä¸€æ®µæ—¶é—´ä¸ç”¨å°±ä¼šè¢«å…³æ‰ï¼Œä¾‹å¦‚supabaseï¼Œè€Œè‡ªå·±éƒ¨ç½²ä¸ä¼šæœ‰è¿™ä¸ªçƒ¦æ¼
- å¦‚æœè€ƒè™‘æ•°æ®å¤‡ä»½ï¼Œæ•°æ®åº“å¯ç”¨æ€§ç­‰é—®é¢˜ï¼Œè¿˜æ˜¯ç›´æ¥ç”¨äº‘æœåŠ¡å•†çš„æ•°æ®åº“æœåŠ¡æ¯”è¾ƒå¥½ã€‚è€Œä¸”ä»£ç é‡Œç”¨ormï¼Œåœ¨ä¸åŒçš„æ•°æ®åº“ç›´æ¥åˆ‡æ¢ä¹Ÿä¼šæ¯”è¾ƒç®€å•äº›ã€‚

# discuss
- ## 

- ## 

- ## 

- ## Every field being optional in Protobufs is actually the only scalable solution for schema migrations
- https://twitter.com/ChShersh/status/1783873173190009168
- Making a field required only means clients will fail the whole parsing operation. â€œrequiredâ€ should be enforced at the application layer, not at the transport layer.

- It just moves the problem somewhere else. Bytes are always optional.
  - At some point your code is going to need to assert the existence of a field (probably).
  - If you don't do it in the schema, then you have to do it somewhere else.
- protoc canâ€™t generate the code that deals gracefully with missing required fields
  - Alright I see the point. I'd argue the problem is protoc then, not the required field, but now I'm with you! Point being: The field is no less required, you just get better errors.

- ## æˆ‘åœ¨æ¢æ¢å½“ PostgreSQL DBAæ—¶ï¼Œ10åˆ†é’Ÿæ•…éšœå¼„ä¸å¥½å¥–é‡‘æ³¡æ±¤ï¼Œå†ä¹…Jobæ²¡äº†
- https://twitter.com/GobeUncleWang/status/1724677788811264261
  - è½¯ä»¶æ•…éšœåŸºæœ¬æ²¡æœ‰ï¼Œæ•°æ®åº“å˜æ›´å‘å¸ƒç”±æˆ‘ä»¬è‡ªå·±åœ¨å·¥ä½œæ—¶é—´çª—å£å†…å¤„ç†ï¼Œæ›´ä¸»è¦è¿˜æ˜¯ç ”å‘åŒäº‹ç»™åŠ›é è°±ã€‚æœ‰å…¨å±€ç›‘æ§ï¼ˆhttps://demo.pigsty.ccï¼‰ï¼Œåˆ«è¯´28åˆ†é’Ÿï¼Œ2.8åˆ†é’Ÿéƒ½ä¸ç”¨å°±å¤Ÿå®šä½ç»å¤§å¤šæ•°æ•…éšœæ ¹å› äº†ã€‚
  - è¦éªŒè¯ä¹Ÿå¾ˆç®€å•ï¼Œå› ä¸ºæˆ‘æŠŠæ•´å¥—æ•°æ®åº“æ¶æ„æ–¹æ¡ˆä¸å·¥å…·éƒ½å¼€æºå‡ºæ¥äº†
  - https://github.com/Vonng/pigsty /python/plpgsql
- pigsty æœ‰æ²¡æœ‰è®¡åˆ’æ”¯æŒä¸‹ http://fly.io è¿™ç§åŸºäºå®¹å™¨çš„ç¯å¢ƒå‘¢ï¼Ÿ
  - æš‚æ—¶æ²¡æœ‰ï¼Œå…¶ä»–ç»„ä»¶æ”¾å®¹å™¨éƒ½è¡Œã€‚æ•°æ®åº“æˆ‘é€‰æ‹©åŸºäºè£¸OSåšã€‚å°±æ˜¯ä¸ºäº†å°½å¯èƒ½å‡å°‘ä¸å¿…è¦çš„ä¾èµ–ï¼Œæ¯”å¦‚é˜¿é‡Œäº‘é‡Œå¯¹è®¤è¯çš„é¢å¤–ä¾èµ–ä¸€æ ·
- å¹ç‰›æ²¡é—®é¢˜ï¼Œä¸å¯¹ç§°å¯¹æ¯”åŠ æ‹‰è¸©å°±æ²¡å¿…è¦äº†ã€‚
- ä½ è¿™åªæ˜¯ä¸€å®¶åç«¯æœåŠ¡é›†ç¾¤ï¼Œäººå®¶æ˜¯æ•´ä¸ªäº‘æœåŠ¡ä¾›åº”å•†ï¼Œä¸¤è€…ä¸åœ¨ä¸€ä¸ªæ°´å¹³ä¸Šå§ã€‚å…¶å®é˜¿é‡Œäº‘çœŸæ­£çš„é—®é¢˜åœ¨äºå¾ˆå¤šä¸œè¥¿ä¾èµ–äºJavaï¼Œå®ƒæ—©å°±åº”è¯¥åˆ†æ•£è¿™ç§å¯¹å•ä¸€è¯­è¨€çš„ä¾èµ–çš„

- ## Lukewarm(å¾®æ¸©çš„; ä¸çƒ­çƒˆçš„) take for database products - focus on winning new workloads, don't worry so much about migrations. 
- https://twitter.com/MarkCallaghanDB/status/1724454882785304672
  - RoI on features that win new workloads >>> RoI on features that get migrations.
- One way to â€œhackâ€ this paradigm is to build based on Postgres, and then contribute/collaborate on open source migration tooling.
- Even more lukewarm take - donâ€™t build a database. Build a data based product within a niche. Then generalize from there if you survive year four.

- ## ğŸ”¥ [What we learned after I deleted the main production database by mistake | Hacker News_202209](https://news.ycombinator.com/item?id=32903367)
- 
- 
- 

- ## ğŸ”¥ [We deleted the production database by accident | Hacker News_202010](https://news.ycombinator.com/item?id=24813795)
- 
- 
- 

- ## ğŸ”¥ [Managing database schema changes without downtime | Hacker News_201803](https://news.ycombinator.com/item?id=16665447)
- 
- 
- 
