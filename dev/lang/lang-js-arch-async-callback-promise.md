---
title: lang-js-arch-async-callback-promise
tags: [architecture, async, js, lang, promise]
created: 2021-08-30T07:00:06.476Z
modified: 2021-08-30T07:01:09.493Z
---

# lang-js-arch-async-callback-promise

# guide

- tips
  - éƒ¨åˆ†æµè§ˆå™¨æ”¯æŒschedulerå’ŒTaskControllerå¯ç”¨æ¥å–æ¶ˆtaskï¼Œä½†firefoxå’Œsafariä¸æ”¯æŒ

- [Learn Asynchronous Patterns in JavaScript with Kyle Simpson](https://frontendmasters.com/courses/rethinking-async-js/)

- [JavaScript Promises vs. RxJS Observables](https://auth0.com/blog/javascript-promises-vs-rxjs-observables/)
  - Promises are very eager(çƒ­åˆ‡çš„ï¼Œæ¸´æœ›çš„). If we had a callback function provided to a Promise, once the Promise is resolved, the `.then` gets executed.
  - Observables are very lazy. We create the Observable, and then it will wait to be subscribed to. We create the Observable, and then it will wait to be subscribed to.
# not-yet
- awaitæ˜¯å¦æ²¡æœ‰è®©å‡ºcpuæ—¶é—´ï¼Ÿ 
- å¦‚ä½•è®©ä¸€ä¸ªfunctionç±»å‹çš„å‚æ•°æ”¯æŒawaitå’Œéawaitè°ƒç”¨ï¼Œå¦‚ä½•æé«˜æ€§èƒ½
# examples
- https://github.com/eldargab/load-script /js
  - load-script appends a `script` node to the `<head>` element in the dom.

- https://github.com/rumkin/pill /js
  - Pill adds dynamic content loading to static sites and makes content loading smooth for users.
  - Intercepts navigation attempts: links clicks and history navigation.
  - Loads requested url using fetch.
  - Grabs content from received HTML
  - Replaces current page content.

## dynamic-load

- https://github.com/systemjs/systemjs /js
  - Dynamic ES module loader

- https://github.com/microsoft/redux-dynamic-modules /202003/ts/inactive
  - aims to make Redux Reducers and middleware easy to modular-ize and add/remove dynamically.
  - In large Javascript applications, it is often desired to perform some kind of code-splitting, so that the initial script size is small. 
  - However, in Redux, you are required to define your reducers and middleware up-front; 
  - there is no good way to dynamically add/remove these constructs at runtime.
  - designed to make dynamically loading these constructs easier

## react-remote

- https://github.com/hupe1980/react-script-hook /ts
  - React hook to dynamically load an external script and know when its loaded

- https://github.com/Paciolan/remote-component /ts
  - Dynamically load a React Component from a URL

## async-utils

- https://github.com/abbr/deasync
  - DeAsync turns async function into sync, implemented with a blocking mechanism by calling Node.js event loop at JavaScript layer. 
  - The core of deasync is written in C++.

- https://github.com/dmaevsky/conclure /MIT/202211/js/NoDeps/inactive
  - Brings cancellation and testability to your async flows.
  - It is a tiny (core is < 200 lines of code), zero dependencies generator runner. 
  - Using generators instead of promises allows for a LOT more flexibility, including cancellation, sync resolution, and better testing. The API is strictly the same as `async/await`.
  - ğŸ¤¼ You should avoid Promises for two major reasons:
    - Promises are greedy: once created, cannot be cancelled
    - `await promise` always inserts a tick into your async flow, even if the promise is already resolved or can be resolved synchronously.
  - You can see a Promise as a particular type of an iterator for which the JS VM provides a built-in runner, a quite poorly designed one nonetheless.
  - Conclure JS is a custom generator runner that
    - allows you to cancel your async flows
    - ensures that sync flows always resolve synchronously
    - delivers better testability through the use of effects as popularized by redux-saga.
# discuss-async-loading
- ## 

- ## 

- ## what are good usecases for _dynamic_ imports in js
- https://twitter.com/threepointone/status/1491467308065243148
  - i.e. `const something = await import(xyz);` where xyz is _not_ statically known / can _not_ be known ahead of runtime? 
  - looking for good usecases that don't have great workarounds.

- One of my pain points with authoring a lib with ES modules is that I _can't_ conditionally import something that's needed for sync startup in DEV mode.
  - We've got some stupid search/replace build shenanigans in redux-RTK related to that.
- Cant it be done with dynamic import?
  - No, and that was exactly the point. In our case, we have Redux middleware that only run in dev. But all the store setup is done synchronously during app setup / module loading. You can't dynamically import a middleware and add it to the store - it has to exist _now_.
- With export conditions u could do this but it probably would involve having to create an identity/noop/passthrough middleware for production
  - Those are still fairly new and some tools might not always support this in the same way

- a plugin system where the list of plugins is stored as user data in a db?
  - yeah, plugin/config systems looks like a very good usecase here

- Plugins...oh 'good' use cases..sorry that's on me I got nothing.
  - only thing worse is order dependent globally mutating middleware

- Loading i18n translations on demand?
  - the workaround here would be a map of keys to imports, like -  { "en-US" : () => import('./translations/en-us'), ... }

- One example that comes to mind is code that doesn't need to run until a user has scrolled to a certain point on a page (e.g., with IntersectionObserver). No need to statically bundle the dependencies if a user hasn't scrolled to that point yet (or a certain distance from it)
  - Actually, this is exactly what Iâ€™m doing. Page contains several React components, and each is imported only when needed/viewed. This: import(`components/${data.componentPath}/index.jsx`) .

1. Test runners that load your test files dynamically. 
2. Plugins that are loaded by (dev) tools (eslint, prettier, StrykerJS) 
3. A playground that lets you create and run multiple JS files

- Importing a module for a new feature behind a feature flag

- Remix uses this for importing the js for routes dynamically on client side transition 

- ## Performance tip: use dynamic imports to ensure JS is only downloaded when needed
- https://twitter.com/Steve8708/status/1502084919488495621
  - When used responsibly, they can greatly reduce your bundle sizes and boost page load times

- The code for dynamic `import` can be placed in the `head` of the file instead of inside the `onClick` function, two benefits: 
  - 1. maintain page performance (dynamic import will start loading after the static import), 
  - 2. no need to wait to use the function inside the onClick function
# discuss-queue/concurrency
- ## 

- ## 

- ## 

- ## [GCP: When to use PubSub vs Task Queues _201702](https://groups.google.com/g/google-appengine/c/IcIjLfgnNXs/m/-m_ik7h6DgAJ)
- Much of the answer is historical. Task Queues evolved as part of the App Engine developer libraries (back in 2009) and was (internally) slated for deprecation and replacement with release of Pub/Sub. As you observed: Pub/Sub does seem like a strong generalization of Task Queues. When Pub/Sub launched, however, we found that it did not meet the needs of a significant number of customers. A number of features that we thought werenâ€™t particularly import (de-duplication, scheduled delivery, rate management, concurrency management, tagged tasks, configurable retries, etc) turned out to be critical and not supported in Pub/Sub.
  - In response to that feedback, we took a step back and tried to define the core differences. The conclusion we arrived at is that Pub/Sub is a networking and big data product. It is agnostic to both the content and the target and focuses on delivering very high throughput capabilities to arbitrary handlers. Task Queues is a managed execution product. It is intended for running and managing large numbers of explicit commands. Weâ€™re working to repackage Task Queues as Cloud Tasks and open it up for broader integration with the rest of GCP. For example, we want to make it possible to enqueue Datastore operations or Cloud Functions for asynchronous execution. The idea is to make it as easy as possible to spin up large distributed systems without needing to write handlers and managers. 

- Personal opinion:
  - Task queues are probably better to use from App Engine Standard. They've existing for a long time, and I suspect the RPC API that is used to call App Engine services is pretty efficient. Using Pub/Sub is likely to be slightly worse in terms of overhead per API call, since it will have to go through the HTTP API via URL Fetch.
  - Pub/Sub is probably better to be used from anywhere else. The API works from anywhere. A single Pub/Sub topic has nearly no limits, while task queues top out at around 500 messages / second. You can also "replicate" a topic to multiple subscribers, which is useful for some applications.

- ## [javascript - what is the difference events and tasks? - Stack Overflow](https://stackoverflow.com/questions/73185642/what-is-the-difference-events-and-tasks)
- Events are signals that tell the event loop that a task is now ready to run. They are not part of the event loop, they come from outside. Examples are DOM events (such as clicks, keyboard events etc), network events (readystatechange, progress), timer events (from setTimeout). 
  - Events are not tasks themselves. They may or may not be fired by another thread - often enough, the event loop polls for them.

- ## ğŸ†šï¸ [Event Loops vs Queues? _201910](https://www.reddit.com/r/esp32/comments/dde864/event_loops_vs_queues/)
  - I'm doing a refactoring of some code and am looking to componentize things. As far as communication between components, is there any "best practice" as to when to use event loops vs queues? 
  - Its seems like you can get the same functionality, ie running a function on an event vs running a function when an item in a queue is received. 
  - I want to do things in an extendable, well maintainable, and "correct" way so does anyone have any advice or resources I can look into to better resolve this?

- â€˜Queuesâ€™ provide a task-to-task, task-to-interrupt, and interrupt-to-task communicationmechanism.
  - Event groups are another feature of FreeRTOS that allow events to be communicated totasks. Unlike queues and semaphores:ï‚· Event groups allow a task to wait in the Blocked state for a combination of one of moreevents to occur.ï‚· Event groups unblock all the tasks that were waiting for the same event, or combinationof events, when the event occurs
- In Summary. 
  - Events are good if you want to wait to do something when the chip has reached a set of states. e.g. I have read the temperature and humidity and I'm connected = OK send the payload. All (or some) conditions must be met for the event to trigger
  - Queues are better for copying information from one task to another. e.g I have 2 tasks. One that handles reading the temperature and another that displays the information. A queue can be used to "notify" (copy) the information from the task that read the data to the other that displays it.
  - As far as Main is concerned, Its just another FreeRtos task. I like to organize my code so that all my tasks, semaphores, events, queues etc, are initialized in main and the tasks act like individual applications thereafter. but there is no hard and fast rule about that as long as you keep your eye on the available stack space

- My answer will be specific to ESP-IDF.
  - The best practice is this: use eventGroup to signalling, use Queue to transfer data between tasks.
  - ESP-IDF framework is oriented to asynchronous programming model i.e. Non-blocking. So the main function should only be used for init'ing and setup handler. It's okay to have small code in main function, but if you're working with a larger systems then you need to consider creating some FreeRTOS tasks from main func. This way you'll keep your project modular.

- ## ğŸ†šï¸ [Message Queue vs Task Queue difference - Stack Overflow](https://stackoverflow.com/questions/10075817/message-queue-vs-task-queue-difference)
- below is my understanding:
  - Message queue is the message broker part - a queue data structure implementation, where you can: send/receive
  - Task queue, on the other hand, is to process tasks: At a desired pace, In an async way
  - As you can see, message queue and task queue focus on different aspects, they can overlap, but not necessarily.
  - An example for task queue but not message queue - if your tasks don't care about ordering - each task does not depend on one another - then you don't need a "queue", FIFO data structure. You can, but you don't have to. You just need a place to store the buffered tasks like a pool, a simple SQL/NoSQL database or even S3 might suffice.
  - An opposite example is push notification. You use message queue but not necessarily task queue. Server generates events/notifications and wants to deliver them to the client. The server will push notifications in the queue. The client consumes/pulls down notifications from the queue when they are ready to do so. Products like GCP PubSub, AWS SNS can be used for this.
- Tools like Celery are task queue + message queue baked into one. There aren't many tools like Celery as I know that do both, guess that's why it's so popular (alternatives are Bull or Bee in NodeJS, or if you know more please let me know!).

- ### ğŸ†šï¸ [Difference between a task queue and worker threads? : r/node _202203](https://www.reddit.com/r/node/comments/tdrjq2/difference_between_a_task_queue_and_worker_threads/)
- A task queue lets you do things like persist, schedule, coordinate and retry jobs in a robust way.
  - A worker thread just spins up a new thread to do some work on. It doesn't help you with the other stuff I mentioned.
  - If you are looking for a lightweight queue and are using Postgres, you might want to check out pg-boss and @graphile/worker, as an alternative to the Redis-based queues like Bull.

- A worker thread is a primitive which gives you the ability to run code in parallel. 
  - A task queue is a pattern for distributing work across potentially many computers.
  - You could implement a task queue pattern on top of worker threads, but as others have pointed out, if your process dies due to an exception, the OOM killer, or even a deployment script, all the threads will be killed along with it.
  - Most of the time when you implement a task queue pattern, you'll want to distribute the work across multiple servers, and store the actual tasks externally (e.g. in a database or Redis).
  - This is why e.g. "worker threads don't automatically retry" like some task queues. They're low level and you can use them to build up many different high level architectures.
# discuss-stars
- ## 

- ## 

- ## 

- ## ğŸ†šï¸ Letâ€™s say `f()` returns a promise:
- https://twitter.com/shuding_/status/1766842504635134271
  - async function a() { return f() }
  - async function b() { return await f() }
  - function c() { return f() }
- A returns a promise like c, since no await is used with async. 
  - B unwraps the promise in f, and rewraps it since async and await are used. 
  - F directly returns the promise from f. Behavior is the same.

- itâ€™s the matter of where you handle the result of Promise, and where the error or success should be handled imo
- The examples are identical unless you expect c() === c() and don't add more code in each function. Try/catch in a() and errors before the return in c() make it behave differently.
- Only b) will return a complete stack trace if the promise code errors

- ## ğŸ†šï¸ [Events vs Streams vs Observables vs Async Iterators - Stack Overflow](https://stackoverflow.com/questions/39439653/events-vs-streams-vs-observables-vs-async-iterators)
- There are roughly two categories of APIs here: pull and push.
  - Push APIs are a good fit for when something is generating data, and the data being generated does not care about whether anyone wants it or not
  - Async pull APIs are a good fit for cases where data is pulled from a source. This source might be a file, or a network socket, or a directory listing, or anything else. The key is that work is done to pull or generate data from the source when asked.

- ## [Would it be a good idea to unify generators and async-await? : r/ProgrammingLanguages _202008](https://www.reddit.com/r/ProgrammingLanguages/comments/igy5jd/would_it_be_a_good_idea_to_unify_generators_and/)
  - Many languages, including C#, Python and JavaScript, support both generators via yield and concurrency via async-await.
  - C# (conceptually) uses source-code transformation to turn coroutine functions of both types into state machines. 
  - Python has the ability to suspend and resume individual stack frames.
  - Do you think it would be a good idea to offer a single coroutine feature, instead of separate generators and async-await?

- Thatâ€™s what goroutines do in golang. Channels and channel-operations are used to model both concurrency and generators. The same is true for core.async in clojure.

- This is what Kotlin does. They offer a generic coroutine framework that lets you build â€œsuspendâ€ functionality
# discuss
- ## 

- ## 

- ## ğŸ’¡ [Is it an anti-pattern to use async/await inside of a new Promise() constructor? - Stack Overflow](https://stackoverflow.com/questions/43036229/is-it-an-anti-pattern-to-use-async-await-inside-of-a-new-promise-constructor)
- You're effectively using promises inside the promise constructor executor function, so this is the Promise constructor anti-pattern.
  - Your code is a good example of the main risk: not propagating all errors safely
  - In addition, the use of async/await can make the same traps even more surprising.
  - any immediate exception in a `Promise` constructor executor function conveniently rejects the newly constructed promise (but inside any `.then` you're on your own).
  - any immediate exception in an `async` function rejects the implicit promise returned by the async function itself.

- 
- 
- 
- 

- ## if you need a pretty simple Queue in JS/TS just use a `TransformStream` . 
- https://x.com/okikio_dev/status/1830083868596036095
  - With the web stream api supporting back pressure, `ReadableStream.tee()` for multiple reads over the Queued data and the fact that TransformStreams are transferable across Workers and the main thread

- ## å‰ç«¯çš„å‘å±•è¿˜æ˜¯å¾ˆå¿«çš„ï¼Œå¯¹è¯­è¨€è®¾è®¡æ¥è¯´å¯ä»¥å¾ˆå¿«è½åœ°è¯•éªŒä¸€äº› feature, 
- https://twitter.com/codeworm96/status/1775764265695322438
  - Javascriptä»¥å¾ˆå¿«çš„é€Ÿåº¦èµ°è¿‡äº† callback -> promise -> async/await çš„è·¯ï¼ˆè€Œ async rust å’Œ c++...ï¼‰è€Œä¸”ç°åœ¨å‰ç«¯ä¹Ÿè¶³å¤Ÿå·¥ç¨‹åŒ–äº†ï¼Œå®Œå…¨è¶³ä»¥è§‚å¯Ÿåœ¨å¤§é¡¹ç›®ä¸­çš„è¡¨ç°
- åˆ«å°¬é»‘ï¼Œæˆ‘å‘ç°çš„å‰ç«¯å¤§éƒ¨åˆ†çš„é—®é¢˜ï¼Œéƒ½æ˜¯ JS æ ¹ä¸Šä¹±æå¯¼è‡´çš„.. å·¥ç¨‹åŒ–çš„äº‹æƒ…ç³»ç»Ÿå¼€å‘å¥½æ—©å°±æ˜ç™½äº†ï¼Œå‰ç«¯å¾—ç­‰åˆ°ç»„ä»¶åŒ–ä»¥åï¼Œå¾ˆå¤šæ–°æŠ€æœ¯ä¹Ÿè¿˜åœ¨æ–—äº‰ï¼Œäº†è§£/å…¼å®¹ä¸€å †æ‘è§„æƒ³æ­»..
- JSä¸»è¦ä½œä¸ºè„šæœ¬è¯­è¨€ï¼Œä»¥æ–‡æœ¬å½¢å¼åˆ†å‘ï¼Œæ‰€ä»¥æ–°ç‰ˆæœ¬è‡³å°‘ä¸èƒ½åœ¨ parse ä¸Š break æ‰æ—§ç‰ˆæœ¬ï¼›äºæ˜¯å°±è¿™ä¹ˆæ‹–ç€å±å±±ä¸€è·¯å‘å‰ã€‚ å¾ˆéš¾æƒ³è±¡åƒ Python 3 é‚£æ ·æè¯­æ³•ä¸å…¼å®¹ä¼šå¯¹ JS äº§ç”Ÿä»€ä¹ˆåæœã€‚
- æˆ‘æ„Ÿè§‰async awaitè·Ÿæ‰‹åŠ¨å†…å­˜ç®¡ç†ç›¸æ€§ä¸å¥½
- æˆ‘è§‰å¾— async await è‡³å°‘æ˜¯ç¬¦åˆ structured concurrency çš„ï¼Œä½†ä¸€äº›æ¯”è¾ƒå¤æ‚çš„æ§åˆ¶æµè¡¨è¾¾ä¸å‡ºæ¥ã€‚ 
  - æˆ‘è§‰å¾—åŸæ–‡ä¼ è¾¾å‡ºæ¥æœ€ä¸»è¦çš„æ„æ€æ˜¯ structured çš„æ§åˆ¶æµï¼ˆé™¤äº†å¾ªç¯ï¼‰åŸºæœ¬æ˜¯ä»ä¸Šè€Œä¸‹é¡ºåºçš„ï¼Œè€Œ goto (go) æ˜¯ä¹±è·³çš„ï¼›async await æ˜¯ç¬¦åˆé¡ºåºçš„ï¼Œè€Œå¦‚æœä½ è¯•è¿‡ç”¨ callback æˆ–è€… Promise å®ç°å¾ªç¯ï¼Œä½ å°±ä¼šå‘ç°ä»£ç çš„é¡ºåºå¾ˆåˆ«æ‰­ã€‚
- go æ€ä¹ˆç±»æ¯”goto å‘¢ï¼Œgo æœ‰ waitgroupï¼Œæ„Ÿè§‰æŒºå®¹æ˜“å†™æˆ structured concurrency å‘€ã€‚æˆ‘çš„ç–‘é—®æ˜¯ï¼Œåç¨‹æœ¬èº«åº”è¯¥æ”¯æŒ structured concurrencyï¼Œè¿™æ˜¯è¶‹åŠ¿ï¼Œä½†æ˜¯å¹¶ä¸æ˜¯ async/await æ›´å®¹æ˜“å†™æˆ structured concurrencyã€‚åƒ go å’Œ java è¿™æ ·ä¸ç”¨å‹¿æ‰°ä»£ç çš„åç¨‹æ–¹å¼ï¼ŒåŒæ ·å¾ˆå®¹æ˜“å®ç° structured concurrency
- å†™è¯´å¯ä»¥å†™çš„ï¼ŒJS ä¹Ÿæœ‰ await Promise.all() ã€‚ä¸»è¦æ˜¯å¤šäººåä½œçš„é¡¹ç›®é‡Œæ„è¯†çš„é—®é¢˜ã€‚ä½ å¯ä»¥ç”¨ go æ¥å®ç° structured concurrencyï¼Œä½†åˆ«äººä¸ä¸€å®šä¼šæœ‰è¿™ä¸ªæ„è¯†ï¼›ç›¸æ¯”ä¹‹ä¸‹ async await ç”±äºä¸æ”¯æŒåƒ go è¿™æ ·è·³ï¼Œä¸‹é™æ›´ä½ä¸€ç‚¹ï¼Œä¸å®¹æ˜“ç”¨å‡ºé—®é¢˜ã€‚goto ä¹Ÿå¯ä»¥å®ç°æ‰€æœ‰çš„æ§åˆ¶æµã€‚
  - ä½ è¯´çš„æ²¡æ¯›ç—…ã€‚ä»€ä¹ˆç‰¹æ€§æ»¥ç”¨éƒ½ä¼šå¯¼è‡´é¢„æ–™å¤–çš„äº‹æƒ…ã€‚æ‰€ä»¥ java åœ¨virtual threadåŸºç¡€ä¸Šåœ¨å®ç° scã€‚ å¹¶é¼“åŠ±ä½¿ç”¨æœ€ä½³å®è·µã€‚goç±»ä¼¼ã€‚ æˆ‘æƒ³è¡¨è¾¾çš„æ˜¯ï¼Œæ ¸å¿ƒæ˜¯ scï¼Œè€Œä¸æ˜¯ await/async æ›´å®¹æ˜“ sc

- ## A common misunderstanding about `Promise.all` is that it cancels the remaining promises as soon as it rejectsâ€”this is NOT true! 
- https://twitter.com/hovhaDovah/status/1765763275545817427
  - It simply ensures that you don't have to *wait* for the remaining promises to resolve if a promise has already rejected. What do you think this code logs?
- In other words, Promise.all gives you fail-fast behavior, allowing you to handle the error case sooner than if you had waited for all of the promises to settle.
- very interesting, even if one promise fails it goes into the catch block, makes a ton of sense to do so.

- ## ğŸ¤”ğŸ†š Have any JS lib maintainers switched back to using callbacks over promises and async/await?
- https://twitter.com/tantaman/status/1758828869530906748
  - The purpose being that by using callbacks you can preserve the task and event loops when the library is deployed with synchronous workloads and still be able to support async workloads.
  -  with promises and async functions, everything resolves asynchronously even if it is synchronous. Thatâ€™s what I want to avoid since, with my lib, some ppl want it to be full synchronous and others full asynchronous. Callbacks allow that as you said. Promises donâ€™t.

- If you create a promise that contains no async call, it will be synchronous, but listeners will be queued in the micro-tasks, which is rarely an issue but maybe it is for you ? You can also return a custom promise to mimic then(), but async stack trace become an issue :/
  - The micro task queueing for â€˜thenâ€™ callers is an issue since it will cause interleaved execution of synchronous code.
  - As a concrete exampleâ€” I have a library where users can provide a data source. That source could be synchronous or async.
  - If my library used promises to expose the synchronous sources then any call to get a result from those sources would resolve in a future micro task. 
  - The most obvious place this is a problem is react controlled inputs. The synchronous sources will cause cursor jumping when put behind a promise api. 
  - Other issues are code someone wants to run sequentially getting interleaved with other code since all â€˜thenâ€™ calls are new tasks.

- pulumi is actually callback based and so the new version of sst is as well
- What did you take into account when deciding to make sst callback based?
  - we actually wanted to maximize parallelism whereas promises would require the end user to ensure they arenâ€™t blocking unnecessarily
  - basically we never want them to await

- ğŸ¤” I've ditched promises long time ago in favor of generators. Wrote a tiny generator runner http://github.com/dmaevsky/conclure that allows me to keep the async/await logic (spelled function*/yield in the iterator world), but sync tasks are still executed sync. And async tasks can be cancelled

- Too many people call await sequentially which kills perf, cause they don't know about parallel.

- I am curious if it possible to make own Promise implementation that will not be falling to microtasks

- Given Iâ€™m mostly writing code (both apps and libraries) using [Effect](https://effect.website/), most APIs are returning Effects - or sync if side-effect free. Effect uses callbacks to implement most operations where necessary.

- ## is there a way to wait for N promises on tests?
- https://twitter.com/sseraphini/status/1365297469911937025
  - I have a test that will receive N messages and process each of them using an async code
  - so I need to wait N process to be processed to do some assertion
- Promise.all() or Promise.allSettled() might be work.
- `await new Promise(setImmediate)` .
  - will this awaits a single promise or all the pending promises?
  - This awaits all promises that are to be resolved in the same event loop

- ## I think we should have an ESLint rule that stops you from `await` -ing in an inline `Promise.all` array
- https://twitter.com/karlhorky/status/1720194025695719503
- You can pass any value in the promise all array so nothing for TS to â€˜catchâ€™. Maybe a lint rule would be handy as you suggest

- ## [Why people still compare Observables as "better" than promise as a primitive?](https://www.reddit.com/r/angular/comments/w9ipf4/why_people_still_compare_observables_as_better/)
- Because observables are much more powerful.

- ## ğŸ¤”ğŸ”¢ [Why the Microtask queued after chained promises are executed after the first promise resolution ignoring the chained ones? - Stack Overflow](https://stackoverflow.com/questions/75373806/why-the-microtask-queued-after-chained-promises-are-executed-after-the-first-pro)

```JS
function tasksAndMicroTasks() {
  const promise = Promise.resolve()

  console.log('#1st call')

  promise
    .then(() => console.log('#3rd call'))
    .then(() => console.log('#4th call'))
    .then(() => console.log('#5th call'))

  queueMicrotask(() => console.log(`I'm microtask from the custom Queue`))

  console.log('#2nd call')
}
tasksAndMicroTasks()

// #1st call
// #2nd call
// #3rd call
// I'm microtask from the custom Queue
// #4th call
// #5th call
```

- `promise.then(fn1).then(fn2);` is not the same as `promise.then(fn1); promise.then(fn2);`.
- For the purposes of your experiment,  `Promise.resolve().then(fn)` is doing the same thing as `queueMicrotask(fn)`. 
  - The Promise is already resolved, so the callback function is queued.
- When you chain .then() callbacks, you're adding callbacks to the returned Promises from the calls to .then(). Those Promise objects will not resolve until each .then() resolves in sequence.

- A promise returned by `.then()` is resolved with the result of the callback, so it fulfills only after the callback has been called. 
  - Only at this point, the promise handlers of the chained promise are scheduled on the microtask queue - after all the ones that had initially been scheduled on the already fulfilled promise or by `queueMicrotask`.

- ## [What are the advantages of async.js over native Promises](https://github.com/caolan/async/issues/1714)
- Promises add a caching layer for results and errors and state machine around your function calls which makes things more stateful and somewhat slower than necessary 
  - and they also allow passing the next point of execution around which breaks encapsulation. 
  - Async/await helps somewhat with the latter but you can get the best of both world with casync along with this library.
- I could do `Promise.all(ratings.map(processRating))` but this would overload my API. With `mapLimit` I can set a max of 25 calls at a time. Rather than 1000's. 

- ## [Node.js å¼‚æ­¥apiçš„æœ¬è´¨å’Œ libuv](https://zhuanlan.zhihu.com/p/402398815)
- Node.js æ˜¯ä¸€ä¸ª Javascript çš„è¿è¡Œæ—¶ï¼Œæä¾›äº†ç³»ç»Ÿèƒ½åŠ›çš„ apiï¼Œä¸»è¦æ˜¯æ–‡ä»¶ã€ç½‘ç»œç›¸å…³çš„ IO apiï¼Œè€Œ IO api çš„å®ç°æ˜¯åœ¨ libuvï¼Œæä¾›äº†åŒæ­¥å¼‚æ­¥ä¸¤ç§å½¢å¼çš„ apiã€‚
- æœ¬æ¥å°±æ¥æ¢ç©¶ä¸‹ libuv çš„åŠŸèƒ½å’Œæä¾›çš„ api çš„å½¢å¼ã€‚
- cpuæ˜¯é¡ºåºæ‰§è¡Œä»£ç çš„ï¼Œé€šè¿‡pcå¯„å­˜å™¨æ¥å­˜å‚¨ç€ä¸‹ä¸€æ¡æŒ‡ä»¤çš„å†…å­˜åœ°å€ã€‚ä»£ç çš„æ‰§è¡Œæµç¨‹å«åšæ§åˆ¶æµã€‚
  - ä½†æ˜¯å¯¹äºä¸€äº›IOæ“ä½œæ¥è¯´ï¼Œå¹¶ä¸éœ€è¦cpuåšè®¡ç®—ï¼Œè€Œæ˜¯åœ¨ç­‰å¾…ç¡¬ç›˜è®¾å¤‡ã€ç½‘ç»œè®¾å¤‡çš„æ•°æ®è¯»å–ï¼Œ
  - è¿™æ—¶å€™ cpu æ˜¯ç©ºé—²çš„ï¼Œæ‰€ä»¥ä¸€æ¡æ§åˆ¶æµä¸è¡Œï¼Œä¼šå¯¼è‡´cpuåˆ©ç”¨ç‡å¤ªä½ã€‚
- æ‰€ä»¥æ“ä½œç³»ç»Ÿåˆæä¾›äº†è¿›ç¨‹ã€çº¿ç¨‹çš„åŠŸèƒ½ï¼Œè¿›ç¨‹æ˜¯åˆ†é…èµ„æºçš„å•ä½ï¼Œè€Œæ‰§è¡Œä»£ç ä¸»è¦æ˜¯é çº¿ç¨‹ï¼Œ
  - ä¸€ä¸ªçº¿ç¨‹å°±æ˜¯ä¸€æ¡æ§åˆ¶æµï¼Œå®ƒæ˜¯cpuè°ƒåº¦çš„åŸºæœ¬å•ä½ï¼Œä¹Ÿå°±æ˜¯è¯´å¯ä»¥åœ¨å¤šä¸ªæ§åˆ¶æµä¹‹é—´åˆ‡æ¢ï¼Œå½“ä¸€ä¸ªçº¿ç¨‹åœ¨åšIOçš„æ—¶å€™å°±é‡Šæ”¾cpuï¼Œè®©å…¶ä»–çº¿ç¨‹å»è·‘ã€‚
- ä¸€ä¸ªçº¿ç¨‹é˜»å¡çš„ç­‰å¾…IOçš„æ–¹å¼å°±æ˜¯åŒæ­¥ï¼Œä¼šæ¯”è¾ƒæµªè´¹ cpuï¼Œ
  - è€Œå¤šä¸ªçº¿ç¨‹åˆ‡æ¢ï¼Œåœ¨åšIOçš„æ—¶å€™è®©å…¶ä»–çº¿ç¨‹ä¸Š cpu è·‘ï¼Œæ‰§è¡Œå®ŒIOå†ç”³è¯·cpuæ¥ç»§ç»­åç»­å¤„ç†ï¼Œè¿™ç§æ–¹å¼å°±æ˜¯å¼‚æ­¥
- å¼‚æ­¥æœ€ç»ˆæ˜¯å¤šçº¿ç¨‹æ¥å®ç°çš„ï¼Œä½†æ˜¯åœ¨ Node.js é‡Œé¢åˆè¿›ä¸€æ­¥é€šè¿‡ event loop åšäº†å°è£…ï¼Œ
  - æ¯”å¦‚æ‰§è¡Œæ–‡ä»¶è¯»å–ã€ç½‘ç»œè®¿é—®çš„æ—¶å€™å¹¶ä¸éœ€è¦å¼€å‘è€…å»åˆ›å»ºçº¿ç¨‹ï¼Œè€Œæ˜¯è°ƒç”¨apiï¼ŒæŒ‡å®šå›è°ƒå‡½æ•°å°±å¯ä»¥äº†ï¼Œè¿™æ˜¯å¯¹å¤šçº¿ç¨‹çš„è¿›ä¸€æ­¥å°è£…ã€‚
- **å¼‚æ­¥çš„åº•å±‚å®ç°éƒ½æ˜¯é€šè¿‡çº¿ç¨‹çš„åˆ‡æ¢ï¼Œä½†æ˜¯æš´éœ²ç»™å¼€å‘è€…çš„å½¢å¼æœ‰ä¸¤ç§**ï¼š
  - ç¬¬ä¸€ç§æ˜¯å¼€å‘è€…æ§åˆ¶çº¿ç¨‹çš„åˆ›å»ºå’Œé”€æ¯ï¼ŒæŒ‡å®šçº¿ç¨‹æ‰§è¡Œçš„å†…å®¹ï¼Œjavaæ˜¯è¿™ç§ã€‚
  - ç¬¬äºŒç§æ˜¯æä¾›äº‹ä»¶å¾ªç¯æœºåˆ¶ï¼Œæä¾›ä¸€ç³»åˆ—å¼‚æ­¥apiï¼Œè¿™äº›å¼‚æ­¥apiæœ€ç»ˆæ˜¯ç”±çº¿ç¨‹æ¥æ‰§è¡Œçš„ï¼Œä½†æ˜¯å¼€å‘è€…ä¸éœ€è¦æ‰‹åŠ¨ç®¡ç†çº¿ç¨‹ã€‚javascriptæ˜¯è¿™ç§ã€‚â€‹
- åœ¨Node.jsé‡Œé¢ï¼Œå®ç° event loop çš„å°±æ˜¯ libuvï¼Œå®ƒæ˜¯ä¸€ä¸ªå¼‚æ­¥IOåº“ï¼Œè´Ÿè´£æ–‡ä»¶å’Œç½‘ç»œçš„ioï¼Œæä¾›äº†äº‹ä»¶å½¢å¼çš„å¼‚æ­¥apiã€‚
  - libuvé‡Œæœ‰ä¸€ä¸ªçº¿ç¨‹æ± è´Ÿè´£ç»´æŠ¤ä¸€äº›çº¿ç¨‹ç”¨æ¥æ‰§è¡Œå¼‚æ­¥apiï¼Œè¿™ä¸ªçº¿ç¨‹æ± çš„å¤§å°æ˜¯å¯ä»¥è®¾ç½®çš„ï¼Œé€šè¿‡ç¯å¢ƒå˜é‡ UV_THREADPOOL_SIZE å¯ä»¥è®¾ç½®ã€‚
- å°±æ˜¯è¯´libuvæ˜¯è´Ÿè´£IOçš„ api çš„å¼‚æ­¥å®ç°çš„ï¼ŒåŸºäºæ›´åº•å±‚çš„æ“ä½œç³»ç»Ÿ apiã€‚
  - è¿™äº›æ“ä½œç³»ç»Ÿapiæœ‰çš„æ˜¯å¼‚æ­¥çš„ï¼Œæœ‰çš„ä¸æ˜¯ï¼Œå¯¹äºä¸æ˜¯å¼‚æ­¥apiçš„é‚£äº›ï¼Œå°±è¦ç”±libuvçš„çº¿ç¨‹æ± ä¸­çš„çº¿ç¨‹æ¥æ‰§è¡Œï¼Œå˜æˆå¼‚æ­¥çš„å½¢å¼ã€‚
- è¿™äº› api åŒ…æ‹¬ï¼š
  - æ‰€æœ‰çš„æ–‡ä»¶ fs apiï¼Œé™¤äº† watch çš„ api
  - åŠ å¯† crypto çš„å¼‚æ­¥ api
  - æ‰€æœ‰å‹ç¼©çš„ zlib api
  - dns.loopup
  - è¿™äº› api å…±ç”¨ä¸€ä¸ªçº¿ç¨‹æ± ï¼Œé‚£ä¹ˆè‚¯å®šä¼šç›¸äº’å½±å“ï¼Œæ‰€ä»¥æœ‰çš„æ—¶å€™éœ€è¦åŠ å¤§çº¿ç¨‹æ± çš„çº¿ç¨‹æ•°é‡ï¼Œé»˜è®¤æ˜¯ 4ï¼Œå½“éœ€è¦çš„æ—¶å€™å¯ä»¥è®¾ç½®è¿™ä¸ªç¯å¢ƒå˜é‡æ¥åŠ å¤§ã€‚
- å½“é¢è¯•é—®åˆ°Node.jsæ€§èƒ½è°ƒä¼˜çš„æ—¶å€™ï¼Œå¯ä»¥ç­”è®¾ç½®libuvçš„çº¿ç¨‹æ± å¤§å°ï¼Œå †å¤§å°è®¾ç½®çš„è¿™ä¸¤ä¸ªå‚æ•°/ç¯å¢ƒå˜é‡ã€‚
- çœ‹äº†æ–‡æ¡£ä¹‹åï¼Œæˆ‘ä»¬æ›´ç¡®è®¤äº†å¼‚æ­¥æœ€åº•å±‚çš„å®ç°å°±æ˜¯çº¿ç¨‹ï¼Œåªä¸è¿‡æ˜¯é€šè¿‡libuvçš„çº¿ç¨‹æ± åšäº†å°è£…ã€‚

- å†æ¥çœ‹ä¸‹ Node.js éƒ½æ€ä¹ˆæä¾›è¿™ä¸¤ç§ api çš„
- åŒæ­¥çš„ api æ¯”è¾ƒç®€å•ï¼Œå°±æ˜¯è°ƒç”¨å‡½æ•°ï¼Œæ‹¿åˆ°è¿”å›å€¼å°±è¡Œï¼Œå¾ˆå¤š xxSync çš„ api éƒ½æ˜¯åŒæ­¥çš„
- è€Œå¼‚æ­¥çš„ api åˆ™åˆ†ä¸ºäº†ä¸¤ç§å½¢å¼ï¼Œcallback å’Œ promise
  - å…¶ä¸­ promise çš„ç‰ˆæœ¬åªæœ‰ä¸¤ä¸ªæ¨¡å—æœ‰ï¼Œfs å’Œ dnsï¼Œæ˜¯åœ¨ Node.js 10.x å¼•å…¥çš„ï¼Œæ–¹ä¾¿ä½¿ç”¨ asyncã€await æ¥ç»„ç»‡ä»£ç 

- æ€»ç»“
- ç¨‹åºåœ¨è¿›è¡ŒIOçš„æ—¶å€™ï¼Œ cpuæ˜¯ç©ºé—²çš„ï¼Œä¸ºäº†æ›´å¥½çš„åˆ©ç”¨cpuï¼Œæ“ä½œç³»ç»Ÿæä¾›äº†è¿›ç¨‹ã€çº¿ç¨‹çš„åŠŸèƒ½ï¼Œä¸€ä¸ªçº¿ç¨‹å°±æ˜¯ä¸€æ¡æ§åˆ¶æµã€‚
  - å½“åœ¨IOçš„æ—¶å€™ï¼Œåˆ‡æ¢åˆ°åˆ«çš„çº¿ç¨‹ï¼Œç­‰IOç»“æŸä¹‹åå†ç»§ç»­æ‰§è¡Œçš„æ–¹å¼å°±æ˜¯å¼‚æ­¥ï¼Œè€Œç›¸åº”çš„ä¸€ä¸ªçº¿ç¨‹é˜»å¡çš„ç­‰å¾…çš„æ–¹å¼å°±æ˜¯åŒæ­¥ã€‚
- å¼‚æ­¥æœ€ç»ˆæ˜¯ç”±çº¿ç¨‹å®ç°çš„ï¼Œä½†æ˜¯æä¾›ç»™å¼€å‘è€…çš„æœ‰ä¸¤ç§å½¢å¼ï¼š
  - ä¸€ç§æ˜¯æä¾›çº¿ç¨‹apiï¼Œè®©å¼€å‘è€…è‡ªå·±ç®¡ç†çº¿ç¨‹ï¼Œ
  - å¦ä¸€ç§æ–¹å¼å°±æ˜¯æä¾›äº‹ä»¶å¾ªç¯ï¼Œå¯¹äºå¼‚æ­¥apié€šè¿‡çº¿ç¨‹æ¥å®ç°ã€‚
  - ç¬¬äºŒç§æ–¹å¼å¯¹å¼€å‘è€…æ›´é€æ˜ï¼Œä¸éœ€è¦å…³å¿ƒçº¿ç¨‹çš„åˆ›å»ºå’Œåˆ‡æ¢ã€‚
- Node.js é‡Œé¢çš„ event loop çš„å®ç°æ˜¯åœ¨ libuvï¼Œå®ƒæä¾›äº†æ–‡ä»¶å’Œç½‘ç»œçš„å¼‚æ­¥ IO çš„ apiï¼Œ
  - ä»æ–‡æ¡£ä¸­æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œlibuvæ˜¯åŸºäºæ“ä½œç³»ç»Ÿçš„ api å®ç°çš„ï¼Œè€Œå…¶ä¸­ä¸€äº›åŒæ­¥çš„apiï¼Œåˆ™æ˜¯ç”± libuv çš„çº¿ç¨‹æ± æ¥æ‰§è¡Œï¼Œè¾¾åˆ°å¼‚æ­¥çš„ç›®çš„ã€‚
  - ä½†æ˜¯çº¿ç¨‹æ± çš„å¤§å°é»˜è®¤æ˜¯ 4ï¼Œæœ‰çš„æ—¶å€™éœ€è¦åŠ å¤§ï¼Œå¯ä»¥é€šè¿‡ä¿®æ”¹ UV_THREADPOOL_SIZE çš„æ–¹å¼ã€‚
- Node.js æä¾›çš„ api æœ‰3ç§å½¢å¼ï¼Œä¸€ç§æ˜¯åŒæ­¥çš„ï¼Œä¸€ç§æ˜¯å¼‚æ­¥callbackã€ä¸€ç§æ˜¯å¼‚æ­¥promiseã€‚
  - å…¶ä¸­å¼‚æ­¥ promises çš„å½¢å¼æ˜¯æ¨èçš„å†™æ³•ï¼Œä½†æ˜¯åªæœ‰åœ¨ fsã€dns ä¸¤ä¸ªæ¨¡å—å¯ç”¨ï¼Œå¹¶ä¸”è¦åœ¨ Node.js 10 ä»¥ä¸Šæ‰è¡Œã€‚

- discussion

- å¼‚æ­¥åº•å±‚å®ç°ä¸ä¸€å®šæ˜¯å¤šçº¿ç¨‹å§ï¼ŒæŸäº›å¼‚æ­¥ä»»åŠ¡ï¼Œå¦‚æœ IO ä»»åŠ¡ç›´æ¥äº¤ç»™ç¡¬ä»¶ï¼Œç„¶åç­‰å¾…ç³»ç»Ÿäº‹ä»¶é€šçŸ¥
  - æ˜¯è¿™æ ·ï¼Œæ¯”å¦‚ dma å°±æ˜¯ï¼Œlibuv æ˜¯é€šè¿‡å¤šçº¿ç¨‹å°è£…äº†ä¸€äº›åŒæ­¥ç³»ç»Ÿ apiï¼Œå¼‚æ­¥ç³»ç»Ÿ api çš„éƒ¨åˆ†ä¸ä¸€å®šæ˜¯å¤šçº¿ç¨‹
  - é™å®šåœ¨è½¯ä»¶çº§åˆ«çš„å¼‚æ­¥å°±æ˜¯é çº¿ç¨‹äº†ï¼Œè½¯ä»¶çš„æ‰§è¡Œæ˜¯é cpuï¼Œä¹Ÿå°±æ˜¯éœ€è¦çº¿ç¨‹ã€‚ç¡¬ä»¶çº§åˆ«çš„å¼‚æ­¥æ˜¯é ç”µè·¯ï¼Œå°±ä¸ç”¨çº¿ç¨‹äº†ã€‚

- ## Are you using async/await safely in Node.js? @simonplend explains why Express is not a safe choice and why you should consider an alternative like Fastify instead.
- https://twitter.com/sebastienlorber/status/1374029709210701831
- [Are you using promises and async/await safely in Node.js?](https://simonplend.com/are-you-using-promises-and-async-await-safely-in-node-js/)

- ## I was chasing the race conditions today in the code that is using observers and async/await syntax. Oh, boy, a day full of fun.
- https://twitter.com/maciejadamczak/status/1374286061543718916
- I still need to fix the root problem

- ## Deleted a thread about async/await flows since I hadnâ€™t realized that it made error-handling more complicated.
- https://twitter.com/JoshWComeau/status/1374056481524482054
- I still think it's a valuable tip. I use it all the time - it really helps to speed things up when you've got independent parallel requests.
- You can use try catch.
  - I think it doesn't work when you don't `await` the async function! And that's what Josh means.
- Now I'm interested in a thread about proper error-handling when working with async functions
  - imo async makes it _easier_ (you just use try/catch). I think the difficulty is when you're mixing async/await with raw promises.

- ## When you have a complex series of async functions to call, how do you manage them? 
- https://twitter.com/JoshWComeau/status/1374027384119263233
  - we'll look at 3 different ways, including an *awesome* way that isn't super well-known.
- First, though, let's look at the most straightforward way: serially, one at a time.
  - The beauty of `async/await` is that it lets us read the code in the order it executes. I love how easy it is to understand.
  - The trouble is that it can be quite slow, since none of these tasks can start until the previous one finishes.
- What about `Promise.all` ? Well, we can't dump all 5 into a single call, since there are dependencies.
- From a performance standpoint, this is quite a lot better, since we can let 3 operations run in parallel.
  - But we can make this even faster 
- This final way makes selective use of the `await` keyword. 
  - We can weave the promises together to create a tapestry without gaps. 
  - Each function starts as soon as possible! 
  - The key insight is that promises can be await-ed at any time, not just on creation!
- Which way is best? Well, it depends on the circumstances.
  - The third way is the fastest, but it's also (IMO) the hardest to follow. 
  - We're trading away some simplicity in order to gain some performance.

- ## I don't like much Promise.all
- https://twitter.com/sebastienlorber/status/1379731789707632640
  - Too sensitive to array destructuring typo
  - Code becomes verbose when input to transform is an object
  - Finally published this little utility: combine-promises
- Reminds me of `Promise.props` in Bluebird. 
  - I wonder why something like this wasnâ€™t part of the Promise spec.
- Another big pain point with Promise.all and variations, is error handling IMO (ex: calling 3 APIs from diff providers). It would be awesome if you could solve this in the lib too. I'd love to help, got some ideas on how to go about doing it.

- ## Problem with `Promise.all()` : Once it encounters a rejection, it doesnâ€™t wait until all Promises are settled (short-circuiting (*)). Consequence: Unexpected things can happen after error handling.
- https://twitter.com/rauschma/status/1405568325724291080
- Tentative idea: Promise.forkJoin(objOrArr). Once all Promises are settled:
  - All fulfilled: fulfill result with obj/arr of values
  - 1+ rejected: reject with AggregateError
  - This is what an implementation of forkJoin() could look like:
  - https://gist.github.com/rauschma/bdc56a046b18528959ad1db3eed05386
- What about `Promise.allSettled` ? Iâ€™ve taken to chaining the outcome to array filter and map (depending on intent, of course).
- Thereâ€™s `Promise.allSettled` , combine it with `Promise.all`

- ## Async functions & microtasks
- https://whistlr.info/2021/async-and-tasks/
- When you invoke an `async` function, the function will run its synchronous prefix immediately, but whenever you `await` something, the rest of its code will be put into a microtask.

```JS
console.info('a');
const p = foo(); // call async and hold Promise in p
console.info('b');
p.then(() => {
  console.info('c');
});

async function foo() {
  console.info('1');
  await Promise.resolve(); // actually do something async
  console.info('2');
}
// a 1 b 2 c
```

- Any time we `.then()` a Promise, that callback is executed as a microtaskâ€”broadly, that code is queued to run "immediately", but after the current execution and other microtasks. (And, the same happens when we use `await` on them.) 

- ## With the rise of async-await, I've noticed more and more JS developers have less understanding of concurrency and how to work with async code flow
- https://twitter.com/dev__adi/status/1417554978130915328
- [How to escape from the async/await hell](https://devadi.netlify.app/blog/async-await-hell)
  - While working with Asynchronous JavaScript, people often write multiple statements one after the other and slap an await before a function call. 
  - **This causes performance issues, as many times one statement doesnâ€™t depend on the previous one** â€” but you still have to wait for the previous one to complete.
  - One interesting property of promises is that you can get a promise in one line and wait for it to resolve in another. This is the key to escaping async/await hell.
- How to get out of async/await hell ?
  - Find statements which depend on the execution of other statements
  - Group-dependent statements in async functions
  - Execute these async functions concurrently: Two common patterns of doing this is returning promises early and the `Promise.all` method.

- ## setTimeout using an AbortController and Promise
- https://twitter.com/rikschennink/status/1691417576868380674

- ## Promise resolvers are one of my absolute favorite little programming tools
- https://twitter.com/aboodman/status/1619426079399350272

- I've been looking for a name for this pattern for years. IIRC I've used it mainly in tests

- I think some people call this "deferred"
  - https://github.com/ljharb/promise-deferred

```JS
// https://github.com/rocicorp/resolver

import { resolver } from '@rocicorp/resolver';

const { promise, resolve } = resolver();
resolve(42);
await promise; // 42

class LongRunning {
  async stop() {
    this._stopper = resolve();
    await this._stopper.promise;
  }

  async run() {
    while (!this._stopper) {
      // ...complex asynchronous process...
    }
    this._stopper.resolve();
  }
}
```

- ## ğŸ¤”ğŸ†š I really wish there were Promises in JS that could be evaluated sync. Itâ€™s a complex problem. _202303
- https://twitter.com/trueadm/status/1630739165045194752
- For UI frameworks you want to allow the user to pass a promise, but ensure that if it is ready that you can render synchronously. But `T | Promise<T>` doesnâ€™t compose the way promises do, so either you accept a perf/UX hit, create your own alternate async ecosystem, etc.
  - I use a WeakMap for this. Only pass promise. Lookup resolution value sync via weakmap where you want to do this. Still agree though: custom thenables are great and Promise.resolve using them is great, async/await not using them sucks
- This was discussed ad nauseum a decade ago. If you want sync promises try jQuery. Deferred.
- https://github.com/abbr/deasync
  - DeAsync turns async function into sync, implemented with a blocking mechanism by calling Node.js event loop at JavaScript layer. 
  - The core of deasync is written in C++.
- conclure js Using generators instead of promises allows for a LOT more flexibility, including cancellation, sync resolution, and better testing. The API is strictly the same as async/await

- I definitely want eager await that resolves sync if the promise resolves sync. Thatâ€™s more in the style of callbacks, and allows you to write a single api for both sync and async interfaces.
  - I struggle with this issue in tuple-database. I want to write the same code that works for an async backend or a sync backend. I donâ€™t want to create an intermediate query languageâ€¦
- My problem is actually pretty specific:
  - For tuple-database, there's an async storage interface and a sync storage interface. 
  - The sync interface is important if you want to use it for application state management and stuff. Or maybe you just want to use local storage...
- Since the lowest level abstraction is either sync or async, it pollutes all the code above it which needs to be written to handle both cases.
  - I looked into coroutines, higher-kinded types, monkey-patching promise... 
  - My solution? Regex lol
- Replicache is designed to be used for application state and it is async. We are religious about 60fps. Promises that resolve immediately *are* slower than sync code but weâ€™re taking microseconds. It works great for 60fps in our experience.
  - We have tons of customers in production using Replicache exactly this way (among them @vercel ) and itâ€™s ~instant.
- Yeah, you can definitely get away with async state management most of the time...
  - I'm curious if that can get in the way of typing into an `<input>` if the input's value is updating async as you type...
- Yes you can. We do this while animating at 60fps.
  - We have many users who back input boxes by @replicache directly. It's a design goal of ours to enable this exactly. Try it out, I think it's an overlooked design pattern.
- ğŸ‘‰ğŸ» å…³äºæ¶æ„å±‚syncæˆ–async apiçš„è®¾è®¡ 
  - The other nice thing about making the api to Replicache asynchronous is that it permits falling back to io as necessary. Many sync systems have this problem where these choose sync apis for perf but eventually data gets large and causes excessive gc.
  - If the core API is async it can be up to the sync system to dynamically manage cache size. Replicache does this, lazily caching data from IDB and paging it out after awhile.
- Getting into the weeds though: on iOS Safari, if you want to call focus() on an element to bring up the keyboard, it must be called synchronously in response to a user action event callback... Now, what if they press a button and you want to open a popup and focus the input?
  - https://twitter.com/ccorcos/status/1631159120043835392
  - In React, at least, you're going to want to update the state, synchronously re-render, and then call focus... This *could* work with a sync state update. Unfortunately, React's move towards async rendering throws a wrench in it. But the problem remains the same.
- I am pretty sure it only needs to be called in the same task (queueing a microtask is fine). So if your data is in memory it will still work.

```js
const foo = await Promise.resolve("foo");

// vs:

const foo = await new Promise((res, rej) => setTimeout(res, 0));
```

- The first runs in *same turn* of event loop as calling code, guaranteed. Second gets queued in event loop.
- Microtasks are crazy fast. All they are doing is delaying a function to run later in the turn of the event loop. No actual IO (to disk, network, whatever) can possibly get between the queuing of a microtask and its execution.
- `setImmediate` is not part of the spec or implemented by browsers, but was meant to queue a task. So shorthand for `setTimeout(fn, 0)`.
- A microtask enqueued from within another microtask would execute immediately I believe, but I bet React's whole rendering model probably has its own considerations for this.
  - I think they were also doing some weird stuff with unwrapping resolved promises.. somehow.. maybe an RFC.

- Itâ€™s important to understand that `async` does not mean â€œyield to event loopâ€. When the underlying promise resolves in same event loop task, the resolution will also run in same event loop task. This usually happens when the data needed is already in memory, because itâ€™s cached.
  - Mutations don't need to go through useEffect or similar in the first place because they aren't an effect of render, but of some UI event. So the whole cycle should happen in one frame if your data is in memory, even if all the methods are `async`.

- Yeah, but my goal was to just have one system that can work either sync or async... Perhaps, that's not a great goal, but that's where I landed on these problems... If generators could have a typed yield (similar to  await), then my problem would be solved...
- It's worked really surprisingly well for us. I think UI developers have a phobia of `async` because it often means 'network activity' in classic web apps. But that isn't actually what `async` means to the browser. It just means >= microtask.

- This is good news. Iâ€™ve done cr-sqlite / vlcn as completely async (and had to part ways with collaborators over that decision) so this gives me some reassurance(è‚¯å®šï¼Œä¿è¯).

- Gotta convince everyone to switch to generator-based effects.

- For UI frameworks you want to allow the user to pass a promise, but ensure that if it is ready that you can render synchronously. But `T | Promise<T>` doesnâ€™t compose the way promises do, so either you accept a perf/UX hit, create your own alternate async ecosystem, etc. promises always incur a microtask
  - I use a `WeakMap` for this. Only pass promise. Lookup resolution value sync via weakmap where you want to do this. Still agree though: custom thenables are great and `Promise.resolve` using them is great, async/await not using them sucks

- Have you looked at @EffectTS_ from @MichaelArnaldi . I think he mentioned that Effect is faster than Promise as it is more sync.
  - Yeah effect only forces a micro task every 2048 suspensions of a fiber and a timer after 2048 microtasks have been executed in a row
  - ofc if you use the sync executor it runs fully sync without ever suspending
