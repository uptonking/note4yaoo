---
title: lib-ai-app-community-model
tags: [ai, community]
created: 2023-10-30T07:33:56.233Z
modified: 2023-10-30T07:34:03.602Z
---

# lib-ai-app-community-model

# guide

- tips
  - å¤§æ¨¡å‹ç›¸å…³çš„äº§å“ç ”å‘ï¼ŒåŸç†çš„å¯è§£é‡Šæ€§å¾ˆå·®ï¼Œæ•ˆæœçš„å¯è§£é‡Šæ€§ä¹Ÿå·®

- model-features
  - ğŸ¤¼: speed, quality, size
  - reasoning/thinking
  - tool-use/function-call
  - vision
  - embedding
  - moe
  - æ³¨æ„æœ‰äº›ç¤¾åŒºé‡åŒ–çš„æ¨¡å‹å¯èƒ½é—æ¼æ ‡æ³¨äº†éƒ¨åˆ†features, å¯åœ¨æœ¬åœ°æµ‹è¯•æ¥ç¡®å®šæ˜¯å¦æ”¯æŒ

- ç§»åŠ¨ç«¯å¤§æ¨¡å‹
  - å‚è€ƒgoogle-gemma-1b

- [å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼šä»ç†è®ºåˆ°å®è·µ](https://intro-llm.github.io/)
  - å¤æ—¦å¤§å­¦å¼ å¥‡æ•™æˆå›¢é˜Ÿå†™äº†ä¸€æœ¬åœ¨çº¿å…è´¹çš„ç”µå­ä¹¦ï¼Œå¤§æ¦‚æœ‰ 300 é¡µç¯‡å¹…ï¼Œå°†å¤§æ¨¡å‹ä»ç†è®ºåˆ°å®æˆ˜çš„æ¯ä¸ªé˜¶æ®µéƒ½æè¿°çš„è¾ƒä¸ºæ¸…æ¥š
# discuss-stars
- ## 

- ## ğŸ“Œ LLM å‡ºæ¥ä¹‹åï¼Œåœ¨åº”ç”¨å±‚çš„æŠ˜è…¾ä»æœªåœæ­‡ã€‚ä» Prompt è°ƒä¼˜åˆ° Workflow é…ç½®ï¼Œå†åˆ° Agent æ„å»ºï¼Œæœ€ç»ˆç›®çš„éƒ½æ˜¯ä¸€æ ·çš„ï¼šè®© LLM æ›´å¥½åœ°ä¸ºäººç±»å¹²æ´»ï¼ŒæŠŠæœºå™¨çš„æ€§èƒ½å‹æ¦¨åˆ°æè‡´ã€‚
- https://x.com/Barret_China/status/1973188130091180466
- å¯¹ LLM çš„å‹æ¦¨ï¼Œå¯ä»¥åˆ†ä¸ºä¸¤ä¸ªç»´åº¦ã€‚
- ä¸€æ˜¯å¸®åŠ©å®ƒæ‰¾åˆ°æœ€ä¼˜ç®—æ³•ï¼Œè®©æ¨ç†å°‘èµ°å¼¯è·¯ã€‚
  - ä¸ºæ­¤æˆ‘ä»¬å‡ ä¹æŠŠèƒ½æƒ³åˆ°çš„è·¯å­éƒ½èµ°äº†ä¸€éï¼Œè®© LLM å­¦ä¼šåæ€ï¼ˆreflectionã€self-consistencyã€self-criticsï¼‰ï¼Œå­¦ä¼šæ¨ç†å’Œè§„åˆ’ï¼ˆreasoningã€planningã€chain-of-thoughtã€tree-of-thoughtï¼‰ï¼›å­¦ä¼šè®°å¿†ï¼ˆshort-term memoryã€long-term memoryï¼‰ï¼Œä¸è‡³äºå¯¹è¯ä¸€é•¿å°±å¤±å¿†ï¼›å­¦ä¼šæ‰¾çŸ¥è¯†ï¼ˆRAGã€knowledge graphï¼‰ï¼Œåœ¨å¤–éƒ¨ä¸–ç•Œé‡Œè¡¥å……äº‹å®ï¼›å­¦ä¼šæ„å»ºä¸Šä¸‹æ–‡ï¼ˆcontext buildingï¼‰ï¼Œåœ¨æœ‰é™ token é‡Œå¡ä¸‹æ›´å¤šæœ‰æ•ˆä¿¡æ¯ï¼›å­¦ä¼šç”¨å·¥å…·ï¼ˆtool-useï¼Œfunction callingï¼ŒMCPï¼‰ï¼ŒæŠŠäº‹æƒ…äº¤ç»™å¤–éƒ¨ç¨‹åºå»è·‘ï¼Œè€Œä¸æ˜¯å…‰é è‡ªå·±ç”Ÿæˆï¼›ç­‰ç­‰ã€‚
  - è¿™äº›ä¸œè¥¿ï¼Œè¯´åˆ°åº•éƒ½æ˜¯æŠ€å·§å’Œæœºåˆ¶ï¼Œæœ¬è´¨ç›®çš„æ˜¯è®© LLM æ›´å¿«ç†è§£äººç±»è¦å¹²å•¥ï¼Œå›´ç»•ç›®æ ‡ï¼ˆgoal-orientedï¼‰å°½å¯èƒ½æ‰¾åˆ°ä¸€æ¡ä»£ä»·æœ€å°çš„è·¯ï¼Œè·‘åˆ°æœ€ä¼˜è§£ä¸Šå»ã€‚
- ç¬¬äºŒä¸ªç»´åº¦ï¼Œæ˜¯å¯¹æ—¶é—´çš„å‹æ¦¨ï¼Œè®© LLM å¯ä»¥åšåˆ° 7Ã—24 å°æ—¶ä¸åœæ­‡ã€‚
  - å½“æˆ‘ä»¬å¯¹ LLM æœ‰äº†æ›´æ·±å…¥çš„ç†è§£ä¹‹åï¼Œå¾ˆå®¹æ˜“æƒ³åˆ°æŠŠå®ƒæ‰“é€ æˆå±äºè‡ªå·±æˆ–ç»„ç»‡çš„â€œæ•°å­—å‘˜å·¥â€ï¼Œå®ƒä¸çŸ¥ç–²æƒ«ã€ä¸ä¼šæŠ±æ€¨ï¼Œå¯ä»¥æŒç»­è¿è½¬ã€ä¸æ–­å­¦ä¹ ã€‚
- å¤§éƒ¨åˆ†äººä»Šå¤©ç”¨ AI çš„æ–¹å¼ï¼Œè¿˜åœç•™åœ¨æŸ¥èµ„æ–™ã€æ€»ç»“å†…å®¹ã€å†™å‘¨æŠ¥æœˆæŠ¥è¿™äº›å•ç‚¹åœºæ™¯ä¸Šï¼Œå¦‚æœè¦çœŸæ­£æ„å»ºä¸€åâ€œä¸åœæ­‡çš„ AI æ•°å­—å‘˜å·¥â€ï¼Œå…‰é è¿™äº›è¿˜ä¸å¤Ÿã€‚æˆ‘ä»¬éœ€è¦å…ˆè§„åˆ’å‡ºå±äºè‡ªå·±çš„ AI æ•°å­—å·¥å‚ â€”â€”æƒ³æ¸…æ¥šè¦é€ å‡ºæ¥çš„â€œäº§å“â€æ˜¯ä»€ä¹ˆï¼Œæ˜¯æ²‰æ·€çŸ¥è¯†çš„ç³»ç»Ÿï¼Œæ˜¯è‡ªåŠ¨åŒ–çš„ä¸šåŠ¡æµç¨‹ï¼Œè¿˜æ˜¯ä¸€ä¸ªå¯ä»¥é•¿æœŸè¿­ä»£çš„æœåŠ¡ã€‚
  - åœ¨è¿™åº§å·¥å‚é‡Œï¼ŒAI æ˜¯ç”Ÿäº§çº¿ä¸Šçš„æ‰§è¡Œè€…ï¼Œå®ƒè´Ÿè´£å…·ä½“çš„åŠ å·¥ä¸äº§å‡ºï¼›è€Œäººç±»çš„è§’è‰²å‘ç”Ÿäº†è½¬å˜ï¼Œä»â€œäº²è‡ªå¹²æ´»çš„å·¥äººâ€å˜æˆâ€œç›‘å·¥ä¸ç®¡ç†è€…â€ã€‚ äººç±»ä¸å†äº²æ‰‹å®Œæˆæ¯ä¸€æ­¥ï¼Œè€Œæ˜¯è¦è®¾è®¡æµæ°´çº¿ï¼Œè®¾å®šè§„åˆ™ï¼Œåˆ¶å®šæŒ‡æ ‡ï¼Œç›‘æ§è´¨é‡ï¼Œå¹¶åœ¨éœ€è¦æ—¶è°ƒåº¦èµ„æºã€‚æ¢å¥è¯è¯´ï¼ŒAI çš„ä»·å€¼ä¸åœ¨äºæ›¿æˆ‘ä»¬â€œå¹²ä¸€ç‚¹æ´»â€ï¼Œè€Œåœ¨äºå¸®æŠŠæ•´æ¡æµæ°´çº¿è·‘èµ·æ¥ï¼Œè€Œäººç±»æ›´åƒæ˜¯â€œæ•°å­—å·¥å‚çš„ç®¡ç†è€…â€ã€‚
  - å½“è¿™ä¸¤ä¸ªç»´åº¦ç»“åˆèµ·æ¥æ—¶ï¼ŒçœŸæ­£çš„æ‹ç‚¹å°±å‡ºç°äº†ã€‚LLM ä¸å†åªæ˜¯ä¸€ä¸ªå†·å†°å†°çš„å·¥å…·ï¼Œè€Œæ˜¯é€æ¸å˜æˆäº†å¯ä»¥é•¿æœŸåä½œçš„ä¼™ä¼´ã€‚å®ƒæ—¢èƒ½æ‰¿æ‹…é‡å¤æ€§åŠ³åŠ¨ï¼Œä¹Ÿèƒ½åœ¨å¤æ‚é—®é¢˜ä¸Šæä¾›æ´è§ã€‚å®ƒä¸ä»…ä»…æ˜¯â€œå¸®ä½ åšäº‹â€ï¼Œæ›´æ˜¯â€œå’Œä½ ä¸€èµ·åšäº‹â€ã€‚
  - æœªæ¥çš„å·®è·ï¼Œä¸åœ¨äºè°èƒ½å†™å‡ºæ›´æ¼‚äº®çš„ Promptï¼Œè€Œåœ¨äºè°èƒ½æŠŠ LLM çœŸæ­£èå…¥åˆ°è‡ªå·±çš„æ—¶é—´å’Œç»„ç»‡é‡Œï¼Œå½¢æˆç¨³å®šçš„ç”Ÿäº§æ–¹å¼ã€‚
  - å› æ­¤ï¼Œä¼šä¸ä¼šç”¨ã€ç”¨åˆ°ä»€ä¹ˆæ·±åº¦ã€èƒ½å¦æŒç»­ä¼˜åŒ–ï¼Œè¿™äº›æ‰æ˜¯é•¿æœŸçš„ç«äº‰åŠ›æ¥æºã€‚è°èƒ½æŠŠ AI è¿è¡Œæˆâ€œå·¥å‚â€ï¼Œè®©è‡ªå·±ä»æ‰§è¡Œè€…è½¬ä¸ºç›‘å·¥å’Œç®¡ç†è€…ï¼Œè°å°±èƒ½åœ¨æœªæ¥çš„æ—¥å¸¸å·¥ä½œå’Œä¸šåŠ¡ä¸­ï¼Œè·å¾—çœŸæ­£å¯å¤ç”¨ã€å¯ç´¯ç§¯çš„ä¼˜åŠ¿ã€‚

- ä»£ç æŠ½è±¡çœŸå®ä¸–ç•Œçš„æ—¶ä»£å¿«è¦ç»“æŸäº†ï¼Œæ¬¢è¿æ¥åˆ°token æŠ½è±¡çœŸå®ä¸–ç•Œçš„æ—¶ä»£ã€‚

- å¦‚æœTOKENæŠ•å…¥äº§å‡ºæ˜¯æ­£å‘çš„ï¼Œæ¨ä¸å¾—ä»–ä¸ä¼‘æ¯ 

- é—®é¢˜æ¥äº†ï¼Œæˆ‘è¦åšä»€ä¹ˆï¼ŒAIè¦æ€ä¹ˆå¸®æˆ‘åš

- ## ğŸ“± [ç«¯ä¾§æ¨¡å‹ä¼šæ˜¯ AI æŠ€æœ¯æ¼”è¿›çš„ä¸‹ä¸€ä¸ª ã€Œå¿…äº‰ä¹‹åœ°ã€ å—ï¼Ÿå½“å‰è½åœ°é¢ä¸´å“ªäº›æ ¸å¿ƒç“¶é¢ˆï¼Ÿ - çŸ¥ä¹](https://www.zhihu.com/question/1914319403023032351)
- TO Cåœºæ™¯åº”ç”¨æœ€å¤§ç‰¹ç‚¹æ˜¯ç¡¬ä»¶å‚å·®ä¸é½ã€‚æ€§èƒ½å·®èƒ½å¤§åˆ°10å¤šå€ä»¥ä¸Šã€‚
  - æŠ€æœ¯æ ˆå¿…é¡»æ»¡è¶³æ‰€æœ‰ä¸»æµç¡¬ä»¶ç»“æ„å·®å¼‚å’Œæ€§èƒ½æ€§èƒ½ä¸‹ï¼Œä¿æŒç›¸å¯¹ä¸€è‡´çš„ä½¿ç”¨ä½“éªŒã€‚è¿™æ˜¯ä¸€ä»¶æç´¯çš„æ´»å„¿ã€‚
  - æœåŠ¡ç«¯ä¸‹ä¸ªå¼€æºæ¨¡å‹æ­ä¸ªWEBæœåŠ¡å†™ä¸ªHTMLå°±èƒ½å–æœåŠ¡äº†ã€‚ç«¯ä¾§æƒ³å†…åµŒAIæ¨¡å‹äº§å“åŒ–ï¼ŒåŒæ—¶è¿˜è¦è§£å†³å®æ—¶æ€§ï¼Œè¦è§£å†³çš„å·¥ç¨‹é—®é¢˜è¦å¤š10å€ä¸æ­¢ã€‚è¦è‡ªå·±ä¼˜åŒ–æ¨¡å‹ã€‚ç”šè‡³è¦è‡ªå·±æ­å»ºæ¨¡å‹ç»“æ„ï¼Œè‡ªå·±å‡†å¤‡æ•°æ®è®­ç»ƒã€‚
- ç›®å‰çœ‹ç«¯ä¾§å®Œå…¨è°ˆä¸ä¸ŠAIæ¼”è¿›å¿…äº‰ä¹‹åœ°ã€‚ä¸€æ¥ç¡¬ä»¶è¾ƒå¼±ä¸”å‚å·®ä¸é½ï¼Œå¯¼è‡´TO Cå·¥ç¨‹ä¿éšœä½“éªŒæåº¦å›°éš¾å’Œå¤æ‚ã€‚äºŒæ¥PCé«˜ç®—åŠ›ç¡¬ä»¶å®Œå…¨ä¸æ˜¯å¤§ä¼—æ¶ˆè´¹çº§çš„å”®ä»·å’Œå®šä½ï¼Œæœ€åï¼Œè¿˜æ²¡æœ‰ä»€ä¹ˆç«¯ä¾§AIè½åœ°äº§å“çš„åº”ç”¨èŒƒå¼ã€‚
  - ä»åº”ç”¨ä½“éªŒä¸Šï¼Œé‚£äº›å…è®¸å»¶è¿Ÿ500æ¯«ç§’ä»¥ä¸Šï¼Œå¯¹å¸¦å®½éœ€æ±‚ä¸å¤§çš„åº”ç”¨ï¼Œéƒ½å¯ä»¥æ”¾åˆ°äº‘ç«¯ã€‚
- çœŸéœ€è¦åšåˆ°ç«¯ä¾§çš„ï¼Œå…¶å®æ˜¯é‚£äº›éœ€è¦å³æ—¶å“åº”çš„åº”ç”¨åœºæ™¯ã€‚
  - ä¸ºæ•°ä¸å¤šçš„åº”ç”¨ç±»åˆ«ï¼Œæ¯”å¦‚å³æ—¶äº¤äº’å½±åƒç›¸å…³ï¼Œè¯­éŸ³ç›¸å…³çš„ï¼Œè¯¸å¦‚æ¸¸æˆï¼Œéœ€è¦å³æ—¶äº¤äº’çš„æ•°å­—äººï¼Œ3Dè™šæ‹ŸAIäººï¼Œè™šæ‹Ÿäººç›´æ’­ç­‰ï¼Œå¯èƒ½ä¼šå¯¹ç«¯ä¾§AIæœ‰éƒ¨åˆ†éœ€æ±‚
- è¿™ç±»åº”ç”¨æœ‰3ä¸ªç‰¹å¾ï¼š 
  - 1 å³æ—¶æ€§ç›´æ¥å½±å“ä½“éªŒï¼Œä¸èƒ½ç­‰ã€‚ 
  - 2 å¯¹ç®—åŠ›è¦æ±‚ç›¸å¯¹ä½ï¼Œè¿ç®—æœ¬åœ°ç®—åŠ›èƒ½å¤Ÿæ»¡è¶³ï¼Œå¹¶ä¸ä¸€å®šéè¦äº‘ç®—åŠ›æ”¯æŒã€‚ 
  - 3 å¯¹å¸¦å®½è¦æ±‚è¾ƒå¤§ï¼Œäº‘æœåŠ¡çš„æˆæœ¬è¿‡é«˜ä½¿å¾—å•†ä¸šæ¨¡å¼ä¸æˆç«‹ï¼Œæ‰€ä»¥éœ€è¦æ”¾å…¥æœ¬åœ°ã€‚
- MOBILEç¦»ç«¯ä¾§å¯èƒ½æ›´è¿œã€‚ ç”±äºç®—åŠ›æä¸ºä½ä¸‹ï¼Œåªæœ‰å¾ˆå°‘çš„æƒ…å†µæ‰éœ€è¦æ‰‹æœºä¸Šå³æ—¶å“åº”AIæ¨ç†ç»™å‡ºçš„ç»“æœã€‚å³é‚£äº›æŠŠæ‰‹æœºä½œä¸ºä¿¡å·ä¼ æ„Ÿå™¨ï¼Œå³æ—¶å¯¹ä¿¡å·è¿ç®—çš„åœºåˆï¼šæ¯”å¦‚è¡¨æƒ…æ•æ‰ã€æ‰‹åŠ¿ã€è‚¢ä½“åŠ¨ä½œæ•æ‰å’Œè¯†åˆ«ï¼Œè¯­éŸ³ã€è¿åŠ¨æ•°æ®å¤„ç†å’Œç”Ÿç‰©ä¿¡å·å¤„ç†ç­‰ã€‚ 
  - å¦‚æœæ‰‹æœºæ²¡æœ‰ä¸“ç”¨ç¥ç»/å¼ é‡èŠ¯ç‰‡ï¼ŒGPUè¿˜éœ€è¦æ‰¿æ‹…æ¸²æŸ“3Då›¾å½¢ï¼Œé‚£ä¹ˆèƒ½è·‘çš„AIæ¨¡å‹ä¼šæ›´åŠ å—é™ã€‚
  - ç›®å‰æµ‹è¯•ï¼ŒæŸæ‰‹æœºç”¨NPUè·‘æ¨¡å‹æ¯”ä¸ç”¨æœ€å¤šèƒ½å¿«10å€ã€‚ 
  - æ‰‹æœºèŠ¯ç‰‡å•†æ˜¯å¦æœ‰åŠ¨åŠ›å‘å±•ï¼Œè¦çœ‹æ‰‹æœºä½œä¸ºæ•°æ®ä¼ æ„Ÿå™¨å³æ—¶å¤„ç†æ•°æ®èƒ½å¸¦æ¥å¤šå¤§çš„åº”ç”¨å¸‚åœºã€‚

- æœ¬åœ°éƒ¨ç½²æ¨¡å‹çš„ä¼˜åŠ¿åœ¨äºä½å»¶è¿Ÿï¼Œè¿™åœ¨æˆ‘çœ‹æ¥å…¶å®ä¹Ÿæ˜¯ä¸ªç›¸å¯¹åä¼ªçš„ä¼˜åŠ¿ã€‚
  - äº‹å®ä¸Šï¼Œç°ä»£ç½‘ç»œç¯å¢ƒå®é™…ä¸Šä»¥åŠè¶³å¤Ÿå¿«é€Ÿå’Œç¨³å®šï¼Œæ— è®ºæ˜¯æµé‡è¿˜æ˜¯WiFiï¼Œè¾…ä»¥CDNè¾¹ç¼˜èŠ‚ç‚¹ä¼˜åŒ–åï¼Œç»å¤§å¤šæ•°ä¸»æµAIåº”ç”¨çš„äº‘ç«¯å“åº”éƒ½èƒ½ç¨³å®šåœ¨å‡ åæ¯«ç§’ä»¥å†…ã€‚
- ç«¯ä¾§è®¾å¤‡å—é™äºåŠŸè€—ã€çƒ­é‡ã€ç®—åŠ›ç­‰ç‰©ç†æ¡ä»¶ï¼Œå¾€å¾€åªèƒ½éƒ¨ç½²è½»é‡åŒ–æ¨¡å‹

- ç§»åŠ¨è®¾å¤‡ä¸Šé•¿æœŸè¿è¡Œä¸€ä¸ªæœ‰ç«äº‰åŠ›çš„å¤§æ¨¡å‹ä»ç„¶ä¸ç°å®ï¼Œè´Ÿè½½ã€èµ„æºå ç”¨ã€ç”µé‡æ¶ˆè€—ã€å‘çƒ­ç­‰ç­‰é—®é¢˜ï¼Œå¾ˆéš¾åšåˆ°å¥½çš„ä½“éªŒï¼Œæ›´ä¸è¦è¯´ç‰©è”ç½‘è®¾å¤‡ã€æ™ºèƒ½éŸ³ç®±ç­‰ä½åŠŸè€—äº§å“äº†ã€‚
  - å¾ˆå¤šå£°ç§°è‡ªå·±ç”¨äº†ç«¯ä¾§å¤§æ¨¡å‹çš„ï¼Œå®é™…ä¸Šä»ç„¶ç¦»ä¸å¼€äº‘ç«¯çš„ååŒé…åˆï¼Œæˆ–è€…è¯´ä¸»è¦é äº‘ç«¯ï¼Œå¤‡ç”¨æ–¹æ¡ˆå¯èƒ½æ˜¯ç«¯ä¾§ï¼Œä½†æŠŠç«¯ä¾§æ‹¿å‡ºæ¥å¤§è‚†å®£æ‰¬ï¼Œæ¥åšå¹¿å‘Šè€Œå·²ã€‚

- ğŸ› ç«¯ä¾§æ¨¡å‹çš„åŠ£åŠ¿
  - ç«¯ä¾§æ¨¡å‹ä»ç„¶å—é™äºè®¾å¤‡æœ¬èº«çš„å†…å­˜ã€åŠŸè€—å’Œç®—åŠ›
  - äº‘ç«¯æ¨¡å‹å¯ä»¥éšæ—¶å‡çº§ï¼Œçƒ­æ›´æ–°æœºåˆ¶ä¿è¯æ‰€æœ‰ç”¨æˆ·ç¬¬ä¸€æ—¶é—´äº«å—æ–°ä¸€ä»£æ¨¡å‹
  - ç«¯ä¾§æ¨¡å‹å¯¹äºä¸åŒè®¾å¤‡å’Œç¡¬ä»¶æ¶æ„éœ€è¦åˆ†åˆ«é€‚é…

- ç«¯ä¾§é€‚åˆçš„åœºæ™¯è¿˜æ˜¯éšç§ã€æä½å»¶è¿Ÿï¼Œæˆ–è€…å…¨å¤©å€™ã€‚

- å¦‚æœå®Œå…¨è·‘åœ¨ç«¯ä¾§ï¼Œé‚£å•†ä¸šæ¨¡å¼æ€ä¹ˆåšï¼Ÿç°åœ¨çš„ä¸»æµæ˜¯è®¢é˜…åˆ¶ï¼Œä½†å®Œå…¨æœ¬åœ°çš„è®¢é˜…åˆ¶ï¼Œå¸å¼•åŠ›æ¯”è¾ƒä½ï¼Œç ´è§£é£é™©æ¯”è¾ƒé«˜å§

- ## deepseek 3fs å…¶å®ä¸æ˜¯å¾ˆç†è§£è¿™æ ·çš„æ„ä¹‰æ˜¯å•¥â€¦ å·²ç»è„±ç¦» FS çš„é€šç”¨æ¥å£äº†ï¼Œä¸ºå•¥è¦ç¡¬æŒ‚ä¸€ä¸ª FUSE VFS å±‚â€¦ ç›´æ¥æ‘’å¼ƒ VFS èµ°ä¸ªç§æœ‰çš„ protocol ä¸å¹²å‡€å¤šäº†â€¦
- https://x.com/silsrc/status/1895390926098571505
- > Most applications use FUSE client, which has a low adoption barrier. Performance-critical applications are integrated with the native client.

- æˆ‘çš„ç¬¬ä¸€ååº”æ˜¯ç°æœ‰æ¡†æ¶åº”è¯¥æ²¡åŠæ³•å¤§æ‰¹é‡æ”¹ç”¨ç§æœ‰çš„ APIï¼Œæ¯”å¦‚åœ¨ Python æˆ‘å°±æ˜¯è¦ç”¨ pathlib. Path å¯¹æ–‡ä»¶åšç‚¹ç®€å•æ“ä½œï¼Œé‚£ç¡®å®åªèƒ½æ˜¯æŒ‚ FUSE ä¸Šå»äº†

- ## èŠä¸€èŠå›½å†…å¤§æ¨¡å‹çš„å®‰å…¨æœºåˆ¶ï¼š ä¸€èˆ¬æ˜¯ä¸¤å¥—ï¼Œåˆ†åˆ«ä½œç”¨äºtrain-timeå’Œtest-timeã€‚
- https://x.com/9hills/status/1840786446153921017
  - è®­ç»ƒçš„æ—¶å€™å¢åŠ å®‰å…¨å’Œä»·å€¼è§‚å¯¹é½çš„SFTå’Œåå¥½å¯¹é½æ•°æ®ã€‚æœ€ç»ˆæ•ˆæœç±»ä¼¼å¼€æºçš„Qwen2æ¨¡å‹ï¼Œæœ‰ç‚¹ç”¨ä½†æ˜¯å¾ˆå®¹æ˜“è¢«Jailbreakã€‚
  - æ¨ç†æ—¶å¢åŠ å®‰å…¨ç®—å­ï¼Œå…·ä½“æœ‰å‡ ç§
- æŠ€æœ¯éš¾ç‚¹æœ‰ä¸¤ä¸ªï¼š
  1. è®­ç»ƒåˆ†ç±»å™¨çš„å¤§é‡éå®‰å…¨æ•°æ®ï¼Œæ‰€ä»¥è¯´ä½ å…ˆæˆä¸ºåè´¼æ‰èƒ½è¯†åˆ«åè´¼ã€‚
  2. æ¨¡å‹è¦åšçš„è¶³å¤Ÿå°è¶³å¤Ÿå¿«ï¼Œæœ€å°åŒ–å½±å“æ¨¡å‹ttftå’Œtpsã€‚
  3. æµå¼å¾ˆéš¾ï¼ŒæŸæ¨¡å‹æœ€æ—©æ˜¯ä¸€å¥å¥è¾“å‡ºçš„ï¼Œåæ¥æ‰æ”¹æˆtokençº§æµå¼ã€‚
- è¯·æ•™ä¸€ä¸‹ï¼Œç°åœ¨å¸‚åœºä¸Šçš„å¤§æ¨¡å‹ï¼Œæ€ä¹ˆçŸ¥é“ä»–ä»¬çš„è®­ç»ƒæ•°æ®æ˜¯å¤šä¹…çš„å‘¢ï¼Ÿ
  - å¯ä»¥é—®ä¸€äº›ç‰¹å®šæ—¶é—´çš„æ–°é—»æ¥éªŒè¯ï¼Œä½†æ˜¯å…¶å®æ²¡å…³ç³»ã€‚æ¨¡å‹çš„ç²¾ç¡®çŸ¥è¯†ä¸é‡è¦ï¼Œä¹Ÿå……æ»¡å¹»è§‰ã€‚

- ## Attention is *Not* All You Needï¼Œè¿˜æ˜¯æœ‰äººåœ¨å°è¯• transformer ä»¥å¤–çš„æ¶æ„ï¼Œ
- https://x.com/liumengxinfly/status/1835251398692508114
  - æ¯•ç«Ÿ transfermor æ¨ç†å¤æ‚åº¦åœ¨æ•°å­¦ä¸Šæ˜¯æ— æ³•çº¿æ€§æ‰©å±•çš„ï¼Œæ—©æ™šä¼šèµ°åˆ°ç“¶é¢ˆ

- ## å›½äº§188ä¸ªå¤§æ¨¡å‹çš„excelæ–‡æ¡£ï¼š åŒ—äº¬69 ä¸Šæµ·22 æ­å·15 å¹¿ä¸œ26ä¸ª æ±Ÿè‹15ä¸ª
- https://twitter.com/FinanceYF5/status/1730912502312296935
  - [å›½äº§å¤§æ¨¡å‹188ä¸ªlist - Feishu Docs](https://zw73xyquvv.feishu.cn/wiki/WXLmwBbYuiTobkkJ6Ojc2cxqnj0?sheet=2XjJlJ&table=tblS2Jv7isKtSODz&view=vewfCdOf0U)

# discuss-llm-architecture
- ## 

- ## 

- ## 

- ## 

- ## 

- ## [I Built Pocket Flow, an LLM Framework in just 100 Lines â€” Here is Why _202503](https://medium.com/@zh2408/i-built-an-llm-framework-in-just-100-lines-83ff1968014b)
- After a year of struggling with bloated frameworks, I decided to strip away anything unnecessary. The result is Pocket Flow, a minimalist LLM framework in just 100 lines of code.

- After a year of building LLM applications from scratch, I had a revelation: beneath all the complexity, LLM systems are fundamentally just simple directed graphs.
  -  By stripping away the unnecessary layers, I created Pocket Flow â€” a framework with zero bloat, zero dependencies, and zero vendor lock-in, all in just 100 lines of code.
- We also support batch processing, asynchronous execution, and parallel processing for both nodes and flows.

- Unlike other frameworks, Pocket Flow deliberately avoids bundling vendor-specific APIs. 
  - No Vendor Lock-in: Youâ€™re free to use any model you want, including local models like OpenLLaMA, without changing your core architecture.

- [I Built an LLM Framework in 179 Linesâ€”Why Are the Others So Bloated?  : r/LangChain _202502](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/)
- I had a look at the code. You've built a simple state machine. 
  - State machine are almost aways the worst time of choice when it comes to composition. 
  - In other words organising everything in flows of Nodes while still writing code is worse then for example carefully providing the data structures yourself and deal with the concurrency and dataflow based on the application specific requirements.
- Thanks for the feedback and example. I opted for a state machine for its simplicity! I'm open to finding a way to balance simple state transitions with tailored data structures though

- how is this different to the approach LangGraph took?
  - We think LangGraphâ€™s approach can feel rigid and tends to enforce a strictly linear, single-threaded execution model! We also want to do more than just manage state transitions!!
  - For example, we can handle asynchronous capabilitiesâ€”like node cloning to avoid race conditions and dedicated AsyncParallelBatchNodes and AsyncParallelBatchFlowsâ€”to enable parallel execution. This means you can run I/O-bound tasks concurrently (such as multiple LLM calls) without being restricted to a single-threaded, linear flow.

- ## ğŸ¤” [I built an AI orchestration platform that breaks your promot and runs GPT-5, Claude Opus 4.1, Gemini 2.5 Pro, and 17+ other models together - with an Auto-Router that picks the best approach : r/LocalLLaMA _202510](https://www.reddit.com/r/LocalLLaMA/comments/1o76n9d/i_built_an_ai_orchestration_platform_that_breaks/)
  - I've been frustrated with choosing between AI models - GPT-5 is great at reasoning, Claude excels at creative writing, Gemini handles data well, Perplexity is best for research - so I built LLM Hub to orchestrate them all intelligently.
  - [LLM HUB - AI Pipeline Orchestration](https://llm-hub.tech/)
  - The Core Problem: Each AI has strengths and weaknesses. Using just one means compromising on quality.
  - ğŸ’¡ The Solution: LLM Hub coordinates 20+ models across 4 execution modes:
- 4 EXECUTION MODES:
  - Single Mode - One model, one response (traditional chat)
  - Sequential Mode - Chain models where each builds on the previous (research â†’ analysis â†’ writing)
  - Parallel Mode - Multiple models tackle the same task, synthesized by a judge model
  - ğŸŒŸ Specialist Mode (the game-changer) - Breaks complex tasks into up to 4 specialized segments, routes each to the expert model, runs them in parallel, then synthesizes everything

- ## Code2Video - é€šè¿‡ä»£ç ç”Ÿæˆæ•™è‚²è§†é¢‘çš„ AI Agent æ¡†æ¶ï¼Œæ¥è‡ªæ–°åŠ å¡å›½ç«‹å¤§å­¦ Show Lab çš„æœ€æ–°ç ”ç©¶ï¼Œè®ºæ–‡å’Œå¼€æºé¡¹ç›®éƒ½å‘å¸ƒäº†ã€‚
- https://x.com/shao__meng/status/1974280130420961548
  - é€šè¿‡ AI Agent çš„æ–¹å¼ç”Ÿæˆç±»ä¼¼ 3Blue1Brown çš„è§†é¢‘ï¼Œå¾ˆæœ‰è¶£ï¼Œå’±ä»¬ä¸€èµ·çœ‹çœ‹ã€‚
  - æ–¹æ³•æ ¸å¿ƒï¼šä¸‰æ™ºèƒ½ä½“åä½œ, è®¾è®¡æ¡†æ¶åˆ†è§£ä»»åŠ¡ä¸ºä¸‰ä¸ªåä½œæ™ºèƒ½ä½“ï¼Œå½¢æˆæ¨¡å—åŒ–ç®¡é“ï¼š
  - Â· Plannerï¼ˆè§„åˆ’è€…ï¼‰ï¼šä»å­¦ä¹ ä¸»é¢˜ï¼ˆå¦‚â€œçº¿æ€§å˜æ¢ä¸çŸ©é˜µâ€ï¼‰ç”Ÿæˆå¤§çº²å’Œæ•…äº‹æ¿ï¼Œç¡®ä¿æ—¶é—´è¿è´¯æ€§ï¼ˆå¦‚æ¦‚å¿µå¼•å…¥ã€æ‰©å±•å’Œå›é¡¾ï¼‰ã€‚å®ƒé›†æˆå¤–éƒ¨æ•°æ®åº“ï¼Œæ£€ç´¢å‚è€ƒå›¾åƒå’Œè§†è§‰èµ„äº§ï¼ˆå¦‚å›¾æ ‡ï¼‰ï¼Œå¹¶è€ƒè™‘å—ä¼—æ°´å¹³ï¼ˆå¦‚é«˜ä¸­ç”Ÿ vs. å¤§å­¦ç”Ÿï¼‰ï¼Œä»¥æå‡äº‹å®å‡†ç¡®æ€§å’Œè§†è§‰ä¸€è‡´æ€§ã€‚
  - Â· Coderï¼ˆç¼–ç è€…ï¼‰ï¼šå°†æ•…äº‹æ¿è½¬æ¢ä¸ºå¯æ‰§è¡Œ Manim åŠ¨ç”»ä»£ç ã€‚é‡‡ç”¨å¹¶è¡Œåˆæˆç­–ç•¥åŠ é€Ÿç”Ÿæˆï¼Œå¹¶å¼•å…¥ ScopeRefineï¼ˆèŒƒå›´å¼•å¯¼ä¿®å¤ï¼‰æœºåˆ¶ï¼šä»è¡Œçº§ï¼ˆå±€éƒ¨ä¿®å¤é”™è¯¯è¡Œï¼‰é€æ­¥æ‰©å±•åˆ°å—çº§å’Œå…¨å±€é‡ç”Ÿï¼Œç¡®ä¿ä»£ç é«˜æ•ˆä¸”æ— è¯­æ³•é”™è¯¯ï¼ŒåŒæ—¶ä¿æŒè·¨èŠ‚ä¸€è‡´æ€§ã€‚
  - Â· Criticï¼ˆæ‰¹è¯„è€…ï¼‰ï¼šä½¿ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰å’Œé”šç‚¹è§†è§‰æç¤ºï¼ˆå¦‚å ç”¨è¡¨å’Œä½ç½®ç½‘æ ¼ï¼‰è¿­ä»£ç²¾ç‚¼æ¸²æŸ“è§†é¢‘ã€‚é’ˆå¯¹ç©ºé—´é—®é¢˜ï¼ˆå¦‚é‡å æˆ–ç©ºæ—·åŒºåŸŸï¼‰ï¼Œå®ƒæä¾›å…·ä½“è§£å†³æ–¹æ¡ˆï¼ˆå¦‚è°ƒæ•´å¯¹è±¡ä½ç½®æˆ–ç¼©æ”¾ï¼‰ï¼Œæå‡å¸ƒå±€æ¸…æ™°åº¦å’Œæ•™è‚²å¸å¼•åŠ›ã€‚
  - æ•´ä¸ªæµç¨‹ä»ç”¨æˆ·æŸ¥è¯¢è¾“å…¥ï¼Œåˆ°è¾“å‡ºæ•™è‚²è§†é¢‘ï¼Œé€šå¸¸éœ€æ•°åˆ†é’Ÿæ¸²æŸ“ï¼Œè¿œä¼˜äºç«¯åˆ°ç«¯åƒç´ ç”Ÿæˆã€‚

- ## [å¦‚ä½•çœ‹å¾…è§‚ç‚¹ï¼šAI çš„å…³é”®ç‚¹ä¸æ˜¯promptï¼Œè€Œæ˜¯Context Engineeringï¼Ÿ - çŸ¥ä¹](https://www.zhihu.com/question/1923364519964545063)
- Contextè¿œä¸æ­¢æ˜¯ä¸€å¥promptï¼Œå®ƒåŒ…æ‹¬ï¼š
  - æŒ‡ä»¤/ç³»ç»Ÿæç¤ºï¼šå®šä¹‰æ¨¡å‹è¡Œä¸ºçš„åˆå§‹æŒ‡ä»¤
  - ç”¨æˆ·æç¤ºï¼šæ¥è‡ªç”¨æˆ·çš„å³æ—¶ä»»åŠ¡æˆ–é—®é¢˜
  - çŠ¶æ€/å†å²ï¼šå½“å‰å¯¹è¯çš„çŸ­æœŸè®°å¿†
  - é•¿æœŸè®°å¿†ï¼šè·¨å¤šæ¬¡å¯¹è¯æ”¶é›†çš„æŒä¹…
  - çŸ¥è¯†åº“æ£€ç´¢ä¿¡æ¯(RAG)ï¼šæ¥è‡ªæ–‡æ¡£ã€æ•°æ®åº“æˆ–APIçš„å¤–éƒ¨çŸ¥è¯†
  - å¯ç”¨å·¥å…·ï¼šæ¨¡å‹å¯ä»¥è°ƒç”¨çš„æ‰€æœ‰åŠŸèƒ½å®šä¹‰
  - ç»“æ„åŒ–è¾“å‡ºï¼šå¯¹æ¨¡å‹å“åº”æ ¼å¼çš„å®šä¹‰
- è¿™å…¶å®å°±æ˜¯åœ¨æ„å»ºä¸€ä¸ªå®Œæ•´çš„ã€ŒAIå·¥ä½œç¯å¢ƒã€ï¼Œè€Œä¸æ˜¯ç®€å•åœ°ç»™AIä¸‹æŒ‡ä»¤ã€‚

- å³ä½¿ä½ å†™ä¸å¥½promptï¼Œå¸‚é¢ä¸Šä¹Ÿæœ‰å¾ˆå¤šAIå·¥å…·å¯ä»¥å¸®ä½ åšprompt enhancement
  - æœŸå¾…AIèƒ½ã€Œæœ‰è®°å¿†ï¼Œæ‡‚ç”¨æˆ·ã€ã€‚å› æ­¤ï¼ŒContext Engineeringï¼ˆä¸Šä¸‹æ–‡å·¥ç¨‹ï¼‰å°±å¼€å§‹è¢«å…³æ³¨åˆ°ã€‚
  - context engineering, æ˜¯æŒ‡é€šè¿‡ç³»ç»Ÿæ€§æ„å»ºã€ç®¡ç†å’Œä¼˜åŒ– AI æ¨¡å‹çš„è¾“å…¥ä¸Šä¸‹æ–‡ï¼Œä»¥æå‡æ¨¡å‹åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„ç†è§£ä¸è¾“å‡ºèƒ½åŠ›ã€‚
  - ç¬¬ä¸€æ˜¯å†å²äº¤äº’æ•°æ®ã€‚
  - ç¬¬äºŒï¼Œæ˜¯contextçš„æ€»ç»“ã€‚å¯¹è¯å¯ä»¥ä¸€ç›´å»¶ç»­ï¼Œä½†æ¨¡å‹çš„ä¸Šä¸‹æ–‡çª—å£æœ‰é™ï¼Œæ€ä¹ˆè®°ä½ä¹‹å‰çš„å¯¹è¯ï¼Ÿå½“ç„¶æ˜¯å‹ç¼©ï¼Œä¾‹å¦‚æŠŠæœ€è¿‘5æ¡å¯¹è¯çš„å†…å®¹åŸå°ä¿ç•™ï¼Œå†ä¹‹å‰çš„å†…å®¹æ€»ç»“ä¸€ä¸‹ã€‚
  - ä½†æ›´é‡è¦çš„ï¼Œæ˜¯é¢†åŸŸçŸ¥è¯†ä¸èƒŒæ™¯ä¿¡æ¯ã€‚
- AIçš„èƒ½åŠ›æ¥æºäºä¸¤ä¸ªæ–¹é¢ in-weights memoryï¼ˆè®­ç»ƒé›†é‡Œå­¦åˆ°çš„ï¼‰ å’Œ in-context memoryï¼ˆå‚è€ƒèµ„æ–™é‡Œå­¦åˆ°çš„ï¼‰ã€‚ in-weights memoryåŸºæœ¬ä¸Šæ˜¯å¾ˆéš¾ä¿®æ”¹çš„, ä½†in-context memory æ›´å®¹æ˜“ä¿®æ”¹å’Œæ›´æ–°ï¼Œä½ åªè¦æä¾›æ–°çš„èµ„æ–™ï¼Œæ­£ç¡®çš„èµ„æ–™ï¼Œæ¨¡å‹å°±èƒ½æœ‰ã€Œæ–°çŸ¥ã€

- å¤æ‚çš„AIåº”ç”¨ï¼Œä¸æ˜¯é chatè¾“å…¥æç¤ºè¯è¿™ä¹ˆç®€å•ï¼Œè€Œæ˜¯éœ€è¦è‡ªåŠ¨åŒ–å¤šæ¬¡å’Œå¤§æ¨¡å‹çš„äº¤äº’ï¼Œè¿™ä¸ªè‡ªåŠ¨çš„è¿‡ç¨‹ä¸­ï¼Œéœ€è¦èƒ½å¤Ÿè‡ªåŠ¨äº§ç”Ÿç»™å¤§æ¨¡å‹çš„æç¤ºè¯ã€‚

- Agent = LLM + Prompt + å·¥å…·è°ƒç”¨ï¼Œä½†ä»å·¥ç¨‹è§†è§’æ¥çœ‹ï¼Œè¿™äº›æœ¬è´¨éƒ½æ˜¯Context Engineeringï¼Œä¹Ÿå°±æ˜¯ä¸Šä¸‹æ–‡å·¥ç¨‹ã€‚
  - Context Engineeringå°±æ˜¯åœ¨æ¯æ¬¡è°ƒç”¨é‡Œï¼ŒæŠŠæ¨¡å‹å®Œæˆä»»åŠ¡æ‰€å¿…éœ€çš„ä¿¡æ¯æŒ‰å¯¹çš„æ ¼å¼ã€åœ¨å¯¹çš„æ—¶æœºå‡†ç¡®æ‰“åŒ…è¿›å»ã€‚

- ä¸Šä¸‹æ–‡å·¥ç¨‹ï¼ŒAIç»˜å›¾ç”¨æˆ·æ—©å°±å¤©å¤©åœ¨ç”¨äº†
  - å½“ä½ ä½¿ç”¨ Inpaintï¼ˆå±€éƒ¨é‡ç»˜ï¼‰ åŠŸèƒ½æ—¶ï¼ŒAIä¸æ˜¯å‡­ç©ºæƒ³è±¡ï¼Œè€Œæ˜¯åŸºäºä½ ç•™ä¸‹çš„ç”»å¸ƒã€è¾¹ç¼˜çº¿æ¡ã€å…‰çº¿æ–¹å‘ã€å·²æœ‰ç”»é£æ¥è¡¥å…¨åŒºåŸŸï¼Œè¿™å°±æ˜¯â€œå›¾åƒä¸Šä¸‹æ–‡â€
  - å½“ä½ è¿›è¡Œ Outpaintï¼ˆå›¾åƒæ‰©å±•ï¼‰ æ—¶ï¼ŒAIå¿…é¡»å‚è€ƒåŸå›¾çš„æ„å›¾é€»è¾‘ã€è‰²å½©æ¸å˜ã€é£æ ¼çº¹ç†ã€äººç‰©é€è§†æ¥ç”Ÿæˆè‡ªç„¶è¡”æ¥çš„éƒ¨åˆ†ã€‚è¿™ç§å¯¹ä¸Šä¸‹æ–‡çš„â€œç†è§£â€å’Œâ€œå»ºæ¨¡â€ï¼Œæ¯”æç¤ºè¯æœ¬èº«æ›´é‡è¦
  - å½“ä½ ç”¨ Photoshopå†…ç½®çš„Fireflyè¿›è¡Œå±€éƒ¨ä¿®æ”¹åˆ›æˆå¼å¡«å……æ—¶ï¼ŒçœŸæ­£èµ·å†³å®šä½œç”¨çš„ä¸æ˜¯ä½ è¯´äº†â€œç»™æˆ‘åŠ ä¸€ä¸ªç¯å¡”â€ï¼Œè€Œæ˜¯AIæ˜¯å¦å‡†ç¡®è¯»å–äº†å½“å‰ç”»é¢æ˜¯å¤œæ™šã€æ˜¯æ°´è¾¹ã€æœ‰å…‰æºæŠ•å°„ã€æœ‰é€è§†æ¶ˆå¤±ç‚¹ã€‚
  - ä¸Šé¢è¿™äº›åŠŸèƒ½ï¼Œå“ªæ€•ä½ æ ¹æœ¬ä¸å†™æç¤ºè¯ï¼Œå¥½çš„å·¥å…·ä¹Ÿèƒ½ç»™ä½ è„‘è¡¥å¥½ï¼Œæ¯”å¦‚æˆ‘ç°åœ¨æ ¹æœ¬æ”¾ä¸å¼€è®¢é˜…çš„Photoshop AIã€‚

- 
- 
- 
- 
- 

- ## DeepSeekæœ€å¤§çš„åˆ›æ–°ï¼Œæ˜¯ä¸éœ€è¦å¤§é‡çš„äººå·¥æ ‡æ³¨ï¼Œè€Œæ˜¯ç›´æ¥ä»å…¶ä»–å¤§æ¨¡å‹è’¸é¦æˆ–è€…ä½¿ç”¨ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ç®—æ³•ï¼ˆGRPOï¼‰ã€CoTï¼ˆè‡ªæˆ‘åæ€ï¼‰æ¥ç»™å¤§æ¨¡å‹åé¦ˆï¼Œ
- https://x.com/seclink/status/1888011462008005030
  - å°±ç›¸å½“äºå®Œå…¨ä½¿ç”¨RLï¼ˆæˆ–è€…å¦ä¸€ä¸ªåŸºç¡€å¤§æ¨¡å‹ï¼‰æ¥æ›¿ä»£äººå·¥æ ‡æ³¨äº†ã€‚
  - è¿™å®é™…ä¸Šæ˜¯æŠ¢äº†Scale AI è¿™ç§å…¬å¸çš„è›‹ç³•ï¼ŒDeepSeekç‰›Xä¹‹å¤„åœ¨äºï¼Œå¾ˆå¤šè€å¤–ä¸€å¼€å§‹ä¸ä¿¡ï¼Œç„¶åç…§ç€è®ºæ–‡é‡Œçš„æ–¹æ³•å¿«é€Ÿï¼ˆå±€ä¿ƒåœ°ï¼‰å¤ç°ï¼Œå´å‘ç°ç«Ÿç„¶ä¹Ÿèƒ½å¤ç°æˆåŠŸã€‚

- cotå’Œè’¸é¦ä¹‹å‰ï¼Œå°±é€šè¿‡grpoè¿›è¡Œrlè·å¾—äº†ç›¸å½“ä¸é”™çš„æ¨ç†èƒ½åŠ›ã€‚ã€‚ä½ è¿™æ•´ç†çš„ä¸æ¸…æ™°ã€‚

- è¿™æ²¡æœ‰ä»»ä½•åˆ›æ–°ï¼ŒGPT1å°±ç”¨äº†åŒæ ·çš„æ–¹æ³•ï¼Œè€Œä¸”ç°åœ¨ä¸ä½¿ç”¨æ˜¯æœ‰ç†ç”±çš„ã€‚å› ä¸ºdeepseekæ¨¡å‹æœ¬èº«ä¸è¡Œï¼Œä¸€ä¸ªqueryéœ€è¦RL chainæ‰èƒ½è¾¾åˆ°å¯æ¥å—çš„ç­”æ¡ˆï¼Œè‡´ä½¿inference æ•ˆç‡ä½åˆ°å¯æ€•ï¼Œè™½ç„¶trainingä¾¿å®œï¼Œä½†æ˜¯operation costè¦å¤šå¥½å‡ å€ï¼Œå¾—ä¸å¿å¤±

- ä½ è¿™ä¸ªè¯´çš„å®Œå…¨ä¸å¯¹ï¼ŒCoTæ˜¯GPTå‘æ˜çš„ï¼Œè’¸é¦ä¹Ÿæ—©å°±æœ‰äº†ï¼ŒRLä¹Ÿæ—©å°±æœ‰äº†ï¼Œdeepseekæ˜¯å‘æ˜äº†RLé‡Œçš„GRPO

- ## I read up on DeepSeekâ€™s learning algo, GRPO. GRPO: group relative policy optimization
- https://x.com/virattt/status/1885102056546910672
- How GRPO works:
  1 â€¢ model generates a group of answers
  2 â€¢ compute score for each answer
  3 â€¢ compute avg score for entire group
  4 â€¢ compare each answer score to avg score
  5 â€¢ reinforce model to favor higher scores
  - This process is repeated, allowing the model to learn and improve over time.
- Other methods like PPO, use a value function model to do reinforcement learning.
  - GRPO does not, which reduces memory and computational overhead when training.

- GRPO was proposed for the first time in Feb 2024 in DeepSeekMath paper. It is not new.
  - Back then they used Neural Networks for Rewards (PRM/ORM). The magic happened when DeepSeek  replaced PRM/ORM with the exact reward (Verified Reward).

- ## ğŸ”¡ OpenAI's Deep Research is just a search+read+reasoning in a while-loop, right? here is my replicate of it in nodejs, using gemini-flash and jina reader
- https://x.com/hxiao/status/1886250705415229627
- If it includes evaluating js driven websites, including images Then yes 
  - To really replicate that, you'd probably wanna just use puppeteer, save the whole page as an image, extract the info from that, and then crunch that data

# discuss-multi-agents ğŸ˜ï¸
- ## 

- ## 

- ## 

- ## ğŸ†š ä»Šå¤©å¾ˆæœ‰è¶£ï¼Œä¸¤å®¶çŸ¥åçš„å…¬å¸å„å‡ºäº†ä¸€ç¯‡æ–‡ç« ï¼Œäº‰è®ºè¦ä¸è¦ä½¿ç”¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿã€‚
- https://x.com/oran_ge/status/1933754019010539923
  - Claude çš„å®˜æ–¹ Anthropic ï¼šå¦‚ä½•æ„å»ºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿ
  - Devin çš„å®˜æ–¹ Cognition ï¼šä¸è¦æ„å»ºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿ
- è¿™æ ¸å¿ƒçš„äº‰è®®ç‚¹åœ¨äºï¼šContext ä¸Šä¸‹æ–‡åˆ°åº•åº”è¯¥å…±äº«è¿˜æ˜¯åˆ†å¼€ï¼Ÿ
  - Claude è¿™è¾¹çš„è§‚ç‚¹æ˜¯ï¼Œæœç´¢ä¿¡æ¯çš„æœ¬è´¨æ˜¯å‹ç¼©ï¼Œå•ä¸ªæ™ºèƒ½ä½“çš„ä¸Šä¸‹æ–‡æœ‰é™ï¼Œé¢å¯¹æ— é™çš„ä¿¡æ¯ï¼Œå‹ç¼©æ¯”å¤ªå¤§å°±ä¼šå¤±çœŸã€‚è¿™æ˜¯é›†ä½“æ™ºæ…§ï¼Œä¸€èµ·åä½œè·å¾—çš„èƒœåˆ©ã€‚
  - Devin è¿™è¾¹çš„è§‚ç‚¹æ˜¯ï¼Œå¤šä¸ªæ™ºèƒ½ä½“çš„ä¸Šä¸‹æ–‡ä¸ä¸€è‡´ï¼Œä¼šå¯¼è‡´ä¿¡æ¯å‰²è£‚ã€è¯¯è§£ã€ä»–ä»¬æ±‡æŠ¥ç»™è€æ¿çš„ä¿¡æ¯ç»å¸¸å……æ»¡äº†çŸ›ç›¾ã€‚
  - è¿™è®©æˆ‘æƒ³åˆ°ï¼Œè½¯ä»¶å·¥ç¨‹ä»æ¥ä¸æ˜¯è¿½æ±‚å®Œç¾ï¼Œè€Œæ˜¯æŒç»­è¿­ä»£ã€‚

- æ²¡å•¥çŸ›ç›¾çš„ã€‚çœ‹éœ€æ±‚ã€‚open-ended çš„é—®é¢˜æ¯”è¾ƒé€‚åˆ multi-agentï¼›ç›®æ ‡å¾ˆå…·ä½“çš„è¯ï¼Œå°±æ¯”è¾ƒé€‚åˆå•ä¸ª agent

- æ„Ÿè§‰å’Œç°å®ä¸­çš„ä¸¤å®¶ä¸åŒç­–ç•¥è¿è¥çš„å…¬å¸å·®ä¸å¤šï¼Œæ²¡æœ‰ç»å¯¹çš„å¯¹å’Œé”™ï¼Œéƒ½èƒ½èµ°å‡ºæ¥çš„å¯èƒ½æ€§ä¹Ÿè¶…å¤§ã€‚

- ## @KuraAIAgents é€šè¿‡åˆ›æ–°çš„äº”é‡ Agent æ¶æ„ï¼ˆè§„åˆ’ã€æ‰§è¡Œã€è¯„ä¼°ï¼‰å®ç°äº† 87% çš„æµè§ˆå™¨è‡ªåŠ¨åŒ–å‡†ç¡®ç‡ï¼Œè¶…è¶Š Claude è®¡ç®—æœºæ“ä½œ 28 ä¸ªç™¾åˆ†ç‚¹ï¼ŒåŒæ—¶æ”¯æŒä½æˆæœ¬æ¨¡å‹æ›¿æ¢æ–¹æ¡ˆ
- https://x.com/shao__meng/status/1857586562588094918
  - åŒ…å«5ä¸ªä¸“é—¨çš„ Agentï¼Œå…¶ä¸­3ä¸ªæ ¸å¿ƒ Agent å½¢æˆä¸€ä¸ªå¾ªç¯ç³»ç»Ÿ
  - åœ¨ WebVoyager åŸºå‡†æµ‹è¯•ä¸­å–å¾— 87% çš„æˆç»©
  - æ¯” Claude çš„è®¡ç®—æœºæ“ä½œé«˜å‡º 28%
- äº”ä¸ªæ ¸å¿ƒ Agentï¼š
a) åˆå§‹è§„åˆ’è€…(Initial Planner)
- è´Ÿè´£åˆ¶å®šé«˜å±‚æ¬¡è®¡åˆ’
- ä½¿ç”¨ OpenAI o1 æ¨¡å‹è¿›è¡Œæ¨ç†
b) å¾ªç¯è§„åˆ’è€…(Agent Loop Planner)
- è¯„ä¼°ä»»åŠ¡æ˜¯å¦å®Œæˆæˆ–ä¸å¯èƒ½å®Œæˆ
- ä¸ºæ‰§è¡Œè€…æä¾›ä¸‹ä¸€æ­¥æŒ‡ä»¤
- æ ¹æ®éœ€è¦ä¿®æ”¹è®¡åˆ’
c) æ‰§è¡Œè€…(Executor)å…·å¤‡ä¸‰é¡¹æ ¸å¿ƒæŠ€èƒ½ï¼š
- ç½‘å€å¯¼èˆªå’Œè¿”å›
- è¯»å–å½“å‰é¡µé¢æ•°æ®
- æ‰§è¡Œå±å¹•æ“ä½œ(ç‚¹å‡»ã€æ»šåŠ¨ã€è¾“å…¥)
d) å¾ªç¯è¯„è®ºè€…(Agent Loop Critic)
- è¯„ä¼°æ‰§è¡Œè€…çš„è¡¨ç°
- ç‰¹åˆ«åœ¨å¤æ‚ç•Œé¢æ“ä½œä¸­èµ·å…³é”®ä½œç”¨
e) æœ€ç»ˆè¯„è®ºè€…(Final Critic)
- è¯„ä¼°æ•´ä¸ªä»»åŠ¡è½¨è¿¹
- å¿…è¦æ—¶æä¾›åé¦ˆå¹¶å¯åŠ¨æ–°çš„å¾ªç¯

- ## OpenAI å‘å¸ƒå¤š Agent ç¼–æ’æ¡†æ¶èƒŒåçš„æ€è€ƒä»¥åŠå®è·µè¿‡ç¨‹
- https://x.com/tuturetom/status/1845634978530693494
  - æ ¸å¿ƒæ˜¯ OpenAI çš„å·¥ç¨‹å¸ˆåœ¨æ€è€ƒ  Agent çš„ã€Œè·¯ç”±ã€ + ã€Œç§»äº¤ã€ç­‰èƒ½åŠ›æ—¶æ‹“å±•å‡ºæ¥çš„ä¸€ä¸ªç¤ºä¾‹ï¼Œè¿›è€Œå‘ç°è¿™ä¸ªç¤ºä¾‹åŸè¯­å¾ˆæ™®é€‚ï¼Œæ‰€ä»¥å¼€å‘äº† Swarm æ¡†æ¶
  - æ‰€æœ‰ä¼Ÿå¤§çš„æ€è€ƒéƒ½æºäºå‘¨æœ«ä¸šä½™å·¥ä½œ

- ## OpenAI æ‚„æ‚„å¼€æºäº†æ„å»ºå¤šä»£ç†æ™ºèƒ½ä½“ååŒæ¡†æ¶ï¼šSwarm
- https://x.com/aigclink/status/1844936446416912628
  - ç”¨äºæ„å»ºã€ç¼–æ’å’Œéƒ¨ç½²å¤šä»£ç†

# discuss-ai-format/interop
- ## 

- ## 

- ## 

- ## [Use YAML over JSON when dumping into prompts for ~2x token saving : r/ChatGPTCoding _202509](https://www.reddit.com/r/ChatGPTCoding/comments/1nl7xux/use_yaml_over_json_when_dumping_into_prompts_for/)
  - [YAML vs. JSON: Which Is More Efficient for Language Models? _202307](https://medium.com/better-programming/yaml-vs-json-which-is-more-efficient-for-language-models-5bc11dd0f6df)
  - It's been pointed out in the comments (with sass) that minifying your JSON is another, perhaps even better, alternative than transforming to YAML. So now there's two options for saving tokens.

- Does the guy who wrote the article know that you don't need to use whitepaces in JSON and you can minify it to consume less space than YAML? Generally speaking, JSON is more space-efficient and compact than YAML.

- Just remove the spaces and condence the JSON into a single line. LLMs don't care about spaces, it's a visual thing for us.

- Thought LLM's don't count white space as context... or if they did, it would be incredibly minimal
  - They kind of have to, if only to correctly write Python
  - ASCII art too

- Another point is accuracy... some like XML more as well - and there is BAML. If i just wanna save money I could get a cheaper model too.
- xml is also what Claude officially recommends for better accuracy.

- I use YAML and JSON, because i use the CMS Drupal since 2006 - so this fits quite well in my workflow

- TOML is actually more verbose when it comes to complex data structures.
  - Which makes sense since it was designed to be a JSON/YAML mappable language for better human readability.
# discuss-local-llm-xp/tips
- ## 

- ## 

- ## 

- ## [What's the missing piece in the LLaMA ecosystem right now? : r/LocalLLaMA _202510](https://www.reddit.com/r/LocalLLaMA/comments/1o5dh3v/whats_the_missing_piece_in_the_llama_ecosystem/)
  - For me, it's the data prep and annotation tools. The models are getting powerful, but cleaning and structuring quality training data for fine-tuning is still a major, manual bottleneck.

- Training-Data is the biggest issue for local ecosystem right now i think. There is so many datasets, but who knows about their real quality.
  - For me personally, finetuning an LLM is like 500x harder than a diffusion model, simply due to the lack of tooling. Unsloth is nice and all, but i dont want to run fucking Jupyter Notebooks, i want something akin to kohya_ss with as many of the relevant hyperparameters exposed.
- Hardware accessibility is only secondary. If you have a small Model, e.g. the Qwen3 0.6B full finetune should be possible on local hardware. If that proves to be effective, renting a GPU machine somewhere for a few bucks shouldnt be the issue.

- llms are very bad at image recognition, give it a civ or other strategy game screenshot and it gets nearly everything wrong.

- Benchmarks. There has been little to no progress in the past two years regarding how LLMs are evaluated. Itâ€™s still mostly huge catalogues of questions with predetermined answers. Thatâ€™s a very poor system for testing intelligence.
# discuss
- ## 

- ## 

- ## 

- ## 

- ## åšäº§å“çº§æœç´¢ä»¥åå‘ç° 3.7 æ•ˆæœç‰¹å¥½ä½†æ˜¯ç‰¹åˆ«è´µï¼Œæ‰€ä»¥å¿…é¡»å¾—åš content cache é™ä½æˆæœ¬ã€‚
- https://x.com/arvin17x/status/1896922111505285484
  - ä½†ä¸ºäº†åš context cache ï¼Œå‘ç°å¿…é¡»å¾—è®°å½• token usageï¼Œä¸ç„¶æ„ŸçŸ¥ä¸åˆ° cache çš„æ•ˆæœã€‚

- å¯ä»¥åˆ†äº«ä¸‹ Context Cache çš„åŸç†ä¹ˆï¼Œæˆ‘è¿˜ä»¥ä¸ºè¿™ç§ä¸œè¥¿åªèƒ½åœ¨æ¨¡å‹ä¾›åº”å•†ä¾§åšã€‚
  - å°±æ˜¯åœ¨æ¨¡å‹ä¾›åº”å•†ä¾§åšã€‚åªæ˜¯ OpenAI å’Œ DeepSeek åšçš„æ˜¯é™é»˜æ–¹æ¡ˆï¼Œè€Œ Anthropic å’Œ Google æ˜¯éœ€è¦å¼€å‘è€…æ‰‹åŠ¨å¼€çš„
- åº”è¯¥æ˜¯ prompt caching å§
  - Anthropicå®¶è‡ªå·±çš„è¯´æ³•æ˜¯ prompt Caching. ä½†æˆ‘æ„Ÿè§‰è¡Œä¸šé‡Œæ„Ÿè§‰è¿˜æ˜¯ä¹ æƒ¯å« context caching çš„ã€‚
  - ä¸è¿‡ OpenAI å®˜æ–¹å’Œ Anthropic å®˜æ–¹éƒ½ç§°ä¹‹ä¸º prompt caching

- å¾ˆå¥‡æ€ªï¼Œè¿™ç©æ„ä¸ºå•¥ä¸é»˜è®¤å¼€å¯ã€‚
  - æŸäº›åœºæ™¯ä¸‹çš„ç¡®ä¸ä¸€å®šé€‚åˆï¼Œå› ä¸ºå†™å…¥ cache çš„æˆæœ¬æ˜¯åŸä»·çš„ 1.25å€

- ## It is common to generate train and validation sets using random splitting.
- https://x.com/_avichawla/status/1898622288737767785
  - However, in many situations, it can be fatal for model building.
  - Consider building a model that generates captions for images.
  - Group shuffle split solves this.

- ## ç”±äºDeepSeek-R1 çˆ†ç«ï¼Œæ‰€ä»¥ä¸ºå¤§å®¶å¸¦æ¥ä»€ä¹ˆæ˜¯LLMè’¸é¦æŠ€æœ¯çš„ç¬”è®°ã€‚
- https://x.com/karminski3/status/1882233538042597423
  - å‡ ä¸ªåŠ©è®°è¯ï¼šæ•™å¸ˆæ¨¡å‹ï¼Œå­¦ç”Ÿæ¨¡å‹ï¼Œè½¯ç›®æ ‡ï¼Œç¡¬ç›®æ ‡ã€‚

- https://x.com/ShanghaoJin/status/1882679738789216456
  - ä½ å¬è¯´è¿‡ä»€ä¹ˆå«â€œè’¸é¦â€ä¹ˆï¼Ÿè¯´ä¸ªå¤§ç™½è¯ï¼šå°±æ˜¯æ‹¿äººå®¶ç®—å‡ºæ¥çš„æ¨¡å‹å‚æ•°ï¼Œè·³è¿‡æ‰€æœ‰æ•°æ®æ¸…æ´—ã€è®­ç»ƒï¼Œåšæœ€åä¸€ç¨‹ã€‚å…¶å®æ²¡æœ‰ä»»ä½•åˆ›æ–°
  - å¥½åƒäººå®¶è¯æ˜äº†Ï€=3.14ï¼Œä»–æ‹¿ç»“æœå»ç®—äº†åœ†é¢ç§¯ã€‚è®©ä»–å†è‡ªå·±å»è¯æ˜ç®—ä¸€ä¸ªeï¼Œä»–åˆæŠ“çäº†
- åƒä¸‡ä¸è¦ç”¨â€œå¤§ç™½è¯â€æ¥è§£é‡Šè‡ªå·±éƒ½æ²¡å®Œå…¨ç†è§£çš„æ¦‚å¿µï¼Œ åªèƒ½è®©å¤–è¡Œæ‹æ‰‹ï¼Œæ‡‚çš„äººåªä¼šç¬‘è¯ä½ ã€‚ ä½ å®Œå…¨ä¸çŸ¥é“è’¸é¦æ˜¯åœ¨å¹²ä»€ä¹ˆã€‚å¦‚æœä½ çŸ¥é“çš„è¯ï¼Œé‚£å°±æ˜¯å®Œå…¨ä¸çŸ¥é“Deepseek åœ¨åšä»€ä¹ˆã€‚
- â€œè’¸é¦â€è¯´æ³•ä¸æ­£ç¡®ã€‚1. è’¸é¦æ•ˆæœä¸€èˆ¬ä¸ä¼šè¶…è¿‡åŸæ¨¡å‹ 2. deepseekçš„ reasoningè¡Œä¸ºå’Œå¸‚é¢ä¸Šå…¶ä»–æ¨¡å‹ä¸ä¸€è‡´(æœ‰è¶…è¶Šäººç±»æ ‡æ³¨çš„å¥‡å¦™è¡Œä¸º) 3. å¼€æ™ºå¯¹å†è®­ç»ƒæ¨¡å‹æœ‰ç¦æ­¢å¹¶ä¼šç›‘æ§ APIæ»¥ç”¨

- ## æˆ‘æ—¥å¸¸ç”¨ Cursor å†™ä»£ç çš„åœºæ™¯ä¹‹ä¸€ï¼šâ€œè¯·å‚è€ƒä»£ç  @ XXX1 @ XXXn åš YYY äº‹ã€‚â€
- https://x.com/dotey/status/1869436413600731146
  - ç®€å•æ¥è¯´å°±æ˜¯è®© AI ç…§è‘«èŠ¦ç”»ç“¢ï¼Œé‡è¦çš„æ˜¯ç»™å‡ºå……è¶³çš„ä¸Šä¸‹æ–‡ï¼Œè®© AI å¯ä»¥å­¦ä¹ å’Œæ¨¡ä»¿ã€‚å‰©ä¸‹çš„å°±æ˜¯ Review + Acceptï¼Œå¾ˆç®€å•é«˜æ•ˆã€‚
  - ç‰¹åˆ«è¦æ³¨æ„çš„æ˜¯ç¬¬ä¸€ä¸ªâ€œè‘«èŠ¦â€è¦æ‰“ç£¨å¥½ï¼Œè¿™æ ·åç»­çš„â€œç“¢â€æ‰ä¸ä¼šç”»æ­ªã€‚

- æ›´ç®€å•çš„åšæ³•æœ‰æ—¶å€™å¯ä»¥ç›´æ¥ @ git æŸæ¬¡æäº¤

- æˆ‘ç°åœ¨æ˜¯æ–°é¡¹ç›®é‡Œåˆ›å»ºä¸€ä¸ªtxtæ–‡ä»¶ï¼Œé‡Œé¢å†™ä¸Šæƒ³æ³•å’Œgptå¯¹æˆ‘æƒ³æ³•çš„å»ºè®®ï¼Œç„¶åè®©cursor å‚è€ƒè¿™ä¸ªæ–‡ä»¶æ¥å¼€å‘ï¼Œé‡Œé¢æˆ‘ä¹Ÿæœ‰æ—¶ä¼šå†™ä¸Šæ­¥éª¤ï¼Œé¦–å…ˆå®ç°ä»€ä¹ˆï¼Œç„¶åå®ç°ä»€ä¹ˆï¼Œåšä¸€æ®µäº†ï¼Œè®©cursoræ ¹æ®è¿™ä¸ªæ–‡ä»¶æ£€æŸ¥ä¸€ä¸‹é¡¹ç›®å®Œæˆåº¦ï¼Œåˆ—å‡ºæ¥å“ªäº›æ²¡åšï¼Œè¿™æ ·åå¤è¿­ä»£å‘å‰

- LM å……åˆ†è¯æ˜äº†äººç±»çš„æœ¬è´¨å°±æ˜¯å¤è¯»æœºã€‚ å“ªé‡Œæœ‰ä»€ä¹ˆæŒ‡ä»¤éµå¾ªï¼Œæ¨ç†ï¼Œå¤§å®¶éƒ½æ˜¯ä»ä¸åŒçš„ç»´åº¦ç”¨ä¸åŒçš„æ–¹å¼åœ¨å¤è¯»ä¸€äº›ä¸œè¥¿è€Œå·²

- ## å¦‚æœæƒ³è¦è®© LLM ç¨³å®šç”Ÿæˆ JSON å¯¹è±¡ï¼Œæœ€ç®€å•çš„æ–¹å¼å°±æ˜¯ä½¿ç”¨ zod å®šä¹‰ schema å¹¶é…åˆ @vercel ai sdkçš„ generateObjectä½¿ç”¨ï¼Œæ¯”å¦‚è¿™é‡Œæˆ‘æƒ³è¦ä»ç½‘é¡µæ–‡æœ¬å†…å®¹æå–ç»“æ„åŒ–çš„ä¿¡æ¯ã€‚
- https://x.com/FeigelC35583/status/1819558128297648412
  - è¿™ç§æ–¹å¼å’Œå½“åˆ langchain åœ¨ prompt é‡Œå†™ä¸€å¤§å †json å®šä¹‰æœ‰æœ¬è´¨åŒºåˆ«ï¼Œåœ¨äºä½¿ç”¨äº† function call çš„èƒ½åŠ›
  - ä»è¯·æ±‚ä¸­å¯ä»¥çœ‹åˆ°ï¼Œæœ¬è´¨ä¸Šæ˜¯åœ¨è°ƒç”¨æ¨¡å‹çš„æ—¶å€™ï¼Œæ„å»ºäº†ä¸€ä¸ªåä¸º json çš„ å‡½æ•°, æè¿°æ˜¯ respond with a json object, å…¶ä¸­å‚æ•°æ˜¯è‡ªå·±å®šä¹‰çš„ schemaï¼Œç„¶ååœ¨ tool_choice ä¸­é™åˆ¶å¿…é¡»è¦ä½¿ç”¨è¿™ä¸ª json å‡½æ•°ï¼Œé‚£ä¹ˆæ¨¡å‹å°±ä¼šè¿”å›è°ƒç”¨json å‡½æ•°çš„å‚æ•°ï¼Œå³ä½ å®šä¹‰çš„ schema
  - ç¤ºä¾‹ä»£ç æ¥è‡ªäºhttps://github.com/DiscovAI/DiscovAI-crawl æˆ‘æ­£åœ¨ building çš„ä¸€ä¸ªé¢å‘ RAG åº”ç”¨çš„çˆ¬è™«å¹³å°
- åº”è¯¥åªæœ‰GPTç³»åˆ—èƒ½ç”¨å§
  - æ”¯æŒfunction callå°±å¯ä»¥ï¼Œdeepseekåº”è¯¥ä¹Ÿå¯ä»¥çš„
- åœ¨è¿™åŸºç¡€ä¸Šã€‚æˆ‘ä¼šè€ƒè™‘ä½¿ç”¨jsonrepairè¿™ä¸ªåŒ…ï¼Œæ‰‹åŠ¨ä¿®å¤ä¸‹ï¼Œå¢åŠ å®¹é”™
- å¦‚æœå¤§æ¨¡å‹æ²¡æœ‰æ²¡æœ‰è¿”å›å¯¹åº”è¦æ±‚çš„å­—æ®µæ•°æ®ï¼Œæˆ–è€…è¿”å›é”™äº†ç±»å‹ï¼Œå®ƒä¼šæ€ä¹ˆæ ·ï¼Œä¼šè‡ªå·±è¡¥å……ç©ºçš„ï¼Œæˆ–è€…è‡ªåŠ¨è½¬æ¢ç±»å‹å—ï¼Ÿ
  - ä¸ä¼šè¡¥å……ï¼Œä¼šthrow errorï¼Œä¹Ÿå¯ä»¥ç”¨ä¸Šé¢æ¨å‹æ¨èçš„jsonrepairæ‰‹åŠ¨fix

- èƒ½æ”¯æŒå¼€æºæ¨¡å‹å—
  - å–å†³äºæ¨¡å‹æ”¯ä¸æ”¯æŒfunction callï¼Œæ”¯æŒçš„è¯å°±å¯ä»¥ï¼Œæ•ˆæœçš„è¯è¦çœ‹æ¨¡å‹çš„èƒ½åŠ›
- ç”¨ function call æ„Ÿè§‰æ¨¡å‹çš„èƒ½åŠ›é™äº†ä¸€ä¸ªç»´åº¦ï¼Œä¸å¦‚ç›´æ¥ç»™æ–‡æœ¬ï¼Œæˆ‘è¿˜æ˜¯æ›´å–œæ¬¢ç”¨xmlè‡ªå·±æå–ã€‚

- æˆ‘æ˜¯ç”¨ä¼ªä»£ç â•ç±»å‹å£°æ˜, ä¹Ÿæ˜¯ä¸€æ ·çš„ç¨³å®šè¾“å‡º json
- langchainæ¡†æ¶ä¸­æœ‰Pydantic json è§£æå™¨å¯ä»¥ç›´æ¥ç”¨ï¼Œæœ¬è´¨ä¹Ÿæ˜¯ç”Ÿæˆschemaï¼Œå†é…åˆé‡è¯•è§£æå™¨ä¹Ÿå¯ä»¥ç¨³å®šç”Ÿæˆjsonæ ¼å¼

- ## ğŸ’¡ LLMs are literally the most unreliable technology of all time (followed by **ing bluetooth)
- https://x.com/Steve8708/status/1819448686424084892
  - After an absurd amount of trial and error, we've internally created a set of rules for make LLMs considerably more reliable
  - our secrets: restrict the llm to only what rag provides

- what's your stance on AI for no-code? Do people prefer drag-and-drop vs prompting?
  - i think the winning move is combining both

- Bluetooth is hell and causes frustration daily.

- ## ğŸŒ° Firefox will use Transformers.js to power on-device features
- https://x.com/osanseviero/status/1797291569348751848
  - In their PDF Editor to generate alt text for images
  - Improve translations
  - Fully offline, open-source and with <200M models
- [Experimenting with local alt text generation in Firefox Nightly - Mozilla Hacks - the Web developer blog _202405](https://hacks.mozilla.org/2024/05/experimenting-with-local-alt-text-generation-in-firefox-nightly/)
  - https://huggingface.co/Mozilla

    - æä¾›äº†æ•°æ®é›†å’Œæ¨¡å‹

- Offline and open-source is a big win for privacy-focused tools

- ## [langchainåˆ°åº•è¯¥æ€ä¹ˆä½¿ç”¨ï¼Œå¤§å®¶åœ¨é¡¹ç›®ä¸­å®è·µæœ‰æˆåŠŸçš„æ¡ˆä¾‹å—? - çŸ¥ä¹](https://www.zhihu.com/question/609483833)
- LangChainä¹‹æ‰€ä»¥å¤§ç«ï¼Œæ˜¯å› ä¸ºå®ƒæä¾›äº†ä¸€ç³»åˆ—æ–¹ä¾¿çš„å·¥å…·ã€ç»„ä»¶å’Œæ¥å£ï¼Œå¤§å¤§é™ä½äº† AI åº”ç”¨å¼€å‘çš„é—¨æ§›ï¼Œä¹Ÿæå¤§ç®€åŒ–äº†å¤§æ¨¡å‹åº”ç”¨ç¨‹åºçš„å¼€å‘è¿‡ç¨‹ã€‚
  - LangChainæ¡†æ¶èƒŒåçš„æ ¸å¿ƒæ€æƒ³æ˜¯å°†è‡ªç„¶è¯­è¨€å¤„ç†åºåˆ—åˆ†è§£ä¸ºå„ä¸ªéƒ¨åˆ†ï¼Œå…è®¸å¼€å‘äººå‘˜æ ¹æ®è‡ªå·±çš„éœ€æ±‚é«˜æ•ˆåœ°å®šåˆ¶å·¥ä½œæµç¨‹ã€‚
- Langchainæœ‰6å¤§æ ¸å¿ƒæ¨¡å—ï¼š
  - Modelsï¼šæ¨¡å‹ï¼Œæ˜¯å„ç§ç±»å‹çš„æ¨¡å‹å’Œæ¨¡å‹é›†æˆã€‚
  - Promptsï¼šæç¤ºï¼ŒåŒ…æ‹¬æç¤ºç®¡ç†ã€æç¤ºä¼˜åŒ–å’Œæç¤ºåºåˆ—åŒ–ã€‚
  - Memoryï¼šè®°å¿†ï¼Œç”¨æ¥ä¿å­˜å’Œæ¨¡å‹äº¤äº’æ—¶çš„ä¸Šä¸‹æ–‡çŠ¶æ€ã€‚
  - Indexesï¼šç´¢å¼•ï¼Œç”¨æ¥ç»“æ„åŒ–æ–‡æ¡£ï¼Œä»¥ä¾¿å’Œæ¨¡å‹äº¤äº’ã€‚åŒ…æ‹¬æ–‡æ¡£åŠ è½½ç¨‹åºã€å‘é‡å­˜å‚¨å™¨ã€æ–‡æœ¬åˆ†å‰²å™¨å’Œæ£€ç´¢å™¨ç­‰ã€‚
  - Agentsï¼šä»£ç†ï¼Œå†³å®šæ¨¡å‹é‡‡å–å“ªäº›è¡ŒåŠ¨ï¼Œæ‰§è¡Œå¹¶ä¸”è§‚å¯Ÿæµç¨‹ï¼Œç›´åˆ°å®Œæˆä¸ºæ­¢ã€‚
  - Chainsï¼šé“¾ï¼Œä¸€ç³»åˆ—å¯¹å„ç§ç»„ä»¶çš„è°ƒç”¨ã€‚
- LangChain é€šå¸¸è¢«ç”¨ä½œã€Œç²˜åˆå‰‚ã€ï¼Œå°†æ„å»º LLM åº”ç”¨æ‰€éœ€çš„å„ä¸ªæ¨¡å—è¿æ¥åœ¨ä¸€èµ·ã€‚ä½¿ç”¨Langchainä¸­ä¸åŒç»„ä»¶çš„ç‰¹æ€§å’Œèƒ½åŠ›ï¼Œå¯ä»¥æ„å»ºä¸åŒåœºæ™¯ä¸‹çš„åº”ç”¨ï¼Œå¦‚èŠå¤©æœºå™¨äººã€åŸºäºæ–‡æ¡£çš„é—®ç­”ã€çŸ¥è¯†ç®¡ç†ã€ä¸ªäººåŠ©ç†ã€Agentæ™ºèƒ½ä½“ç­‰ç­‰ã€‚

- ä½ çš„è¿™ä¸ªè®¤è¯†å­˜åœ¨ä¸€äº›åå·®ï¼Œé¦–å…ˆï¼Œä¾èµ–API key æ˜¯ä¸ºäº†ä½ ä½¿ç”¨å¤§æ¨¡å‹å‚å•†çš„æœåŠ¡å’Œé‰´æƒï¼Œè¿™æ²¡æœ‰ä»€ä¹ˆæ‹‰è·¨çš„ã€‚å¾ˆå¤šç¬¬ä¸‰æ–¹çš„æœåŠ¡éƒ½éœ€è¦é‰´æƒéªŒè¯ï¼Œè¿™æ˜¯æ¯”è¾ƒä¸»æµçš„æ–¹å¼ã€‚
- å¯ä»¥ä¼ä¸šè‡ªå·±éƒ¨ç½²å¤§æ¨¡å‹ï¼Œè¿™ç§æˆæœ¬æ˜¯å¾ˆé«˜çš„ã€‚ä»æˆ‘ä»¬è‡ªå·±çš„å®éªŒæ•ˆæœæ¥çœ‹ï¼Œ13B ä»¥ä¸‹çš„å¤§æ¨¡å‹åŸºæœ¬å°±æ˜¯ç©å…·ï¼Œä¼˜åŒ–åŠå¤©è´¹æ—¶è´¹åŠ›ï¼Œè€Œ 34B æˆ–è€…æ›´å¤§çš„æ¨¡å‹ï¼Œå…¬å¸éƒ¨ç½²æˆæœ¬åˆå¾ˆé«˜ã€‚
- langchain ä¸­çš„ç‰¹è‰²æ˜¯å®ƒçš„ langchain expression language (LCELï¼‰ï¼Œæ˜¯ä¸€ç§ç±»ä¼¼ linux ç®¡é“å½¢å¼çš„è°ƒç”¨æ–¹å¼ï¼Œå¯ä»¥å¾ˆç®€å•çš„å®ç°å®ƒçš„ chain ç›¸å…³çš„åŠŸèƒ½ã€‚è¿™ä¸ªï¼Œåœ¨æˆ‘å®é™…ä½¿ç”¨çš„æ—¶å€™ï¼Œæ²¡æœ‰æƒ³è±¡çš„é‚£ä¹ˆå¥½ç”¨ï¼Œå¯ä»¥æ ¹æ®å®é™…æƒ…å†µå»å­¦ä¹ ã€‚
- æœ€åï¼Œlangchain ä¸­è¿˜æœ‰ä¸€ä¸ªå«åš langgraph çš„ç»„ä»¶ï¼Œèƒ½å¤Ÿå’Œ pytorch ä¸€æ ·ç”¨æ­ç§¯æœ¨çš„æ–¹å¼å»æ„é€ ä¸€ä¸ªæœ‰å‘æ— ç¯å›¾ã€å¾ªç¯çš„é“¾ï¼Œæ¯” LCEL æ›´é«˜çº§ã€‚

- 
- 

- ## LLMæåç¼–è¯‘ï¼Œ.not careå’ŒJvavç”¨æˆ·å†ä¹Ÿä¸ç”¨æŠ˜è…¾ä»€ä¹ˆæ··æ·†äº†ï¼Œéƒ½æ²¡ç”¨äº†
- https://twitter.com/geniusvczh/status/1774053196039962758
  - æ–‡ç« é‡Œåç¼–è¯‘çš„æ˜¯x86, x86éƒ½å¯ä»¥ï¼ŒILéš¾åº¦åªä¼šæ›´ä½
- å¤§æ¦‚çœ‹äº†ä¸€ä¸‹ï¼Œå°±æ˜¯æŠŠç¼–è¯‘å‡ºçš„æ±‡ç¼–è·Ÿæºä»£ç åšäº†ä¸€ä¸ªç®€å•çš„seq2seqçš„fine tuneï¼Œè®­ç»ƒé›†è¿æ··æ·†éƒ½æ²¡æœ‰ï¼Œç¦»è®©æ‰€æœ‰æ··æ·†éƒ½æ²¡ç”¨é‚£æ›´æ˜¯è¿˜å·®å¾—è¿œã€‚
- 17å¹´googleé‚£ç¯‡transformerçš„è®ºæ–‡å°±é è¿™æ ·å®Œæˆäº†è‡ªç„¶è¯­è¨€çš„ç¿»è¯‘ï¼Œè¿™äº›éƒ½æ˜¯è¿Ÿæ—©çš„äº‹ï¼Œåç¼–è¯‘å’Œåæ··æ·†çš„è®­ç»ƒæ•°æ®éƒ½æ˜¯å¯ä»¥æ‰¹é‡ç”Ÿæˆçš„ï¼Œåšèµ·æ¥ç®€å•å¤šäº†
  - æˆ‘è§‰å¾—LLMå¯¹äºåç¼–è¯‘å’Œåæ··æ·†ï¼Œå¯èƒ½æ›´å¤§çš„ä½œç”¨åœ¨äºç”Ÿæˆäººç±»å‹å¥½çš„å˜é‡/ç¨‹åºç»“æ„ã€‚æ¯•ç«Ÿåç¼–è¯‘å’Œåæ··æ·†æ˜¯çŒ«é¼ æ¸¸æˆï¼Œæ€»å¯ä»¥æƒ³å‡ºæ–°ç‚¹å­ï¼Œäººç±»çš„å¹²é¢„è¿˜æ˜¯å¿…ä¸å¯å°‘çš„ï¼Œè¿™ç§æƒ…å†µä¸‹ï¼ŒåŸºäºè§„åˆ™/ç¨‹åºåˆ†æçš„ä¼ ç»Ÿæ–¹æ³•å¯èƒ½æ›´å¥½ï¼Œç„¶åå†ç”¨LLMçŒœå˜é‡å
- ä¸ºäº†æ‹‰èµ„é‡‘è€Œå·²ï¼Œé’±ç”³è¯·åˆ°äº†è®ºæ–‡å°±æ²¡å•¥ç”¨äº†â€¦â€¦å¤„ç†å±å±±ç•™ç»™å·¨å¤´çš„ç¨‹åºå‘˜å°±è¡Œäº†ï¼Œè¿˜è½®ä¸åˆ°å­¦æœ¯åœˆæ¥æŒ‡ç‚¹æ±Ÿå±±
- è¿™ç§å±€é™äºå‡½æ•°çš„åæ··æ·†å•¥ç”¨éƒ½æ²¡æœ‰ï¼Œå¯¹ä»˜ç‚¹ä¸‰è„šçŒ«åŠŸå¤«çš„æ··æ·†è¿˜å·®ä¸å¤š

- ## ğŸª§ ç ”ç©¶äº†ä¸€ä¸‹æœ¬åœ°å¤§æ¨¡å‹çš„åœºæ™¯ï¼š
- https://twitter.com/changmingY/status/1773336179296887162
  1. ä¸èƒ½è”ç½‘çš„å›½å†…ç”¨æˆ·
  2. ä¸€èˆ¬ç”¨æˆ·æœºå™¨é…ç½®è¾¾ä¸åˆ°ï¼Œæ•ˆç‡å¤ªå·®
  3. æœ¬åœ°çŸ¥è¯†åº“ç®—æ˜¯ä¸€ä¸ªåˆšæ€§éœ€æ±‚
  4. å‚ç›´é¢†åŸŸæ¨¡å‹è¶Šæ¥è¶Šå¤š, ä¸€ä¸ªhubé›†ä¸­ä½¿ç”¨
  5. å°è€Œç¾çš„æ¨¡å‹ä¼šè¶Šæ¥è¶Šå¤šï¼Œå®Œæˆä¸€ä¸ªç‰¹å®šåŠŸèƒ½

- ## ollama çš„ç¼–è¯‘ç©çš„å¤ªèŠ±äº†ï¼Œå…ˆæ˜¯å§ llama.cpp åœ¨ä¸åŒ cpu å’Œ gpu çš„åŠ¨æ€é“¾æ¥åº“éƒ½ç¼–è¯‘äº†å‡ºæ¥é¿å…ç”¨æˆ·åœ¨è¿è¡Œæ—¶å†å»ç¼–è¯‘ï¼Œ
- https://twitter.com/liumengxinfly/status/1767073319956971891
  - ç„¶åç”¨ go çš„ embed ç‰¹æ€§ç›´æ¥æŠŠè¿™äº›åŠ¨æ€åº“å…¨éƒ½æ‰“åŒ…åˆ° go çš„äºŒè¿›åˆ¶é‡Œï¼Œç„¶ååœ¨ç”¨ cgo å’Œ dlfcn åŠ è½½å’Œè°ƒç”¨ llama.cppï¼Œå®ç°äº†ä¸€ä¸ªäºŒè¿›åˆ¶æ–‡ä»¶å…ç¼–è¯‘ï¼Œå…å®‰è£…çš„è§£å†³æ‰€æœ‰é—®é¢˜

- https://twitter.com/holegots/status/1767427148506431665
  - ä¸è¿‡è¿™ä¸ªæœ¬è´¨ä¹Ÿæ˜¯ llama.cpp å¥—å£³å§ , åº•å±‚è¿˜æ˜¯ cpp, golang å¹¶ä¸å‚ä¸å®é™…çš„æ¨ç†.

- ## æœ€æ–°ç‰ˆçš„ OpenAI Translator å·²ç»æ— ç¼æ”¯æŒæœ¬åœ°å¤§æ¨¡å‹äº†ï¼ˆOllamaï¼‰ï¼Œæ— éœ€è”ç½‘ï¼Œå¿«é€Ÿä¾¿æ·ï¼Œå®‰å…¨ç¨³å®šï¼å†ä¹Ÿä¸æ€• OpenAI è´¦å·è¢«å°äº†ï¼ç¿»è¯‘æ•ˆæœå¯¹æ¯”å¤§å®¶å¯ä»¥çœ‹ä¸€ä¸‹æˆªå›¾ï¼Œå¤§å®¶å¿«æ¥ä¸‹è½½ä½“éªŒä¸€ä¸‹å§ï¼ _202402
- https://twitter.com/yetone/status/1761607398819840511
- ç°åœ¨å¥½åƒè¿˜ä¸æ”¯æŒè‡ªå®šä¹‰æ¨¡å‹ï¼Ÿåªæœ‰æœ‰é™çš„å‡ ä¸ªæ¨¡å‹å¯ä¾›é€‰æ‹©ï¼Œæœ€å¥½æ˜¯æœ‰ä¸€ä¸ªæ–‡æœ¬æ¡†å¯ä»¥è‡ªå®šä¹‰è¾“å…¥
- è¿™æ˜¯Mistralå¤šå¤§çš„æ¨¡å‹ï¼Œ7Bçš„å—ï¼Ÿ
  - æ˜¯çš„

- ä¸çŸ¥é“è¿™äº›7b 13bçš„å°æ¨¡å‹å“ªä¸ªç¿»è¯‘è´¨é‡æ›´é«˜

- ## é˜¿é‡Œäº‘ç«Ÿç„¶æ”¯æŒè¿™ä¹ˆå¤šæ¨¡å‹äº†
- https://twitter.com/yihong0618/status/1746745371441967540
- http://ai.azureä¹ŸåŒ…å«äº†å¥½å¤šæ¨¡å‹ï¼Œæ˜¨å¤©æƒŠåˆ°äº†

- ## è¶Šæ¥è¶Šè§‰å¾— RAG è¿™ä¸œè¥¿æœ‰æ„æ€ã€‚
- https://twitter.com/wwwgoubuli/status/1737471851654160548
  - åŠå¹´å‰æ¥è§¦åˆ°è¿™ä¸ªè¯çš„æ—¶å€™å¼€å§‹æˆ‘è¿˜æœ‰äº›ä¸å±‘ï¼Œæœç´¢å†…å®¹æ’å…¥åˆ°æç¤ºè¯ç®—ä»€ä¹ˆå˜›ï¼Œå°å­¦äºŒå¹´çº§éƒ½èƒ½æ˜ç™½ã€‚å°¤å…¶æ˜¯çœ‹åˆ°éšä¾¿ä¸¢å‘é‡åº“éƒ½èƒ½è·‘å‡ºä¸ªä¸ƒä¸ƒå…«å…«ï¼Œè¶Šå‘è§‰å¾—è¿™ä¸ªç®€å•ã€‚
  - ä½†ç°åœ¨çœŸçš„æäº†åŠå¹´ï¼Œæˆ‘è¶Šå‘çš„è§‰å¾—è¿™æ‰æ˜¯ä¸‹ä¸€ä¸ªå¤§å¤šæ•°äººå¯ä»¥å‚ä¸çš„é£å£ã€‚å®ƒæœ‰é—¨æ§›ã€‚
- æŠ€å·§å¾ˆå¤š æ‰€ä»¥å¥½ç© ä½†é£é™©æ˜¯å¤§éƒ¨ä»½æŠ€å·§éƒ½è¢«æ¨¡å‹æä¾›å•†ç©è¿‡ï¼Œ80%éœ€æ±‚éƒ½å¯èƒ½è¢«ä»–ä»¬ç›´æ¥è¦†ç›–
  - RAGä¸å°±æ˜¯query transformation/rewrite/expanding, hybrid search, reranking, etcå—ï¼Ÿå½“ç„¶è¿˜æœ‰äº›å…¶ä»–æŠ€å·§å•¥IAGä¹‹ç±»çš„ã€‚æ•°æ®ingestionä¹Ÿæœ‰äº›æŠ€å·§ï¼Œä¸è¿‡æˆ‘çœ‹ä¸»è¦è¿˜æ˜¯åœ¨queryä¸Šã€‚ è¿™äº›å¤§éƒ¨åˆ†OAI, Baichuan, æœˆä¹‹æš—é¢å†…éƒ¨éƒ½æ¢ç´¢è¿‡äº†å§
- RAGä¸€çœ‹å°±æ˜¯ä¸€ä¸ªæœ‰é—®é¢˜çš„åŒºåŸŸï¼Œå¤§æ¨¡å‹éšæ—¶ä¸‹ä¸€æ¬¡å‡çº§å¯èƒ½å°±ä¼šæ”¹å˜æ•´ä¸ªæ¡†æ¶ï¼Œ3.5è¿˜èƒ¡è¯´å…«é“ï¼Œ4å·²ç»å¾ˆå¤šéƒ½æ˜¯æœ‰æ ¹æœ‰æ®çš„äº†
- æåˆ°æœ€åï¼Œè¿˜æ˜¯æ¸…æ´—æ•°æ®ï¼ŒRAGåªç”¨ç®€å•ç­–ç•¥è§£å†³å¤§å¤šæ•°é—®é¢˜ï¼Œå¯è§‚æµ‹ã€‚å‰ææ˜¯æ‰€æœ‰å¤æ‚ç­–ç•¥éƒ½è¦è¯•è¿‡æ‰çŸ¥é“ã€‚

- ## LangChainå¼€æºäº†AnythingLLMï¼šå¯ä»¥ä¸ä»»ä½•å†…å®¹èŠå¤©çš„ç§äºº ChatGPTï¼Œåº”è¯¥å°±æ˜¯ä»–ä»¬è‡ªå·±æ–‡æ¡£ç³»ç»Ÿç”¨çš„é‚£ä¸€å¥—ã€‚
- https://twitter.com/op7418/status/1733893368974073873
  - An efficient, customizable, and open-source enterprise-ready document chatbot solution.
  - https://github.com/Mintplex-Labs/anything-llm /MIT/js/python

- æœ‰æ²¡æœ‰è¯¦ç»†è¯´æ˜ï¼Ÿæœ€å¤§å¯ä»¥æ”¯æ’‘å¤šå¤§çš„æ–‡æ¡£ï¼Ÿ
  - åº”è¯¥æ˜¯ä¸é™å¤§å°çš„ï¼Œæ‹†å¼€å°±å¥½äº†
- è¯´æ²¡è¯´ç¡¬ä»¶éœ€æ±‚ï¼Ÿ

- ## å¤§æ¨¡å‹çš„è¿™äº› benchmark åº”è¯¥æ˜¯å…¨å®‡å®™æœ€æ²¡ç”¨çš„ benchmark äº†å§ï¼Ÿ
- https://twitter.com/yihong0618/status/1721401347533324688
- ä¹Ÿä¸æ˜¯å…¨æ²¡ç”¨ï¼Œä¹Ÿæœ‰ä¸€äº›æœ‰ç”¨çš„, å°¤å…¶ç»†åˆ†ä»»åŠ¡ä¸Šçš„ï¼Œè¿˜æ˜¯æŒºæœ‰ç”¨çš„ã€‚å½“å‰ç›¸æ¯”å…¶ä»–benchmarkï¼Œå¯æ“ä½œç©ºé—´ç¡®å®å¤§
- å…¬å¼€çš„åªèƒ½å…¨çœ‹è‡ªè§‰

- ## ä¸­æ–‡å¼€æºæ¨¡å‹è™½å¤šï¼Œæ•°æ®é›†å´å¾ˆå°‘å¼€æºã€‚
- https://twitter.com/9hills/status/1718828132046942218
  - ç›®å‰è‹±æ–‡ 7B è§„æ¨¡çš„ SOTA æ¨¡å‹æ˜¯ zephyr-7b-betaã€‚å®ƒæ”¾å¼ƒäº†è´¨é‡å‚å·®ä¸é½çš„å¼€æºæ•°æ®é›†ï¼Œä½¿ç”¨ChatGPTå’ŒGPT-4 å…¨æ–°æ ‡æ³¨äº† UltraChat å’Œ UltraFeedback æ•°æ®é›†ï¼ˆå·²å¼€æºï¼‰ã€‚æ˜¯ llama-index é¡¹ç›®å®æµ‹å‡ºæ¥å”¯ä¸€èƒ½å¤Ÿæ”¯æŒ Agent çš„å°å‚æ•°æ¨¡å‹ã€‚
- ä¸­æ–‡æ•°æ®é›†éƒ½æ˜¯æ‹¿æ¥å–é’±çš„
